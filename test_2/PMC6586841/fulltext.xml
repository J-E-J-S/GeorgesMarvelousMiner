<!DOCTYPE article PUBLIC "-//NLM//DTD JATS (Z39.96) Journal Archiving and Interchange DTD v1.2 20190208//EN" "JATS-archivearticle1.dtd"> 
<article xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink" article-type="research-article"><?properties open_access?><?DTDIdentifier.IdentifierValue -//Springer-Verlag//DTD A++ V2.4//EN?><?DTDIdentifier.IdentifierType public?><?SourceDTD.DTDName A++V2.4.dtd?><?SourceDTD.Version 2.4?><?ConverterInfo.XSLTName springer2nlmx2.xsl?><?ConverterInfo.Version 1?><front><journal-meta><journal-id journal-id-type="nlm-ta">Sci Rep</journal-id><journal-id journal-id-type="iso-abbrev">Sci Rep</journal-id><journal-title-group><journal-title>Scientific Reports</journal-title></journal-title-group><issn pub-type="epub">2045-2322</issn><publisher><publisher-name>Nature Publishing Group UK</publisher-name><publisher-loc>London</publisher-loc></publisher></journal-meta><article-meta><article-id pub-id-type="pmcid">6586841</article-id><article-id pub-id-type="publisher-id">45301</article-id><article-id pub-id-type="doi">10.1038/s41598-019-45301-0</article-id><article-categories><subj-group subj-group-type="heading"><subject>Article</subject></subj-group></article-categories><title-group><article-title>Structure-preserving visualisation of high dimensional single-cell datasets</article-title></title-group><contrib-group><contrib contrib-type="author"><name><surname>Szubert</surname><given-names>Benjamin</given-names></name><xref ref-type="aff" rid="Aff1">1</xref></contrib><contrib contrib-type="author"><name><surname>Cole</surname><given-names>Jennifer E.</given-names></name><xref ref-type="aff" rid="Aff2">2</xref></contrib><contrib contrib-type="author"><contrib-id contrib-id-type="orcid">http://orcid.org/0000-0003-1985-4914</contrib-id><name><surname>Monaco</surname><given-names>Claudia</given-names></name><xref ref-type="aff" rid="Aff2">2</xref></contrib><contrib contrib-type="author" corresp="yes"><name><surname>Drozdov</surname><given-names>Ignat</given-names></name><address><email>idrozdov@beringresearch.com</email></address><xref ref-type="aff" rid="Aff1">1</xref></contrib><aff id="Aff1"><label>1</label>Bering Limited, London, United Kingdom </aff><aff id="Aff2"><label>2</label><institution-wrap><institution-id institution-id-type="ISNI">0000 0004 1936 8948</institution-id><institution-id institution-id-type="GRID">grid.4991.5</institution-id><institution>Kennedy Institute of Rheumatology, Nuffield Department of Orthopaedics, Rheumatology and Musculoskeletal Sciences, </institution><institution>University of Oxford, </institution></institution-wrap>Oxford, OX3 7FY UK </aff></contrib-group><pub-date pub-type="epub"><day>20</day><month>6</month><year>2019</year></pub-date><pub-date pub-type="pmc-release"><day>20</day><month>6</month><year>2019</year></pub-date><pub-date pub-type="collection"><year>2019</year></pub-date><volume>9</volume><elocation-id>8914</elocation-id><history><date date-type="received"><day>31</day><month>8</month><year>2018</year></date><date date-type="accepted"><day>24</day><month>5</month><year>2019</year></date></history><permissions><copyright-statement>&#x000a9; The Author(s) 2019</copyright-statement><license license-type="OpenAccess"><license-p><bold>Open Access</bold> This article is licensed under a Creative Commons Attribution 4.0 International License, which permits use, sharing, adaptation, distribution and reproduction in any medium or format, as long as you give appropriate credit to the original author(s) and the source, provide a link to the Creative Commons license, and indicate if changes were made. The images or other third party material in this article are included in the article&#x02019;s Creative Commons license, unless indicated otherwise in a credit line to the material. If material is not included in the article&#x02019;s Creative Commons license and your intended use is not permitted by statutory regulation or exceeds the permitted use, you will need to obtain permission directly from the copyright holder. To view a copy of this license, visit <ext-link ext-link-type="uri" xlink:href="http://creativecommons.org/licenses/by/4.0/">http://creativecommons.org/licenses/by/4.0/</ext-link>.</license-p></license></permissions><abstract id="Abs1"><p id="Par1">Single-cell technologies offer an unprecedented opportunity to effectively characterize cellular heterogeneity in health and disease. Nevertheless, visualisation and interpretation of these multi-dimensional datasets remains a challenge. We present a novel framework, ivis, for dimensionality reduction of single-cell expression data. ivis utilizes a siamese neural network architecture that is trained using a novel triplet loss function. Results on simulated and real datasets demonstrate that ivis preserves global data structures in a low-dimensional space, adds new data points to existing embeddings using a parametric mapping function, and scales linearly to hundreds of thousands of cells. ivis is made publicly available through Python and R interfaces on <ext-link ext-link-type="uri" xlink:href="https://github.com/beringresearch/ivis">https://github.com/beringresearch/ivis</ext-link>.</p></abstract><kwd-group kwd-group-type="npg-subject"><title>Subject terms</title><kwd>Genomics</kwd><kwd>Computational biology and bioinformatics</kwd></kwd-group><funding-group><award-group><funding-source><institution-wrap><institution-id institution-id-type="FundRef">https://doi.org/10.13039/501100000780</institution-id><institution>European Commission (EC)</institution></institution-wrap></funding-source><award-id>HEALTH-F2-2013-602114</award-id><award-id>HEALTH-F2-2013-602114</award-id><award-id>HEALTH-F2-2013-602114</award-id><award-id>HEALTH-F2-2013-602114</award-id><principal-award-recipient><name><surname>Szubert</surname><given-names>Benjamin</given-names></name><name><surname>Cole</surname><given-names>Jennifer E.</given-names></name><name><surname>Monaco</surname><given-names>Claudia</given-names></name><name><surname>Drozdov</surname><given-names>Ignat</given-names></name></principal-award-recipient></award-group></funding-group><custom-meta-group><custom-meta><meta-name>issue-copyright-statement</meta-name><meta-value>&#x000a9; The Author(s) 2019</meta-value></custom-meta></custom-meta-group></article-meta></front><body><sec id="Sec1" sec-type="introduction"><title>Introduction</title><p id="Par2">Characterising cellular composition is crucial for defining functional heterogeneity in health and disease<sup><xref ref-type="bibr" rid="CR1">1</xref></sup>. The advent of technologies that interrogate genome-scale molecular information at single-cell resolution provides an unprecedented opportunity for systematic investigation at the level of DNA<sup><xref ref-type="bibr" rid="CR2">2</xref>,<xref ref-type="bibr" rid="CR3">3</xref></sup>, RNA<sup><xref ref-type="bibr" rid="CR4">4</xref></sup>, proteins<sup><xref ref-type="bibr" rid="CR5">5</xref></sup>, and metabolites<sup><xref ref-type="bibr" rid="CR6">6</xref></sup>. Indeed, increasing utilization of these technologies has facilitated characterisation of previously unknown cell types<sup><xref ref-type="bibr" rid="CR7">7</xref>,<xref ref-type="bibr" rid="CR8">8</xref></sup> developmental lineages<sup><xref ref-type="bibr" rid="CR9">9</xref></sup> and patterns of cellular organization<sup><xref ref-type="bibr" rid="CR10">10</xref></sup>.</p><p id="Par3">Visualisation and interpretation of single-cell experiments are underpinned by dimensionality reduction (DR) techniques. Non-linear approaches, including the t-distributed Stochastic Neighbor Embedding (t-SNE) algorithm<sup><xref ref-type="bibr" rid="CR11">11</xref></sup>, have been shown to effectively capture complex data structures, outperforming linear projection methods such as Principal Component Analysis (PCA)<sup><xref ref-type="bibr" rid="CR12">12</xref>,<xref ref-type="bibr" rid="CR13">13</xref></sup> Nevertheless, t-SNE has several limitations<sup><xref ref-type="bibr" rid="CR14">14</xref>,<xref ref-type="bibr" rid="CR15">15</xref></sup>. First, t-SNE is not robust in the presence of technical noise and tends to form spurious clusters from randomly distributed data points<sup><xref ref-type="bibr" rid="CR14">14</xref></sup>, producing misleading results that may hinder biological interpretation. Second, due to non-parametric nature of t-SNE, addition of new data points to existing embeddings is not possible<sup><xref ref-type="bibr" rid="CR11">11</xref>,<xref ref-type="bibr" rid="CR15">15</xref></sup>. Instead, t-SNE needs to be rerun on the combined dataset, which is computationally expensive and not scalable. Third, t-SNE has a time complexity of <italic>O</italic>(<italic>N</italic><sup>2</sup><italic>D</italic>) and space complexity of <italic>O</italic>(<italic>N</italic><sup>2</sup>), where <italic>N</italic> is the number of observations and <italic>D</italic> is the number of features in the data<sup><xref ref-type="bibr" rid="CR11">11</xref>,<xref ref-type="bibr" rid="CR15">15</xref>,<xref ref-type="bibr" rid="CR16">16</xref></sup>. Whilst complexity can be reduced to <italic>O</italic>(<italic>N log N</italic>) by approximating the gradient using tree-based algorithms<sup><xref ref-type="bibr" rid="CR17">17</xref></sup>, dimensionality reduction across tens of thousands of exemplars remains challenging. Finally, t-SNE preserves the local clustering structures<sup><xref ref-type="bibr" rid="CR15">15</xref></sup>, but global structures such as inter-cluster relationships and distances cannot be reliably preserved<sup><xref ref-type="bibr" rid="CR18">18</xref></sup>. As such, the biological information that may be extracted through t-SNE embeddings remains limited.</p><p id="Par4">Neural Network (NN) models have been proposed as effective non-linear DR techniques<sup><xref ref-type="bibr" rid="CR15">15</xref>,<xref ref-type="bibr" rid="CR19">19</xref>,<xref ref-type="bibr" rid="CR20">20</xref></sup>. Generally, unsupervised NNs with multiple layers are trained by optimizing a target function, whilst an intermediate layer with small cardinality serves as a low dimensional representation of the input data<sup><xref ref-type="bibr" rid="CR19">19</xref>,<xref ref-type="bibr" rid="CR21">21</xref></sup>. In this paper we introduce a scalable algorithm, ivis, which effectively captures local as well as global features of high-dimensional datasets. Additionally, ivis learns a parametric mapping from the high-dimensional space to low-dimensional embedding, facilitating seamless addition of new data points to the mapping function. Importantly, we demonstrate that ivis preserves distances in low-dimensional projections, enabling biological interpretation. We validate our method using synthetic, cytometry by time of flight (CyTOF), and scRNA-seq datasets.</p></sec><sec id="Sec2" sec-type="results"><title>Results</title><sec id="Sec3"><title>ivis benchmarks on synthetic datasets</title><p id="Par5">To demonstrate that ivis can uncover&#x000a0;the global structure of a high-dimensional dataset, we first generated three synthetic datasets - random uniform noise, Cassini problem, and Smiley dataset (Figs&#x000a0;<xref rid="Fig1" ref-type="fig">1A</xref>, <xref rid="Fig2" ref-type="fig">2A,D</xref>). The Cassini problem is a two-dimensional dataset with three clusters containing uniformly distributed data points. The smiley dataset consists of two Gaussian eyes, a trapezoid nose, and a parabola mouth with vertical Gaussian noise. Two-dimensional coordinates (x, y), were mapped to a nine-dimensional space by the transformation (x&#x02009;+&#x02009;y, x&#x02009;&#x02212;&#x02009;y, xy, x<sup>2</sup>, y<sup>2</sup>, x<sup>2</sup>y, xy<sup>2</sup>, x<sup>3</sup>, y<sup>3</sup>)<sup><xref ref-type="bibr" rid="CR15">15</xref></sup>. The nine-dimensional datasets were used as inputs to ivis and t-SNE algorithms.<fig id="Fig1"><label>Figure 1</label><caption><p>Benchmarking ivis and t-SNE on 5,000 uniformly distributed random data-points. (<bold>A</bold>) Original two-dimensional data. (<bold>B</bold>) ivis embedding of the nine-dimensional dataset. (<bold>C</bold>) t-SNE embedding of the nine-dimensional dataset.</p></caption><graphic xlink:href="41598_2019_45301_Fig1_HTML" id="d29e439"/></fig><fig id="Fig2"><label>Figure 2</label><caption><p>Benchmarking ivis and t-SNE on two synthetic datasets. (<bold>A</bold>,<bold>D</bold>) The original two-dimensional dataset consisting of 5,000 points, colored by cluster labels. (<bold>B</bold>,<bold>E</bold>) ivis embedding of the nine-dimensional dataset. (<bold>C</bold>,<bold>F</bold>) t-SNE embedding of the nine-dimensional dataset.</p></caption><graphic xlink:href="41598_2019_45301_Fig2_HTML" id="d29e467"/></fig></p><p id="Par6">Visual assessment suggests that ivis preserves random distributions of the original dataset (Fig.&#x000a0;<xref rid="Fig1" ref-type="fig">1B</xref>). However, t-SNE groups random points into multiple compact clusters with clear boundaries (Fig.&#x000a0;<xref rid="Fig1" ref-type="fig">1C</xref>). Subsequently, we assessed the capacity of ivis and t-SNE algorithms to extract inter-cluster relationships. Whilst both ivis and t-SNE uncovered the three clusters in the Cassini dataset (Fig.&#x000a0;<xref rid="Fig2" ref-type="fig">2A&#x02013;C</xref>), t-SNE did not preserve inter-cluster relationships. Additionally, increasing cluster complexity using the Smiley dataset (Fig.&#x000a0;<xref rid="Fig2" ref-type="fig">2D&#x02013;F</xref>), demonstrated that ivis preserves both the shape and relative locations of each cluster in the embedding space (Fig.&#x000a0;<xref rid="Fig2" ref-type="fig">2E</xref>). In contrast, t-SNE embeddings yielded additional spurious clusters and complete loss of all inter-cluster relationships (Fig.&#x000a0;<xref rid="Fig2" ref-type="fig">2F</xref>).</p><p id="Par7">ivis utilizes several stochastic processes - namely approximate identification of the k -nearest neighbors (KNNs) using random projection trees and random initialisation of neural network weights. As such, the low-dimensional data representation may change across multiple ivis runs. To test stability of the two-dimensional embedding, we ran ivis ten times on the Smiley benchmark dataset (Supplementary Fig.&#x000a0;<xref rid="MOESM1" ref-type="media">S2</xref>). The two-dimensional structure across all ten runs was consistently preserved. Conversely, cluster layout and organization changed drastically for each t-SNE run (Supplementary Fig.&#x000a0;<xref rid="MOESM1" ref-type="media">S3</xref>).</p></sec><sec id="Sec4"><title>Single-cell CyTOF datasets</title><p id="Par8">The capacity of ivis to uncover structure in single cell experiments was evaluated using two CyTOF datasets. First, the human BMMC and mouse bone marrow (Samusik) datasets were reduced to two ivis dimensions and cellular populations were identified using phenograph<sup><xref ref-type="bibr" rid="CR22">22</xref></sup> clustering of the two-dimensional embeddings. Phenograph identified 12 and 25, clusters in the BMMC and Samusik dataset respectively, which exhibited high concordance with manual gates (adjusted Rand Index<sub>BMMC</sub>&#x02009;=&#x02009;0.97, Fig.&#x000a0;<xref rid="Fig3" ref-type="fig">3A</xref>, adjusted Rand Index<sub>Samusik</sub>&#x02009;=&#x02009;0.45, Fig.&#x000a0;<xref rid="Fig3" ref-type="fig">3C</xref>). To establish how well ivis and t-SNE preserve global features, a Euclidean distance matrix between centroids of the manually-gated cells was created for the original data, the ivis embeddings, and the t-SNE embeddings. The level of correlation between the original distance matrix and the distance matrices in the embedding spaces was then assessed using the Mantel test (see Methods). This process was repeated for one hundred random subsamples of the data (n&#x02009;=&#x02009;10,000 cells per subsample selected without replacement) to generate a distribution of correlation values. Cluster centroid distances in the ivis space were significantly correlated with the original dataset using the Pearson&#x02019;s Correlation Coefficient (PCC) (median PCC<sub>ivis-BMMC</sub>&#x02009;=&#x02009;0.76 vs. median PCC<sub>t-SNE-BMMC</sub>&#x02009;=&#x02009;0.53, p-value &#x0226a;&#x02009;0.01, Fig.&#x000a0;<xref rid="Fig3" ref-type="fig">3B</xref>, median PCC<sub>ivis-Samusik</sub>&#x02009;=&#x02009;0.73 vs. median PCC<sub>t-SNE-Samusik</sub>&#x02009;=&#x02009;0.14, p-value &#x0226a;&#x02009;0.01, Fig.&#x000a0;<xref rid="Fig3" ref-type="fig">3D</xref>).<fig id="Fig3"><label>Figure 3</label><caption><p>Phenotypic characterisation of healthy human BMMCs. (<bold>A</bold>) ivis display of 10,000 cells from healthy BMMC benchmark data. Cells are colored by cell-type assignments established by manual gating. (<bold>B</bold>) Boxplot of Pearson&#x02019;s correlation coefficients (PCC) between centroids of manual gates in the full-dimensional data and centroids of those same points in either ivis or t-SNE embedding (median PCC<sub>ivis</sub>&#x02009;=&#x02009;0.76, median PCC<sub>t-SNE</sub>&#x02009;=&#x02009;0.53). (<bold>C</bold>) ivis display of all cells from the Samusik dataset. Cells are colored by cell-type assignments established by manual gating. (<bold>D</bold>) Boxplot of PCCs between centroids of manual gates in the full-dimensional data and centroids of those same points in either ivis or t-SNE embedding (median PCC<sub>ivis</sub>&#x02009;=&#x02009;0.73, median PCC<sub>t-SNE</sub>&#x02009;=&#x02009;0.13).</p></caption><graphic xlink:href="41598_2019_45301_Fig3_HTML" id="d29e571"/></fig></p><p id="Par9">The healthy human BMMC and the Samusik datasets are well-characterised benchmarks for dimensionality reduction problems, mainly due to the highly informative features (cellular markers) within each dataset. In practice, feature selection is an integral part of the discovery process and often CyTOF datasets comprise both informative as well as noisy markers. To assess how well the&#x000a0;ivis methodology performs on a typical discovery dataset, we applied the ivis algorithm to 21 markers in myeloid cells collected from aortas of Apoe<sup>&#x02212;/&#x02212;</sup> mice (see Methods). Two-dimensional ivis embedding preserved phenograph-derived clusters of the full dataset (Fig.&#x000a0;<xref rid="Fig4" ref-type="fig">4A</xref>), whilst better retaining the global inter-cluster distances as compared to t-SNE (median PCC<sub>ivis</sub>&#x02009;=&#x02009;0.25 vs. median PCC<sub>t-SNE</sub>&#x02009;=&#x02009;0.18, t-statistic&#x02009;=&#x02009;4.50, p-value &#x0226a;&#x02009;0.01, Fig.&#x000a0;<xref rid="Fig4" ref-type="fig">4B</xref>).<fig id="Fig4"><label>Figure 4</label><caption><p>Visualisation of myeloid cells from ApoE<sup>&#x02212;/&#x02212;</sup> mice. (<bold>A</bold>) Two-dimensional ivis embedding of a random sub-sample of 10,000 cells. Each cell is coloured according to a unique cluster identified by the application of phenograph algorithm to the full 21-dimensional dataset. (<bold>B</bold>) Boxplot of Pearson&#x02019;s correlation coefficients between centroids of gates in the full-dimensional data and centroids of those same points in both ivis and t-SNE embeddings across one-hundred random subsamples of the data. Median PCC<sub>ivis</sub>&#x02009;=&#x02009;0.25 vs. median PCC<sub>t-SNE</sub>&#x02009;=&#x02009;0.18. (<bold>C</bold>) Heatmap overlay that displays how marker expression and intensity profiles express in monocyte and macrophage populations.</p></caption><graphic xlink:href="41598_2019_45301_Fig4_HTML" id="d29e617"/></fig></p></sec><sec id="Sec5"><title>Single-cell RNAseq datasets</title><p id="Par10">Given the relatively low dimensionality of CyTOF datasets (typically tens of features), we investigated whether the ivis algorithm is also applicable to scRNA-seq experiments that contain thousands of features. Due to the high-throughput nature of these datasets, we used PCA as a noise-reducing pre-processing step<sup><xref ref-type="bibr" rid="CR12">12</xref></sup>, projecting all cells to 50 Principal Components prior to embedding with ivis.</p><p id="Par11">First, we assessed the scalability of ivis using 1.3 million cells from the 10X genomics mouse dataset<sup><xref ref-type="bibr" rid="CR23">23</xref></sup>. The scikit-learn Barnes-Hut t-SNE implementation did not finish analysis within 24&#x02009;hours and was terminated. Conversely, we were able to obtain meaningful ivis embeddings without subsampling in &#x0003c;30&#x02009;minutes (Fig.&#x000a0;<xref rid="Fig5" ref-type="fig">5A</xref>).<fig id="Fig5"><label>Figure 5</label><caption><p>Structure-preserving dimensionality reduction of single cell transcriptomes using ivis. (<bold>A</bold>) The 10x genomics mouse brain dataset (n&#x02009;=&#x02009;1.3 million cells). Contours represent dense regions in the embedding space. (<bold>B</bold>) The hippocampus dataset (n&#x02009;=&#x02009;1,402 cells. (<bold>C</bold>) The melanoma dataset (n&#x02009;=&#x02009;4,645 cells). (<bold>D</bold>) Mouse retinal bipolar neural cells (n&#x02009;=&#x02009;27,499 cells) In all cases, each cell is colored by its cell type.</p></caption><graphic xlink:href="41598_2019_45301_Fig5_HTML" id="d29e656"/></fig></p><p id="Par12">Projection of the hippocampus dataset into two-dimensional ivis space revealed distinct nuclei clusters that corresponded to known cell types and anatomical regions in the hippocampus (Fig.&#x000a0;<xref rid="Fig5" ref-type="fig">5B</xref>). Importantly, ivis captured the flow of sensory information within the hippocampus from the dentate gyrus (DG) to CA3 and CA1 nuclei, as exemplified by the mutual cell proximities in these clusters. Additionally, functional dissimilarity between CA2 and CA3 was highlighted through more distal positioning of these nuclei in the embedding space.</p><p id="Par13">Similarly, analysis of intra-tumor heterogeneity in metastatic melanoma revealed that normal and malignant cells formed distinct clusters (Fig.&#x000a0;<xref rid="Fig5" ref-type="fig">5C</xref>). Interestingly, normal immune cells, such as T cells, B cells, and macrophages originating from different individuals, were grouped together by cell type rather than origin. Importantly, Cancer Associated Fibroblasts (CAF) were found to be adjacent to both normal and malignant cells.</p><p id="Par14">Finally, ivis embeddings of the retinal bipolar dataset showed clear segregation between non-bipolar (amacrine cells [AC], photoreceptors Mueller glia [MG]) and bipolar (rod and cone bipolar cells) cells (Fig.&#x000a0;<xref rid="Fig5" ref-type="fig">5D</xref>). Furthermore, the &#x0201c;off&#x0201d; cone bipolar cells (BC1A, BC1B, BC2, BC3A, BC3B, BC4) and the &#x02018;on&#x02019; cone bipolar cells (BC5A-D, BC6, BC7, BC8/9) were localised to two distinct regions of the embedding space, exhibiting a direct correlation between biological function and embedding proximities. Finally, doublets and contaminants (2.4% of the dataset) were reliably grouped together, despite being a low-frequency population.</p></sec><sec id="Sec6"><title>Learning embeddings for single-cell datasets</title><p id="Par15">To assess whether our algorithm could be used to extrapolate embeddings to out-of-sample data points, the ivis model was trained on randomized subsets of the BMMC dataset (n&#x02009;=&#x02009;1,000&#x02013;30,000 rows in intervals of 1,000). This process was repeated ten times to generate a distribution for each subset size (Fig.&#x000a0;<xref rid="Fig6" ref-type="fig">6A</xref>). Next, a random forest classifier was used to learn the mapping between two-dimensional embeddings and the corresponding manually defined cell populations. Finally, new two-dimensional embeddings were generated for the out-of-sample data points using ivis projections and predicted cell population labels were extracted using the pre-trained random forest. The accuracy of the random forest classifier increased with subsample size (Fig.&#x000a0;<xref rid="Fig6" ref-type="fig">6A</xref>). Interestingly, the worst performing run (subsample size of 1,000) still achieved a classification accuracy of 0.91 on out-of-sample predictions, despite using less than 1% of the 104,184 data-points present in the dataset.<fig id="Fig6"><label>Figure 6</label><caption><p>Random forest classifier performance on ivis embeddings inferred from independent subsets of healthy human BMMC data. (<bold>A</bold>) Scatterplot depicting accuracy of a random forest classifier when trained on embedded subsets of varying size. The experiments for each subset size were repeated ten times. (<bold>B</bold>) Confusion matrix for a single random forest classifier trained on a subset of 10,000 embedded data-points and validated on the remaining 94,184 points.</p></caption><graphic xlink:href="41598_2019_45301_Fig6_HTML" id="d29e697"/></fig></p></sec><sec id="Sec7"><title>Sensitivity to hyperparameters</title><p id="Par16">ivis has several hyperparameters, such as margin (<italic>m</italic> in equation (<xref rid="Equ2" ref-type="">2</xref>)), <italic>k</italic> (the number of nearest neighbors for positive and negative point selection), and loss function. We sought to evaluate whether ivis is resistant to variations in these values and subsequently identify sensible defaults for DR problems.</p><p id="Par17">Systematically increasing <italic>m</italic> for three datasets (Cassini, Smiley, and BMMC, Supplementary Figs 4&#x02013;6 in an interval (0, 1000] demonstrated that ivis embeddings with <italic>m</italic> in [0.1, 500] retained the shape of the original data. However, for <italic>m</italic>&#x02009;&#x0003e;&#x02009;100, we noted increasing information loss in the embedding space, manifested through highly correlated ivis dimensions (Supplementary Fig.&#x000a0;<xref rid="MOESM1" ref-type="media">S4H&#x02013;J</xref>, Supplementary Fig.&#x000a0;<xref rid="MOESM1" ref-type="media">S6G&#x02013;J</xref>). Interestingly, for <italic>m</italic>&#x02009;&#x0003e;&#x02009;500 we observed greater incidence of exploding gradients resulting in uninformative embeddings (Supplementary Fig.&#x000a0;<xref rid="MOESM1" ref-type="media">S5I</xref>).</p><p id="Par18">To evaluate the effects of <italic>k</italic> on embedding accuracy, we subsampled the BMMC and Samusik datasets with subsample sizes in {1000, 2500, 5000, 10000, 20000, 50000} with <italic>k</italic> in {2, 4, 8, 16, 32, 64, 128, 256, 512, 1024, 2048, 4096}. For each combination of subsample and <italic>k</italic> we generated ivis embeddings which were used to train a random forest classifier that mapped embeddings to manual gates. Subsequently, for the remaining out-of-sample cells, we predicted ivis coordinates and corresponding cellular populations. Accuracy was assessed by comparing predicted population labels with manual gates. Although prediction accuracies were generally stable for 16&#x02009;&#x0003c;&#x02009;k&#x02009;&#x0003c;&#x02009;256 irrespective of subsample size, we observed that setting <italic>k</italic> to 0.5&#x02013;1% of the number of observations consistently resulted in greater accuracies (Supplementary Fig.&#x000a0;<xref rid="MOESM1" ref-type="media">S7</xref>).</p><p id="Par19">Finally, we assessed whether our variant of the triplet-loss function (pn loss, see Methods) presents an effective alternative to the conventional triplet loss and softmax-ratio loss functions<sup><xref ref-type="bibr" rid="CR24">24</xref></sup>. For each subsample multiple loss functions were used to generate ivis embeddings, which were subsequently used to train a random forest classifier that mapped embeddings to manual gates. For the remaining out-of-sample cells (held out test set), we obtained predicted ivis embeddings and the corresponding cellular populations. Accuracy was assessed by comparing predicted population labels with manual gates. Overall, pn loss with a Euclidean distance metric outperformed other loss functions (Table&#x000a0;<xref rid="Tab1" ref-type="table">1</xref>). However, the Manhattan distance metric appeared to perform slightly better on the smallest subset (n&#x02009;=&#x02009;1,000 data points).<table-wrap id="Tab1"><label>Table 1</label><caption><p>Out-of-sample accuracies of ivis embeddings generated using multiple loss and distance functions.</p></caption><table frame="hsides" rules="groups"><thead><tr><th rowspan="2">Loss</th><th colspan="4">Subsample</th></tr><tr><th>n&#x02009;=&#x02009;1,000</th><th>n&#x02009;=&#x02009;5,000</th><th>n&#x02009;=&#x02009;10,000</th><th>n&#x02009;=&#x02009;15,000</th></tr></thead><tbody><tr><td>Euclidean PN</td><td>0.94</td><td><bold>0</bold>.<bold>96</bold></td><td><bold>0</bold>.<bold>97</bold></td><td><bold>0</bold>.<bold>97</bold></td></tr><tr><td>Euclidean</td><td>0.93</td><td>0.95</td><td>0.95</td><td>0.95</td></tr><tr><td>Manhattan PN</td><td><bold>0</bold>.<bold>95</bold></td><td>0.96</td><td>0.96</td><td>0.96</td></tr><tr><td>Manhattan</td><td>0.93</td><td>0.95</td><td>0.96</td><td>0.96</td></tr><tr><td>Chebyshev PN</td><td>0.93</td><td>0.96</td><td>0.97</td><td>0.97</td></tr><tr><td>Chebyshev</td><td>0.92</td><td>0.95</td><td>0.96</td><td>0.96</td></tr><tr><td>Softmax Ratio PN</td><td>0.93</td><td>0.95</td><td>0.94</td><td>0.93</td></tr><tr><td>Softmax Ratio</td><td>0.9</td><td>0.92</td><td>0.96</td><td>0.93</td></tr></tbody></table></table-wrap></p></sec></sec><sec id="Sec8" sec-type="discussion"><title>Discussion</title><p id="Par20">In this work we present a novel algorithm for visualisation and interpretation of single-cell datasets. Our approach effectively captures higher orders of structure in a low-dimensional space by minimising a triplet-loss function (see Methods, Supplementary Fig.&#x000a0;<xref rid="MOESM1" ref-type="media">S1</xref>).</p><p id="Par21">Our analysis using a synthetic dataset demonstrated that ivis is robust in the presence of uniform random noise. Given that high-throughput experiments are frequently subject to technical outliers<sup><xref ref-type="bibr" rid="CR25">25</xref>&#x02013;<xref ref-type="bibr" rid="CR28">28</xref></sup>, we believe that ivis offers a realistic data representation framework. Although t-SNE is often a method of choice for visualization of single cell experiments<sup><xref ref-type="bibr" rid="CR13">13</xref>,<xref ref-type="bibr" rid="CR29">29</xref></sup>, we demonstrated that in the presence of random noise, the algorithm tends to yield spurious clusters with clean boundaries, potentially hindering accurate interpretation and discovery (Fig.&#x000a0;<xref rid="Fig1" ref-type="fig">1C</xref>). This phenomenon has been recapitulated in other real-world, as well as synthetic, datasets<sup><xref ref-type="bibr" rid="CR14">14</xref>,<xref ref-type="bibr" rid="CR15">15</xref></sup> and may be a general feature of algorithms that aim to preserve the pairwise (dis)similarities (e.g. LargeVis)<sup><xref ref-type="bibr" rid="CR14">14</xref></sup>.</p><p id="Par22">Using two synthetic and three CyTOF datasets, we have shown that ivis reduces dimensionality whilst preserving the &#x0201c;global&#x0201d; structure in a dataset. For example, in the synthetic Smiley dataset, ivis preserved both the shape and relative locations of each cluster in the embedding space. In contrast, t-SNE embedding resulted in emergence of spurious clusters and complete loss of overall inter-cluster relationships (Fig.&#x000a0;<xref rid="Fig2" ref-type="fig">2F</xref>). Furthermore, in CyTOF experiments, ivis embeddings exhibited greater degrees of correlation with the original multi-dimensional data structures compared to t-SNE (Figs&#x000a0;<xref rid="Fig3" ref-type="fig">3</xref>, <xref rid="Fig4" ref-type="fig">4</xref>). This is consistent with the capacity of t-SNE to effectively characterize the local neighborhood of each point in the original space and low-dimensional embedding at the expense of overall structure<sup><xref ref-type="bibr" rid="CR30">30</xref></sup>. Given that ivis samples positive and negative data-points for each triplet, from the KNN vector and outside the KNN vector respectively, the choice of triplets at the time of training captures both local and global information of the data (see Methods).</p><p id="Par23">Furthermore, structure-preserving properties of the ivis algorithm can greatly enhance discovery in single-cell datasets. For instance, ivis embeddings of the hippocampus dataset captured distinct nuclei clusters that correspond to known cell types and anatomical regions. Importantly, embedding regions of DG, CA3, and CA1 nuclei correctly reflect the flow of sensory information in the hippocampus<sup><xref ref-type="bibr" rid="CR31">31</xref></sup>, suggesting that ivis is able to capture phenotypical variation in the data. In the metastatic melanoma dataset, malignant cells localised to the same ivis region, forming cluster based on the patient origin, whilst healthy immune cells from different patients clustered together by cell types. Importantly, CAF cells were localised adjacent to the malignant cells, further highlighting the phenotype-preserving characteristic of the ivis algorithm.</p><p id="Par24">Single-cells experiments are increasingly used to define molecular characteristics and clinical outcomes in conditions such as cancer<sup><xref ref-type="bibr" rid="CR32">32</xref>&#x02013;<xref ref-type="bibr" rid="CR34">34</xref></sup> and atherosclerosis<sup><xref ref-type="bibr" rid="CR35">35</xref></sup>. As these technologies become further integrated with precision medicine approaches, parametric methods that learn to generalize embeddings, without the need to be retrained, will become essential for scalable prediction of complex outcomes including response to treatment and patient survival<sup><xref ref-type="bibr" rid="CR36">36</xref></sup>. We demonstrated that ivis requires as little as 1,000 cells (1% of the full dataset) to reliably (&#x0003e;90% accuracy) embed an out-of-sample dataset with 100,000 cells. Although conventional deep neural network approaches may require tens of thousands of exemplars to learn a generalizable set of parameters<sup><xref ref-type="bibr" rid="CR37">37</xref>,<xref ref-type="bibr" rid="CR38">38</xref></sup>, ivis employs a siamese neural network architecture<sup><xref ref-type="bibr" rid="CR39">39</xref></sup> that learns to discriminate between similar and dissimilar points without imposing strong priors. A variation of our approach has been previously applied to solve the one-shot learning problem for image recognition in which a network must correctly make predictions given only a single example of each new class<sup><xref ref-type="bibr" rid="CR40">40</xref></sup>.</p><p id="Par25">Whilst t-SNE remains a popular DR and visualization method, several algorithms have been introduced to improve either its computational performance or interpretability. The SIMLR algorithm improves upon t-SNE by learning a similarity matrix between cells, which is then used as an input to t-SNE for dimensionality reduction<sup><xref ref-type="bibr" rid="CR41">41</xref></sup>. However, this approach is computationally expensive as the objective function involves an expensive multiplication of an N&#x02009;&#x000d7;&#x02009;N kernel matrix and N&#x02009;&#x000d7;&#x02009;N similarity matrix, where N is the number of cells<sup><xref ref-type="bibr" rid="CR15">15</xref></sup>. Parametric t-SNE<sup><xref ref-type="bibr" rid="CR11">11</xref></sup> learns a parametric mapping from the high-dimensional space to a lower dimensional embedding. The method is generalizable to out-of-sample data and computes a loss function that minimizes Kullback-Leibler (KL) divergence between the point distributions in the original and the low-dimensional space. However, this approach does not preserve global distances and only local structures are captured by taking advantage of KL-divergence&#x02019;s asymmetric properties<sup><xref ref-type="bibr" rid="CR42">42</xref></sup>.</p><p id="Par26">More recently, the scvis algorithm was introduced to facilitate interpretable dimensionality reduction for single-cell experiments<sup><xref ref-type="bibr" rid="CR15">15</xref></sup>. The algorithm utilizes a Variational Autoencoder (VAE) with an additional regularization term that encourages the formation of gaps between clusters of data points. scvis was shown to preserve global structure of the high-dimensional measurements. The algorithm relies on obtaining the pairwise distances between two cells in a mini-batch during the training process, which takes <italic>O</italic>(<italic>TN</italic><sup>2</sup><italic>D</italic>&#x02009;+&#x02009;<italic>TN</italic><sup>2</sup><italic>d</italic>) time, where <italic>N</italic> is the mini-batch size, <italic>D</italic> is the dimensionality of the input data, <italic>d</italic> is the dimensionality of the low-dimensional latent variables, and <italic>T</italic> is the number of iterations. Conversely, ivis exhibits a linear time complexity <italic>O</italic>(<italic>N</italic>), where N is the dimensionality of the input data, due to selection of triplets without the need to pre-compute pairwise-distances (Supplementary Fig.&#x000a0;<xref rid="MOESM1" ref-type="media">S9</xref>).</p><p id="Par27">Finally, the DeepCyTOF framework<sup><xref ref-type="bibr" rid="CR43">43</xref></sup> contains a denoising autoencoder component designed to handle missing data in CyTOF experiments. However, the framework facilitates semi-automatic gating and does not focus on data visualization.</p><p id="Par28">In conclusion, we have developed a robust dimensionality reduction framework that retains global and local features of single-cell experiments in a low-dimensional space and is robust to hyperparameter settings. We demonstrate that ivis scales seamlessly to hundreds of thousands of cells, facilitating visualization and biological interpretation of complex features. As single-cell technologies continue to proliferate, we anticipate that ivis will offer a powerful computational approach for data visualization and discovery.</p></sec><sec id="Sec9"><title>Methods</title><sec id="Sec10"><title>Neural network architecture and training</title><p id="Par29">Structure-preserving dimensionality reduction is achieved using siamese neural networks (SNNs)<sup><xref ref-type="bibr" rid="CR40">40</xref></sup>. SNNs are a class of neural network that employ a unique architecture to naturally rank similarity between inputs. The ivis SNN consists of three identical base networks (Supplementary Fig.&#x000a0;<xref rid="MOESM1" ref-type="media">S1A</xref>); each base network has three dense layers of 128 neurons followed by a final embedding layer. The size of the embedding layer reflects the desired dimensionality of outputs; results presented in this work utilize a final embedding layer with two neurons.</p><p id="Par30">The layers preceding the embedding layer use the SELU activation function,<disp-formula id="Equ1"><label>1</label><alternatives><tex-math id="M1">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$selu(x)=\lambda \{\begin{array}{lc}x &#x00026; if\,x &#x0003e; 0\\ \alpha {e}^{x}-\alpha  &#x00026; if\,x\le 0\end{array}$$\end{document}</tex-math><mml:math id="M2" display="block"><mml:mi>s</mml:mi><mml:mi>e</mml:mi><mml:mi>l</mml:mi><mml:mi>u</mml:mi><mml:mrow><mml:mo stretchy="true">(</mml:mo><mml:mi>x</mml:mi><mml:mo stretchy="true">)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mi>&#x003bb;</mml:mi><mml:mrow><mml:mo stretchy="true">{</mml:mo><mml:mrow><mml:mtable><mml:mtr><mml:mtd columnalign="left"><mml:mi>x</mml:mi></mml:mtd><mml:mtd><mml:mrow><mml:mi>i</mml:mi><mml:mi>f</mml:mi><mml:mspace width=".20em"/><mml:mi>x</mml:mi><mml:mo>&#x0003e;</mml:mo><mml:mn>0</mml:mn></mml:mrow></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:mrow><mml:mi>&#x003b1;</mml:mi><mml:msup><mml:mrow><mml:mi>e</mml:mi></mml:mrow><mml:mi>x</mml:mi></mml:msup><mml:mo>&#x02212;</mml:mo><mml:mi>&#x003b1;</mml:mi></mml:mrow></mml:mtd><mml:mtd><mml:mrow><mml:mi>i</mml:mi><mml:mi>f</mml:mi><mml:mspace width=".20em"/><mml:mi>x</mml:mi><mml:mo>&#x02264;</mml:mo><mml:mn>0</mml:mn></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:mrow></mml:mrow></mml:math><graphic xlink:href="41598_2019_45301_Article_Equ1.gif" position="anchor"/></alternatives></disp-formula>which gives the network a self-normalizing property<sup><xref ref-type="bibr" rid="CR44">44</xref></sup>. The values for &#x003b1; and &#x003bb; were set to 1.6733 and 1.0507 respectively<sup><xref ref-type="bibr" rid="CR44">44</xref></sup>. The weights for these layers are randomly initialized with the LeCun normal distribution. The embedding layers use a linear activation and have their weights initialized using Glorot&#x02019;s uniform distribution.</p><p id="Par31">To regularize the network and prevent over-fitting, each dense layer is interleaved by Alpha Dropout layers with a dropout rate of 0.1; these layers randomly set a fraction of input units to 0 at each update, but are designed to work with SELU to maintain the property of self-normalization by maintaining the mean and variance of inputs.</p><p id="Par32">The loss function used to train the network is a variant of the standard triplet loss function<sup><xref ref-type="bibr" rid="CR41">41</xref>,<xref ref-type="bibr" rid="CR45">45</xref></sup>:<disp-formula id="Equ2"><label>2</label><alternatives><tex-math id="M3">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${L}_{tri}(\theta )={[\sum _{a,p,n}{D}_{a,p}-min({D}_{a,n},{D}_{p,n})+m]}_{+}$$\end{document}</tex-math><mml:math id="M4" display="block"><mml:msub><mml:mrow><mml:mi>L</mml:mi></mml:mrow><mml:mrow><mml:mi>t</mml:mi><mml:mi>r</mml:mi><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mi>&#x003b8;</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>=</mml:mo><mml:msub><mml:mrow><mml:mo stretchy="true">[</mml:mo><mml:mrow><mml:munder><mml:mo>&#x02211;</mml:mo><mml:mrow><mml:mi>a</mml:mi><mml:mo>,</mml:mo><mml:mi>p</mml:mi><mml:mo>,</mml:mo><mml:mi>n</mml:mi></mml:mrow></mml:munder><mml:msub><mml:mrow><mml:mi>D</mml:mi></mml:mrow><mml:mrow><mml:mi>a</mml:mi><mml:mo>,</mml:mo><mml:mi>p</mml:mi></mml:mrow></mml:msub><mml:mo>&#x02212;</mml:mo><mml:mi>m</mml:mi><mml:mi>i</mml:mi><mml:mi>n</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mrow><mml:mi>D</mml:mi></mml:mrow><mml:mrow><mml:mi>a</mml:mi><mml:mo>,</mml:mo><mml:mi>n</mml:mi></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mrow><mml:mi>D</mml:mi></mml:mrow><mml:mrow><mml:mi>p</mml:mi><mml:mo>,</mml:mo><mml:mi>n</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">)</mml:mo><mml:mo>+</mml:mo><mml:mi>m</mml:mi></mml:mrow><mml:mo stretchy="true">]</mml:mo></mml:mrow><mml:mrow><mml:mo>+</mml:mo></mml:mrow></mml:msub></mml:math><graphic xlink:href="41598_2019_45301_Article_Equ2.gif" position="anchor"/></alternatives></disp-formula>where <italic>a</italic>, <italic>p</italic>, and <italic>n</italic> correspond to anchor, positive, and negative points respectively, <italic>D</italic> is the Euclidean distance, and <italic>m</italic> is the margin. The Euclidean distance <italic>D</italic> (3) reflects similarity between points <italic>a</italic> and <italic>b</italic> in the embedding space.<disp-formula id="Equ3"><label>3</label><alternatives><tex-math id="M5">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${D}_{a,b}=\sqrt{\sum _{i=1}^{n}{({a}_{i}-{b}_{i})}^{2}}$$\end{document}</tex-math><mml:math id="M6" display="block"><mml:msub><mml:mrow><mml:mi>D</mml:mi></mml:mrow><mml:mrow><mml:mi>a</mml:mi><mml:mo>,</mml:mo><mml:mi>b</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:msqrt><mml:mrow><mml:munderover><mml:mo>&#x02211;</mml:mo><mml:mrow><mml:mi>i</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mi>n</mml:mi></mml:munderover><mml:msup><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mrow><mml:mi>a</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>&#x02212;</mml:mo><mml:msub><mml:mrow><mml:mi>b</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mn>2</mml:mn></mml:msup></mml:mrow></mml:msqrt></mml:math><graphic xlink:href="41598_2019_45301_Article_Equ3.gif" position="anchor"/></alternatives></disp-formula></p><p id="Par33">Although other distance metrics can be used, the Euclidean distance consistently outperforms other approaches and may be more interpretable from a biological standpoint (Table&#x000a0;<xref rid="Tab1" ref-type="table">1</xref>). Our implementation of the triplet loss function (pn loss) trains the network to satisfy the constraints of each triplet by simultaneously minimizing the Euclidean distance between the <italic>anchor</italic> (a point of interest) and the <italic>positive</italic> exemplar (a point similar to the Anchor) while maximizing the distance between the <italic>anchor</italic> and the <italic>negative</italic> exemplar (a point that is different from the anchor) (Supplementary Fig.&#x000a0;<xref rid="MOESM1" ref-type="media">S1B</xref>). This triplet constraint is said to be satisfied if the anchor point is closer to the positive point than to the negative point by a margin <italic>m</italic>. The pn loss function also takes into account the distance between the positive and the negative point by requiring the anchor and positive to be closer than the minimum between the anchor positive distance and the positive negative distance. This leads to a more robust loss function that improves separability in the embedding space (Supplementary Fig.&#x000a0;<xref rid="MOESM1" ref-type="media">S8</xref>) and avoids calculation of pairwise distances across a batch.</p><p id="Par34">The triplet sampling procedure is as follows. Each triplet sampled from the dataset is made up of an anchor, a positive point that is similar to the anchor, and a negative point that is dissimilar to the anchor. The <italic>k-</italic>nearest neighbors (KNNs)&#x000a0;are retrieved for each point in the dataset and a neighbor&#x000a0;is randomly selected to be the positive example in the triplet. A random data-point outside of the <italic>k-</italic>nearest neighbors&#x000a0;is used as the negative example. Setting <italic>k</italic> to an integer value between 0.5% and 1% of the number of observations appears to produce the most accurate embeddings (Supplementary Fig.&#x000a0;<xref rid="MOESM1" ref-type="media">S7</xref>) The triplets&#x000a0;are generated dynamically during training, ensuring that each epoch contains different sets of triplets that reflect both local and global information of the data. The KNNs&#x000a0;are estimated for each point using random projection trees implemented in the Annoy system<sup><xref ref-type="bibr" rid="CR46">46</xref></sup>.</p><p id="Par35">The SNN was trained on mini-batches of size 128 for 1000 epochs using the Adam optimizer function with a learning rate of 0.001 and standard parameters (<inline-formula id="IEq1"><alternatives><tex-math id="M7">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${\beta }_{1}=0.9,{B}_{2}=0.999$$\end{document}</tex-math><mml:math id="M8"><mml:msub><mml:mrow><mml:mi>&#x003b2;</mml:mi></mml:mrow><mml:mrow><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mn>0.9</mml:mn><mml:mo>,</mml:mo><mml:msub><mml:mrow><mml:mi>B</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mn>0.999</mml:mn></mml:math><inline-graphic xlink:href="41598_2019_45301_Article_IEq1.gif"/></alternatives></inline-formula>). Training was halted early if the loss failed to decrease over 50 consecutive epochs.</p></sec><sec id="Sec11"><title>Performance assessment</title><p id="Par36">To quantitate the degree to which ivis and t-SNE embeddings preserve the global structure of the data, we first cluster the original data, obtaining cluster centroids (average cluster expression vectors) and compute the inter-centroid distance matrix. Clusters are obtained either by using manual gating information or by applying the phenograph algorithm<sup><xref ref-type="bibr" rid="CR22">22</xref></sup> in cases where gold-standard cluster assignments are not provided. In all cases, phenograph clustering was applied using default hyperparameters. Next, we embed high-dimensional datasets into two-dimensional space using either ivis or t-SNE and calculate the distance matrix between cluster centroids within these embeddings. We then measure the Pearson Correlation Coefficient (PCC), with respective p-values, between centroid distance matrices in the original and embedding spaces using the Mantel test. This process was repeated on one hundred random subsamples of the dataset to generate a distribution of correlation values for both the ivis and t-SNE embeddings. Subsampling was carried out without replacement. Means of each distribution were compared using a two-tailed Student&#x02019;s <italic>t</italic>-test.</p></sec><sec id="Sec12"><title>Learning a mapping function</title><p id="Par37">To investigate whether a subset of cells is sufficient to extrapolate ivis embeddings to an out-of-sample dataset, we generated ivis coordinates for multiple small subsample of the dataset. All subsampling was performed without replacement. A supervised random forest classifier was then trained on the subset embeddings and respective cluster assignments. Subsequently, the ivis model was used to predict embeddings on out-of-sample data and the random forest classifier was used to infer the class of these embeddings. Classifier performance metrics on all out-of-sample predictions were subsequently obtained.</p></sec><sec id="Sec13"><title>Computational Complexity Analysis</title><p id="Par38">To test the scalability of ivis, synthetic datasets of increasing size were generated and the required processing time to generate the ivis embeddings was measured. The synthetic datasets were 32-dimensional, with the number of rows doubling each iteration. The scikit-learn implementation of the Barnes-Hut t-SNE algorithm was also used to embed the datasets. All experiments were run on a server equipped with 32GB RAM and an Intel Xeon E5-2630 v3 processer with a clock speed of 2.40&#x02009;GHz, using 12 of the 16 available logical threads.</p></sec><sec id="Sec14"><title>Single cell datasets</title><sec id="Sec15"><title>CyTOF</title><p id="Par39">Three datasets were used for CyTOF evaluation. First, a 32-dimensional dataset consisting of protein expression levels of healthy human bone marrow mononuclear cells (BMMCs) from two healthy individuals<sup><xref ref-type="bibr" rid="CR22">22</xref></sup>. Second, a 21-dimensional dataset of myeloid cell events from aortas of apolipoprotein E-deficient (ApoE<sup>&#x02212;/&#x02212;</sup>) mice fed either a chow or a high fat diet<sup><xref ref-type="bibr" rid="CR47">47</xref></sup>.</p><p id="Par40">The Samusik dataset<sup><xref ref-type="bibr" rid="CR48">48</xref></sup> is a 39-dimensional data set, consisting of 10 replicate bone marrow samples from C57BL/6J mice (samples from 10 different mice). Manually gated cell population labels were available for 24 immune cell populations. Cells not assigned to any population by manual gating were excluded from analysis.</p><p id="Par41">In all cases, the&#x000a0;arcsinh transform (scale factor 5) was applied to the raw FCS files<sup><xref ref-type="bibr" rid="CR49">49</xref></sup>.</p></sec><sec id="Sec16"><title>scRNA-seq</title><p id="Par42">Four scRNA-seq datasets were included in this study. All data was downloaded from the single-cell portal<sup><xref ref-type="bibr" rid="CR50">50</xref></sup>. For all the scRNA-seq datasets, we used PCA (as a noise-reduction preprocessing step<sup><xref ref-type="bibr" rid="CR12">12</xref></sup>) to project the cells into a 50-dimensional space and used the projected coordinates in the 50-dimensional space as inputs to ivis<sup><xref ref-type="bibr" rid="CR15">15</xref></sup>.</p><p id="Par43">The 10X Genomics neural cell dataset consists of 1,306,127 cells from cortex, hippocampus, and subventricular zones of two E18 C57BL/6 mice<sup><xref ref-type="bibr" rid="CR23">23</xref></sup>. The cells were sequenced on 11 Illumina Hiseq. 4000 machines to produce 98&#x02009;bp reads<sup><xref ref-type="bibr" rid="CR22">22</xref></sup>.</p><p id="Par44">The adult mouse hippocampus consists of 1,402 single nuclei from hippocampal anatomical sub-regions (DG, CA1, CA2, and CA3), including enrichment of genetically-tagged lowly abundant GABAergic neurons<sup><xref ref-type="bibr" rid="CR51">51</xref></sup>. The dataset contains high-quality outputs across animal age groups (including 2 years old mice), detecting 5,100 expressed genes per nucleus on average.</p><p id="Par45">The melanoma dataset monitors expression of 4,645 cells isolated from 19 metastatic melanoma patients<sup><xref ref-type="bibr" rid="CR52">52</xref></sup>. The cDNAs from each cell were sequenced by an Illumina NextSeq. 500 instrument to 30&#x02009;bp pair-end reads with a median of ~150,000 reads per cell. The expression of each gene (23,686 genes in total) is quantified by log2 (TPM/10&#x02009;+&#x02009;1)<sup><xref ref-type="bibr" rid="CR15">15</xref></sup>.</p><p id="Par46">The bipolar dataset consists of 27,499 mouse retinal bipolar neural cells from a transgenic mouse interrogated using low-coverage (median depth of 8,200 mapped reads per cell) sequencing<sup><xref ref-type="bibr" rid="CR12">12</xref></sup>. The dataset comprises of 15 clusters. Fourteen of these were assigned to bipolar cells and one cluster comprised of Mueller glia cells. These 15 clusters account for 96% of all the 27,499 cells. Doublets and contaminants (669 cells) account for 2.4% of all cells<sup><xref ref-type="bibr" rid="CR15">15</xref></sup>.</p></sec></sec></sec><sec sec-type="supplementary-material"><title>Supplementary information</title><sec id="Sec17"><p>
<supplementary-material content-type="local-data" id="MOESM1"><media xlink:href="41598_2019_45301_MOESM1_ESM.pdf"><caption><p>Supplementary Information</p></caption></media></supplementary-material>
</p></sec></sec></body><back><fn-group><fn><p><bold>Publisher&#x02019;s note:</bold> Springer Nature remains neutral with regard to jurisdictional claims in published maps and institutional affiliations.</p></fn></fn-group><sec><title>Supplementary information</title><p><bold>Supplementary information</bold> accompanies this paper at 10.1038/s41598-019-45301-0.</p></sec><ack><title>Acknowledgements</title><p>This work was supported by funding from the European Commission&#x02019;s Seventh Framework Programme [FP7-2007-2013] under grant agreement n&#x000b0;HEALTH-F2-2013-602114 (Athero-B-Cell).</p></ack><notes notes-type="author-contribution"><title>Author Contributions</title><p>B.S. and I.D. developed the algorithm, carried out experiments, and wrote the manuscript. J.E.C. and C.M. provided CyTOF Apoe<sup>&#x02212;/&#x02212;</sup> datasets, interpreted results, and contextualized biological findings.</p></notes><notes notes-type="data-availability"><title>Code Availability</title><p>The ivis Python and R packages are available from github (<ext-link ext-link-type="uri" xlink:href="https://github.com/beringresearch/ivis">https://github.com/beringresearch/ivis</ext-link>).</p></notes><notes notes-type="COI-statement"><title>Competing Interests</title><p id="Par47">B.S. and I.D. are employees of Bering Limited. Their work was supported by the European Commission&#x02019;s Seventh Framework Programme grant agreement n&#x000b0;HEALTH-F2-2013-602114 to Bering Limited.</p></notes><ref-list id="Bib1"><title>References</title><ref id="CR1"><label>1.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Yuan</surname><given-names>GC</given-names></name><etal/></person-group><article-title>Challenges and emerging directions in single-cell analysis</article-title><source>Genome Biol</source><year>2017</year><volume>18</volume><fpage>84</fpage><pub-id pub-id-type="doi">10.1186/s13059-017-1218-y</pub-id><?supplied-pmid 28482897?><pub-id pub-id-type="pmid">28482897</pub-id></element-citation></ref><ref id="CR2"><label>2.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Eberwine</surname><given-names>J</given-names></name><name><surname>Sul</surname><given-names>JY</given-names></name><name><surname>Bartfai</surname><given-names>T</given-names></name><name><surname>Kim</surname><given-names>J</given-names></name></person-group><article-title>The promise of single-cell sequencing</article-title><source>Nat Methods</source><year>2014</year><volume>11</volume><fpage>25</fpage><lpage>27</lpage><pub-id pub-id-type="doi">10.1038/nmeth.2769</pub-id><pub-id pub-id-type="pmid">24524134</pub-id></element-citation></ref><ref id="CR3"><label>3.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Blainey</surname><given-names>PC</given-names></name><name><surname>Quake</surname><given-names>SR</given-names></name></person-group><article-title>Dissecting genomic diversity, one cell at a time</article-title><source>Nat Methods</source><year>2014</year><volume>11</volume><fpage>19</fpage><lpage>21</lpage><pub-id pub-id-type="doi">10.1038/nmeth.2783</pub-id><pub-id pub-id-type="pmid">24524132</pub-id></element-citation></ref><ref id="CR4"><label>4.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Sandberg</surname><given-names>R</given-names></name></person-group><article-title>Entering the era of single-cell transcriptomics in biology and medicine</article-title><source>Nat Methods</source><year>2014</year><volume>11</volume><fpage>22</fpage><lpage>24</lpage><pub-id pub-id-type="doi">10.1038/nmeth.2764</pub-id><pub-id pub-id-type="pmid">24524133</pub-id></element-citation></ref><ref id="CR5"><label>5.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Spitzer</surname><given-names>MH</given-names></name><name><surname>Nolan</surname><given-names>GP</given-names></name></person-group><article-title>Mass Cytometry: Single Cells, Many Features</article-title><source>Cell</source><year>2016</year><volume>165</volume><fpage>780</fpage><lpage>791</lpage><pub-id pub-id-type="doi">10.1016/j.cell.2016.04.019</pub-id><?supplied-pmid 27153492?><pub-id pub-id-type="pmid">27153492</pub-id></element-citation></ref><ref id="CR6"><label>6.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Zenobi</surname><given-names>R</given-names></name></person-group><article-title>Single-cell metabolomics: analytical and biological perspectives</article-title><source>Science</source><year>2013</year><volume>342</volume><fpage>1243259</fpage><pub-id pub-id-type="doi">10.1126/science.1243259</pub-id><?supplied-pmid 24311695?><pub-id pub-id-type="pmid">24311695</pub-id></element-citation></ref><ref id="CR7"><label>7.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Zeisel</surname><given-names>A</given-names></name><etal/></person-group><article-title>Brain structure. Cell types in the mouse cortex and hippocampus revealed by single-cell RNA-seq</article-title><source>Science</source><year>2015</year><volume>347</volume><fpage>1138</fpage><lpage>1142</lpage><pub-id pub-id-type="doi">10.1126/science.aaa1934</pub-id><?supplied-pmid 25700174?><pub-id pub-id-type="pmid">25700174</pub-id></element-citation></ref><ref id="CR8"><label>8.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Patel</surname><given-names>AP</given-names></name><etal/></person-group><article-title>Single-cell RNA-seq highlights intratumoral heterogeneity in primary glioblastoma</article-title><source>Science</source><year>2014</year><volume>344</volume><fpage>1396</fpage><lpage>1401</lpage><pub-id pub-id-type="doi">10.1126/science.1254257</pub-id><?supplied-pmid 24925914?><pub-id pub-id-type="pmid">24925914</pub-id></element-citation></ref><ref id="CR9"><label>9.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Porpiglia</surname><given-names>E</given-names></name><etal/></person-group><article-title>High-resolution myogenic lineage mapping by single-cell mass cytometry</article-title><source>Nat Cell Biol</source><year>2017</year><volume>19</volume><fpage>558</fpage><lpage>567</lpage><pub-id pub-id-type="doi">10.1038/ncb3507</pub-id><?supplied-pmid 28414312?><pub-id pub-id-type="pmid">28414312</pub-id></element-citation></ref><ref id="CR10"><label>10.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Wagner</surname><given-names>A</given-names></name><name><surname>Regev</surname><given-names>A</given-names></name><name><surname>Yosef</surname><given-names>N</given-names></name></person-group><article-title>Revealing the vectors of cellular identity with single-cell genomics</article-title><source>Nat Biotechnol</source><year>2016</year><volume>34</volume><fpage>1145</fpage><lpage>1160</lpage><pub-id pub-id-type="doi">10.1038/nbt.3711</pub-id><?supplied-pmid 27824854?><pub-id pub-id-type="pmid">27824854</pub-id></element-citation></ref><ref id="CR11"><label>11.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Maaten</surname><given-names>L</given-names></name></person-group><article-title>v. d. Learning a parametric embedding by preserving local structure</article-title><source>Proceedings of the Twelth International Conference on Artificial Intelligence and Statistics</source><year>2009</year><volume>5</volume><fpage>384</fpage><lpage>391</lpage></element-citation></ref><ref id="CR12"><label>12.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Shekhar</surname><given-names>K</given-names></name><etal/></person-group><article-title>Comprehensive Classification of Retinal Bipolar Neurons by Single-Cell Transcriptomics</article-title><source>Cell</source><year>2016</year><volume>166</volume><fpage>1308</fpage><lpage>1323 e1330</lpage><pub-id pub-id-type="doi">10.1016/j.cell.2016.07.054</pub-id><?supplied-pmid 27565351?><pub-id pub-id-type="pmid">27565351</pub-id></element-citation></ref><ref id="CR13"><label>13.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Amir el</surname><given-names>AD</given-names></name><etal/></person-group><article-title>viSNE enables visualization of high dimensional single-cell data and reveals phenotypic heterogeneity of leukemia</article-title><source>Nat Biotechnol</source><year>2013</year><volume>31</volume><fpage>545</fpage><lpage>552</lpage><pub-id pub-id-type="doi">10.1038/nbt.2594</pub-id><pub-id pub-id-type="pmid">23685480</pub-id></element-citation></ref><ref id="CR14"><label>14.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Amid</surname><given-names>E</given-names></name><name><surname>Warmuth</surname><given-names>MK</given-names></name></person-group><article-title>A more globally accurate dimensionality reduction method using triplets</article-title><source>eprint arXiv</source><year>2018</year><volume>1803</volume><fpage>00854</fpage></element-citation></ref><ref id="CR15"><label>15.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Ding</surname><given-names>J</given-names></name><name><surname>Condon</surname><given-names>A</given-names></name><name><surname>Shah</surname><given-names>SP</given-names></name></person-group><article-title>Interpretable dimensionality reduction of single cell transcriptome data with deep generative models</article-title><source>Nat Commun</source><year>2018</year><volume>9</volume><fpage>2002</fpage><pub-id pub-id-type="doi">10.1038/s41467-018-04368-5</pub-id><?supplied-pmid 29784946?><pub-id pub-id-type="pmid">29784946</pub-id></element-citation></ref><ref id="CR16"><label>16.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Maaten</surname><given-names>LVD</given-names></name><name><surname>Hinton</surname><given-names>G</given-names></name></person-group><article-title>Visualizing Data using t-SNE</article-title><source>JMLR</source><year>2008</year><volume>9</volume><fpage>2579</fpage><lpage>2605</lpage></element-citation></ref><ref id="CR17"><label>17.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Maaten</surname><given-names>LVD</given-names></name></person-group><article-title>Accelerating t-sne using tree- based algorithms</article-title><source>Journal of machine learning research</source><year>2014</year><volume>15</volume><fpage>3221</fpage><lpage>3245</lpage></element-citation></ref><ref id="CR18"><label>18.</label><mixed-citation publication-type="other">Schubert, E. &#x00026; Gertz, M. Intrinsic t-Stochastic Neighbor Embedding for Visualization and Outlier Detection &#x02013; A Remedy Against the Curse of Dimensionality? <italic>Proceedings of the 10th International Conference on Similarity Search and Applications</italic> (<italic>SISAP</italic>) (2017).</mixed-citation></ref><ref id="CR19"><label>19.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Hinton</surname><given-names>GE</given-names></name><name><surname>Salakhutdinov</surname><given-names>RR</given-names></name></person-group><article-title>Reducing the dimensionality of data with neural networks</article-title><source>Science</source><year>2006</year><volume>313</volume><fpage>504</fpage><lpage>507</lpage><pub-id pub-id-type="doi">10.1126/science.1127647</pub-id><?supplied-pmid 16873662?><pub-id pub-id-type="pmid">16873662</pub-id></element-citation></ref><ref id="CR20"><label>20.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Lin</surname><given-names>C</given-names></name><name><surname>Jain</surname><given-names>S</given-names></name><name><surname>Kim</surname><given-names>H</given-names></name><name><surname>Bar-Joseph</surname><given-names>Z</given-names></name></person-group><article-title>Using neural networks for reducing the dimensions of single-cell RNA-Seq data</article-title><source>Nucleic Acids Res</source><year>2017</year><volume>45</volume><fpage>e156</fpage><pub-id pub-id-type="doi">10.1093/nar/gkx681</pub-id><?supplied-pmid 28973464?><pub-id pub-id-type="pmid">28973464</pub-id></element-citation></ref><ref id="CR21"><label>21.</label><mixed-citation publication-type="other">Chopra, S., Hadsell, R. &#x00026; LeCun, Y. Learning a similarity metric discriminatively, with application to face verification. Computer Vision and Pattern Recognition. <italic>IEEE Computer Society Conference on IEEE</italic><bold>1</bold>, IEEE Computer Society Conference on IEEE (2005).</mixed-citation></ref><ref id="CR22"><label>22.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Levine</surname><given-names>JH</given-names></name><etal/></person-group><article-title>Data-Driven Phenotypic Dissection of AML Reveals Progenitor-like Cells that Correlate with Prognosis</article-title><source>Cell</source><year>2015</year><volume>162</volume><fpage>184</fpage><lpage>197</lpage><pub-id pub-id-type="doi">10.1016/j.cell.2015.05.047</pub-id><?supplied-pmid 26095251?><pub-id pub-id-type="pmid">26095251</pub-id></element-citation></ref><ref id="CR23"><label>23.</label><mixed-citation publication-type="other"><italic>10X</italic><italic>Genomics</italic>. <italic>1</italic>.<italic>3 million brain cells from E18 mice</italic>, <ext-link ext-link-type="uri" xlink:href="https://community.10xgenomics.com/t5/10x-Blog/Our-1-3-million-single-cell-dataset-is-ready-to-download/ba-p/276">https://community.10xgenomics.com/t5/10x-Blog/Our-1-3-million-single-cell-dataset-is-ready-to-download/ba-p/276</ext-link> (2017).</mixed-citation></ref><ref id="CR24"><label>24.</label><mixed-citation publication-type="other">Hoffer, E. &#x00026; Ailon, N. Deep metric learning using Triplet network. <italic>ICLR</italic> (2015).</mixed-citation></ref><ref id="CR25"><label>25.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Johnson</surname><given-names>WE</given-names></name><name><surname>Li</surname><given-names>C</given-names></name><name><surname>Rabinovic</surname><given-names>A</given-names></name></person-group><article-title>Adjusting batch effects in microarray expression data using empirical Bayes methods</article-title><source>Biostatistics</source><year>2007</year><volume>8</volume><fpage>118</fpage><lpage>127</lpage><pub-id pub-id-type="doi">10.1093/biostatistics/kxj037</pub-id><?supplied-pmid 16632515?><pub-id pub-id-type="pmid">16632515</pub-id></element-citation></ref><ref id="CR26"><label>26.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Benito</surname><given-names>M</given-names></name><etal/></person-group><article-title>Adjustment of systematic microarray data biases</article-title><source>Bioinformatics</source><year>2004</year><volume>20</volume><fpage>105</fpage><lpage>114</lpage><pub-id pub-id-type="doi">10.1093/bioinformatics/btg385</pub-id><pub-id pub-id-type="pmid">14693816</pub-id></element-citation></ref><ref id="CR27"><label>27.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Brennecke</surname><given-names>P</given-names></name><etal/></person-group><article-title>Accounting for technical noise in single-cell RNA-seq experiments</article-title><source>Nat Methods</source><year>2013</year><volume>10</volume><fpage>1093</fpage><lpage>1095</lpage><pub-id pub-id-type="doi">10.1038/nmeth.2645</pub-id><?supplied-pmid 24056876?><pub-id pub-id-type="pmid">24056876</pub-id></element-citation></ref><ref id="CR28"><label>28.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Ilicic</surname><given-names>T</given-names></name><etal/></person-group><article-title>Classification of low quality cells from single-cell RNA-seq data</article-title><source>Genome Biol</source><year>2016</year><volume>17</volume><fpage>29</fpage><pub-id pub-id-type="doi">10.1186/s13059-016-0888-1</pub-id><?supplied-pmid 26887813?><pub-id pub-id-type="pmid">26887813</pub-id></element-citation></ref><ref id="CR29"><label>29.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Park</surname><given-names>J</given-names></name><etal/></person-group><article-title>Single-cell transcriptomics of the mouse kidney reveals potential cellular targets of kidney disease</article-title><source>Science</source><year>2018</year><volume>360</volume><fpage>758</fpage><lpage>763</lpage><pub-id pub-id-type="doi">10.1126/science.aar2131</pub-id><?supplied-pmid 29622724?><pub-id pub-id-type="pmid">29622724</pub-id></element-citation></ref><ref id="CR30"><label>30.</label><mixed-citation publication-type="other">Arora, S., Hu, W. &#x00026; Kothari, P. K. An Analysis of the t-SNE Algorithm for Data Visualization. <italic>CoRR</italic><bold>abs/1803</bold>.<bold>01768</bold> (2018).</mixed-citation></ref><ref id="CR31"><label>31.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Goodrich-Hunsaker</surname><given-names>NJ</given-names></name><name><surname>Hunsaker</surname><given-names>MR</given-names></name><name><surname>Kesner</surname><given-names>RP</given-names></name></person-group><article-title>The interactions and dissociations of the dorsal hippocampus subregions: how the dentate gyrus, CA3, and CA1 process spatial information</article-title><source>Behav Neurosci</source><year>2008</year><volume>122</volume><fpage>16</fpage><lpage>26</lpage><pub-id pub-id-type="doi">10.1037/0735-7044.122.1.16</pub-id><?supplied-pmid 18298245?><pub-id pub-id-type="pmid">18298245</pub-id></element-citation></ref><ref id="CR32"><label>32.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Savas</surname><given-names>P</given-names></name><etal/></person-group><article-title>Single-cell profiling of breast cancer T cells reveals a tissue-resident memory subset associated with improved prognosis</article-title><source>Nat Med</source><year>2018</year><volume>24</volume><fpage>986</fpage><lpage>993</lpage><pub-id pub-id-type="doi">10.1038/s41591-018-0078-7</pub-id><?supplied-pmid 29942092?><pub-id pub-id-type="pmid">29942092</pub-id></element-citation></ref><ref id="CR33"><label>33.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Lambrechts</surname><given-names>D</given-names></name><etal/></person-group><article-title>Phenotype molding of stromal cells in the lung tumor microenvironment</article-title><source>Nat Med</source><year>2018</year><volume>24</volume><fpage>1277</fpage><lpage>1289</lpage><pub-id pub-id-type="doi">10.1038/s41591-018-0096-5</pub-id><?supplied-pmid 29988129?><pub-id pub-id-type="pmid">29988129</pub-id></element-citation></ref><ref id="CR34"><label>34.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Krieg</surname><given-names>C</given-names></name><etal/></person-group><article-title>High-dimensional single-cell analysis predicts response to anti-PD-1 immunotherapy</article-title><source>Nat Med</source><year>2018</year><volume>24</volume><fpage>144</fpage><lpage>153</lpage><pub-id pub-id-type="doi">10.1038/nm.4466</pub-id><?supplied-pmid 29309059?><pub-id pub-id-type="pmid">29309059</pub-id></element-citation></ref><ref id="CR35"><label>35.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Cochain</surname><given-names>C</given-names></name><etal/></person-group><article-title>Single-Cell RNA-Seq Reveals the Transcriptional Landscape and Heterogeneity of Aortic Macrophages in Murine Atherosclerosis</article-title><source>Circ Res</source><year>2018</year><volume>122</volume><fpage>1661</fpage><lpage>1674</lpage><pub-id pub-id-type="doi">10.1161/CIRCRESAHA.117.312509</pub-id><?supplied-pmid 29545365?><pub-id pub-id-type="pmid">29545365</pub-id></element-citation></ref><ref id="CR36"><label>36.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Grimes</surname><given-names>T</given-names></name><name><surname>Walker</surname><given-names>AR</given-names></name><name><surname>Datta</surname><given-names>S</given-names></name><name><surname>Datta</surname><given-names>S</given-names></name></person-group><article-title>Predicting survival times for neuroblastoma patients using RNA-seq expression profiles</article-title><source>Biol Direct</source><year>2018</year><volume>13</volume><fpage>11</fpage><pub-id pub-id-type="doi">10.1186/s13062-018-0213-x</pub-id><?supplied-pmid 29848365?><pub-id pub-id-type="pmid">29848365</pub-id></element-citation></ref><ref id="CR37"><label>37.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Esteva</surname><given-names>A</given-names></name><etal/></person-group><article-title>Dermatologist-level classification of skin cancer with deep neural networks</article-title><source>Nature</source><year>2017</year><volume>542</volume><fpage>115</fpage><lpage>118</lpage><pub-id pub-id-type="doi">10.1038/nature21056</pub-id><?supplied-pmid 28117445?><pub-id pub-id-type="pmid">28117445</pub-id></element-citation></ref><ref id="CR38"><label>38.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Kermany</surname><given-names>DS</given-names></name><etal/></person-group><article-title>Identifying Medical Diagnoses and Treatable Diseases by Image-Based Deep Learning</article-title><source>Cell</source><year>2018</year><volume>172</volume><fpage>1122</fpage><lpage>1131 e1129</lpage><pub-id pub-id-type="doi">10.1016/j.cell.2018.02.010</pub-id><?supplied-pmid 29474911?><pub-id pub-id-type="pmid">29474911</pub-id></element-citation></ref><ref id="CR39"><label>39.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Bromley</surname><given-names>J</given-names></name><etal/></person-group><article-title>Signature verification using a siamese time delay neural network</article-title><source>International Jour- nal of Pattern Recognition and Artificial Intelligence</source><year>1993</year><volume>7</volume><fpage>669</fpage><lpage>688</lpage><pub-id pub-id-type="doi">10.1142/S0218001493000339</pub-id></element-citation></ref><ref id="CR40"><label>40.</label><mixed-citation publication-type="other">Koch, G., Zemel, R. &#x00026; Salakhutdinov, R. Siamese Neural Networks for One-shot Image Recognition. <italic>Proceedings of the 32nd International Conference on Machine Learning</italic> (2015).</mixed-citation></ref><ref id="CR41"><label>41.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Wang</surname><given-names>B</given-names></name><name><surname>Zhu</surname><given-names>J</given-names></name><name><surname>Pierson</surname><given-names>E</given-names></name><name><surname>Ramazzotti</surname><given-names>D</given-names></name><name><surname>Batzoglou</surname><given-names>S</given-names></name></person-group><article-title>Visualization and analysis of single-cell RNA-seq data by kernel-based similarity learning</article-title><source>Nat Methods</source><year>2017</year><volume>14</volume><fpage>414</fpage><lpage>416</lpage><pub-id pub-id-type="doi">10.1038/nmeth.4207</pub-id><?supplied-pmid 28263960?><pub-id pub-id-type="pmid">28263960</pub-id></element-citation></ref><ref id="CR42"><label>42.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Yamano</surname><given-names>T</given-names></name></person-group><article-title>A generalization of the Kullback-Leibler divergence and its properties</article-title><source>Journal of Mathematical Physics</source><year>2009</year><volume>50</volume><fpage>043302</fpage><lpage>043302-043311</lpage><pub-id pub-id-type="doi">10.1063/1.3116115</pub-id></element-citation></ref><ref id="CR43"><label>43.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Li</surname><given-names>H</given-names></name><etal/></person-group><article-title>Gating mass cytometry data by deep learning</article-title><source>Bioinformatics</source><year>2017</year><volume>33</volume><fpage>3423</fpage><lpage>3430</lpage><pub-id pub-id-type="doi">10.1093/bioinformatics/btx448</pub-id><?supplied-pmid 29036374?><pub-id pub-id-type="pmid">29036374</pub-id></element-citation></ref><ref id="CR44"><label>44.</label><mixed-citation publication-type="other">Klambauer, G., Unterthiner, T., Mayr, A. &#x00026; Hochreiter, S. Self-Normalizing Neural Networks. <italic>Advances in Neural Information Processing Systems</italic> (2017).</mixed-citation></ref><ref id="CR45"><label>45.</label><mixed-citation publication-type="other">Hermans, A., Beyer, L. &#x00026; Leibe, B. In Defense of the Triplet Loss for Person Re-Identification. <italic>CoRR</italic> (2017).</mixed-citation></ref><ref id="CR46"><label>46.</label><mixed-citation publication-type="other">Bernhardsson, E. <italic>Approximate Nearest Neighbors in C</italic>&#x02009;++<italic>&#x02009;/Python optimized for memory usage and loading/saving to disk</italic>, <ext-link ext-link-type="uri" xlink:href="https://github.com/spotify/annoy">https://github.com/spotify/annoy</ext-link> (2018).</mixed-citation></ref><ref id="CR47"><label>47.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Cole</surname><given-names>JE</given-names></name><etal/></person-group><article-title>Immune cell census in murine atherosclerosis: cytometry by time of flight illuminates vascular myeloid cell diversity</article-title><source>Cardiovasc Res</source><year>2018</year><volume>114</volume><fpage>1360</fpage><lpage>1371</lpage><pub-id pub-id-type="doi">10.1093/cvr/cvy109</pub-id><?supplied-pmid 29726984?><pub-id pub-id-type="pmid">29726984</pub-id></element-citation></ref><ref id="CR48"><label>48.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Samusik</surname><given-names>N</given-names></name><name><surname>Good</surname><given-names>Z</given-names></name><name><surname>Spitzer</surname><given-names>MH</given-names></name><name><surname>Davis</surname><given-names>KL</given-names></name><name><surname>Nolan</surname><given-names>GP</given-names></name></person-group><article-title>Automated mapping of phenotype space with single-cell data</article-title><source>Nat Methods</source><year>2016</year><volume>13</volume><fpage>493</fpage><lpage>496</lpage><pub-id pub-id-type="doi">10.1038/nmeth.3863</pub-id><?supplied-pmid 27183440?><pub-id pub-id-type="pmid">27183440</pub-id></element-citation></ref><ref id="CR49"><label>49.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Bendall</surname><given-names>SC</given-names></name><etal/></person-group><article-title>Single-cell mass cytometry of differential immune and drug responses across a human hematopoietic continuum</article-title><source>Science</source><year>2011</year><volume>332</volume><fpage>687</fpage><lpage>696</lpage><pub-id pub-id-type="doi">10.1126/science.1198704</pub-id><?supplied-pmid 21551058?><pub-id pub-id-type="pmid">21551058</pub-id></element-citation></ref><ref id="CR50"><label>50.</label><mixed-citation publication-type="other"><italic>Single-Cell Portal</italic>, <ext-link ext-link-type="uri" xlink:href="https://portals.broadinstitute.org/single_cell">https://portals.broadinstitute.org/single_cell</ext-link> (2018).</mixed-citation></ref><ref id="CR51"><label>51.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Habib</surname><given-names>N</given-names></name><etal/></person-group><article-title>Div-Seq: Single-nucleus RNA-Seq reveals dynamics of rare adult newborn neurons</article-title><source>Science</source><year>2016</year><volume>353</volume><fpage>925</fpage><lpage>928</lpage><pub-id pub-id-type="doi">10.1126/science.aad7038</pub-id><?supplied-pmid 27471252?><pub-id pub-id-type="pmid">27471252</pub-id></element-citation></ref><ref id="CR52"><label>52.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Tirosh</surname><given-names>I</given-names></name><etal/></person-group><article-title>Dissecting the multicellular ecosystem of metastatic melanoma by single-cell RNA-seq</article-title><source>Science</source><year>2016</year><volume>352</volume><fpage>189</fpage><lpage>196</lpage><pub-id pub-id-type="doi">10.1126/science.aad0501</pub-id><?supplied-pmid 27124452?><pub-id pub-id-type="pmid">27124452</pub-id></element-citation></ref></ref-list></back></article>