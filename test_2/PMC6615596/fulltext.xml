<!DOCTYPE article PUBLIC "-//NLM//DTD JATS (Z39.96) Journal Archiving and Interchange DTD v1.2 20190208//EN" "JATS-archivearticle1.dtd"> 
<article xmlns:xlink="http://www.w3.org/1999/xlink" xmlns:mml="http://www.w3.org/1998/Math/MathML" article-type="research-article"><?properties open_access?><?DTDIdentifier.IdentifierValue -//NLM//DTD JATS (Z39.96) Journal Publishing DTD v1.1d3 20150301//EN?><?DTDIdentifier.IdentifierType public?><?SourceDTD.DTDName JATS-journalpublishing1.dtd?><?SourceDTD.Version 39.96?><?ConverterInfo.XSLTName jp2nlmx2.xsl?><?ConverterInfo.Version 1?><front><journal-meta><journal-id journal-id-type="nlm-ta">PLoS One</journal-id><journal-id journal-id-type="iso-abbrev">PLoS ONE</journal-id><journal-id journal-id-type="publisher-id">plos</journal-id><journal-id journal-id-type="pmc">plosone</journal-id><journal-title-group><journal-title>PLoS ONE</journal-title></journal-title-group><issn pub-type="epub">1932-6203</issn><publisher><publisher-name>Public Library of Science</publisher-name><publisher-loc>San Francisco, CA USA</publisher-loc></publisher></journal-meta><article-meta><article-id pub-id-type="pmcid">6615596</article-id><article-id pub-id-type="publisher-id">PONE-D-19-01516</article-id><article-id pub-id-type="doi">10.1371/journal.pone.0211608</article-id><article-categories><subj-group subj-group-type="heading"><subject>Research Article</subject></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Biology and Life Sciences</subject><subj-group><subject>Neuroscience</subject><subj-group><subject>Cognitive Science</subject><subj-group><subject>Cognitive Psychology</subject><subj-group><subject>Language</subject></subj-group></subj-group></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Biology and Life Sciences</subject><subj-group><subject>Psychology</subject><subj-group><subject>Cognitive Psychology</subject><subj-group><subject>Language</subject></subj-group></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Social Sciences</subject><subj-group><subject>Psychology</subject><subj-group><subject>Cognitive Psychology</subject><subj-group><subject>Language</subject></subj-group></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Research and Analysis Methods</subject><subj-group><subject>Database and Informatics Methods</subject><subj-group><subject>Bioinformatics</subject></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Social Sciences</subject><subj-group><subject>Economics</subject><subj-group><subject>Labor Economics</subject><subj-group><subject>Employment</subject><subj-group><subject>Jobs</subject></subj-group></subj-group></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Engineering and Technology</subject><subj-group><subject>Mechanical Engineering</subject><subj-group><subject>Engines</subject></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Biology and Life Sciences</subject><subj-group><subject>Computational Biology</subject><subj-group><subject>Genome Analysis</subject></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Biology and Life Sciences</subject><subj-group><subject>Genetics</subject><subj-group><subject>Genomics</subject><subj-group><subject>Genome Analysis</subject></subj-group></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Computer and Information Sciences</subject><subj-group><subject>Data Management</subject></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Engineering and Technology</subject><subj-group><subject>Human Factors Engineering</subject><subj-group><subject>Man-Computer Interface</subject><subj-group><subject>Graphical User Interfaces</subject></subj-group></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Computer and Information Sciences</subject><subj-group><subject>Computer Architecture</subject><subj-group><subject>User Interfaces</subject><subj-group><subject>Graphical User Interfaces</subject></subj-group></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Biology and Life Sciences</subject><subj-group><subject>Computational Biology</subject><subj-group><subject>Genome Complexity</subject></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Biology and Life Sciences</subject><subj-group><subject>Genetics</subject><subj-group><subject>Genomics</subject><subj-group><subject>Genome Complexity</subject></subj-group></subj-group></subj-group></subj-group></article-categories><title-group><article-title>Managing genomic variant calling workflows with Swift/T</article-title><alt-title alt-title-type="running-head">Genomic workflow management with Swift/T</alt-title></title-group><contrib-group><contrib contrib-type="author" equal-contrib="yes"><name><surname>Ahmed</surname><given-names>Azza E.</given-names></name><role content-type="http://credit.casrai.org/">Conceptualization</role><role content-type="http://credit.casrai.org/">Data curation</role><role content-type="http://credit.casrai.org/">Formal analysis</role><role content-type="http://credit.casrai.org/">Investigation</role><role content-type="http://credit.casrai.org/">Software</role><role content-type="http://credit.casrai.org/">Visualization</role><role content-type="http://credit.casrai.org/">Writing &#x02013; original draft</role><xref ref-type="aff" rid="aff001"><sup>1</sup></xref><xref ref-type="aff" rid="aff002"><sup>2</sup></xref></contrib><contrib contrib-type="author" equal-contrib="yes"><name><surname>Heldenbrand</surname><given-names>Jacob</given-names></name><role content-type="http://credit.casrai.org/">Conceptualization</role><role content-type="http://credit.casrai.org/">Data curation</role><role content-type="http://credit.casrai.org/">Formal analysis</role><role content-type="http://credit.casrai.org/">Investigation</role><role content-type="http://credit.casrai.org/">Software</role><role content-type="http://credit.casrai.org/">Visualization</role><role content-type="http://credit.casrai.org/">Writing &#x02013; original draft</role><xref ref-type="aff" rid="aff003"><sup>3</sup></xref></contrib><contrib contrib-type="author"><name><surname>Asmann</surname><given-names>Yan</given-names></name><role content-type="http://credit.casrai.org/">Resources</role><xref ref-type="aff" rid="aff004"><sup>4</sup></xref></contrib><contrib contrib-type="author"><name><surname>Fadlelmola</surname><given-names>Faisal M.</given-names></name><role content-type="http://credit.casrai.org/">Supervision</role><xref ref-type="aff" rid="aff001"><sup>1</sup></xref></contrib><contrib contrib-type="author"><contrib-id authenticated="true" contrib-id-type="orcid">http://orcid.org/0000-0001-5934-7525</contrib-id><name><surname>Katz</surname><given-names>Daniel S.</given-names></name><role content-type="http://credit.casrai.org/">Supervision</role><role content-type="http://credit.casrai.org/">Writing &#x02013; review &#x00026; editing</role><xref ref-type="aff" rid="aff003"><sup>3</sup></xref></contrib><contrib contrib-type="author"><name><surname>Kendig</surname><given-names>Katherine</given-names></name><role content-type="http://credit.casrai.org/">Writing &#x02013; review &#x00026; editing</role><xref ref-type="aff" rid="aff003"><sup>3</sup></xref></contrib><contrib contrib-type="author"><name><surname>Kendzior</surname><given-names>Matthew C.</given-names></name><role content-type="http://credit.casrai.org/">Investigation</role><role content-type="http://credit.casrai.org/">Software</role><role content-type="http://credit.casrai.org/">Validation</role><xref ref-type="aff" rid="aff005"><sup>5</sup></xref></contrib><contrib contrib-type="author"><name><surname>Li</surname><given-names>Tiffany</given-names></name><role content-type="http://credit.casrai.org/">Writing &#x02013; original draft</role><xref ref-type="aff" rid="aff003"><sup>3</sup></xref></contrib><contrib contrib-type="author"><name><surname>Ren</surname><given-names>Yingxue</given-names></name><role content-type="http://credit.casrai.org/">Data curation</role><xref ref-type="aff" rid="aff004"><sup>4</sup></xref></contrib><contrib contrib-type="author"><name><surname>Rodriguez</surname><given-names>Elliott</given-names></name><role content-type="http://credit.casrai.org/">Software</role><xref ref-type="aff" rid="aff003"><sup>3</sup></xref></contrib><contrib contrib-type="author"><name><surname>Weber</surname><given-names>Matthew R.</given-names></name><role content-type="http://credit.casrai.org/">Investigation</role><role content-type="http://credit.casrai.org/">Validation</role><xref ref-type="aff" rid="aff005"><sup>5</sup></xref></contrib><contrib contrib-type="author"><name><surname>Wozniak</surname><given-names>Justin M.</given-names></name><role content-type="http://credit.casrai.org/">Resources</role><role content-type="http://credit.casrai.org/">Software</role><xref ref-type="aff" rid="aff006"><sup>6</sup></xref></contrib><contrib contrib-type="author"><name><surname>Zermeno</surname><given-names>Jennie</given-names></name><role content-type="http://credit.casrai.org/">Writing &#x02013; original draft</role><xref ref-type="aff" rid="aff003"><sup>3</sup></xref></contrib><contrib contrib-type="author"><contrib-id authenticated="true" contrib-id-type="orcid">http://orcid.org/0000-0001-7121-0214</contrib-id><name><surname>Mainzer</surname><given-names>Liudmila S.</given-names></name><role content-type="http://credit.casrai.org/">Conceptualization</role><role content-type="http://credit.casrai.org/">Formal analysis</role><role content-type="http://credit.casrai.org/">Funding acquisition</role><role content-type="http://credit.casrai.org/">Methodology</role><role content-type="http://credit.casrai.org/">Project administration</role><role content-type="http://credit.casrai.org/">Resources</role><role content-type="http://credit.casrai.org/">Supervision</role><role content-type="http://credit.casrai.org/">Validation</role><role content-type="http://credit.casrai.org/">Writing &#x02013; review &#x00026; editing</role><xref ref-type="aff" rid="aff003"><sup>3</sup></xref><xref ref-type="aff" rid="aff007"><sup>7</sup></xref><xref ref-type="corresp" rid="cor001">*</xref></contrib></contrib-group><aff id="aff001">
<label>1</label>
<addr-line>Centre for Bioinformatics &#x00026; Systems Biology, Faculty of Science, University of Khartoum, Khartoum, Sudan</addr-line>
</aff><aff id="aff002">
<label>2</label>
<addr-line>Department of Electrical and Electronic Engineering, Faculty of Engineering, University of Khartoum, Khartoum, Sudan</addr-line>
</aff><aff id="aff003">
<label>3</label>
<addr-line>National Center for Supercomputing Applications, University of Illinois at Urbana-Champaign, Urbana-Champaign, Illinois, United States of America</addr-line>
</aff><aff id="aff004">
<label>4</label>
<addr-line>Department of Health Sciences Research, Mayo Clinic, Jacksonville, Florida, United States of America</addr-line>
</aff><aff id="aff005">
<label>5</label>
<addr-line>Department of Crop Sciences, University of Illinois at Urbana-Champaign, Urbana-Champaign, Illinois, United States of America</addr-line>
</aff><aff id="aff006">
<label>6</label>
<addr-line>Argonne National Laboratory, Argonne, Illinois, United States of America</addr-line>
</aff><aff id="aff007">
<label>7</label>
<addr-line>Institute for Genomic Biology, University of Illinois at Urbana-Champaign, Urbana-Champaign, Illinois, United States of America</addr-line>
</aff><contrib-group><contrib contrib-type="editor"><name><surname>Chen</surname><given-names>Li</given-names></name><role>Editor</role><xref ref-type="aff" rid="edit1"/></contrib></contrib-group><aff id="edit1">
<addr-line>Auburn University - Harrison School of Pharmacy, UNITED STATES</addr-line>
</aff><author-notes><fn fn-type="COI-statement" id="coi001"><p><bold>Competing Interests: </bold>The authors have declared that no competing interests exist.</p></fn><corresp id="cor001">* E-mail: <email>lmainzer@illinois.edu</email></corresp></author-notes><pub-date pub-type="collection"><year>2019</year></pub-date><pub-date pub-type="epub"><day>9</day><month>7</month><year>2019</year></pub-date><volume>14</volume><issue>7</issue><elocation-id>e0211608</elocation-id><history><date date-type="received"><day>16</day><month>1</month><year>2019</year></date><date date-type="accepted"><day>8</day><month>6</month><year>2019</year></date></history><permissions><copyright-statement>&#x000a9; 2019 Ahmed et al</copyright-statement><copyright-year>2019</copyright-year><copyright-holder>Ahmed et al</copyright-holder><license xlink:href="http://creativecommons.org/licenses/by/4.0/"><license-p>This is an open access article distributed under the terms of the <ext-link ext-link-type="uri" xlink:href="http://creativecommons.org/licenses/by/4.0/">Creative Commons Attribution License</ext-link>, which permits unrestricted use, distribution, and reproduction in any medium, provided the original author and source are credited.</license-p></license></permissions><self-uri content-type="pdf" xlink:href="pone.0211608.pdf"/><abstract><p>Bioinformatics research is frequently performed using complex workflows with multiple steps, fans, merges, and conditionals. This complexity makes management of the workflow difficult on a computer cluster, especially when running in parallel on large batches of data: hundreds or thousands of samples at a time. Scientific workflow management systems could help with that. Many are now being proposed, but is there yet the &#x0201c;best&#x0201d; workflow management system for bioinformatics? Such a system would need to satisfy numerous, sometimes conflicting requirements: from ease of use, to seamless deployment at peta- and exa-scale, and portability to the cloud. We evaluated Swift/T as a candidate for such role by implementing a primary genomic variant calling workflow in the Swift/T language, focusing on workflow management, performance and scalability issues that arise from production-grade big data genomic analyses. In the process we introduced novel features into the language, which are now part of its open repository. Additionally, we formalized a set of design criteria for quality, robust, maintainable workflows that must function at-scale in a production setting, such as a large genomic sequencing facility or a major hospital system. The use of Swift/T conveys two key advantages. (1) It operates transparently in multiple cluster scheduling environments (PBS Torque, SLURM, Cray aprun environment, etc.), thus a single workflow is trivially portable across numerous clusters. (2) The leaf functions of Swift/T permit developers to easily swap executables in and out of the workflow, which makes it easy to maintain and to request resources optimal for each stage of the pipeline. While Swift/T&#x02019;s data-level parallelism eliminates the need to code parallel analysis of multiple samples, it does make debugging more difficult, as is common for implicitly parallel code. Nonetheless, the language gives users a powerful and portable way to scale up analyses in many computing architectures. The code for our implementation of a variant calling workflow using Swift/T can be found on GitHub at <ext-link ext-link-type="uri" xlink:href="https://github.com/ncsa/Swift-T-Variant-Calling">https://github.com/ncsa/Swift-T-Variant-Calling</ext-link>, with full documentation provided at <ext-link ext-link-type="uri" xlink:href="http://swift-t-variant-calling.readthedocs.io/en/latest/">http://swift-t-variant-calling.readthedocs.io/en/latest/</ext-link>.</p></abstract><funding-group><funding-statement>This research is part of the Blue Waters sustained-petascale computing project, which is supported by the National Science Foundation (awards OCI-0725070 and ACI-1238993) and the state of Illinois. DSK and JMW are supported by the NSF award ACI-1550588. Blue Waters is a joint effort of the University of Illinois at Urbana-Champaign and its National Center for Supercomputing Applications. LSM was awarded an allocation on the Blue Waters supercomputer, which was used for some of the computational tests. This work used the Extreme Science and Engineering Discovery Environment (XSEDE), which is supported by National Science Foundation grant number ACI-1548562. DSK was awarded an allocation on XSEDE, which was used for some of the computational tests. LSM, AEA and FMF are H3ABioNet members and supported by the National Institutes of Health Common Fund under grant number U41HG006941. The content is solely the responsibility of the authors and does not necessarily represent the official views of the National Institutes of Health.</funding-statement></funding-group><counts><fig-count count="2"/><table-count count="4"/><page-count count="20"/></counts><custom-meta-group><custom-meta id="data-availability"><meta-name>Data Availability</meta-name><meta-value>All code is available from <ext-link ext-link-type="uri" xlink:href="https://github.com/ncsa/Swift-T-Variant-Calling">https://github.com/ncsa/Swift-T-Variant-Calling</ext-link> Code is documented on <ext-link ext-link-type="uri" xlink:href="http://swift-t-variant-calling.readthedocs.io/en/latest/">http://swift-t-variant-calling.readthedocs.io/en/latest/</ext-link>.</meta-value></custom-meta></custom-meta-group></article-meta><notes><title>Data Availability</title><p>All code is available from <ext-link ext-link-type="uri" xlink:href="https://github.com/ncsa/Swift-T-Variant-Calling">https://github.com/ncsa/Swift-T-Variant-Calling</ext-link> Code is documented on <ext-link ext-link-type="uri" xlink:href="http://swift-t-variant-calling.readthedocs.io/en/latest/">http://swift-t-variant-calling.readthedocs.io/en/latest/</ext-link>.</p></notes></front><body><sec sec-type="intro" id="sec001"><title>Introduction</title><p>Advancements in sequencing technology [<xref rid="pone.0211608.ref001" ref-type="bibr">1</xref>, <xref rid="pone.0211608.ref002" ref-type="bibr">2</xref>] have paved the way for many applications of Whole Genome Sequencing (WGS) and Whole Exome Sequencing (WES) in genomic research and the clinic [<xref rid="pone.0211608.ref003" ref-type="bibr">3</xref>, <xref rid="pone.0211608.ref004" ref-type="bibr">4</xref>]. Be it primary variant calling, RNASeq, genome assembly or annotation, a genomics analysis invariably involves constructing a complex workflow that could be hard to manage for large sample sizes (hundreds and beyond, [<xref rid="pone.0211608.ref005" ref-type="bibr">5</xref>&#x02013;<xref rid="pone.0211608.ref007" ref-type="bibr">7</xref>]) that necessitate the use of large computer clusters. In such cases, features like resiliency and auto-restart in case of node failures, tracking of individual samples, efficient node utilization, and easy debugging of errors and failures are very important. Without a high-quality workflow manager, these requirements can be difficult to satisfy, resulting in error-prone workflow development, maintenance and execution. An additional challenge is porting the workflow among different computing environments, a common need in collaborative and consortium projects.</p><p>Monolithic solutions, where a single executable runs the entire analysis, can replace the complex multi-stage workflow and obviate the need for workflow management. Examples of these solutions for primary variant calling include Isaac [<xref rid="pone.0211608.ref008" ref-type="bibr">8</xref>], Genalice [<xref rid="pone.0211608.ref009" ref-type="bibr">9</xref>] and Dragen [<xref rid="pone.0211608.ref010" ref-type="bibr">10</xref>]. These programs offer a plethora of options, but may be too rigid for some analyses, preventing users from swapping algorithms for better accuracy or making adjustments for different species (reference genome, ploidy, known SNP sets etc.) [<xref rid="pone.0211608.ref011" ref-type="bibr">11</xref>]. These monolithic solutions are also developed and maintained by private companies, which may delay or preclude the incorporation of novel approaches and algorithms developed by the scientific and medical community.</p><p>Multiple workflow management systems are now available [<xref rid="pone.0211608.ref012" ref-type="bibr">12</xref>] that differ in their design philosophy and implementation. None so far have been found to be the &#x0201c;best&#x0201d; choice for bioinformatics, although some winners are emerging, such as the Common Workflow Language (CWL [<xref rid="pone.0211608.ref013" ref-type="bibr">13</xref>]) and the Workflow Definition Language (WDL [<xref rid="pone.0211608.ref014" ref-type="bibr">14</xref>]), see <xref ref-type="sec" rid="sec014">Discussion</xref>. Key distinguishing features are the underlying language and syntax in which the workflow is expressed, and the monitoring and parallel processing capabilities of workflows while executing. Swift/T [<xref rid="pone.0211608.ref015" ref-type="bibr">15</xref>] is one such workflow management system, composed of Swift&#x02014;a high-level, general-purpose dataflow scripting language [<xref rid="pone.0211608.ref016" ref-type="bibr">16</xref>], and Turbine&#x02014;a workflow execution engine [<xref rid="pone.0211608.ref017" ref-type="bibr">17</xref>]. The greatest purported advantages of Swift/T are its high portability and ability to scale up to extreme petascale computation levels [<xref rid="pone.0211608.ref018" ref-type="bibr">18</xref>]. Additionally, a number of features make this language an attractive choice for complex bioinformatics workflows [<xref rid="pone.0211608.ref019" ref-type="bibr">19</xref>]:
<list list-type="bullet"><list-item><p><italic>Abstraction and portability</italic>, where cluster resource management is largely hidden from the user, allowing the same code to be seamlessly ported among clusters with different schedulers;</p></list-item><list-item><p><italic>Modularity</italic> through the use of leaf functions to define heavyweight processing tasks that are called as need arises;</p></list-item><list-item><p><italic>Extensibility</italic> through easy integration of functions written in other languages;</p></list-item><list-item><p><italic>Dataflow-based programming framework</italic> that ensures efficient use of compute resources through compile-time optimization for distributed-memory computing models and hybrid parallelism, resulting in high scalability;</p></list-item><list-item><p><italic>Code readability</italic> due to its C-like syntax; and</p></list-item><list-item><p><italic>Code expressibility</italic>&#x02014;inclusion of standard programming features, such as conditional execution, iteration, and recursive functions [<xref rid="pone.0211608.ref020" ref-type="bibr">20</xref>].</p></list-item></list></p><p>We explored Swift/T as a choice in the space of currently available workflow management systems. This paper documents our experience implementing, debugging and deploying a genomic variant calling workflow in Swift/T available at <ext-link ext-link-type="uri" xlink:href="https://github.com/ncsa/Swift-T-Variant-Calling">https://github.com/ncsa/Swift-T-Variant-Calling</ext-link> and documented on <ext-link ext-link-type="uri" xlink:href="http://swift-t-variant-calling.readthedocs.io/en/latest/">http://swift-t-variant-calling.readthedocs.io/en/latest/</ext-link>.</p></sec><sec id="sec002"><title>Methods and results</title><p>Our chosen use case is genomic variant calling, commonly performed in accordance with the Best Practices established by the GATK team (Genome Analysis Toolkit) [<xref rid="pone.0211608.ref021" ref-type="bibr">21</xref>&#x02013;<xref rid="pone.0211608.ref023" ref-type="bibr">23</xref>]. It is likely that the GATK will continue to be the standard in research and medicine for those reasons, and also due to the need for HIPAA [<xref rid="pone.0211608.ref024" ref-type="bibr">24</xref>]/CLIA [<xref rid="pone.0211608.ref025" ref-type="bibr">25</xref>] approval and compliance. The GATK is well trusted, validated by the community, and grandfathered in. Thus, the need for a generic, modular and flexible workflow built around the toolkit will persist for some time. We focused only on the primary analysis: the steps from aligning raw reads through variant calling, excluding any downstream steps, such as phasing and annotation. Additionally, we focused on small variant discovery, i.e. the detection of SNPs and InDels, not including structural variant calling. The implementation focused on WGS and WES data. The included functionality was sufficient to test the power and ability of Swift/T and evaluate its usefulness in creating extensible workflows that could be augmented with additional steps.</p><p>The variant calling workflow consists of multiple steps that require conditional adjustments based on the analysis use case, such as whole genome vs. exome sequencing, paired- or single-end reads, species or ploidy, etc. The primary role of the workflow management system, such as Swift/T, is to handle this conditional branching and coordinate the launch of command-line tools in accordance with the user-defined configuration and data dependencies, while efficiently managing the computational resources. The underlying workflow language should make it easy to develop and maintain such complex workflows. Based on our prior experience in scaling-up the variant calling workflow [<xref rid="pone.0211608.ref026" ref-type="bibr">26</xref>&#x02013;<xref rid="pone.0211608.ref028" ref-type="bibr">28</xref>], and that of others [<xref rid="pone.0211608.ref029" ref-type="bibr">29</xref>&#x02013;<xref rid="pone.0211608.ref031" ref-type="bibr">31</xref>], we have put together a list of requirements to be satisfied while redesigning the workflow in Swift/T, and used them to evaluate the performance of the language for our purposes.</p><sec id="sec003"><title>Workflow design requirements</title><sec id="sec004"><title>Modularity</title><p>By definition, a workflow is a series of computational tasks, where outputs of one task serve as inputs to the next. Each task can be performed by a selection of bioinformatics software package options driven by the nature of the analysis (<xref rid="pone.0211608.t001" ref-type="table">Table 1</xref>). This flexibility can be enabled by constructing <italic>modular</italic> workflows, such that each executable is incorporated via a generic wrapper, making it easy for the developer to swap executables at the task level. For example, at the level of the <italic>Alignment</italic> task, the workflow language should permit easy swapping of BWA MEM [<xref rid="pone.0211608.ref032" ref-type="bibr">32</xref>] for Novoalign [<xref rid="pone.0211608.ref033" ref-type="bibr">33</xref>], conditionally on an option stated in a configuration or run file.</p><table-wrap id="pone.0211608.t001" orientation="portrait" position="float"><object-id pub-id-type="doi">10.1371/journal.pone.0211608.t001</object-id><label>Table 1</label><caption><title>Tools commonly used in genomic variant calling workflows.</title></caption><alternatives><graphic id="pone.0211608.t001g" xlink:href="pone.0211608.t001"/><table frame="box" rules="all" border="0"><colgroup span="1"><col align="left" valign="middle" span="1"/><col align="left" valign="middle" span="1"/></colgroup><thead><tr><th align="left" rowspan="1" colspan="1">Workflow Task</th><th align="center" rowspan="1" colspan="1">Bioinformatics tools</th></tr></thead><tbody><tr><td align="left" rowspan="1" colspan="1">Alignment</td><td align="center" rowspan="1" colspan="1">BWA MEM [<xref rid="pone.0211608.ref032" ref-type="bibr">32</xref>], Novoalign [<xref rid="pone.0211608.ref033" ref-type="bibr">33</xref>], Bowtie2 [<xref rid="pone.0211608.ref034" ref-type="bibr">34</xref>]<xref ref-type="table-fn" rid="t001fn001">&#x02020;</xref></td></tr><tr><td align="left" rowspan="1" colspan="1">Soringt SAM</td><td align="center" rowspan="1" colspan="1">Novosort [<xref rid="pone.0211608.ref033" ref-type="bibr">33</xref>], Samtools [<xref rid="pone.0211608.ref035" ref-type="bibr">35</xref>], Sambamba [<xref rid="pone.0211608.ref036" ref-type="bibr">36</xref>]<xref ref-type="table-fn" rid="t001fn001">&#x02020;</xref></td></tr><tr><td align="left" rowspan="1" colspan="1">Marking duplicates</td><td align="center" rowspan="1" colspan="1">Samblaster [<xref rid="pone.0211608.ref037" ref-type="bibr">37</xref>], Novosort [<xref rid="pone.0211608.ref033" ref-type="bibr">33</xref>], Picard [<xref rid="pone.0211608.ref038" ref-type="bibr">38</xref>]</td></tr><tr><td align="left" rowspan="1" colspan="1">Indel Realignment<xref ref-type="table-fn" rid="t001fn002">&#x02021;</xref></td><td align="center" rowspan="2" colspan="1">GATK [<xref rid="pone.0211608.ref039" ref-type="bibr">39</xref>]</td></tr><tr><td align="left" rowspan="1" colspan="1">Base Recalibration</td></tr><tr><td align="left" rowspan="1" colspan="1">Variant Calling</td><td align="center" rowspan="1" colspan="1">GATK HaplotypeCaller [<xref rid="pone.0211608.ref040" ref-type="bibr">40</xref>] or UnifiedGenotyper, Samtools mpileup<xref ref-type="table-fn" rid="t001fn001">&#x02020;</xref> [<xref rid="pone.0211608.ref035" ref-type="bibr">35</xref>], Platypus<xref ref-type="table-fn" rid="t001fn001">&#x02020;</xref> [<xref rid="pone.0211608.ref041" ref-type="bibr">41</xref>], Strelka2<xref ref-type="table-fn" rid="t001fn001">&#x02020;</xref> [<xref rid="pone.0211608.ref042" ref-type="bibr">42</xref>]</td></tr><tr><td align="left" rowspan="1" colspan="1">Joint Genotyping</td><td align="center" rowspan="1" colspan="1">GATK GenotypeGVCFs</td></tr></tbody></table></alternatives><table-wrap-foot><fn id="t001fn001"><p><sup>&#x02020;</sup> Options absent from our implementation</p></fn><fn id="t001fn002"><p><sup>&#x02021;</sup> Indel realignment is not necessary past GATK version 3.6, but can be included to comply with legacy analyses, and to enable the use of non-GATK variant callers that require realignment.</p></fn></table-wrap-foot></table-wrap><p>Many tools in <xref rid="pone.0211608.t001" ref-type="table">Table 1</xref> can take a long time to run on deeply-sequenced samples. This poses a problem for analyses run on computer clusters that have a restrictive maximum job walltime limit. Thus it is useful to break up the workflow into <italic>stages</italic>&#x02014;integrated sets of tasks that can be viewed as higher-level modules. Each module is then executed as its own cluster job that fits within the maximum walltime constraint. Chaining such modules together into one executable script effectively requires support for &#x0201c;workflows of workflows&#x0201d;.</p><p>The modular architecture has additional advantages conferring economy of compute resources and maintainability of code. It allows the user to run a portion of the workflow on the resources optimal for that particular stage, which is useful when a workflow has many fans and merges, but the fans have different node-widths among them. In case of runtime failure, it also enables users to restart the workflow at a failed stage without having to recompute successful upstream calculations. The latter advantage, however, is obviated if the workflow management system itself provides seamless workflow restart from the point of failure&#x02014;a required feature for complex workflows running at scale. Finally, modularity ensures that the implementation of individual stages can be altered without breaking the workflow, as long as inputs and outputs remain consistent. This way, workflows can be updated with new methodologies as the scientific field and respective tools evolve.</p></sec><sec id="sec005"><title>Data parallelism and scalability</title><p>A major expectation of a good workflow management system is the ability to develop a single code path that will automatically run in parallel on multiple samples and not force the user to manually code data-level parallelism. This <italic>implicit</italic> parallelism is not just a matter of convenience, but a significant performance boost. Bioinformatics tools are commonly implemented as multithreaded executables that are not MPI-enabled. Thus, in Bash workflows each task on each sample has to be run as an individual cluster job. If the cluster does not support job arrays, its workload manager can get overwhelmed by the high number of jobs when analyzing large datasets, leading to slow queues or failures. In contrast, a proper workflow management system should run a workflow as a single multi-node job, handle the placement of tasks across the nodes using embedded parallel mechanisms, such as MPI, and scale well with the number of samples.</p><p>The workflow manager should also support repetitive fans and merges in the code. For example, in variant calling it is common to cut the walltime of analysis by splitting the input sequencing data into chunks, performing alignment in parallel on all chunks, merging the aligned files per-sample for sorting and deduplication, and finally splitting again for parallel realignment and recalibration per-chromosome (<xref ref-type="fig" rid="pone.0211608.g001">Fig 1</xref>, left panel). This pattern of parallelization is more complex than merely running each task on each input sample&#x02014;yet is a common workflow requirement.</p><fig id="pone.0211608.g001" orientation="portrait" position="float"><object-id pub-id-type="doi">10.1371/journal.pone.0211608.g001</object-id><label>Fig 1</label><caption><title>Swift/T variant calling code, under the hood.</title><p>Left: Patterns of parallelization implemented in our Swift/T variant calling workflow. Right: Colored blocks represent the different stages of the workflow. Black blocks indicate methods within the respective modules.</p></caption><graphic xlink:href="pone.0211608.g001"/></fig><p>Finally, in bioinformatics we only need certain tools to run on multiple samples in parallel. Other tasks, such as creating folders, user notification or running QC on the whole stage, can and sometimes should be run sequentially. Therefore, it is beneficial to support differential use of data-level parallelism in some modules but not others.</p></sec><sec id="sec006"><title>Real-time logging and monitoring</title><p>When analyzing many samples at once, especially in a production environment where the data flow continuously through the cluster, it is important to have a good system for logging and monitoring progress of the jobs. At any moment during the run, the analyst should be able to assess (1) which stage of the workflow is running for every sample batch, (2) which samples may have failed and why, (3) which nodes are being used by the analysis, and their health status. Additionally, a well-structured post-analysis record of all events executed on each sample is necessary to ensure reproducibility of the analysis. This can be manually accomplished by developing a system of runtime logs captured via <monospace>stdout</monospace> dumps, and handling user notification via <monospace>mailx</monospace>, but both are quite tedious to code for complex, branched, multi-task workflows. A good workflow manager should provide these capabilities implicitly.</p></sec><sec id="sec007"><title>Portability</title><p>A developer should be able to write a workflow once and then deploy it in many environments: clusters with different node configuration, multiple queues and job schedulers, in HPC or in the cloud. For a workflow as complex as genomic variant calling, having to change and adapt for each different cluster is extremely counterproductive.</p></sec></sec><sec id="sec008"><title>Implementation of design requirements in Swift/T</title><sec id="sec009"><title>Modularity</title><p>The Swift/T language natively supports modularity by defining a &#x0201c;worker&#x0201d; for each executable (&#x0201c;leaf function&#x0201d; in Swift/T terminology), to be called at the appropriate place in the workflow. For example, we implemented the choice to align reads either using BWA MEM or Novoalign, as follows.</p><p specific-use="line">@dispatch=WORKER</p><p specific-use="line">app (file output, file outLog) bwa_mem (string bwaexe, string read1, string read2, string INDEX, string bwamemparams[], <bold>int</bold> PBSCORES, string rgheader)</p><p specific-use="line">{</p><p specific-use="line">&#x02003;bwaexe &#x0201c;mem&#x0201d; bwamemparams &#x0201c;-t&#x0201d; PBSCORES &#x0201c;-R&#x0201d; rgheader</p><p specific-use="line">&#x02003;&#x02003;INDEX read1 read2 @stdout=output @stderr=outLog;</p><p specific-use="line">}</p><p specific-use="line">@dispatch=WORKER</p><p specific-use="line">app (file output, file outLog) novoalign (string novoalignexe, string read1, string read2, string INDEX, string novoalignparams[], <bold>int</bold> PBSCORES, string rgheader)</p><p specific-use="line">{</p><p specific-use="line">&#x02003;novoalignexe &#x0201c;-c&#x0201d; PBSCORES &#x0201c;-d&#x0201d; INDEX &#x0201c;-f&#x0201d; read1 read2 &#x0201c;-o&#x0201d; &#x0201c;SAM&#x0201d;</p><p specific-use="line">&#x02003;&#x02003;rgheader @stdout=output @stderr=outLog;</p><p specific-use="line">}</p><p>Here each executable is wrapped using the generic &#x0201c;worker&#x0201d; syntax, and workers are conditionally invoked in a compact fashion to perform the Alignment task of the workflow.</p><p specific-use="line">import bioapps.align_dedup;</p><p specific-use="line"><bold>if</bold> (vars[&#x0201c;ALIGNERTOOL&#x0201d;] == &#x0201c;BWAMEM&#x0201d;)</p><p specific-use="line">{</p><p specific-use="line">&#x02003;exec_check(vars[&#x0201c;BWAEXE&#x0201d;], &#x0201c;BWAEXE&#x0201d;);</p><p specific-use="line">&#x02003;// <italic>Directly return the .sam file created from bwa_mem</italic></p><p specific-use="line">&#x02003;outputSam, alignedLog, tmpalignedLog = bwa_mem_logged(vars[&#x0201c;BWAEXE&#x0201d;], reads[0], reads[1], vars[&#x0201c;BWAINDEX&#x0201d;], [vars[&#x0201c;BWAMEMPARAMS&#x0201d;]], threads, rgheader, sampleName);</p><p specific-use="line">}</p><p specific-use="line"><bold>else</bold></p><p specific-use="line">{ // <italic>Novoalign is the default aligner</italic></p><p specific-use="line">&#x02003;exec_check(vars[&#x0201c;NOVOALIGNEXE&#x0201d;], &#x0201c;NOVOALIGNEXE&#x0201d;);</p><p specific-use="line">&#x02003;// <italic>Directly return the .sam file created from novoalign</italic></p><p specific-use="line">&#x02003;outputSam, alignedLog, tmpalignedLog = novoalign_logged(vars[&#x0201c;NOVOALIGNEXE&#x0201d;], reads[0], reads[1], vars[&#x0201c;NOVOALIGNINDEX&#x0201d;], [vars[&#x0201c;NOVOALIGNPARAMS&#x0201d;]], threads, rgheader, sampleName);</p><p specific-use="line">}</p><p>Subworkflows, or &#x0201c;stages&#x0201d;, are implemented as individual Swift/T app functions that are chained together by the primary workflow script (<xref ref-type="fig" rid="pone.0211608.g001">Fig 1</xref>, right panel). At each stage, the user can direct the workflow to generate the output files necessary for the next stage, or pass on the output generated from a previous run. At the end of each stage, there is an implicit wait instruction that ensures all tasks have finished before the next stage can run (also see next section).</p></sec><sec id="sec010"><title>Data parallelism and scalability</title><p>The &#x0201c;data flow&#x0201d; programming model of Swift/T implicitly supports parallel execution of tasks. Statements are evaluated in parallel unless prohibited by a data dependency or resource constraints, without the developer needing to explicitly code parallelism or synchronization. Swift/T will automatically wait on a process to finish if the next step depends on its output. For example, after read alignment, the step to mark duplicates in an aligned BAM (<monospace>picard_logged</monospace>) depends on the previous step (<monospace>novosort_logged</monospace>), which produces a sorted BAM (<monospace>alignedsortedbam</monospace>) to serve as input to the deduplication step. The essense of implicit parallelization is that <monospace>picard_logged</monospace> will wait until <monospace>novosort_logged</monospace> is finished due to this data dependency.</p><p specific-use="line">// <italic>Sort</italic></p><p specific-use="line">alignedsortedbam, sortLog, tmpnovosortLog = novosort_logged(vars[&#x0201c;NOVOSORTEXE&#x0201d;], alignedBam, vars[&#x0201c;TMPDIR&#x0201d;], threads, [], string2int(vars[&#x0201c;NOVOSORT_MEMLIMIT&#x0201d;]), sampleName);</p><p specific-use="line">// <italic>Mark Duplicates</italic></p><p specific-use="line">dedupSortedBam, picardLog, metricsfile, tmppicardLog = picard_logged(vars[&#x0201c;JAVAEXE&#x0201d;], vars[&#x0201c;JAVA_MAX_HEAP_SIZE&#x0201d;], vars[&#x0201c;PICARDJAR&#x0201d;], vars[&#x0201c;TMPDIR&#x0201d;], alignedsortedbam, sampleName);</p><p>There are some places in the workflow where a stage must wait on another, yet a direct data dependency does not exist. For example, log information begins to be produced right away as the Alignment module begins execution. The output log folder must first exist for this purpose, but the asynchronous parallel execution function of Swift/T may start the Alignment module before it runs the statement to create the log folder. This can be addressed by explicitly forcing the wait either via the &#x0201c;=&#x0003e;&#x0201d; symbol, via <monospace>wait()</monospace> statement, or via a dummy variable that &#x0201c;fakes&#x0201d; a data dependency.</p><p specific-use="line">mkdir(LogDir) =&#x0003e;</p><p specific-use="line">mkdir(AlignDir) =&#x0003e;</p><p specific-use="line"><bold>void</bold> mkdirSignal = mkdir(tmpLogDir);</p><p specific-use="line">wait (mkdirSignal) {</p><p specific-use="line">&#x02003;alignedsam = alignReads(vars, sampleName, reads, rgheader);</p><p specific-use="line">}</p><p>The above example illustrates the use of a <monospace>wait()</monospace> statement, and also the drawbacks of enforcing implicit parallelism across the entire workflow. In bioinformatics, patterns of execution are usually mixed: individual commands running in parallel on many samples are intermixed with serial blocks of code that perform quality control, data management, user notification, or other tasks. It would be useful to have these blocks fenced-off to prevent Swift/T from attempting to run them all asynchronously and in parallel. Parsl, the next step in evolution of Swift language, has that capability [<xref rid="pone.0211608.ref043" ref-type="bibr">43</xref>, <xref rid="pone.0211608.ref044" ref-type="bibr">44</xref>].</p><p>Nonetheless, Swift/T does take care of parallelism in a smart and transparent way that makes efficient use of resources. The user should still take care to request a reasonable number of nodes: too few&#x02014;and many samples will be processed in series; too many&#x02014;and resources will be reserved unnecessarily. Beyond that there is no need to worry about task placement, as Turbine will take care of it. This is extremely useful, because bioinformatics programs do not always scale well to the full number of cores available on the compute nodes, and therefore running multiple instances of a task simultaneously on the same node may improve the overall efficiency. For example, BWA MEM normally scales well up to eight threads, so running two eight-thread processes in parallel on a 16-core node is more efficient than running two sixteen-thread processes in series. We implemented this as user-level options that specify the number of cores per node and the number of programs to run on each node simultaneously. From there the workflow determines the number of threads to use for each bioinformatics program, and Swift/T uses Asynchronous Dynamic Load Balancing (ADLB) [<xref rid="pone.0211608.ref045" ref-type="bibr">45</xref>] to distribute those programs across nodes as they become available at run time. Without ADLB one would have to code this explicitly for each job scheduler, which becomes very complicated on clusters that do not support node sharing, i.e. only one job is allowed to run per node. In the latter case a vanilla Bash workflow [<xref rid="pone.0211608.ref046" ref-type="bibr">46</xref>] would need to incorporate an MPI wrapper (e.g. [<xref rid="pone.0211608.ref047" ref-type="bibr">47</xref>]) to take care of program placement across nodes. The MPI backend of ADLB fulfills that function in Swift/T.</p><p>We verified correctness of the task dependency chains and parallel execution by tracking start and end times of each task for multiple samples in some of our tests (see next section and <xref ref-type="fig" rid="pone.0211608.g002">Fig 2</xref>).</p><fig id="pone.0211608.g002" orientation="portrait" position="float"><object-id pub-id-type="doi">10.1371/journal.pone.0211608.g002</object-id><label>Fig 2</label><caption><title>Timing provenance tracking of a 3-sample pipeline run (synthetic whole exome sequencing dataset at 30X, 50X and 70X) on Biocluster [<xref rid="pone.0211608.ref050" ref-type="bibr">50</xref>].</title><p>This plot view is interactive, allowing full pan and zoom and was generated using plotly library in R.</p></caption><graphic xlink:href="pone.0211608.g002"/></fig></sec><sec id="sec011"><title>Real-time logging and monitoring</title><p>The underlying MPI-based implementation of Swift/T logic makes it possible to leverage standard MPI logging libraries to collect run-time details about the status of every sample. We used the Message Passing Environment (MPE) library [<xref rid="pone.0211608.ref045" ref-type="bibr">45</xref>] to log the usage of the MPI library itself and ADLB calls [<xref rid="pone.0211608.ref048" ref-type="bibr">48</xref>], and implemented visualization in Jumpshot viewer. To enable such logging requires installation of the MPE library in addition to the standard Swift/T components (C-utils, ADLB library, Turbine and STC). This turned out to be a bit cumbersome because it requires creation of new functions: <monospace>tcl</monospace> wrappers around MPE to log when each executable starts and stops.</p><p>Another approach to tracking the workflow run time execution is to manually implement Swift/T leaf functions such that the start and end timing of each function are logged. A timing graph can be generated using R script based on this information, showing the analysis steps across samples, chromosomes and specific applications (<xref ref-type="fig" rid="pone.0211608.g002">Fig 2</xref>). Interactivity is added via Shiny R package [<xref rid="pone.0211608.ref049" ref-type="bibr">49</xref>]. This is a fairly manual approach, little better than the Bash <monospace>echo date</monospace> statements. Nonetheless, it permits one to view the patterns of pipeline execution even if it fails, and partial logs can similarly be viewed as the pipeline is running. To obtain the up-to-date trace, one can type in the R terminal:</p><p specific-use="line"><bold>if</bold> (!require(shiny)) {</p><p specific-use="line">&#x02003;install.packages(&#x02018;shiny&#x02019;)</p><p specific-use="line">&#x02003;library(shiny)</p><p specific-use="line">}</p><p specific-use="line">runGitHub(repo = &#x0201c;ncsa/Swift-T-Variant-Calling&#x0201d;, ref = &#x0201c;master&#x0201d;, \subdir = &#x0201c;src/plotting_app&#x0201d;)</p><p>In conclusion, logging and monitoring can be usefully implemented in a Swift/T workflow, but are not adequately supported at the time of this writing and require quite a bit of work.</p></sec><sec id="sec012"><title>Portability</title><p>Swift/T runs as an MPI program that uses the Turbine [<xref rid="pone.0211608.ref017" ref-type="bibr">17</xref>] and ADLB [<xref rid="pone.0211608.ref045" ref-type="bibr">45</xref>] libraries to manage and distribute the workflow execution on local compute resources (desktop/laptop), parallel computers (clusters/HPCs), and distributed systems (grid/cloud). Its built-in wrappers can launch jobs on many common resource schedulers, such as PBS Torque, Cobalt, Cray aprun, and SLURM [<xref rid="pone.0211608.ref051" ref-type="bibr">51</xref>], using the <monospace>-m</monospace> flag passed to the Swift/T executable, i.e. <monospace>swift-t -m slurm</monospace>. Through these unified wrappers, the user is only left with the trivial task of specifying the required computational resources: queue, memory, wall time, etc.:</p><p specific-use="line"><bold>export</bold> PPN=&#x0003c;PROGRAMS_PER_NODE&#x0003e;</p><p specific-use="line"><bold>export</bold> NODES=&#x0003c;NUMBER_OF_NODES_TO_RESERVE&#x0003e;</p><p specific-use="line"><bold>export</bold> PROCS=$(($PPN * $NODES))</p><p specific-use="line"><bold>export</bold> WALLTIME=&#x0003c;HH:MM:SS&#x0003e;</p><p specific-use="line"><bold>export</bold> QUEUE=&#x0003c;Queue&#x0003e;</p><p specific-use="line"><bold>export</bold> SWIFT_TMP=/path/to/directory/temp</p><p specific-use="line">swift-t -m slurm -O3 -n $PROCS</p><p specific-use="line">&#x02003;-o /path/to/where/compiled/should/be/saved/compiled.tic</p><p specific-use="line">&#x02003;-I /path/to/Swift-T-Variant-Calling/src/</p><p specific-use="line">&#x02003;-r /path/to/Swift-T-Variant-Calling/src/bioapps/path/to/Swift-T-Variant-Calling/src/VariantCalling.swift</p><p specific-use="line">&#x02003;-runfile=/path/to/your.runfile</p><p>We verified both portability and scalability conferred by Swift/T by testing on a variety of HPC systems with a range of cluster setups, job schedulers and patterns of execution (<xref rid="pone.0211608.t002" ref-type="table">Table 2</xref>). Portability across resource schedulers works as expected, although unique setups may require tweaks, such as setting of environmental variables [<xref rid="pone.0211608.ref052" ref-type="bibr">52</xref>], with configuration of 1 sample/node and 2 samples/node.</p><table-wrap id="pone.0211608.t002" orientation="portrait" position="float"><object-id pub-id-type="doi">10.1371/journal.pone.0211608.t002</object-id><label>Table 2</label><caption><title>Swift/T delivers on its promise of portability and scalability.</title><p>Synthetic data were generated using the NEAT synthetic read simulator [<xref rid="pone.0211608.ref054" ref-type="bibr">54</xref>]. Node sharing column indicates whether the cluster permits jobs to share the same node.</p></caption><alternatives><graphic id="pone.0211608.t002g" xlink:href="pone.0211608.t002"/><table frame="box" rules="all" border="0"><colgroup span="1"><col align="left" valign="middle" span="1"/><col align="left" valign="middle" span="1"/><col align="left" valign="middle" span="1"/><col align="left" valign="middle" span="1"/><col align="left" valign="middle" span="1"/><col align="left" valign="middle" span="1"/></colgroup><thead><tr><th align="center" rowspan="1" colspan="1">System</th><th align="center" rowspan="1" colspan="1">Resource manager</th><th align="left" rowspan="1" colspan="1">Node type</th><th align="center" rowspan="1" colspan="1"># nodes per run</th><th align="center" rowspan="1" colspan="1">Node sharing</th><th align="center" rowspan="1" colspan="1">Test data</th></tr></thead><tbody><tr><td align="center" rowspan="1" colspan="1">iForge [<xref rid="pone.0211608.ref055" ref-type="bibr">55</xref>]</td><td align="center" rowspan="1" colspan="1">PBS Torque</td><td align="left" rowspan="1" colspan="1">IvyBridge,<break/>20 cores,<break/>256 GB RAM</td><td align="center" rowspan="1" colspan="1">1-8</td><td align="center" rowspan="1" colspan="1">No</td><td align="center" rowspan="1" colspan="1">Soy NAM [<xref rid="pone.0211608.ref056" ref-type="bibr">56</xref>] using 2, 6, 12, or 16 sample batches <xref ref-type="table-fn" rid="t002fn001">&#x02020;</xref></td></tr><tr><td align="center" rowspan="1" colspan="1">XSEDE Stampede2 [<xref rid="pone.0211608.ref057" ref-type="bibr">57</xref>]</td><td align="center" rowspan="1" colspan="1">Slurm</td><td align="left" rowspan="1" colspan="1">KNL,<break/>68 cores,<break/>4 hardware threads/core,<break/>96 GB DDR4,<break/>16 GB MCDRAM</td><td align="center" rowspan="1" colspan="1">1</td><td align="center" rowspan="1" colspan="1">Yes</td><td align="center" rowspan="1" colspan="1">GIAB NA12878 Illumina HiSeq Exome (NIST7035) [<xref rid="pone.0211608.ref058" ref-type="bibr">58</xref>];<break/>Synthetic chr1 exome seq 50X</td></tr><tr><td align="center" rowspan="1" colspan="1">Biocluster [<xref rid="pone.0211608.ref050" ref-type="bibr">50</xref>]</td><td align="center" rowspan="1" colspan="1">Slurm</td><td align="left" rowspan="1" colspan="1">Dell PowerEdge R620,<break/>24 Cores,<break/>384 GB RAM</td><td align="center" rowspan="1" colspan="1">1; 3</td><td align="center" rowspan="1" colspan="1">Yes</td><td align="center" rowspan="1" colspan="1">Synthetic WES 30X;<break/>Synthetic WES 50X;<break/>Synthetic WES 70X</td></tr><tr><td align="center" rowspan="1" colspan="1">Single server at CBSB, H3ABioNet node</td><td align="center" rowspan="1" colspan="1">N/A</td><td align="left" rowspan="1" colspan="1">HP Proliant dl380p gen. 8<break/>24 cores<break/>125 G RAM</td><td align="center" rowspan="1" colspan="1">1</td><td align="center" rowspan="1" colspan="1">Yes</td><td align="center" rowspan="1" colspan="1">Synthetic chr1 exome seq 50X</td></tr></tbody></table></alternatives><table-wrap-foot><fn id="t002fn001"><p><sup>&#x02020;</sup> This Swift/T variant calling workflow was also used on iForge for a variety of analyses on WES and WGS data in different species.</p></fn></table-wrap-foot></table-wrap><p>All other functionality of our workflow was also fully validated on soybean and human Illumina sequencing data, as well as synthetic datasets. The complete list of tested options and features can be found on our GitHub repository [<xref rid="pone.0211608.ref053" ref-type="bibr">53</xref>].</p></sec><sec id="sec013"><title>Robustness against failure</title><p>Swift/T has native support for restarting a task after failure. The user controls the maximum number of allowed retries, and a randomized exponential backoff delay is applied between them, attempting to rerun the task until success or the pipeline terminates, whichever is sooner. Retries do not correct for bugs in the pipeline code, but only for Swift/T leaf function failures that are not related to compilation errors or &#x0201c;<monospace>assert</monospace>&#x0201d; failures.</p><p>This is useful when applications fail for nondeterministic reasons, such as a filesystem under load slowing down I/O and making the application wait for data, thus causing it to time out. However, when running wide jobs on large clusters, it is also necessary to have robustness against node failure. In collaboration with the Swift/T team, we introduced the support for moving the retries of the failed task to another, randomly chosen, MPI rank. For reproducibility purposes, random number generation in Swift/T defaults to start from the same seed, which is dependent on the MPI rank where the process is to be evaluated, unless the seed is specified by the turbine variable &#x0201c;<monospace>TURBINE_SRAND</monospace>&#x0201d;.</p></sec></sec></sec><sec sec-type="conclusions" id="sec014"><title>Discussion</title><p>Complexity of problems in biology means that nearly every kind of analytics is a multi-step process, a pipeline of individual analyses that feed their outputs to each other (e.g. [<xref rid="pone.0211608.ref059" ref-type="bibr">59</xref>&#x02013;<xref rid="pone.0211608.ref061" ref-type="bibr">61</xref>]). The algorithms and methods used for those processing steps are in continual development by scientists, as computational biology and specifically bioinformatics are still rapidly developing. Few studies can be accomplished via a single integrated executable. Instead, we deal with a heterogeneous medley of software of varied robustness and accuracy, frequently with multiple packages available to perform seemingly the same kind of analysis&#x02014;yet subtly differing in applicability depending on the species or input data type. Thus bioinformatics today requires advanced, flexible automation via modular data-driven workflows. This is a tall order, considering the added requirements of scalability, portability and robustness. Genomics is a big data field: we no longer talk about sequencing individual organisms, but every baby being born (&#x0223c;500 per day per state in the US) and every patient who comes in for a checkup (a million per year in a major hospital), not to mention the massive contemporary crop and livestock genotyping efforts. The workflows managing data analysis at that scale must take full advantage of parallelism on modern hardware, be portable among multiple HPC systems and the cloud, be robust against data corruption and hardware failure, and provide full logging and reporting to the analyst for monitoring and reproducibility.</p><p>Recently there has been an incredible upsurge in developing scientific workflow management systems, enough to have resulted in calls for standardization and quality assurance [<xref rid="pone.0211608.ref062" ref-type="bibr">62</xref>]. In this manuscript we reviewed our experience with one such system, Swift/T, touching on workflow management, performance and scalability issues; security was deemed out of scope.</p><sec id="sec015"><title>Pros and cons of Swift/T for bioinformatics workflows</title><p>Swift/T is a powerful and versatile language that offers many advantages for production large-scale bioinformatics workflows. It allowed us to fulfill most of the requirements outlined in the <italic>Requirements</italic> section, for variant calling workflow as a use case. Below is our summary of pros and cons based on that experience.</p><p><underline>Portability</underline> may well be the greatest strength of Swift/T: a workflow written in Swift/T can be executed on a wide variety of compute infrastructures without changing the code, and the user does not need to know about the underlying scheduling environment on the cluster. The language abstracts away the low level concerns such as load balancing, inter-process communication and synchronization of tasks automatically through its compiler (stc) and runtime engine (Turbine), allowing the programmer to focus on the workflow design [<xref rid="pone.0211608.ref063" ref-type="bibr">63</xref>]. Significantly, Swift/T was designed for use in HPC and distributed cluster environments, where the use of containerization is still largely limited due to performance and security concerns. It does not natively support containerization, which would have made porting bioinformatics workflows even more more convenient, as it would have eliminated the need to install all of the (numerous) dependencies. Unfortunately, this is not possible with Swift/T at the moment.</p><p><underline>Modularity</underline> is another excellent advantage of Swift/T. The language glues together command line tools: either directly by wrapping them in Swift/T app functions if they solely operate on files; or indirectly as tcl packages with corresponding Swift/T app function declarations if they produce numerical or string outputs. Under the hood, Swift/T code is actually compiled into Tcl syntax before Turbine gets to manage the distribution and execution of tasks to compute resources. This further means that wrapping any C, C++ or Fortran application is also easy due to Tcl. This leaf-function modularization, and the ease of integrating code written in other languages into Swift/T environment, is the reason why we preferred this to its predecessor Swift/K [<xref rid="pone.0211608.ref016" ref-type="bibr">16</xref>], which had superior provenance and checkpointing capabilities [<xref rid="pone.0211608.ref064" ref-type="bibr">64</xref>].</p><p><underline>Implicit data parallelism and scalability</underline> of Swift/T is a powerful way of enabling big data analyses by increasing the amount of simultaneous computation. The language particularly lends itself to use cases that require asynchronous rapid-fire of small, quick parallel jobs [<xref rid="pone.0211608.ref065" ref-type="bibr">65</xref>]. That is one of the many kinds of bioinformatics workloads, but not the most typical one for primary analysis of genomic data. In this field we frequently require a simple wrapper to run a single, time-consuming step on a large number of samples or other units of data level parallelization: i.e. conversion of several thousand BAMs back to FASTQs for reanalysis with the most recent reference genome. However, the data flow task parallelism framework has a substantial learning curve, despite offering familiar control flow statements and expressions in C-like syntax [<xref rid="pone.0211608.ref066" ref-type="bibr">66</xref>]. Coding and debugging can require a more substantial effort than say, Nextflow [<xref rid="pone.0211608.ref067" ref-type="bibr">67</xref>], and that can be a barrier for biologists. An additional inconvenience is that Swift/T does not support piping between applications, which is extensively used in bioinformatics analyses, as they are still overwhelmingly file-based pipelines.</p><p><underline>Robustness against failures</underline> in Swift/T is supported via leaf function retries, attempting to rerun the task on one of the available ranks. This confers resilience against nondeterministic failures, such as filesystem or cluster interconnect hiccups as well as hardware failures&#x02014;an important advantage for big data genomics.</p><p><underline>Real time logging</underline> is provided via runtime Turbine logs, with user-controlled verbosity. These can be quite detailed but challenging to use for debugging when the analyst must understand whether a failure occurred due to data, a bioinformatics application or the Swift/T code bug. The greatest difficulty stems from asynchronous log records, caused by asynchronous execution of tasks. Thus an error printout rarely corresponds to the execution message that immediately precedes it in the log, and finding the failed tasks from the log alone is nearly impossible. We had to manually implement the per-task and per-executable logs in our code, to counteract this inconvenience.</p><p>In summary, Swift/T language lends itself to creating highly portable, modular and implicitly parallel workflows. It is very powerful, especially when a workflow consists of raw code pieces written in C, C++, Fortran, etc. However, it may be overkill for those bioinformatics workflows that consist of pre-compiled executables glued together. The lack of support for piping between applications is a major drawback for big-data bioinformatics, resulting in proliferation of intermediary files. Portability, the main advantage of Swift/T, could perhaps be accomplished in simpler ways. In the following sections we review other workflow management systems, to put Swift/T into the broader context of life sciences.</p></sec><sec id="sec016"><title>Comparison with GATK reference pipelines</title><p>Officially, the GATK provides a set of 2 independent reference pipeline implementations, one for per-sample calling, and the other for joint genotyping across a cohort of samples. These pipelines are written in WDL (<ext-link ext-link-type="uri" xlink:href="https://github.com/gatk-workflows/">https://github.com/gatk-workflows/</ext-link>), which is runnable via Cromwell and Toil (alpha support pre-dates Draft-3 of the language). These reference implementations have been very useful for a large community of bioinformaticians, so we compare them to our Swift/T implementation to highlight the differences among them.</p><p><underline>GATK version</underline>: Due to early start, our Swift/T pipeline was written with GATK&#x0003c;4 invocations, whereas the GATK reference WDL pipelines leverage GATK4+. However, as discussed above, Swift/T language makes the workflow trrivially extensible, such that the switch to GATK4 or addition of further steps can be easily accomplished without the loss of maintainability or ease of deployment.</p><p><underline>Analysis stages</underline>: user of the Broad&#x02019;s GATK pipeline can either analyze a single sample from the alignment stage up to producing a gvcf file from the HaplotypeCaller, or jointly analyze the gvcfs of many samples together. The user of our Swift/T pipeline may run complete variant calling for a cohort of samples from alignment to joint calling, or may run a specific stage desired independently by defining the desired analysis stages in a run file. We have not implemented the joint calling, but the repository is open for contributions.</p><p><underline>Analysis tools</underline>: The reference GATK pipelines assume specific tools for carrying the analysis. The Swift/T implementation was designed to give the user more freedom for specifying tools at each stage. Our implementation makes it easy for the end user to comply with functional equivalence guidelines if desired (or not, depending on the specifics of a given study design).</p><p><underline>Language &#x00026; semantics</underline>: The flexibility in choosing tools and analysis stages in our Swift/T pipeline stems from the expressiveness of the Swift/T language itself and the coherence between the language and its execution engine. The two execution engines for running WDL code, Cromwell and Toil, lack support for nested scatter blocks and nested conditionals within scatter blocks, respectively. In other words, parallelization and conditionals are not flexibly supported by Cromwell and Toil.</p><p><underline>HPC deployment</underline>: For WDL pipelines, Cromwell does work in cluster environments, but has limited scalability in <monospace>run</monospace> mode (analysis confined to single node). Supporting the <monospace>server</monospace> mode is not attractive to some HPC system administrators for security reasons. In contrast, Swift/T is a language and engine for running analysis on HPC environments, and readily supports a wide range of HPC job schedulers.</p><p><underline>Cloud deployment</underline>: A motive for WDL and its engines is running analysis jobs in the cloud. In fact, the GATK pipelines implemented by the Broad team are highly cost-optimized for running in both Google Cloud Platform (via FireCloud) and AWS (via AWS batch). On the other hand, Swift/T has less support for usage in cloud environments.</p><p><underline>Containerization</underline>: Since a main driver for Swift/T development is scalable analysis in HPC environments, it does not readily support containerization technology, nor does our pipeline. WDL on the other hand was developed with an aim to run analysis pipelines in the cloud, and hence containerization is supported via both its engines, Cromwell and Toil.</p></sec><sec id="sec017"><title>Challenges in building the &#x0201c;right&#x0201d; workflow manager for computational biology</title><p>The implementation of workflow management systems (WMS) for computational biology, bioinformatics and genomics is strongly influenced by culture and prevailing expertise in the multidisciplinary fields. One has to contend with two populations of scientists: those with strong biology background, driven to solve research problems, to whom programming is an unavoidable yet joyless burden; and those able to produce complex and capable code that is not perhaps very user-friendly. This creates a real problem with adoption of any software, including a WMS: the harder it is for a scientist to use a software package compared to an ad-hoc hack, the lower its widespread acceptance in the community [<xref rid="pone.0211608.ref062" ref-type="bibr">62</xref>]. Perhaps that&#x02019;s why simple glue solutions via Bash, Perl, Python, Make, CMake and similar, have persisted for so long. Their shallow learning curve permits quick production of short-term analytic solutions, which get used over and over despite poor scaling with growing dataset size, and despite requiring a lot of work to port among compute systems.</p><p>Scientific Workflow Systems are the next step up from scripting. Those that provide a graphical user interface, such as Taverna [<xref rid="pone.0211608.ref068" ref-type="bibr">68</xref>], Galaxy [<xref rid="pone.0211608.ref069" ref-type="bibr">69</xref>] and Kepler [<xref rid="pone.0211608.ref070" ref-type="bibr">70</xref>] (<xref rid="pone.0211608.t003" ref-type="table">Table 3</xref>), have good accessibility for scientists with less programming experience but require quite a bit of effort to be set up and maintained, and have limited set of features. In contrast, lower level systems with a command-line interface (CLI), such as Snakemake [<xref rid="pone.0211608.ref071" ref-type="bibr">71</xref>], Luigi [<xref rid="pone.0211608.ref072" ref-type="bibr">72</xref>], BcBio [<xref rid="pone.0211608.ref073" ref-type="bibr">73</xref>], Bpipe [<xref rid="pone.0211608.ref074" ref-type="bibr">74</xref>], are easier to maintain and share, provide good documentation and reproducibility, fault tolerance, and task automation; however, they require a lot more programming expertise.</p><table-wrap id="pone.0211608.t003" orientation="portrait" position="float"><object-id pub-id-type="doi">10.1371/journal.pone.0211608.t003</object-id><label>Table 3</label><caption><title>Popular workflow management systems.</title></caption><alternatives><graphic id="pone.0211608.t003g" xlink:href="pone.0211608.t003"/><table frame="box" rules="all" border="0"><colgroup span="1"><col align="left" valign="middle" span="1"/><col align="left" valign="middle" span="1"/><col align="left" valign="middle" span="1"/><col align="left" valign="middle" span="1"/><col align="left" valign="middle" span="1"/></colgroup><thead><tr><th align="center" rowspan="1" colspan="1">Comparison aspect</th><th align="center" rowspan="1" colspan="1">Swift/T [<xref rid="pone.0211608.ref015" ref-type="bibr">15</xref>]</th><th align="center" rowspan="1" colspan="1">NextFlow [<xref rid="pone.0211608.ref067" ref-type="bibr">67</xref>]</th><th align="center" rowspan="1" colspan="1">Galaxy [<xref rid="pone.0211608.ref069" ref-type="bibr">69</xref>]</th><th align="center" rowspan="1" colspan="1">Kepler [<xref rid="pone.0211608.ref070" ref-type="bibr">70</xref>]</th></tr></thead><tbody><tr><td align="center" rowspan="1" colspan="1">Nature</td><td align="center" rowspan="1" colspan="1">WL<xref ref-type="table-fn" rid="t003fn001"><sup>&#x02020;</sup></xref> and execution engine</td><td align="center" rowspan="1" colspan="1">WL and execution engine</td><td align="center" rowspan="1" colspan="1">Web interface</td><td align="center" rowspan="1" colspan="1">WL and execution engine</td></tr><tr><td align="center" rowspan="1" colspan="1">Support community standard WL?</td><td align="center" rowspan="1" colspan="1">No</td><td align="center" rowspan="1" colspan="1">No</td><td align="center" rowspan="1" colspan="1">CWL</td><td align="center" rowspan="1" colspan="1">No</td></tr><tr><td align="center" rowspan="1" colspan="1">User interface</td><td align="center" rowspan="1" colspan="1">CLI</td><td align="center" rowspan="1" colspan="1">CLI,<break/>REPL [<xref rid="pone.0211608.ref075" ref-type="bibr">75</xref>],<break/>IDE [<xref rid="pone.0211608.ref076" ref-type="bibr">76</xref>]</td><td align="center" rowspan="1" colspan="1">GUI</td><td align="center" rowspan="1" colspan="1">GUI,<break/>CLI,<break/>Jupyter notebooks</td></tr><tr><td align="center" rowspan="1" colspan="1">Programming paradigm [<xref rid="pone.0211608.ref077" ref-type="bibr">77</xref>]</td><td align="center" rowspan="1" colspan="1">Dataflow</td><td align="center" rowspan="1" colspan="1">Dataflow</td><td align="center" rowspan="1" colspan="1">Sequential [<xref rid="pone.0211608.ref078" ref-type="bibr">78</xref>]</td><td align="center" rowspan="1" colspan="1">Sequential,<break/>dataflow,<break/>process network or continuous time [<xref rid="pone.0211608.ref079" ref-type="bibr">79</xref>]</td></tr><tr><td align="center" rowspan="1" colspan="1">Containerization support</td><td align="center" rowspan="1" colspan="1">None</td><td align="center" rowspan="1" colspan="1">Docker,<break/>Singularity</td><td align="center" rowspan="1" colspan="1">Docker,<break/>Singularity</td><td align="center" rowspan="1" colspan="1">Docker</td></tr><tr><td align="center" rowspan="1" colspan="1">Scalability [<xref rid="pone.0211608.ref080" ref-type="bibr">80</xref>]</td><td align="center" rowspan="1" colspan="1">Extreme scale [<xref rid="pone.0211608.ref081" ref-type="bibr">81</xref>]</td><td align="center" rowspan="1" colspan="1">Yes</td><td align="center" rowspan="1" colspan="1">Complicated <xref ref-type="table-fn" rid="t003fn002"><sup>&#x02021;</sup></xref> [<xref rid="pone.0211608.ref069" ref-type="bibr">69</xref>]</td><td align="center" rowspan="1" colspan="1">Yes</td></tr><tr><td align="center" rowspan="1" colspan="1">Checkpointing and caching</td><td align="center" rowspan="1" colspan="1">No</td><td align="center" rowspan="1" colspan="1">Yes</td><td align="center" rowspan="1" colspan="1">Yes</td><td align="center" rowspan="1" colspan="1">Yes</td></tr><tr><td align="center" rowspan="1" colspan="1">Portability <xref ref-type="table-fn" rid="t003fn003"><sup>&#x000b6;</sup></xref></td><td align="center" rowspan="1" colspan="1">Cray aprun, LSF</td><td align="center" rowspan="1" colspan="1">LSF, NQSII,<break/>HTCondor,<break/>Kubernetes,<break/>Ignite,<break/>DNAnexus</td><td align="center" rowspan="1" colspan="1">LSF, HTCondor,<break/>Galaxy Pulsar [<xref rid="pone.0211608.ref082" ref-type="bibr">82</xref>]<break/>XSEDE Jetstream [<xref rid="pone.0211608.ref083" ref-type="bibr">83</xref>]</td><td align="center" rowspan="1" colspan="1">Open stack,<break/>Google cloud,<break/>Apache Mesos</td></tr><tr><td align="center" rowspan="1" colspan="1">Distributed execution</td><td align="center" rowspan="1" colspan="1">MPI-based</td><td align="center" rowspan="1" colspan="1">Apache Ignite/ MPI</td><td align="center" rowspan="1" colspan="1">Spark [<xref rid="pone.0211608.ref084" ref-type="bibr">84</xref>], Hadoop [<xref rid="pone.0211608.ref085" ref-type="bibr">85</xref>]</td><td align="center" rowspan="1" colspan="1">Spark, Hadoop</td></tr><tr><td align="center" rowspan="1" colspan="1">Supported compute architecture</td><td align="center" rowspan="1" colspan="1">Homogeneous</td><td align="center" rowspan="1" colspan="1">Homogeneous or heterogeneous</td><td align="center" rowspan="1" colspan="1">Not clear</td><td align="center" rowspan="1" colspan="1">Homogeneous or heterogeneous</td></tr><tr><td align="center" rowspan="1" colspan="1">Compute resource allocation</td><td align="center" rowspan="1" colspan="1">Reserved a priori</td><td align="center" rowspan="1" colspan="1">Reserved a priori</td><td align="center" rowspan="1" colspan="1">Multiple deployment strategies [<xref rid="pone.0211608.ref086" ref-type="bibr">86</xref>]</td><td align="center" rowspan="1" colspan="1">Allocated dynamically</td></tr></tbody></table></alternatives><table-wrap-foot><fn id="t003fn001"><p><sup>&#x02020;</sup> WL = workflow language; REPL = Read-Eval-Print-Loop console; CLI = Command Line Interface; GUI = graphical user interface.</p></fn><fn id="t003fn002"><p><sup>&#x02021;</sup> Recent optimizations of Galaxy for <italic>User interface scalability</italic> and <italic>Server scalability</italic> enable analysis of large datasets for many users.</p></fn><fn id="t003fn003"><p><sup>&#x000b6;</sup> All these workflow management systems can run on a single server, on clusters managed by PBS, Grid Engine, Slurm, and on AWS.</p></fn></table-wrap-foot></table-wrap><p>The cultural gap in capabilities between developers and end users can be closed via implementation of visual programming (GUI-like interface with CLI-like capabilities), thus allowing for customization of analytic tools and technologies with little to no programming background. But, ultimately the right approach to providing scalability and interoperability is probably via implementation of generic low level bioinformatics specific libraries to be used universally across different sets of tools [<xref rid="pone.0211608.ref087" ref-type="bibr">87</xref>].</p><p>In the meantime, great strides are being made by the community in trying out different approaches to scientific workflow management and automation, aiming to satisfy the complex requirements [<xref rid="pone.0211608.ref012" ref-type="bibr">12</xref>]:
<list list-type="bullet"><list-item><p>seamlessly managing both serial and parallel steps without creating data waits and computational bottlenecks;</p></list-item><list-item><p>managing complex task dependencies via explicit configuration (e.g. a user-produced XML file in Pegasus [<xref rid="pone.0211608.ref088" ref-type="bibr">88</xref>]), language-specific syntax (BigDataScript [<xref rid="pone.0211608.ref089" ref-type="bibr">89</xref>]), automatic construction of workflow graphs (Swift [<xref rid="pone.0211608.ref016" ref-type="bibr">16</xref>], WDL [<xref rid="pone.0211608.ref014" ref-type="bibr">14</xref>], Nextflow [<xref rid="pone.0211608.ref067" ref-type="bibr">67</xref>]), rule-based approaches (Ruffus [<xref rid="pone.0211608.ref090" ref-type="bibr">90</xref>] and bpipe [<xref rid="pone.0211608.ref074" ref-type="bibr">74</xref>]) or implicit conventions, while abstracting away from HPC cluster management concerns (Job Management System [<xref rid="pone.0211608.ref091" ref-type="bibr">91</xref>]);</p></list-item><list-item><p>flexibility to work with varied software being run by the workflow (i.e. via containerization), and widely variegated parameter values and configurations (i.e. through workflow autogeneration [<xref rid="pone.0211608.ref092" ref-type="bibr">92</xref>]);</p></list-item><list-item><p>ability to handle both fixed and user-defined parameters.</p></list-item></list></p><p>The field seems to have converged on a set of relatively widely used workflow languages (WL) to describe the actual flow of computation, and execution engines (EE) that provide automation and portability on HPC environments. Some solutions are by their nature an integrated package of WL+EE (<xref rid="pone.0211608.t003" ref-type="table">Table 3</xref>). However, there has been a widespread recognition of the need to standardize WLs, for the sake of reproducibility&#x02014;particularly important for clinical applications. Thus separating out an execution engine that could operate on workflows written in a variety of WLs is very attractive. A few clear leaders have recently emerged: CWL [<xref rid="pone.0211608.ref013" ref-type="bibr">13</xref>] and WDL [<xref rid="pone.0211608.ref014" ref-type="bibr">14</xref>] for workflow definition languages, and Toil [<xref rid="pone.0211608.ref093" ref-type="bibr">93</xref>, <xref rid="pone.0211608.ref094" ref-type="bibr">94</xref>], Rabix [<xref rid="pone.0211608.ref095" ref-type="bibr">95</xref>] and Cromwell [<xref rid="pone.0211608.ref014" ref-type="bibr">14</xref>] for execution engines (<xref rid="pone.0211608.t004" ref-type="table">Table 4</xref>). CWL enjoys very wide adoption, either being supported, or upcoming support announced among Taverna [<xref rid="pone.0211608.ref068" ref-type="bibr">68</xref>], Galaxy [<xref rid="pone.0211608.ref069" ref-type="bibr">69</xref>], Toil [<xref rid="pone.0211608.ref093" ref-type="bibr">93</xref>], Arvados [<xref rid="pone.0211608.ref096" ref-type="bibr">96</xref>], Rabix [<xref rid="pone.0211608.ref095" ref-type="bibr">95</xref>], Cromwell [<xref rid="pone.0211608.ref014" ref-type="bibr">14</xref>]. To some extent such data-driven workflow languages as CWL and WDL can be viewed as a more advanced step in evolution of a formal scientific workflow. Indeed, when a scientist is only experimenting with the new analysis, it is useful to program it in a powerful lower-level language like Swift, which allows a lot of experimentation with the structure and content of the workflow. Once this has been developed and validated, formalizing it in more rigid data-driven framework (CWL, WDL) for reproducibility and later use by non-programmers has a lot of value.</p><table-wrap id="pone.0211608.t004" orientation="portrait" position="float"><object-id pub-id-type="doi">10.1371/journal.pone.0211608.t004</object-id><label>Table 4</label><caption><title>Popular workflow management systems.</title></caption><alternatives><graphic id="pone.0211608.t004g" xlink:href="pone.0211608.t004"/><table frame="box" rules="all" border="0"><colgroup span="1"><col align="left" valign="middle" span="1"/><col align="left" valign="middle" span="1"/><col align="left" valign="middle" span="1"/><col align="left" valign="middle" span="1"/></colgroup><thead><tr><th align="center" rowspan="1" colspan="1">Comparison aspect</th><th align="center" rowspan="1" colspan="1">Toil <xref ref-type="table-fn" rid="t004fn001"><sup>&#x02720;</sup></xref> [<xref rid="pone.0211608.ref093" ref-type="bibr">93</xref>]</th><th align="center" rowspan="1" colspan="1">Rabix [<xref rid="pone.0211608.ref095" ref-type="bibr">95</xref>]</th><th align="center" rowspan="1" colspan="1">Cromwell [<xref rid="pone.0211608.ref014" ref-type="bibr">14</xref>]</th></tr></thead><tbody><tr><td align="center" rowspan="1" colspan="1">Nature</td><td align="center" rowspan="1" colspan="1">Execution engine</td><td align="center" rowspan="1" colspan="1">Execution engine</td><td align="center" rowspan="1" colspan="1">Execution engine</td></tr><tr><td align="center" rowspan="1" colspan="1">Support community standard WL?</td><td align="center" rowspan="1" colspan="1">CWL, WDL</td><td align="center" rowspan="1" colspan="1">CWL</td><td align="center" rowspan="1" colspan="1">WDL <xref ref-type="table-fn" rid="t004fn002"><sup>#</sup></xref> [<xref rid="pone.0211608.ref097" ref-type="bibr">97</xref>]</td></tr><tr><td align="center" rowspan="1" colspan="1">User interface</td><td align="center" rowspan="1" colspan="1">CLI</td><td align="center" rowspan="1" colspan="1">GUI <xref ref-type="table-fn" rid="t004fn003"><sup>&#x022c6;</sup></xref>, CLI</td><td align="center" rowspan="1" colspan="1">CLI</td></tr><tr><td align="center" rowspan="1" colspan="1">Programming paradigm [<xref rid="pone.0211608.ref077" ref-type="bibr">77</xref>]</td><td align="center" rowspan="1" colspan="1">Sequential <xref ref-type="table-fn" rid="t004fn004"><sup>&#x02020;</sup></xref> [<xref rid="pone.0211608.ref013" ref-type="bibr">13</xref>, <xref rid="pone.0211608.ref094" ref-type="bibr">94</xref>]</td><td align="center" rowspan="1" colspan="1">Dataflow [<xref rid="pone.0211608.ref013" ref-type="bibr">13</xref>]</td><td align="center" rowspan="1" colspan="1">Dataflow</td></tr><tr><td align="center" rowspan="1" colspan="1">Containerization support</td><td align="center" rowspan="1" colspan="1">Docker</td><td align="center" rowspan="1" colspan="1">Docker</td><td align="center" rowspan="1" colspan="1">Docker</td></tr><tr><td align="center" rowspan="1" colspan="1">Scalability [<xref rid="pone.0211608.ref080" ref-type="bibr">80</xref>]</td><td align="center" rowspan="1" colspan="1">Petascale</td><td align="center" rowspan="1" colspan="1">Yes</td><td align="center" rowspan="1" colspan="1">Yes</td></tr><tr><td align="center" rowspan="1" colspan="1">Checkpointing and caching</td><td align="center" rowspan="1" colspan="1">Yes</td><td align="center" rowspan="1" colspan="1">Yes</td><td align="center" rowspan="1" colspan="1">Yes</td></tr><tr><td align="center" rowspan="1" colspan="1">Portability <xref ref-type="table-fn" rid="t004fn005"><sup>&#x000b6;</sup></xref></td><td align="center" rowspan="1" colspan="1">LSF, Parasol,<break/>Apache Mesos,<break/>Open stack,<break/>MS Azure,<break/>Google Cloud <sup>&#x00026;</sup> Compute Engine</td><td align="center" rowspan="1" colspan="1">Open stack,<break/>Google Cloud <xref ref-type="table-fn" rid="t004fn006"><sup>&#x000a7;</sup></xref></td><td align="center" rowspan="1" colspan="1">LSF,<break/>HTCondor,<break/>Google JES <xref ref-type="table-fn" rid="t004fn006"><sup>&#x000a7;</sup></xref></td></tr><tr><td align="center" rowspan="1" colspan="1">Distributed execution</td><td align="center" rowspan="1" colspan="1">Spark</td><td align="center" rowspan="1" colspan="1">-</td><td align="center" rowspan="1" colspan="1">Spark</td></tr><tr><td align="center" rowspan="1" colspan="1">Supported compute architecture</td><td align="center" rowspan="1" colspan="1">Homogeneous or heterogeneous</td><td align="center" rowspan="1" colspan="1">Homogeneous <xref ref-type="table-fn" rid="t004fn006"><sup>&#x000a7;</sup></xref></td><td align="center" rowspan="1" colspan="1">Homogeneous <xref ref-type="table-fn" rid="t004fn006"><sup>&#x000a7;</sup></xref></td></tr><tr><td align="center" rowspan="1" colspan="1">Compute resource allocation</td><td align="center" rowspan="1" colspan="1">Allocated dynamically</td><td align="center" rowspan="1" colspan="1">Reserved apriori <xref ref-type="table-fn" rid="t004fn006"><sup>&#x000a7;</sup></xref></td><td align="center" rowspan="1" colspan="1">Reserved a priori</td></tr></tbody></table></alternatives><table-wrap-foot><fn id="t004fn001"><p><sup>&#x02720;</sup> Toil uniquely has notions of object store and data encryption, which can assure compliance with strict data security requirements.</p></fn><fn id="t004fn002"><p><sup>#</sup> Work is ongoing to incorporate support for CWL into Cromwell.</p></fn><fn id="t004fn003"><p><sup>&#x022c6;</sup> Rabix composer (<ext-link ext-link-type="uri" xlink:href="http://docs.rabix.io/rabix-composer-home">http://docs.rabix.io/rabix-composer-home</ext-link>) is a stand-alone GUI editor for CWL workflows.</p></fn><fn id="t004fn004"><p><sup>&#x02020;</sup> In Toil <italic>child jobs</italic> are executed after their parents have completed (in parallel), and <italic>follow-on jobs</italic> are run after the successors and their child jobs have finished execution (also in parallel). This creates a Directed Acyclic Graph of jobs to be run, similarly to dataflow. But, unlike in dataflow model, the order of execution depends on whether the parent job has finished and its relation to other jobs, as opposed to whether the data are ready.</p></fn><fn id="t004fn005"><p><sup>&#x000b6;</sup> All these workflow management systems can run on a single server, on clusters managed by PBS, Grid Engine, Slurm, and also on AWS.</p></fn><fn id="t004fn006"><p><sup>&#x000a7;</sup> Work is ongoing to also provide support for the GA4GH TES job management system.</p></fn></table-wrap-foot></table-wrap><p>Further efforts toward wider adoption recognize the need to execute biomedical workflows on big data platforms, such as Hadoop and Spark (e.g. Luigi), and the cloud (e.g. Toil, DNAnexus, SevenBridges, Illumina&#x02019;s BaseSpace, Curoverse&#x02019;s Arvados and iPlant Collaborative&#x02019;s Agave).</p></sec></sec><sec sec-type="conclusions" id="sec018"><title>Conclusion</title><p>Our experience implementing a genomic variant calling workflow in Swift/T suggests that it is a very powerful system for workflow management in supercomputing environments. The language is rich with features that give developers control over their workflow structure and execution while providing familiar syntax. The execution engine also has intelligent mechanisms for task placement and regulation, permitting efficient use of compute resources. This unfortunately comes at the cost of a relatively steep learning curve&#x02014;a common trade-off for programming languages in general. Thus Swift/T can be an extremely useful&#x02014;and possibly the best&#x02014;tool for certain genomics analyses, though its complexity may pose an adoption barrier for biologists.</p></sec></body><back><ack><p>We are grateful for the support of the Blue Waters team, NCSA Industry, and the Argonne/U. Chicago Swift/T developer team during the implementation, testing, and scalability efforts in this project.</p><p>This work used Biocluster, the High Performance Computing (HPC) resource for the Carl R Woese Institute for Genomic Biology (IGB) at the University of Illinois at Urbana-Champaign (UIUC). We are grateful for the support by the Computer Network Resource Group (CNRG) while testing the pipeline.</p></ack><ref-list><title>References</title><ref id="pone.0211608.ref001"><label>1</label><mixed-citation publication-type="journal">
<name><surname>Metzker</surname><given-names>ML</given-names></name>. <article-title>Sequencing technologies&#x02014;the next generation</article-title>. <source>Nat Rev Genet</source>. <year>2010</year>;<volume>11</volume>(<issue>1</issue>):<fpage>31</fpage>&#x02013;<lpage>46</lpage>. <pub-id pub-id-type="doi">10.1038/nrg2626</pub-id>
<?supplied-pmid 19997069?><pub-id pub-id-type="pmid">19997069</pub-id></mixed-citation></ref><ref id="pone.0211608.ref002"><label>2</label><mixed-citation publication-type="journal">
<name><surname>Goodwin</surname><given-names>S</given-names></name>, <name><surname>McPherson</surname><given-names>JD</given-names></name>, <name><surname>McCombie</surname><given-names>WR</given-names></name>. <article-title>Coming of age: ten years of next-generation sequencing technologies</article-title>. <source>Nat Rev Genet</source>. <year>2016</year>;<volume>17</volume>(<issue>6</issue>):<fpage>333</fpage>&#x02013;<lpage>351</lpage>. <pub-id pub-id-type="doi">10.1038/nrg.2016.49</pub-id>
<?supplied-pmid 27184599?><pub-id pub-id-type="pmid">27184599</pub-id></mixed-citation></ref><ref id="pone.0211608.ref003"><label>3</label><mixed-citation publication-type="journal">
<name><surname>Rabbani</surname><given-names>B</given-names></name>, <name><surname>Tekin</surname><given-names>M</given-names></name>, <name><surname>Mahdieh</surname><given-names>N</given-names></name>. <article-title>The promise of whole-exome sequencing in medical genetics</article-title>. <source>J Hum Genet</source>. <year>2014</year>;<volume>59</volume>(<issue>1</issue>):<fpage>5</fpage>&#x02013;<lpage>15</lpage>. <pub-id pub-id-type="doi">10.1038/jhg.2013.114</pub-id>
<?supplied-pmid 24196381?><pub-id pub-id-type="pmid">24196381</pub-id></mixed-citation></ref><ref id="pone.0211608.ref004"><label>4</label><mixed-citation publication-type="journal">
<name><surname>Allard</surname><given-names>MW</given-names></name>. <article-title>The Future of Whole-Genome Sequencing for Public Health and the Clinic</article-title>. <source>J Clin Microbiol</source>. <year>2016</year>;<volume>54</volume>(<issue>8</issue>):<fpage>1946</fpage>&#x02013;<lpage>1948</lpage>. <pub-id pub-id-type="doi">10.1128/JCM.01082-16</pub-id>
<?supplied-pmid 27307454?><pub-id pub-id-type="pmid">27307454</pub-id></mixed-citation></ref><ref id="pone.0211608.ref005"><label>5</label><mixed-citation publication-type="journal">
<name><surname>Bao</surname><given-names>R</given-names></name>, <name><surname>Huang</surname><given-names>L</given-names></name>, <name><surname>Andrade</surname><given-names>J</given-names></name>, <name><surname>Tan</surname><given-names>W</given-names></name>, <name><surname>Kibbe</surname><given-names>WA</given-names></name>, <name><surname>Jiang</surname><given-names>H</given-names></name>, <etal>et al</etal>
<article-title>Review of current methods, applications, and data management for the bioinformatics analysis of whole exome sequencing</article-title>. <source>Cancer Inform</source>. <year>2014</year>;<volume>13</volume>(<issue>Suppl 2</issue>):<fpage>67</fpage>&#x02013;<lpage>82</lpage>. <pub-id pub-id-type="doi">10.4137/CIN.S13779</pub-id>
<?supplied-pmid 25288881?><pub-id pub-id-type="pmid">25288881</pub-id></mixed-citation></ref><ref id="pone.0211608.ref006"><label>6</label><mixed-citation publication-type="journal">
<name><surname>Petersen</surname><given-names>BS</given-names></name>, <name><surname>Fredrich</surname><given-names>B</given-names></name>, <name><surname>Hoeppner</surname><given-names>MP</given-names></name>, <name><surname>Ellinghaus</surname><given-names>D</given-names></name>, <name><surname>Franke</surname><given-names>A</given-names></name>. <article-title>Opportunities and challenges of whole-genome and -exome sequencing</article-title>. <source>BMC Genet</source>. <year>2017</year>;<volume>18</volume>(<issue>1</issue>):<fpage>14</fpage>
<pub-id pub-id-type="doi">10.1186/s12863-017-0479-5</pub-id>
<?supplied-pmid 28193154?><pub-id pub-id-type="pmid">28193154</pub-id></mixed-citation></ref><ref id="pone.0211608.ref007"><label>7</label><mixed-citation publication-type="journal">
<name><surname>Stephens</surname><given-names>ZD</given-names></name>, <name><surname>Lee</surname><given-names>SY</given-names></name>, <name><surname>Faghri</surname><given-names>F</given-names></name>, <name><surname>Campbell</surname><given-names>RH</given-names></name>, <name><surname>Zhai</surname><given-names>C</given-names></name>, <name><surname>Efron</surname><given-names>MJ</given-names></name>, <etal>et al</etal>
<article-title>Big data: astronomical or genomical?</article-title>
<source>PLoS Biol</source>. <year>2015</year>;<volume>13</volume>(<issue>7</issue>):<fpage>e1002195</fpage>
<pub-id pub-id-type="doi">10.1371/journal.pbio.1002195</pub-id>
<?supplied-pmid 26151137?><pub-id pub-id-type="pmid">26151137</pub-id></mixed-citation></ref><ref id="pone.0211608.ref008"><label>8</label><mixed-citation publication-type="journal">
<name><surname>Raczy</surname><given-names>C</given-names></name>, <name><surname>Petrovski</surname><given-names>R</given-names></name>, <name><surname>Saunders</surname><given-names>CT</given-names></name>, <name><surname>Chorny</surname><given-names>I</given-names></name>, <name><surname>Kruglyak</surname><given-names>S</given-names></name>, <name><surname>Margulies</surname><given-names>EH</given-names></name>, <etal>et al</etal>
<article-title>Isaac: ultra-fast whole-genome secondary analysis on Illumina sequencing platforms</article-title>. <source>Bioinformatics</source>. <year>2013</year>;<volume>29</volume>(<issue>16</issue>):<fpage>2041</fpage>&#x02013;<lpage>2043</lpage>. <pub-id pub-id-type="doi">10.1093/bioinformatics/btt314</pub-id>
<?supplied-pmid 23736529?><pub-id pub-id-type="pmid">23736529</pub-id></mixed-citation></ref><ref id="pone.0211608.ref009"><label>9</label><mixed-citation publication-type="other">Genalice. NGS Analysis| Genalice Map; 2017. Available from: <ext-link ext-link-type="uri" xlink:href="http://www.genalice.com/product/genalice-map/">http://www.genalice.com/product/genalice-map/</ext-link>.</mixed-citation></ref><ref id="pone.0211608.ref010"><label>10</label><mixed-citation publication-type="journal">
<name><surname>Goyal</surname><given-names>A</given-names></name>, <name><surname>Kwon</surname><given-names>HJ</given-names></name>, <name><surname>Lee</surname><given-names>K</given-names></name>, <name><surname>Garg</surname><given-names>R</given-names></name>, <name><surname>Yun</surname><given-names>SY</given-names></name>, <name><surname>Kim</surname><given-names>YH</given-names></name>, <etal>et al</etal>
<article-title>Ultra-Fast Next Generation Human Genome Sequencing Data Processing Using DRAGEN<sup><italic>TM</italic></sup> Bio-IT Processor for Precision Medicine</article-title>. <source>Open Journal of Genetics</source>. <year>2017</year>;<volume>7</volume>(<issue>1</issue>):<fpage>9</fpage>&#x02013;<lpage>19</lpage>. <pub-id pub-id-type="doi">10.4236/ojgen.2017.71002</pub-id></mixed-citation></ref><ref id="pone.0211608.ref011"><label>11</label><mixed-citation publication-type="journal">
<name><surname>Monat</surname><given-names>C</given-names></name>, <name><surname>Tranchant-Dubreuil</surname><given-names>C</given-names></name>, <name><surname>Kougbeadjo</surname><given-names>A</given-names></name>, <name><surname>Farcy</surname><given-names>C</given-names></name>, <name><surname>Ortega-Abboud</surname><given-names>E</given-names></name>, <name><surname>Amanzougarene</surname><given-names>S</given-names></name>, <etal>et al</etal>
<article-title>TOGGLE: toolbox for generic NGS analyses</article-title>. <source>BMC Bioinformatics</source>. <year>2015</year>;<volume>16</volume>(<issue>1</issue>):<fpage>374</fpage>
<pub-id pub-id-type="doi">10.1186/s12859-015-0795-6</pub-id>
<?supplied-pmid 26552596?><pub-id pub-id-type="pmid">26552596</pub-id></mixed-citation></ref><ref id="pone.0211608.ref012"><label>12</label><mixed-citation publication-type="journal">
<name><surname>Leipzig</surname><given-names>J</given-names></name>. <article-title>A review of bioinformatic pipeline frameworks</article-title>. <source>Brief Bioinformatics</source>. <year>2017</year>;<volume>18</volume>(<issue>3</issue>):<fpage>530</fpage>&#x02013;<lpage>536</lpage>. <pub-id pub-id-type="doi">10.1093/bib/bbw020</pub-id>
<?supplied-pmid 27013646?><pub-id pub-id-type="pmid">27013646</pub-id></mixed-citation></ref><ref id="pone.0211608.ref013"><label>13</label><mixed-citation publication-type="other">Peter Amstutz, Michael R Crusoe, Neboj&#x00161;a Tijani&#x00107;. Common Workflow Language (CWL) Workflow Description, v1.0.2; 2017. Available from: <ext-link ext-link-type="uri" xlink:href="http://www.commonwl.org/v1.0/Workflow.html#Workflow">http://www.commonwl.org/v1.0/Workflow.html#Workflow</ext-link>.</mixed-citation></ref><ref id="pone.0211608.ref014"><label>14</label><mixed-citation publication-type="journal">
<name><surname>Voss</surname><given-names>K</given-names></name>, <name><surname>Gentry</surname><given-names>J</given-names></name>, <name><surname>der Auwera</surname><given-names>GV</given-names></name>, <name><surname>Voss</surname><given-names>K</given-names></name>, <name><surname>Gentry</surname><given-names>J</given-names></name>, <name><surname>Van der Auwera</surname><given-names>G</given-names></name>. <article-title>Full-stack genomics pipelining with GATK4 + WDL + Cromwell</article-title>. <source>F1000Research</source>. <year>2017</year>;<volume>6</volume>.</mixed-citation></ref><ref id="pone.0211608.ref015"><label>15</label><mixed-citation publication-type="other">Wozniak JM, Armstrong TG, Wilde M, Katz DS, Lusk E, Foster IT. Swift/T: Large-Scale Application Composition via Distributed-Memory Dataflow Processing. In: 2013 13th IEEE/ACM International Symposium on Cluster, Cloud, and Grid Computing. IEEE; 2013. p. 95&#x02013;102. Available from: <ext-link ext-link-type="uri" xlink:href="http://ieeexplore.ieee.org/document/6546066/">http://ieeexplore.ieee.org/document/6546066/</ext-link>.</mixed-citation></ref><ref id="pone.0211608.ref016"><label>16</label><mixed-citation publication-type="journal">
<name><surname>Wilde</surname><given-names>M</given-names></name>, <name><surname>Hategan</surname><given-names>M</given-names></name>, <name><surname>Wozniak</surname><given-names>JM</given-names></name>, <name><surname>Clifford</surname><given-names>B</given-names></name>, <name><surname>Katz</surname><given-names>DS</given-names></name>, <name><surname>Foster</surname><given-names>I</given-names></name>. <article-title>Swift: A language for distributed parallel scripting</article-title>. <source>Parallel Computing</source>. <year>2011</year>;<volume>37</volume>(<issue>9</issue>):<fpage>633</fpage>&#x02013;<lpage>652</lpage>. <pub-id pub-id-type="doi">10.1016/j.parco.2011.05.005</pub-id></mixed-citation></ref><ref id="pone.0211608.ref017"><label>17</label><mixed-citation publication-type="other">Wozniak JM, Armstrong TG, Maheshwari K, Lusk EL, Katz DS, Wilde M, et al. Turbine: A distributed-memory dataflow engine for extreme-scale many-task applications. In: Proceedings of the 1st ACM SIGMOD Workshop on Scalable Workflow Execution Engines and Technologies. ACM; 2012. p. 5.</mixed-citation></ref><ref id="pone.0211608.ref018"><label>18</label><mixed-citation publication-type="other">Ozik J, Collier NT, Wozniak JM, Spagnuolo C. From Desktop to Large-Scale Model Exploration with Swift/T. In: 2016 Winter Simulation Conference (WSC). IEEE; 2016. p. 206&#x02013;220. Available from: <ext-link ext-link-type="uri" xlink:href="http://ieeexplore.ieee.org/document/7822090/">http://ieeexplore.ieee.org/document/7822090/</ext-link>.</mixed-citation></ref><ref id="pone.0211608.ref019"><label>19</label><mixed-citation publication-type="other">Wozniak JM. Highlights of X-Stack ExM Deliverable Swift/T. Argonne National Lab.(ANL), Argonne, IL (United States); 2016.</mixed-citation></ref><ref id="pone.0211608.ref020"><label>20</label><mixed-citation publication-type="other">Katz D. Expressing workflows as code vs. data.; 2018. Available from: <ext-link ext-link-type="uri" xlink:href="https://danielskatzblog.wordpress.com/2018/01/08/expressing-workflows-as-code-vs-data/">https://danielskatzblog.wordpress.com/2018/01/08/expressing-workflows-as-code-vs-data/</ext-link>.</mixed-citation></ref><ref id="pone.0211608.ref021"><label>21</label><mixed-citation publication-type="journal">
<name><surname>McKenna</surname><given-names>A</given-names></name>, <name><surname>Hanna</surname><given-names>M</given-names></name>, <name><surname>Banks</surname><given-names>E</given-names></name>, <name><surname>Sivachenko</surname><given-names>A</given-names></name>, <name><surname>Cibulskis</surname><given-names>K</given-names></name>, <name><surname>Kernytsky</surname><given-names>A</given-names></name>, <etal>et al</etal>
<article-title>The Genome Analysis Toolkit: A MapReduce framework for analyzing next-generation DNA sequencing data</article-title>. <source>Genome Research</source>. <year>2010</year>;<volume>20</volume>(<issue>9</issue>):<fpage>1297</fpage>&#x02013;<lpage>1303</lpage>. <pub-id pub-id-type="doi">10.1101/gr.107524.110</pub-id>
<?supplied-pmid 20644199?><pub-id pub-id-type="pmid">20644199</pub-id></mixed-citation></ref><ref id="pone.0211608.ref022"><label>22</label><mixed-citation publication-type="journal">
<name><surname>DePristo</surname><given-names>MA</given-names></name>, <name><surname>Banks</surname><given-names>E</given-names></name>, <name><surname>Poplin</surname><given-names>R</given-names></name>, <name><surname>Garimella</surname><given-names>KV</given-names></name>, <name><surname>Maguire</surname><given-names>JR</given-names></name>, <name><surname>Hartl</surname><given-names>C</given-names></name>, <etal>et al</etal>
<article-title>A framework for variation discovery and genotyping using next-generation DNA sequencing data</article-title>. <source>Nat Genet</source>. <year>2011</year>;<volume>43</volume>(<issue>5</issue>):<fpage>491</fpage>&#x02013;<lpage>498</lpage>. <pub-id pub-id-type="doi">10.1038/ng.806</pub-id>
<?supplied-pmid 21478889?><pub-id pub-id-type="pmid">21478889</pub-id></mixed-citation></ref><ref id="pone.0211608.ref023"><label>23</label><mixed-citation publication-type="journal">
<name><surname>Van der Auwera</surname><given-names>GA</given-names></name>, <name><surname>Carneiro</surname><given-names>MO</given-names></name>, <name><surname>Hartl</surname><given-names>C</given-names></name>, <name><surname>Poplin</surname><given-names>R</given-names></name>, <name><surname>Del Angel</surname><given-names>G</given-names></name>, <name><surname>Levy-Moonshine</surname><given-names>A</given-names></name>, <etal>et al</etal>
<article-title>From FastQ data to high confidence variant calls: the Genome Analysis Toolkit best practices pipeline</article-title>. <source>Curr Protoc Bioinformatics</source>. <year>2013</year>;<volume>11</volume>(<issue>1110</issue>):<fpage>11.10.1</fpage>&#x02013;<lpage>11.10.33</lpage>.</mixed-citation></ref><ref id="pone.0211608.ref024"><label>24</label><mixed-citation publication-type="other">US Government Publishing Office. type [; 2018]Available from: <ext-link ext-link-type="uri" xlink:href="https://www.govinfo.gov/content/pkg/PLAW-104publ191/html/PLAW-104publ191.htm">https://www.govinfo.gov/content/pkg/PLAW-104publ191/html/PLAW-104publ191.htm</ext-link>.</mixed-citation></ref><ref id="pone.0211608.ref025"><label>25</label><mixed-citation publication-type="other">eCFR &#x02014;Code of Federal Regulations. type [; 2018]Available from: <ext-link ext-link-type="uri" xlink:href="https://www.ecfr.gov/cgi-bin/text-idx?SID=1248e3189da5e5f936e55315402bc38b&#x00026;node=pt42.5.493&#x00026;rgn=div5">https://www.ecfr.gov/cgi-bin/text-idx?SID=1248e3189da5e5f936e55315402bc38b&#x00026;node=pt42.5.493&#x00026;rgn=div5</ext-link>.</mixed-citation></ref><ref id="pone.0211608.ref026"><label>26</label><mixed-citation publication-type="other">Mainzer L, Botha G, Meintjes A, Jongeneel V, Mulder N. Design of a custom genotyping chip for African populations. In: Blue Waters Symposium Proceedings; 2016. Available from: <ext-link ext-link-type="uri" xlink:href="https://bluewaters.ncsa.illinois.edu/science-teams?page=detail&#x00026;psn=jti">https://bluewaters.ncsa.illinois.edu/science-teams?page=detail&#x00026;psn=jti</ext-link>.</mixed-citation></ref><ref id="pone.0211608.ref027"><label>27</label><mixed-citation publication-type="other">Mainzer LS, Asmann Y, Hudson M. Identification of missing variants in Alzheimer&#x02019;s disease, and the new standards for genomic variant identification in large cohorts. In: Blue Waters Report; 2018. Available from: <ext-link ext-link-type="uri" xlink:href="https://bluewaters.ncsa.illinois.edu/apps/bwst/api/file.php/file/5ae7a1747688d7642613016e">https://bluewaters.ncsa.illinois.edu/apps/bwst/api/file.php/file/5ae7a1747688d7642613016e</ext-link>.</mixed-citation></ref><ref id="pone.0211608.ref028"><label>28</label><mixed-citation publication-type="other">Mainzer LS, Fields C, Rendon G, Jongeneel V. Instrumenting Human Variant Calling Workflow on Blue Waters. In: Blue Waters Symposium Proceedings; 2015. Available from: <ext-link ext-link-type="uri" xlink:href="https://bluewaters.ncsa.illinois.edu/liferay-content/document-library/2015%20symposium/Mainzer%20presentation.pdf">https://bluewaters.ncsa.illinois.edu/liferay-content/document-library/2015%20symposium/Mainzer%20presentation.pdf</ext-link>.</mixed-citation></ref><ref id="pone.0211608.ref029"><label>29</label><mixed-citation publication-type="journal">
<name><surname>Kawalia</surname><given-names>A</given-names></name>, <name><surname>Motameny</surname><given-names>S</given-names></name>, <name><surname>Wonczak</surname><given-names>S</given-names></name>, <name><surname>Thiele</surname><given-names>H</given-names></name>, <name><surname>Nieroda</surname><given-names>L</given-names></name>, <name><surname>Jabbari</surname><given-names>K</given-names></name>, <etal>et al</etal>
<article-title>Leveraging the power of high performance computing for next generation sequencing data analysis: tricks and twists from a high throughput exome workflow</article-title>. <source>PLoS ONE</source>. <year>2015</year>;<volume>10</volume>(<issue>5</issue>):<fpage>e0126321</fpage>
<pub-id pub-id-type="doi">10.1371/journal.pone.0126321</pub-id>
<?supplied-pmid 25942438?><pub-id pub-id-type="pmid">25942438</pub-id></mixed-citation></ref><ref id="pone.0211608.ref030"><label>30</label><mixed-citation publication-type="other">Jason Pitt KW. SwiftSeq: A High-Performance Workflow for Processing DNA Sequencing Data; 2014. Available from: <ext-link ext-link-type="uri" xlink:href="http://beagle.ci.uchicago.edu/wp-content/files/2014/05/may_newsletter_2014.pdf">http://beagle.ci.uchicago.edu/wp-content/files/2014/05/may_newsletter_2014.pdf</ext-link>.</mixed-citation></ref><ref id="pone.0211608.ref031"><label>31</label><mixed-citation publication-type="journal">
<name><surname>Puckelwartz</surname><given-names>MJ</given-names></name>, <name><surname>Pesce</surname><given-names>LL</given-names></name>, <name><surname>Nelakuditi</surname><given-names>V</given-names></name>, <name><surname>Dellefave-Castillo</surname><given-names>L</given-names></name>, <name><surname>Golbus</surname><given-names>JR</given-names></name>, <name><surname>Day</surname><given-names>SM</given-names></name>, <etal>et al</etal>
<article-title>Supercomputing for the parallelization of whole genome analysis</article-title>. <source>Bioinformatics</source>. <year>2014</year>;<volume>30</volume>(<issue>11</issue>):<fpage>1508</fpage>&#x02013;<lpage>1513</lpage>. <pub-id pub-id-type="doi">10.1093/bioinformatics/btu071</pub-id>
<?supplied-pmid 24526712?><pub-id pub-id-type="pmid">24526712</pub-id></mixed-citation></ref><ref id="pone.0211608.ref032"><label>32</label><mixed-citation publication-type="other">Li H. Aligning sequence reads, clone sequences and assembly contigs with BWA-MEM; 2013. Available from: <ext-link ext-link-type="uri" xlink:href="http://arxiv.org/abs/1303.3997v2">http://arxiv.org/abs/1303.3997v2</ext-link>.</mixed-citation></ref><ref id="pone.0211608.ref033"><label>33</label><mixed-citation publication-type="other">NOVOCRAFT TECHNOLOGIES SDN BHD. Novocraft; 2014. Available from: <ext-link ext-link-type="uri" xlink:href="http://www.novocraft.com/">http://www.novocraft.com/</ext-link>.</mixed-citation></ref><ref id="pone.0211608.ref034"><label>34</label><mixed-citation publication-type="journal">
<name><surname>Langmead</surname><given-names>B</given-names></name>, <name><surname>Salzberg</surname><given-names>S</given-names></name>. <article-title>Fast gapped-read alignment with Bowtie 2</article-title>. <source>Nature Methods</source>. <year>2012</year>;<volume>9</volume>:<fpage>357</fpage>&#x02013;<lpage>359</lpage>. <pub-id pub-id-type="doi">10.1038/nmeth.1923</pub-id>
<?supplied-pmid 22388286?><pub-id pub-id-type="pmid">22388286</pub-id></mixed-citation></ref><ref id="pone.0211608.ref035"><label>35</label><mixed-citation publication-type="journal">
<name><surname>Li</surname><given-names>H</given-names></name>, <name><surname>Handsaker</surname><given-names>B</given-names></name>, <name><surname>Wysoker</surname><given-names>A</given-names></name>, <name><surname>Fennell</surname><given-names>T</given-names></name>, <name><surname>Ruan</surname><given-names>J</given-names></name>, <name><surname>Homer</surname><given-names>N</given-names></name>, <etal>et al</etal>
<article-title>The Sequence Alignment/Map format and SAMtools</article-title>. <source>Bioinformatics</source>. <year>2009</year>;<volume>25</volume>(<issue>16</issue>):<fpage>2078</fpage>&#x02013;<lpage>2079</lpage>. <pub-id pub-id-type="doi">10.1093/bioinformatics/btp352</pub-id>
<?supplied-pmid 19505943?><pub-id pub-id-type="pmid">19505943</pub-id></mixed-citation></ref><ref id="pone.0211608.ref036"><label>36</label><mixed-citation publication-type="journal">
<name><surname>Tarasov</surname><given-names>A</given-names></name>, <name><surname>Vilella</surname><given-names>AJ</given-names></name>, <name><surname>Cuppen</surname><given-names>E</given-names></name>, <name><surname>Nijman</surname><given-names>IJ</given-names></name>, <name><surname>Prins</surname><given-names>P</given-names></name>. <article-title>Sambamba: fast processing of NGS alignment formats</article-title>. <source>Bioinformatics</source>. <year>2015</year>;<volume>31</volume>(<issue>12</issue>):<fpage>2032</fpage>&#x02013;<lpage>2034</lpage>. <pub-id pub-id-type="doi">10.1093/bioinformatics/btv098</pub-id>
<?supplied-pmid 25697820?><pub-id pub-id-type="pmid">25697820</pub-id></mixed-citation></ref><ref id="pone.0211608.ref037"><label>37</label><mixed-citation publication-type="journal">
<name><surname>Faust</surname><given-names>GG</given-names></name>, <name><surname>Hall</surname><given-names>IM</given-names></name>. <article-title>SAMBLASTER: fast duplicate marking and structural variant read extraction</article-title>. <source>Bioinformatics</source>. <year>2014</year>;<volume>30</volume>(<issue>17</issue>):<fpage>2503</fpage>&#x02013;<lpage>2505</lpage>. <pub-id pub-id-type="doi">10.1093/bioinformatics/btu314</pub-id>
<?supplied-pmid 24812344?><pub-id pub-id-type="pmid">24812344</pub-id></mixed-citation></ref><ref id="pone.0211608.ref038"><label>38</label><mixed-citation publication-type="other">The Broad Institute. Picard Tools; 2017. Available from: <ext-link ext-link-type="uri" xlink:href="https://broadinstitute.github.io/picard/">https://broadinstitute.github.io/picard/</ext-link>.</mixed-citation></ref><ref id="pone.0211608.ref039"><label>39</label><mixed-citation publication-type="other">The Broad Institute. GATK |Best Practices; 2017. Available from: <ext-link ext-link-type="uri" xlink:href="https://software.broadinstitute.org/gatk/best-practices/">https://software.broadinstitute.org/gatk/best-practices/</ext-link>.</mixed-citation></ref><ref id="pone.0211608.ref040"><label>40</label><mixed-citation publication-type="journal">
<name><surname>Poplin</surname><given-names>R</given-names></name>, <name><surname>Ruano-Rubio</surname><given-names>V</given-names></name>, <name><surname>DePristo</surname><given-names>MA</given-names></name>, <name><surname>Fennell</surname><given-names>TJ</given-names></name>, <name><surname>Carneiro</surname><given-names>MO</given-names></name>, <name><surname>Van der Auwera</surname><given-names>GA</given-names></name>, <etal>et al</etal>
<article-title>Scaling accurate genetic variant discovery to tens of thousands of samples</article-title>. <source>BioRxiv</source>. <year>2017</year>.</mixed-citation></ref><ref id="pone.0211608.ref041"><label>41</label><mixed-citation publication-type="journal">
<name><surname>Rimmer</surname><given-names>A</given-names></name>, <name><surname>Phan</surname><given-names>H</given-names></name>, <name><surname>Mathieson</surname><given-names>I</given-names></name>, <name><surname>Iqbal</surname><given-names>Z</given-names></name>, <name><surname>Twigg</surname><given-names>SRF</given-names></name>, <name><surname>Consortium</surname><given-names>W</given-names></name>, <etal>et al</etal>
<article-title>Integrating mapping-, assembly- and haplotype-based approaches for calling variants in clinical sequencing applications</article-title>. <source>Nat Genet</source>. <year>2014</year>;<volume>46</volume>(<issue>8</issue>):<fpage>912</fpage>&#x02013;<lpage>918</lpage>. <pub-id pub-id-type="doi">10.1038/ng.3036</pub-id>
<?supplied-pmid 25017105?><pub-id pub-id-type="pmid">25017105</pub-id></mixed-citation></ref><ref id="pone.0211608.ref042"><label>42</label><mixed-citation publication-type="journal">
<name><surname>Kim</surname><given-names>S</given-names></name>, <name><surname>Scheffler</surname><given-names>K</given-names></name>, <name><surname>Halpern</surname><given-names>AL</given-names></name>, <name><surname>Bekritsky</surname><given-names>MA</given-names></name>, <name><surname>Noh</surname><given-names>E</given-names></name>, <name><surname>K&#x000e4;llberg</surname><given-names>M</given-names></name>, <etal>et al</etal>
<article-title>Strelka2: fast and accurate calling of germline and somatic variants</article-title>. <source>Nat Methods</source>. <year>2018</year>;<volume>15</volume>(<issue>8</issue>):<fpage>591</fpage>&#x02013;<lpage>594</lpage>. <pub-id pub-id-type="doi">10.1038/s41592-018-0051-x</pub-id>
<?supplied-pmid 30013048?><pub-id pub-id-type="pmid">30013048</pub-id></mixed-citation></ref><ref id="pone.0211608.ref043"><label>43</label><mixed-citation publication-type="other">Babuji Y, Chard K, Foster I, Katz DS, Wilde M, Woodard A, et al. Parsl: Scalable Parallel Scripting in Python. In: 10th International Workshop on Science Gateways (IWSG 2018); 2018.</mixed-citation></ref><ref id="pone.0211608.ref044"><label>44</label><mixed-citation publication-type="other">Parsl- Parallel Scripting Library; 2018. Available from: <ext-link ext-link-type="uri" xlink:href="http://parsl-project.org">http://parsl-project.org</ext-link>.</mixed-citation></ref><ref id="pone.0211608.ref045"><label>45</label><mixed-citation publication-type="journal">
<name><surname>Lusk</surname><given-names>E</given-names></name>, <name><surname>Pieper</surname><given-names>S</given-names></name>, <name><surname>Butler</surname><given-names>R</given-names></name>. <article-title>More scalability, less pain: A simple programming model and its implementation for extreme computing</article-title>. <source>SciDAC Review</source>. <year>2010</year>;<volume>17</volume>:<fpage>30</fpage>&#x02013;<lpage>37</lpage>.</mixed-citation></ref><ref id="pone.0211608.ref046"><label>46</label><mixed-citation publication-type="other">HPCBio. BW_VariantCalling; 2016. Available from: <ext-link ext-link-type="uri" xlink:href="https://github.com/HPCBio/BW_VariantCalling">https://github.com/HPCBio/BW_VariantCalling</ext-link>.</mixed-citation></ref><ref id="pone.0211608.ref047"><label>47</label><mixed-citation publication-type="other">NCSA. Scheduler; 2017. Available from: <ext-link ext-link-type="uri" xlink:href="https://github.com/ncsa/Scheduler">https://github.com/ncsa/Scheduler</ext-link>.</mixed-citation></ref><ref id="pone.0211608.ref048"><label>48</label><mixed-citation publication-type="other">Wozniak JM, Chan A, Armstrong TG, Wilde M, Lusk E, Foster IT. A model for tracing and debugging large-scale task-parallel programs with MPE. Proc LASH-C at PPoPP. 2013.</mixed-citation></ref><ref id="pone.0211608.ref049"><label>49</label><mixed-citation publication-type="other">Chang W, Cheng J, Allaire J, Xie Y, McPherson J. shiny: Web Application Framework for R; 2017. Available from: <ext-link ext-link-type="uri" xlink:href="https://CRAN.R-project.org/package=shiny">https://CRAN.R-project.org/package=shiny</ext-link>.</mixed-citation></ref><ref id="pone.0211608.ref050"><label>50</label><mixed-citation publication-type="other">Carl R Woese Institute for Genomic Biology at the University of Illinois at Urbana-Champaign. Biocluster (High Performance Computing resource); 2017. Available from: <ext-link ext-link-type="uri" xlink:href="https://help.igb.illinois.edu/Biocluster">https://help.igb.illinois.edu/Biocluster</ext-link>.</mixed-citation></ref><ref id="pone.0211608.ref051"><label>51</label><mixed-citation publication-type="other">Wozniak JM. Swift/T Sites Guide; 2017. Available from: <ext-link ext-link-type="uri" xlink:href="http://swift-lang.github.io/swift-t/sites.html">http://swift-lang.github.io/swift-t/sites.html</ext-link>.</mixed-citation></ref><ref id="pone.0211608.ref052"><label>52</label><mixed-citation publication-type="other">NCSA. Swift-T-Variant-Calling/README.md; 2017. Available from: <ext-link ext-link-type="uri" xlink:href="https://github.com/ncsa/Swift-T-Variant-Calling/blob/master/README.md#cray-system-like-blue-waters-at-uiuc">https://github.com/ncsa/Swift-T-Variant-Calling/blob/master/README.md#cray-system-like-blue-waters-at-uiuc</ext-link>.</mixed-citation></ref><ref id="pone.0211608.ref053"><label>53</label><mixed-citation publication-type="other">NCSA. Swift-T-Variant-Calling/test/TestCases.txt; 2017. Available from: <ext-link ext-link-type="uri" xlink:href="https://github.com/ncsa/Swift-T-Variant-Calling/blob/master/test/TestCases.txt">https://github.com/ncsa/Swift-T-Variant-Calling/blob/master/test/TestCases.txt</ext-link>.</mixed-citation></ref><ref id="pone.0211608.ref054"><label>54</label><mixed-citation publication-type="journal">
<name><surname>Stephens</surname><given-names>ZD</given-names></name>, <name><surname>Hudson</surname><given-names>ME</given-names></name>, <name><surname>Mainzer</surname><given-names>LS</given-names></name>, <name><surname>Taschuk</surname><given-names>M</given-names></name>, <name><surname>Weber</surname><given-names>MR</given-names></name>, <name><surname>Iyer</surname><given-names>RK</given-names></name>. <article-title>Simulating Next-Generation Sequencing Datasets from Empirical Mutation and Sequencing Models</article-title>. <source>PLOS ONE</source>. <year>2016</year>;<volume>11</volume>(<issue>11</issue>):<fpage>1</fpage>&#x02013;<lpage>18</lpage>. <pub-id pub-id-type="doi">10.1371/journal.pone.0167047</pub-id></mixed-citation></ref><ref id="pone.0211608.ref055"><label>55</label><mixed-citation publication-type="other">The University of Illinois at Urbana-Champaign&#x02014;National Center for Supercomputing Applications. iForge Cluster; 2017. Available from: <ext-link ext-link-type="uri" xlink:href="http://www.ncsa.illinois.edu/industry/iforge">http://www.ncsa.illinois.edu/industry/iforge</ext-link>.</mixed-citation></ref><ref id="pone.0211608.ref056"><label>56</label><mixed-citation publication-type="other">USDA. SoyBase and Soybean Breeder&#x02019;s Toolbox&#x02014;Nested Association Mapping; 2015. Available from: <ext-link ext-link-type="uri" xlink:href="https://www.soybase.org/SoyNAM/soynamdetails.php">https://www.soybase.org/SoyNAM/soynamdetails.php</ext-link>.</mixed-citation></ref><ref id="pone.0211608.ref057"><label>57</label><mixed-citation publication-type="other">The University of Texas at Austin&#x02019;s Texas Advanced Computing Center. Stampede2 supercomputer; 2017. Available from: <ext-link ext-link-type="uri" xlink:href="https://www.tacc.utexas.edu/systems/stampede2">https://www.tacc.utexas.edu/systems/stampede2</ext-link>.</mixed-citation></ref><ref id="pone.0211608.ref058"><label>58</label><mixed-citation publication-type="other">giab_data_indexes: This repository contains data indexes from NIST&#x02019;s Genome in a Bottle project; 2017. Available from: <ext-link ext-link-type="uri" xlink:href="https://github.com/genome-in-a-bottle/giab_data_indexes">https://github.com/genome-in-a-bottle/giab_data_indexes</ext-link>.</mixed-citation></ref><ref id="pone.0211608.ref059"><label>59</label><mixed-citation publication-type="journal">
<name><surname>Grabherr</surname><given-names>MG</given-names></name>, <name><surname>Haas</surname><given-names>BJ</given-names></name>, <name><surname>Yassour</surname><given-names>M</given-names></name>, <name><surname>Levin</surname><given-names>JZ</given-names></name>, <name><surname>Thompson</surname><given-names>DA</given-names></name>, <name><surname>Amit</surname><given-names>I</given-names></name>, <etal>et al</etal>
<article-title>Full-length transcriptome assembly from RNA-Seq data without a reference genome</article-title>. <source>Nature biotechnology</source>. <year>2011</year>;<volume>29</volume>(<issue>7</issue>):<fpage>644</fpage>
<pub-id pub-id-type="doi">10.1038/nbt.1883</pub-id>
<?supplied-pmid 21572440?><pub-id pub-id-type="pmid">21572440</pub-id></mixed-citation></ref><ref id="pone.0211608.ref060"><label>60</label><mixed-citation publication-type="journal">
<name><surname>Campbell</surname><given-names>MS</given-names></name>, <name><surname>Holt</surname><given-names>C</given-names></name>, <name><surname>Moore</surname><given-names>B</given-names></name>, <name><surname>Yandell</surname><given-names>M</given-names></name>. <article-title>Genome annotation and curation using MAKER and MAKER-P</article-title>. <source>Current Protocols in Bioinformatics</source>. <year>2014</year>;<volume>48</volume>(<issue>1</issue>):<fpage>4</fpage>&#x02013;<lpage>11</lpage>. <pub-id pub-id-type="doi">10.1002/0471250953.bi0411s48</pub-id>
<?supplied-pmid 25501943?><pub-id pub-id-type="pmid">25501943</pub-id></mixed-citation></ref><ref id="pone.0211608.ref061"><label>61</label><mixed-citation publication-type="journal">
<name><surname>Deutsch</surname><given-names>EW</given-names></name>, <name><surname>Mendoza</surname><given-names>L</given-names></name>, <name><surname>Shteynberg</surname><given-names>D</given-names></name>, <name><surname>Farrah</surname><given-names>T</given-names></name>, <name><surname>Lam</surname><given-names>H</given-names></name>, <name><surname>Tasman</surname><given-names>N</given-names></name>, <etal>et al</etal>
<article-title>A guided tour of the Trans-Proteomic Pipeline</article-title>. <source>Proteomics</source>. <year>2010</year>;<volume>10</volume>(<issue>6</issue>):<fpage>1150</fpage>&#x02013;<lpage>1159</lpage>. <pub-id pub-id-type="doi">10.1002/pmic.200900375</pub-id>
<?supplied-pmid 20101611?><pub-id pub-id-type="pmid">20101611</pub-id></mixed-citation></ref><ref id="pone.0211608.ref062"><label>62</label><mixed-citation publication-type="journal">
<name><surname>Spjuth</surname><given-names>O</given-names></name>, <name><surname>Bongcam-Rudloff</surname><given-names>E</given-names></name>, <name><surname>Hern&#x000e1;ndez</surname><given-names>GC</given-names></name>, <name><surname>Forer</surname><given-names>L</given-names></name>, <name><surname>Giovacchini</surname><given-names>M</given-names></name>, <name><surname>Guimera</surname><given-names>RV</given-names></name>, <etal>et al</etal>
<article-title>Experiences with workflows for automating data-intensive bioinformatics</article-title>. <source>Biology Direct</source>. <year>2015</year>;<volume>10</volume>(<issue>1</issue>):<fpage>43</fpage>
<pub-id pub-id-type="doi">10.1186/s13062-015-0071-8</pub-id>
<?supplied-pmid 26282399?><pub-id pub-id-type="pmid">26282399</pub-id></mixed-citation></ref><ref id="pone.0211608.ref063"><label>63</label><mixed-citation publication-type="other">Armstrong TG, Wozniak JM, Wilde M, Foster IT. Compiler techniques for massively scalable implicit task parallelism. In: SC14: International Conference for High Performance Computing, Networking, Storage and Analysis. IEEE; 2014. p. 299&#x02013;310. Available from: <ext-link ext-link-type="uri" xlink:href="http://ieeexplore.ieee.org/document/7013012/">http://ieeexplore.ieee.org/document/7013012/</ext-link>.</mixed-citation></ref><ref id="pone.0211608.ref064"><label>64</label><mixed-citation publication-type="journal">
<name><surname>Gadelha</surname><given-names>LMR</given-names><suffix>Jr</suffix></name>, <name><surname>Clifford</surname><given-names>B</given-names></name>, <name><surname>Mattoso</surname><given-names>M</given-names></name>, <name><surname>Wilde</surname><given-names>M</given-names></name>, <name><surname>Foster</surname><given-names>I</given-names></name>. <article-title>Provenance management in Swift</article-title>. <source>Future Generation Computer Systems</source>. <year>2011</year>;<volume>27</volume>(<issue>6</issue>):<fpage>775</fpage>&#x02013;<lpage>780</lpage>. <pub-id pub-id-type="doi">10.1016/j.future.2010.05.003</pub-id></mixed-citation></ref><ref id="pone.0211608.ref065"><label>65</label><mixed-citation publication-type="other">Wilde M, Wozniak JM, Armstrong TG, Katz DS, Foster IT. Productive composition of extreme-scale applications using implicitly parallel dataflow. In: DOE Workshop on Software Productivity for eXtreme scale Science (SWP4XS); 2014.</mixed-citation></ref><ref id="pone.0211608.ref066"><label>66</label><mixed-citation publication-type="journal">
<name><surname>Wozniak</surname><given-names>JM</given-names></name>, <name><surname>Wilde</surname><given-names>M</given-names></name>, <name><surname>Foster</surname><given-names>IT</given-names></name>. <article-title>Language Features for Scalable Distributed-Memory Dataflow Computing</article-title>. In: <source>Data-flow Execution Models for Extreme-scale Computing</source>; <year>2014</year>.</mixed-citation></ref><ref id="pone.0211608.ref067"><label>67</label><mixed-citation publication-type="journal">
<name><surname>Di Tommaso</surname><given-names>P</given-names></name>, <name><surname>Chatzou</surname><given-names>M</given-names></name>, <name><surname>Floden</surname><given-names>EW</given-names></name>, <name><surname>Barja</surname><given-names>PP</given-names></name>, <name><surname>Palumbo</surname><given-names>E</given-names></name>, <name><surname>Notredame</surname><given-names>C</given-names></name>. <article-title>Nextflow enables reproducible computational workflows</article-title>. <source>Nat Biotech</source>. <year>2017</year>;<volume>35</volume>(<issue>4</issue>):<fpage>316</fpage>&#x02013;<lpage>319</lpage>. <pub-id pub-id-type="doi">10.1038/nbt.3820</pub-id></mixed-citation></ref><ref id="pone.0211608.ref068"><label>68</label><mixed-citation publication-type="journal">
<name><surname>Wolstencroft</surname><given-names>K</given-names></name>, <name><surname>Haines</surname><given-names>R</given-names></name>, <name><surname>Fellows</surname><given-names>D</given-names></name>, <name><surname>Williams</surname><given-names>A</given-names></name>, <name><surname>Withers</surname><given-names>D</given-names></name>, <name><surname>Owen</surname><given-names>S</given-names></name>, <etal>et al</etal>
<article-title>The Taverna workflow suite: designing and executing workflows of Web Services on the desktop, web or in the cloud</article-title>. <source>Nucleic Acids Res</source>. <year>2013</year>;<volume>41</volume>(<issue>Web Server issue</issue>):<fpage>W557</fpage>&#x02013;<lpage>61</lpage>. <pub-id pub-id-type="doi">10.1093/nar/gkt328</pub-id>
<?supplied-pmid 23640334?><pub-id pub-id-type="pmid">23640334</pub-id></mixed-citation></ref><ref id="pone.0211608.ref069"><label>69</label><mixed-citation publication-type="journal">
<name><surname>Afgan</surname><given-names>E</given-names></name>, <name><surname>Baker</surname><given-names>D</given-names></name>, <name><surname>Batut</surname><given-names>B</given-names></name>, <name><surname>van den Beek</surname><given-names>M</given-names></name>, <name><surname>Bouvier</surname><given-names>D</given-names></name>, <name><surname>Cech</surname><given-names>M</given-names></name>, <etal>et al</etal>
<article-title>The Galaxy platform for accessible, reproducible and collaborative biomedical analyses: 2018 update</article-title>. <source>Nucleic Acids Res</source>. <year>2018</year>;<volume>46</volume>(<issue>W1</issue>):<fpage>W537</fpage>&#x02013;<lpage>W544</lpage>. <pub-id pub-id-type="doi">10.1093/nar/gky379</pub-id>
<?supplied-pmid 29790989?><pub-id pub-id-type="pmid">29790989</pub-id></mixed-citation></ref><ref id="pone.0211608.ref070"><label>70</label><mixed-citation publication-type="other">Altintas I, Berkley C, Jaeger E, Jones M, Ludascher B, Mock S. Kepler: an extensible system for design and execution of scientific workflows. In: Scientific and Statistical Database Management, 2004. Proceedings. 16th International Conference on. IEEE; 2004. p. 423&#x02013;424.</mixed-citation></ref><ref id="pone.0211608.ref071"><label>71</label><mixed-citation publication-type="journal">
<name><surname>K&#x000f6;ster</surname><given-names>J</given-names></name>, <name><surname>Rahmann</surname><given-names>S</given-names></name>. <article-title>Snakemake&#x02014;a scalable bioinformatics workflow engine</article-title>. <source>Bioinformatics</source>. <year>2012</year>;<volume>28</volume>(<issue>19</issue>):<fpage>2520</fpage>&#x02013;<lpage>2522</lpage>. <pub-id pub-id-type="doi">10.1093/bioinformatics/bts480</pub-id>
<?supplied-pmid 22908215?><pub-id pub-id-type="pmid">22908215</pub-id></mixed-citation></ref><ref id="pone.0211608.ref072"><label>72</label><mixed-citation publication-type="other">GitHub&#x02014;spotify/luigi; 2018. Available from: <ext-link ext-link-type="uri" xlink:href="https://github.com/spotify/luigi">https://github.com/spotify/luigi</ext-link>.</mixed-citation></ref><ref id="pone.0211608.ref073"><label>73</label><mixed-citation publication-type="journal">
<name><surname>Guimera</surname><given-names>RV</given-names></name>. <article-title>bcbio-nextgen: Automated, distributed next-gen sequencing pipeline</article-title>. <source>EMBnet j</source>. <year>2012</year>;<volume>17</volume>(<issue>B</issue>):<fpage>30</fpage>
<pub-id pub-id-type="doi">10.14806/ej.17.B.286</pub-id></mixed-citation></ref><ref id="pone.0211608.ref074"><label>74</label><mixed-citation publication-type="journal">
<name><surname>Sadedin</surname><given-names>SP</given-names></name>, <name><surname>Pope</surname><given-names>B</given-names></name>, <name><surname>Oshlack</surname><given-names>A</given-names></name>. <article-title>Bpipe: a tool for running and managing bioinformatics pipelines</article-title>. <source>Bioinformatics</source>. <year>2012</year>;<volume>28</volume>(<issue>11</issue>):<fpage>1525</fpage>&#x02013;<lpage>1526</lpage>. <pub-id pub-id-type="doi">10.1093/bioinformatics/bts167</pub-id>
<?supplied-pmid 22500002?><pub-id pub-id-type="pmid">22500002</pub-id></mixed-citation></ref><ref id="pone.0211608.ref075"><label>75</label><mixed-citation publication-type="other">Tommaso PD. Nextflow&#x02014;Introducing Nextflow REPL Console; 2015. Available from: <ext-link ext-link-type="uri" xlink:href="https://www.nextflow.io/blog/2015/introducing-nextflow-console.html">https://www.nextflow.io/blog/2015/introducing-nextflow-console.html</ext-link>.</mixed-citation></ref><ref id="pone.0211608.ref076"><label>76</label><mixed-citation publication-type="other">Kurs JP, Simi M, Campagne F. NextflowWorkbench: Reproducible and Reusable Workflows for Beginners and Experts. bioRxiv. 2016; p. 041236.</mixed-citation></ref><ref id="pone.0211608.ref077"><label>77</label><mixed-citation publication-type="book">
<name><surname>Roosta</surname><given-names>SH</given-names></name>. <chapter-title>Data Flow and Functional Programming</chapter-title> In: <source>Parallel Processing and Parallel Algorithms</source>. <publisher-loc>New York, NY</publisher-loc>: <publisher-name>Springer New York</publisher-name>; <year>2000</year> p. <fpage>411</fpage>&#x02013;<lpage>437</lpage>. Available from: <ext-link ext-link-type="uri" xlink:href="http://link.springer.com/10.1007/978-1-4612-1220-1_9">http://link.springer.com/10.1007/978-1-4612-1220-1_9</ext-link>.</mixed-citation></ref><ref id="pone.0211608.ref078"><label>78</label><mixed-citation publication-type="journal">
<name><surname>Abouelhoda</surname><given-names>M</given-names></name>, <name><surname>Issa</surname><given-names>S</given-names></name>, <name><surname>Ghanem</surname><given-names>M</given-names></name>. <article-title>Tavaxy: Integrating Taverna and Galaxy workflows with cloud computing support</article-title>. <source>BMC Bioinformatics</source>. <year>2012</year>;<volume>13</volume>(<issue>1</issue>):<fpage>77</fpage>
<pub-id pub-id-type="doi">10.1186/1471-2105-13-77</pub-id>
<?supplied-pmid 22559942?><pub-id pub-id-type="pmid">22559942</pub-id></mixed-citation></ref><ref id="pone.0211608.ref079"><label>79</label><mixed-citation publication-type="journal">
<name><surname>Goderis</surname><given-names>A</given-names></name>, <name><surname>Brooks</surname><given-names>C</given-names></name>, <name><surname>Altintas</surname><given-names>I</given-names></name>, <name><surname>Lee</surname><given-names>EA</given-names></name>, <name><surname>Goble</surname><given-names>C</given-names></name>. <article-title>Composing Different Models of Computation in Kepler and Ptolemy II 1 The Need for Composing Models of Computation in E-Science</article-title>. <source>LNCS</source>. <year>2007</year>;<volume>4489</volume>:<fpage>182</fpage>&#x02013;<lpage>190</lpage>.</mixed-citation></ref><ref id="pone.0211608.ref080"><label>80</label><mixed-citation publication-type="journal">
<name><surname>Ferreira da Silva</surname><given-names>R</given-names></name>, <name><surname>Filgueira</surname><given-names>R</given-names></name>, <name><surname>Pietri</surname><given-names>I</given-names></name>, <name><surname>Jiang</surname><given-names>M</given-names></name>, <name><surname>Sakellariou</surname><given-names>R</given-names></name>, <name><surname>Deelman</surname><given-names>E</given-names></name>. <article-title>A characterization of workflow management systems for extreme-scale applications</article-title>. <source>Future Generation Computer Systems</source>. <year>2017</year>;<volume>75</volume>:<fpage>228</fpage>&#x02013;<lpage>238</lpage>. <pub-id pub-id-type="doi">10.1016/j.future.2017.02.026</pub-id></mixed-citation></ref><ref id="pone.0211608.ref081"><label>81</label><mixed-citation publication-type="other">Wilde M, Wozniak JM, Armstrong TG, Katz DS, Foster IT. Productive composition of extreme-scale applications using implicitly parallel dataflow. In: ASCR Workshop on Software Productivity for Extreme-Scale Science; 2014.</mixed-citation></ref><ref id="pone.0211608.ref082"><label>82</label><mixed-citation publication-type="other">Chilton J, Moskalenko O, Frey J, Chorny I. Running Galaxy Tools on a Cluster; 2018. Available from: <ext-link ext-link-type="uri" xlink:href="https://docs.galaxyproject.org/en/latest/admin/cluster.html">https://docs.galaxyproject.org/en/latest/admin/cluster.html</ext-link>.</mixed-citation></ref><ref id="pone.0211608.ref083"><label>83</label><mixed-citation publication-type="journal">
<name><surname>Afgan</surname><given-names>E</given-names></name>, <name><surname>Baker</surname><given-names>D</given-names></name>, <name><surname>Beek</surname><given-names>MVD</given-names></name>, <name><surname>Blankenberg</surname><given-names>D</given-names></name>, <name><surname>Bouvier</surname><given-names>D</given-names></name>, <name><surname>Chilton</surname><given-names>J</given-names></name>, <etal>et al</etal>
<article-title>The Galaxy platform for accessible, reproducible and collaborative biomedical analyses: 2016 update</article-title>. <source>Nucleic Acids Research</source>. <year>2016</year>;<volume>44</volume>(<issue>W1</issue>):<fpage>3</fpage>&#x02013;<lpage>10</lpage>. <pub-id pub-id-type="doi">10.1093/nar/gkw343</pub-id></mixed-citation></ref><ref id="pone.0211608.ref084"><label>84</label><mixed-citation publication-type="other">Riazi S. SparkGalaxy: Workflow-based Big Data Processing; 2016.</mixed-citation></ref><ref id="pone.0211608.ref085"><label>85</label><mixed-citation publication-type="other">Pireddu L, Leo S, Soranzo N, Zanetti G. A Hadoop-Galaxy adapter for user-friendly and scalable data-intensive bioinformatics in Galaxy. In: Proceedings of the 5th ACM Conference on Bioinformatics, Computational Biology, and Health Informatics&#x02014;BCB&#x02019;14. New York, New York, USA: ACM Press; 2014. p. 184&#x02013;191. Available from: <ext-link ext-link-type="uri" xlink:href="http://dl.acm.org/citation.cfm?doid=2649387.2649429">http://dl.acm.org/citation.cfm?doid=2649387.2649429</ext-link>.</mixed-citation></ref><ref id="pone.0211608.ref086"><label>86</label><mixed-citation publication-type="other">Galaxy: Scaling and Load balancing; 2018. Available from: <ext-link ext-link-type="uri" xlink:href="https://docs.galaxyproject.org/en/latest/admin/scaling.html">https://docs.galaxyproject.org/en/latest/admin/scaling.html</ext-link>.</mixed-citation></ref><ref id="pone.0211608.ref087"><label>87</label><mixed-citation publication-type="journal">
<name><surname>Milicchio</surname><given-names>F</given-names></name>, <name><surname>Rose</surname><given-names>R</given-names></name>, <name><surname>Bian</surname><given-names>J</given-names></name>, <name><surname>Min</surname><given-names>J</given-names></name>, <name><surname>Prosperi</surname><given-names>M</given-names></name>. <article-title>Visual programming for next-generation sequencing data analytics</article-title>. <source>BioData Mining</source>. <year>2016</year>;<volume>9</volume>(<issue>1</issue>):<fpage>16</fpage>
<pub-id pub-id-type="doi">10.1186/s13040-016-0095-3</pub-id>
<?supplied-pmid 27127540?><pub-id pub-id-type="pmid">27127540</pub-id></mixed-citation></ref><ref id="pone.0211608.ref088"><label>88</label><mixed-citation publication-type="journal">
<name><surname>Deelman</surname><given-names>E</given-names></name>, <name><surname>Vahi</surname><given-names>K</given-names></name>, <name><surname>Juve</surname><given-names>G</given-names></name>, <name><surname>Rynge</surname><given-names>M</given-names></name>, <name><surname>Callaghan</surname><given-names>S</given-names></name>, <name><surname>Maechling</surname><given-names>PJ</given-names></name>, <etal>et al</etal>
<article-title>Pegasus: a Workflow Management System for Science Automation</article-title>. <source>Future Generation Computer Systems</source>. <year>2015</year>;<volume>46</volume>:<fpage>17</fpage>&#x02013;<lpage>35</lpage>. <pub-id pub-id-type="doi">10.1016/j.future.2014.10.008</pub-id></mixed-citation></ref><ref id="pone.0211608.ref089"><label>89</label><mixed-citation publication-type="journal">
<name><surname>Cingolani</surname><given-names>P</given-names></name>, <name><surname>Sladek</surname><given-names>R</given-names></name>, <name><surname>Blanchette</surname><given-names>M</given-names></name>. <article-title>BigDataScript: a scripting language for data pipelines</article-title>. <source>Bioinformatics</source>. <year>2014</year>;<volume>31</volume>(<issue>1</issue>):<fpage>10</fpage>&#x02013;<lpage>16</lpage>. <pub-id pub-id-type="doi">10.1093/bioinformatics/btu595</pub-id>
<?supplied-pmid 25189778?><pub-id pub-id-type="pmid">25189778</pub-id></mixed-citation></ref><ref id="pone.0211608.ref090"><label>90</label><mixed-citation publication-type="journal">
<name><surname>Goodstadt</surname><given-names>L</given-names></name>. <article-title>Ruffus: a lightweight Python library for computational pipelines</article-title>. <source>Bioinformatics</source>. <year>2010</year>;<volume>26</volume>(<issue>21</issue>):<fpage>2778</fpage>&#x02013;<lpage>2779</lpage>. <pub-id pub-id-type="doi">10.1093/bioinformatics/btq524</pub-id>
<?supplied-pmid 20847218?><pub-id pub-id-type="pmid">20847218</pub-id></mixed-citation></ref><ref id="pone.0211608.ref091"><label>91</label><mixed-citation publication-type="journal">
<name><surname>Brown</surname><given-names>DK</given-names></name>, <name><surname>Penkler</surname><given-names>DL</given-names></name>, <name><surname>Musyoka</surname><given-names>TM</given-names></name>, <name><surname>Bishop</surname><given-names>OT</given-names></name>. <article-title>JMS: An Open Source Workflow Management System and Web-Based Cluster Front-End for High Performance Computing</article-title>. <source>PLOS ONE</source>. <year>2015</year>;<volume>10</volume>(<issue>8</issue>):<fpage>1</fpage>&#x02013;<lpage>25</lpage>. <pub-id pub-id-type="doi">10.1371/journal.pone.0134273</pub-id></mixed-citation></ref><ref id="pone.0211608.ref092"><label>92</label><mixed-citation publication-type="journal">
<name><surname>Garcia Castro</surname><given-names>A</given-names></name>, <name><surname>Thoraval</surname><given-names>S</given-names></name>, <name><surname>Garcia</surname><given-names>LJ</given-names></name>, <name><surname>Ragan</surname><given-names>MA</given-names></name>. <article-title>Workflows in bioinformatics: meta-analysis and prototype implementation of a workflow generator</article-title>. <source>BMC Bioinformatics</source>. <year>2005</year>;<volume>6</volume>(<issue>1</issue>):<fpage>87</fpage>
<pub-id pub-id-type="doi">10.1186/1471-2105-6-87</pub-id>
<?supplied-pmid 15813976?><pub-id pub-id-type="pmid">15813976</pub-id></mixed-citation></ref><ref id="pone.0211608.ref093"><label>93</label><mixed-citation publication-type="journal">
<name><surname>Vivian</surname><given-names>J</given-names></name>, <name><surname>Rao</surname><given-names>AA</given-names></name>, <name><surname>Nothaft</surname><given-names>FA</given-names></name>, <name><surname>Ketchum</surname><given-names>C</given-names></name>, <name><surname>Armstrong</surname><given-names>J</given-names></name>, <name><surname>Novak</surname><given-names>A</given-names></name>, <etal>et al</etal>
<article-title>Toil enables reproducible, open source, big biomedical data analyses</article-title>. <source>Nature Biotechnology</source>. <year>2017</year>;<volume>35</volume>(<issue>4</issue>):<fpage>314</fpage>&#x02013;<lpage>316</lpage>. <pub-id pub-id-type="doi">10.1038/nbt.3772</pub-id>
<?supplied-pmid 28398314?><pub-id pub-id-type="pmid">28398314</pub-id></mixed-citation></ref><ref id="pone.0211608.ref094"><label>94</label><mixed-citation publication-type="other">UCSC Computational Genomics Lab. Developing a Workflow&#x02014;Toil 3.12.0 documentation; 2017. Available from: <ext-link ext-link-type="uri" xlink:href="http://toil.readthedocs.io/en/3.12.0/developingWorkflows/developing.html#workflows-with-multiple-jobs">http://toil.readthedocs.io/en/3.12.0/developingWorkflows/developing.html#workflows-with-multiple-jobs</ext-link>.</mixed-citation></ref><ref id="pone.0211608.ref095"><label>95</label><mixed-citation publication-type="journal">
<name><surname>Kaushik</surname><given-names>G</given-names></name>, <name><surname>Ivkovic</surname><given-names>S</given-names></name>, <name><surname>Simonovic</surname><given-names>J</given-names></name>, <name><surname>Tijanic</surname><given-names>N</given-names></name>, <name><surname>Davis-Dusenbery</surname><given-names>B</given-names></name>, <name><surname>Kural</surname><given-names>D</given-names></name>. <article-title>Rabix: an Open-Source Workflow Executor Supporting Recomputability and Interoperability of Workflow Descriptions</article-title>. <source>Pacific Symposium on Biocomputing Pacific Symposium on Biocomputing</source>. <year>2016</year>;<volume>22</volume>:<fpage>154</fpage>&#x02013;<lpage>165</lpage>.</mixed-citation></ref><ref id="pone.0211608.ref096"><label>96</label><mixed-citation publication-type="other">Arvados| Open Source Big Data Processing and Bioinformatics;. Available from: <ext-link ext-link-type="uri" xlink:href="https://arvados.org/">https://arvados.org/</ext-link>.</mixed-citation></ref><ref id="pone.0211608.ref097"><label>97</label><mixed-citation publication-type="other">Gentry J. Multiple workflow languages coming to Cromwell, starting with CWL; 2018. Available from: <ext-link ext-link-type="uri" xlink:href="https://gatkforums.broadinstitute.org/wdl/discussion/11109/">https://gatkforums.broadinstitute.org/wdl/discussion/11109/</ext-link>.</mixed-citation></ref></ref-list></back></article>