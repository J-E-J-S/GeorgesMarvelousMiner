<!DOCTYPE article PUBLIC "-//NLM//DTD JATS (Z39.96) Journal Archiving and Interchange DTD v1.1 20151215//EN" "JATS-archivearticle1.dtd"> 
<article xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink" article-type="research-article"><?properties open_access?><?DTDIdentifier.IdentifierValue -//Springer-Verlag//DTD A++ V2.4//EN?><?DTDIdentifier.IdentifierType public?><?SourceDTD.DTDName A++V2.4.dtd?><?SourceDTD.Version 2.4?><?ConverterInfo.XSLTName springer2nlmx2.xsl?><?ConverterInfo.Version 1?><front><journal-meta><journal-id journal-id-type="nlm-ta">BMC Genomics</journal-id><journal-id journal-id-type="iso-abbrev">BMC Genomics</journal-id><journal-title-group><journal-title>BMC Genomics</journal-title></journal-title-group><issn pub-type="epub">1471-2164</issn><publisher><publisher-name>BioMed Central</publisher-name><publisher-loc>London</publisher-loc></publisher></journal-meta><article-meta><article-id pub-id-type="pmcid">6456962</article-id><article-id pub-id-type="publisher-id">5468</article-id><article-id pub-id-type="doi">10.1186/s12864-019-5468-9</article-id><article-categories><subj-group subj-group-type="heading"><subject>Research</subject></subj-group></article-categories><title-group><article-title>GPU accelerated sequence alignment with traceback for GATK HaplotypeCaller</article-title></title-group><contrib-group><contrib contrib-type="author"><name><surname>Ren</surname><given-names>Shanshan</given-names></name><xref ref-type="aff" rid="Aff1"/></contrib><contrib contrib-type="author"><name><surname>Ahmed</surname><given-names>Nauman</given-names></name><xref ref-type="aff" rid="Aff1"/></contrib><contrib contrib-type="author"><name><surname>Bertels</surname><given-names>Koen</given-names></name><xref ref-type="aff" rid="Aff1"/></contrib><contrib contrib-type="author" corresp="yes"><name><surname>Al-Ars</surname><given-names>Zaid</given-names></name><address><email>z.al-ars@tudelft.nl</email></address><xref ref-type="aff" rid="Aff1"/></contrib><aff id="Aff1"><institution-wrap><institution-id institution-id-type="ISNI">0000 0001 2097 4740</institution-id><institution-id institution-id-type="GRID">grid.5292.c</institution-id><institution>Delft University of Technology, </institution></institution-wrap>Mekelweg 4, Delft, 2628 CD The Netherlands </aff></contrib-group><pub-date pub-type="epub"><day>4</day><month>4</month><year>2019</year></pub-date><pub-date pub-type="pmc-release"><day>4</day><month>4</month><year>2019</year></pub-date><pub-date pub-type="collection"><year>2019</year></pub-date><volume>20</volume><issue>Suppl 2</issue><issue-sponsor>Publication of this supplement has not been supported by sponsorship. Information about the source of funding for publication charges can be found in the individual articles. The articles have undergone the journal's standard peer review process for supplements. The Supplement Editors declare that they have no competing interests.</issue-sponsor><elocation-id>184</elocation-id><permissions><copyright-statement>&#x000a9; The Author(s) 2019</copyright-statement><license license-type="OpenAccess"><license-p><bold>Open Access</bold> This article is distributed under the terms of the Creative Commons Attribution 4.0 International License(<ext-link ext-link-type="uri" xlink:href="http://creativecommons.org/licenses/by/4.0/">http://creativecommons.org/licenses/by/4.0/</ext-link>), which permits unrestricted use, distribution, and reproduction in any medium, provided you give appropriate credit to the original author(s) and the source, provide a link to the Creative Commons license, and indicate if changes were made. The Creative Commons Public Domain Dedication waiver(<ext-link ext-link-type="uri" xlink:href="http://creativecommons.org/publicdomain/zero/1.0/">http://creativecommons.org/publicdomain/zero/1.0/</ext-link>) applies to the data made available in this article, unless otherwise stated.</license-p></license></permissions><abstract id="Abs1"><sec><title>Background</title><p>Pairwise sequence alignment is widely used in many biological tools and applications. Existing GPU accelerated implementations mainly focus on calculating optimal alignment score and omit identifying the optimal alignment itself. In GATK HaplotypeCaller (HC), the semi-global pairwise sequence alignment with traceback has so far been difficult to accelerate effectively on GPUs.</p></sec><sec><title>Results</title><p>We first analyze the characteristics of the semi-global alignment with traceback in GATK HC and then propose a new algorithm that allows for retrieving the optimal alignment efficiently on GPUs. For the first stage, we choose intra-task parallelization model to calculate the position of the optimal alignment score and the backtracking matrix. Moreover, in the first stage, our GPU implementation also records the length of consecutive matches/mismatches in addition to lengths of consecutive insertions and deletions as in the CPU-based implementation. This helps efficiently retrieve the backtracking matrix to obtain the optimal alignment in the second stage.</p></sec><sec><title>Conclusions</title><p>Experimental results show that our alignment kernel with traceback is up to 80x and 14.14x faster than its CPU counterpart with synthetic datasets and real datasets, respectively. When integrated into GATK HC (alongside a GPU accelerated pair-HMMs forward kernel), the overall acceleration is 2.3x faster than the baseline GATK HC implementation, and 1.34x faster than the GATK HC implementation with the integrated GPU-based pair-HMMs forward algorithm. Although the methods proposed in this paper is to improve the performance of GATK HC, they can also be used in other pairwise alignments and applications.</p></sec></abstract><kwd-group xml:lang="en"><title>Keywords</title><kwd>Semi-global alignment with traceback</kwd><kwd>Optimal alignment</kwd><kwd>GATK HaplotypeCaller (HC)</kwd><kwd>GPUs</kwd></kwd-group><conference xlink:href="http://glab.hzau.edu.cn/APBC2019/"><conf-name>The 17th Asia Pacific Bioinformatics Conference (APBC 2019)</conf-name><conf-acronym>APBC 2019</conf-acronym><conf-loc>Wuhan, China</conf-loc><conf-date>14-16 January 2019</conf-date></conference><custom-meta-group><custom-meta><meta-name>issue-copyright-statement</meta-name><meta-value>&#x000a9; The Author(s) 2019</meta-value></custom-meta></custom-meta-group></article-meta></front><body><sec id="Sec1"><title>Background</title><p>NGS (Next Generation Sequencing) platforms offer the capacity to generate large amounts of DNA sequencing data in a short time and at a low cost. However, the analysis of the dramatic amounts of DNA sequencing data is still a computational challenge. Researchers have proposed many methods to improve the performance of the DNA sequencing data analysis tools and applications. One method is to execute these tools and applications on high performance computing architectures, such as supercomputers, clusters and even cloud environments. Another method is to use accelerators, such as GPUs and FPGAs, to accelerate the time-consuming kernels of these tools and applications to improve their performance.</p><p>GATK HaplotypeCaller (HC) is a popular variant caller, which is used to find the differences (or variants) between the sample DNA sequence compared with the reference sequence. Although GATK HC has higher accuracy of identifying variants compared with many other variant callers, its feasibility is limited by the long execution time needed for the analysis, which has proven to be difficult to optimize. This has driven researchers to improve its performance. Intel and IBM researchers both employ vector instructions to optimize the pair-HMMs forward algorithm [<xref ref-type="bibr" rid="CR1">1</xref>, <xref ref-type="bibr" rid="CR2">2</xref>], which is the most time-consuming part of GATK HC, to reduce the total execution time. Ren et al. [<xref ref-type="bibr" rid="CR3">3</xref>, <xref ref-type="bibr" rid="CR4">4</xref>] uses GPUs to accelerate the pair-HMMs forward algorithm in GATK HC, which achieved 1.71x speedup in single thread mode. After accelerating the pair-HMMs forward algorithm on GPUs, profiling of GATK HC shows that the semi-global pairwise sequence alignment accounts for around 34.5% of the overall execution time, making it the most time-consuming kernel in the application. This provides an opportunity to further improve the performance of GATK HC using GPU acceleration.</p><p>Pairwise sequence alignment, which includes global alignment, semi-global alignment and local alignment, is one of the commonly used techniques in many biological tools and applications. The global alignment and the semi-global alignment are calculated by the Needleman-Wunsch algorithm and the modified Needleman-Wunsch algorithm, respectively, while the local alignment is calculated by the Smith-Waterman algorithm. Although there are some differences existing in the three algorithms, the main framework of these algorithms is similar, which includes two stages: (1) a dynamic programming kernel to calculate the score matrices and find the optimal alignment score; (2) a traceback (or backtracking) kernel to find the optimal alignment.</p><p>Since three kinds of pairwise sequence alignment (global, semi-global and local) have the same framework and differ only in details, techniques of speeding up one can be applied to the other two with tiny modifications. Different kinds of high-performance platforms, especially accelerators, such as FPGAs [<xref ref-type="bibr" rid="CR5">5</xref>, <xref ref-type="bibr" rid="CR6">6</xref>] and GPUs [<xref ref-type="bibr" rid="CR7">7</xref>&#x02013;<xref ref-type="bibr" rid="CR16">16</xref>], are used to reduce their execution time.</p><p>There has been much research done to reduce the execution time of the three kinds of pairwise alignment on GPUs. There are two approaches to implement the first stage of the pairwise sequence alignment on GPUs (which is to calculate the optimal alignment score): inter-task parallelization model and intra-task parallelization model. The former is that each thread performs one alignment independently, such as [<xref ref-type="bibr" rid="CR7">7</xref>] and [<xref ref-type="bibr" rid="CR8">8</xref>]. The latter is that threads in a block cooperate to perform an alignment, such as [<xref ref-type="bibr" rid="CR9">9</xref>]. If the pairwise sequence alignment is applied for sequence database scanning, aligning a query sequence with all database sequences for sequence similarity, a query profile and related data storage and access techniques are employed to reduce memory accesses on GPUs, such as [<xref ref-type="bibr" rid="CR10">10</xref>] and [<xref ref-type="bibr" rid="CR11">11</xref>]. In [<xref ref-type="bibr" rid="CR11">11</xref>], alignments are performed in interleaved mode in order to amortize the cost of initiating each execution pass.</p><p>However, very few researchers implement the second stage on GPUs. The existing implementations can be classified into two groups. The implementations of the first group are based on backtracking matrices. Liu et al. [<xref ref-type="bibr" rid="CR11">11</xref>] proposed to store the score matrices and backtrack the score matrices to obtain the optimal alignment. However, the method is not described clearly. gpu-pairAlign [<xref ref-type="bibr" rid="CR12">12</xref>] proposed to store the alignment moves in four Boolean backtracking matrices during the first stage and retrieve the four Boolean backtracking matrices instead of the score matrices. This group of implementations obtain the optimal alignment in linear time, but the disadvantage is that their space complexity is quadratic. The implementations of the second group are based on the Myers-Miller algorithm. MSA-CUDA [<xref ref-type="bibr" rid="CR13">13</xref>] developed a stack-based iterative implementation of the Myers-Miller algorithm [<xref ref-type="bibr" rid="CR17">17</xref>] to retrieve the optimal alignment in linear space. SW# [<xref ref-type="bibr" rid="CR14">14</xref>] proposed a modified Myers-Miller algorithm. CUDAlign 2.0 [<xref ref-type="bibr" rid="CR15">15</xref>] combined the Myers-Miller and Smith-Waterman algorithm. Moreover, with several versions of incremental optimizations, CUDAlign 4.0 [<xref ref-type="bibr" rid="CR16">16</xref>] is able to achieve the optimal alignment of chromosome-wide sequences using multiple GPUs. However, their approaches have quadratic time complexity, making them only suitable for the pairwise alignment of very long DNA and protein sequences.</p><p>In this paper, we provide an accelerated solution tailored to GATK HC which implements the semi-global pairwise sequence alignment with traceback on GPUs to further improve the performance. The contributions of this paper are as follows: 
<list list-type="bullet"><list-item><p>We first analyze the characteristics of the semi-global alignment in GATK HC and then propose a GPU-based implementation of the semi-global alignment with traceback based on the analysis.</p></list-item><list-item><p>During the first stage, we propose to record the length of consecutive match(es)/mismatch(es) and store the alignment moves in a special backtracking matrix.</p></list-item><list-item><p>We also propose a new algorithm that allows for retrieving the optimal alignment efficiently on GPUs.</p></list-item><list-item><p>We benchmark the results and show an overall speedup of GATK HC of about 2.3x over the non-accelerated version.</p></list-item></list></p><p>Although this paper proposes to improve the performance of GATK HC, the GPU-based implementation of the semi-global alignment with traceback can be used in other applications and tools. Moreover, since there are only small differences among the global alignment, semi-global alignment and local alignment, the methods proposed in this paper can also be applied to the global alignment and local alignment.</p></sec><sec id="Sec2"><title>Methods</title><sec id="Sec3"><title>A brief overview of semi-global alignment</title><p>Semi-global alignment finds the overlap between two sequences. Insertion and deletions introduce gaps in the alignment. Gaps at the start or end of the sequences may be neglected. Hence, different types of semi-global alignments are possible between two sequences. Figure&#x000a0;<xref rid="Fig1" ref-type="fig">1</xref> shows an example of the type of the semi-global alignment performed in GATK HC.
<fig id="Fig1"><label>Fig. 1</label><caption><p>An example of an semi-global alignment of two sequences in GATK HC. R1 and R2 represent two sequences. Gaps (&#x02018;-&#x02019;) at the start and end of two sequences are neglected. In the alignment, there are three kinds of operations indicating how R2 aligns with R1. &#x02018;M&#x02019; indicates that a base in R2 aligns with a base in R1 (matches or mismatches); &#x02018;I&#x02019; indicates that a base in R2 is not in R1; &#x02018;D&#x02019; indicates that a base in R1 is not in R2</p></caption><graphic xlink:href="12864_2019_5468_Fig1_HTML" id="MO1"/></fig></p><p>The pairwise sequence alignment is to find the optimal alignment between two sequences, which has the optimal alignment score. The modified Needleman-Wunsch algorithm with affine gap penalties to calculate the optimal alignment score of the semi-global alignment in GATK HC is defined as</p><p>Initialization: 
<disp-formula id="Equ1"><label>1</label><alternatives><tex-math id="M1">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document} $$ \begin{aligned} M_{i,0} &#x00026;=0 &#x00026; (0\leq i\leq m)\\ M_{0,j} &#x00026;=0 &#x00026; (0\leq j\leq n)\\ \end{aligned}  $$ \end{document}</tex-math><mml:math id="M2"><mml:mtable><mml:mtr><mml:mtd><mml:msub><mml:mrow><mml:mi>M</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mo>,</mml:mo><mml:mn>0</mml:mn></mml:mrow></mml:msub></mml:mtd><mml:mtd><mml:mo>=</mml:mo><mml:mn>0</mml:mn></mml:mtd><mml:mtd><mml:mo>(</mml:mo><mml:mn>0</mml:mn><mml:mo>&#x02264;</mml:mo><mml:mi>i</mml:mi><mml:mo>&#x02264;</mml:mo><mml:mi>m</mml:mi><mml:mo>)</mml:mo></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:msub><mml:mrow><mml:mi>M</mml:mi></mml:mrow><mml:mrow><mml:mn>0</mml:mn><mml:mo>,</mml:mo><mml:mi>j</mml:mi></mml:mrow></mml:msub></mml:mtd><mml:mtd><mml:mo>=</mml:mo><mml:mn>0</mml:mn></mml:mtd><mml:mtd><mml:mo>(</mml:mo><mml:mn>0</mml:mn><mml:mo>&#x02264;</mml:mo><mml:mi>j</mml:mi><mml:mo>&#x02264;</mml:mo><mml:mi>n</mml:mi><mml:mo>)</mml:mo></mml:mtd></mml:mtr><mml:mtr/></mml:mtable></mml:math><graphic xlink:href="12864_2019_5468_Article_Equ1.gif" position="anchor"/></alternatives></disp-formula></p><p>Recurrence: 
<disp-formula id="Equ2"><label>2</label><alternatives><tex-math id="M3">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document} $$ \begin{aligned} M_{i,j} &#x00026; = max \left\{ \begin{array}{l} M_{i-1,j-1} + sbt\left({R1[i],R2\left[j\right]} \right) \\ D_{i,j} \\ I_{i,j} \\ \end{array} \right.\\ D_{i,j} &#x00026; = max \left\{ \begin{array}{l} D_{i-1,j}- \beta \\ M_{i-1,j}- \alpha \\ \end{array} \right.\\ I_{i,j} &#x00026; = max \left\{ \begin{array}{l} I_{i,j-1}-\beta \\ M_{i,j-1}-\alpha \\ \end{array} \right.\\ \end{aligned}  $$ \end{document}</tex-math><mml:math id="M4"><mml:mtable><mml:mtr><mml:mtd><mml:msub><mml:mrow><mml:mi>M</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mo>,</mml:mo><mml:mi>j</mml:mi></mml:mrow></mml:msub></mml:mtd><mml:mtd><mml:mo>=</mml:mo><mml:mtext mathvariant="italic">max</mml:mtext><mml:mfenced close="" open="{" separators=""><mml:mrow><mml:mtable><mml:mtr><mml:mtd><mml:msub><mml:mrow><mml:mi>M</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mo>&#x02212;</mml:mo><mml:mn>1</mml:mn><mml:mo>,</mml:mo><mml:mi>j</mml:mi><mml:mo>&#x02212;</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:mtext mathvariant="italic">sbt</mml:mtext><mml:mfenced close=")" open="(" separators=""><mml:mrow><mml:mi>R</mml:mi><mml:mn>1</mml:mn><mml:mo>[</mml:mo><mml:mi>i</mml:mi><mml:mo>]</mml:mo><mml:mo>,</mml:mo><mml:mi>R</mml:mi><mml:mn>2</mml:mn><mml:mfenced close="]" open="[" separators=""><mml:mrow><mml:mi>j</mml:mi></mml:mrow></mml:mfenced></mml:mrow></mml:mfenced></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:msub><mml:mrow><mml:mi>D</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mo>,</mml:mo><mml:mi>j</mml:mi></mml:mrow></mml:msub></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:msub><mml:mrow><mml:mi>I</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mo>,</mml:mo><mml:mi>j</mml:mi></mml:mrow></mml:msub></mml:mtd></mml:mtr><mml:mtr/></mml:mtable></mml:mrow></mml:mfenced></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:msub><mml:mrow><mml:mi>D</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mo>,</mml:mo><mml:mi>j</mml:mi></mml:mrow></mml:msub></mml:mtd><mml:mtd><mml:mo>=</mml:mo><mml:mtext mathvariant="italic">max</mml:mtext><mml:mfenced close="" open="{" separators=""><mml:mrow><mml:mtable><mml:mtr><mml:mtd><mml:msub><mml:mrow><mml:mi>D</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mo>&#x02212;</mml:mo><mml:mn>1</mml:mn><mml:mo>,</mml:mo><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mo>&#x02212;</mml:mo><mml:mi>&#x003b2;</mml:mi></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:msub><mml:mrow><mml:mi>M</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mo>&#x02212;</mml:mo><mml:mn>1</mml:mn><mml:mo>,</mml:mo><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mo>&#x02212;</mml:mo><mml:mi>&#x003b1;</mml:mi></mml:mtd></mml:mtr><mml:mtr/></mml:mtable></mml:mrow></mml:mfenced></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:msub><mml:mrow><mml:mi>I</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mo>,</mml:mo><mml:mi>j</mml:mi></mml:mrow></mml:msub></mml:mtd><mml:mtd><mml:mo>=</mml:mo><mml:mtext mathvariant="italic">max</mml:mtext><mml:mfenced close="" open="{" separators=""><mml:mrow><mml:mtable><mml:mtr><mml:mtd><mml:msub><mml:mrow><mml:mi>I</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mo>,</mml:mo><mml:mi>j</mml:mi><mml:mo>&#x02212;</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>&#x02212;</mml:mo><mml:mi>&#x003b2;</mml:mi></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:msub><mml:mrow><mml:mi>M</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mo>,</mml:mo><mml:mi>j</mml:mi><mml:mo>&#x02212;</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>&#x02212;</mml:mo><mml:mi>&#x003b1;</mml:mi></mml:mtd></mml:mtr><mml:mtr/></mml:mtable></mml:mrow></mml:mfenced></mml:mtd></mml:mtr><mml:mtr/></mml:mtable></mml:math><graphic xlink:href="12864_2019_5468_Article_Equ2.gif" position="anchor"/></alternatives></disp-formula></p><p>Termination: 
<disp-formula id="Equ3"><label>3</label><alternatives><tex-math id="M5">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document} $$ Result=max \left\{ \begin{array}{l} \max_{\{1 \leq i \leq m \}} M_{i,n}\\ \max_{\{ {1 \leq j \leq n} \}} M_{m,j}\\ \end{array} \right.  $$ \end{document}</tex-math><mml:math id="M6"><mml:mtext mathvariant="italic">Result</mml:mtext><mml:mo>=</mml:mo><mml:mtext mathvariant="italic">max</mml:mtext><mml:mfenced close="" open="{" separators=""><mml:mrow><mml:mtable><mml:mtr><mml:mtd><mml:munder><mml:mrow><mml:mo>max</mml:mo></mml:mrow><mml:mrow><mml:mo>{</mml:mo><mml:mn>1</mml:mn><mml:mo>&#x02264;</mml:mo><mml:mi>i</mml:mi><mml:mo>&#x02264;</mml:mo><mml:mi>m</mml:mi><mml:mo>}</mml:mo></mml:mrow></mml:munder><mml:msub><mml:mrow><mml:mi>M</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mo>,</mml:mo><mml:mi>n</mml:mi></mml:mrow></mml:msub></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:munder><mml:mrow><mml:mo>max</mml:mo></mml:mrow><mml:mrow><mml:mo>{</mml:mo><mml:mn>1</mml:mn><mml:mo>&#x02264;</mml:mo><mml:mi>j</mml:mi><mml:mo>&#x02264;</mml:mo><mml:mi>n</mml:mi><mml:mo>}</mml:mo></mml:mrow></mml:munder><mml:msub><mml:mrow><mml:mi>M</mml:mi></mml:mrow><mml:mrow><mml:mi>m</mml:mi><mml:mo>,</mml:mo><mml:mi>j</mml:mi></mml:mrow></mml:msub></mml:mtd></mml:mtr><mml:mtr/></mml:mtable></mml:mrow></mml:mfenced></mml:math><graphic xlink:href="12864_2019_5468_Article_Equ3.gif" position="anchor"/></alternatives></disp-formula></p><p>where m and n are the length of R1 and R2, respectively. In these equations, <italic>M</italic><sub><italic>i</italic>,<italic>j</italic></sub> represents the optimal alignment score of two subsequences <italic>R</italic>1[1]...<italic>R</italic>1[<italic>i</italic>] and <italic>R</italic>2[1]...<italic>R</italic>2[<italic>j</italic>], while <italic>I</italic><sub><italic>i</italic>,<italic>j</italic></sub> and <italic>D</italic><sub><italic>i</italic>,<italic>j</italic></sub> represent the optimal alignment score of two subsequences <italic>R</italic>1[1]...<italic>R</italic>1[<italic>i</italic>] and <italic>R</italic>2[1]...<italic>R</italic>2[<italic>j</italic>] with <italic>R</italic>2[<italic>j</italic>] aligned to a gap and <italic>R</italic>1[<italic>i</italic>] aligned to a gap, respectively. Here, the semi-global alignment uses an affine gap penalty model to calculate gap penalties, in which <italic>&#x003b1;</italic> and <italic>&#x003b2;</italic> are the gap open penalty and the gap extension penalty, respectively. <italic>sbt</italic> is the score of a match or mismatch. As shown by Eq. <xref rid="Equ1" ref-type="">1</xref>, the penalties of gaps at the start and end of two sequences are neglected. As shown by Eq. <xref rid="Equ3" ref-type="">3</xref>, the optimal alignment score of the semi-global alignment in GATK HC is the greatest value of the elements in the last row and the last column of the matrix M.</p><p>These equations indicate that the computation complexity of the modified Needleman-Wunsch algorithm is <italic>O</italic>(<italic>m</italic><italic>n</italic>), which makes the execution time increase quadratically with the sequence length. Usually, the algorithm is implemented using dynamic programming which solves three two dimensional matrices. According to the equations, <italic>M</italic><sub><italic>i</italic>,<italic>j</italic></sub>, <italic>I</italic><sub><italic>i</italic>,<italic>j</italic></sub> and <italic>D</italic><sub><italic>i</italic>,<italic>j</italic></sub> only depend on the up-left, up and left neighbor elements, which implies that the elements on the same anti-diagonal can be computed in parallel. Thus, a method employed by many researchers to reduce the execution time is to exploit this inherent parallelism in the algorithm.</p><p>If the alignment only needs to find the optimal alignment score of two sequences, the dynamic programming kernel can be calculated in linear space. Otherwise, the alignment with affine gap penalties generally uses three backtracking matrices to store the scores or alignment moves calculated by the dynamic programming kernel. The optimal alignment traceback starts from the position of the element with the optimal alignment score until reaching any element in the first row or the first column of the backtracking matrices, which is calculated in linear time. Figure&#x000a0;<xref rid="Fig2" ref-type="fig">2</xref> presents an example of backtracking an optimal alignment based on the score matrices.
<fig id="Fig2"><label>Fig. 2</label><caption><p>An example of backtracking an optimal alignment. The backtracking of an optimal alignment starts from <italic>M</italic><sub>6,5</sub> (central matrix in the figure), passes through <italic>M</italic><sub>5,4</sub>, jumps to <italic>D</italic><sub>5,4</sub> (right matrix in the figure), passes through <italic>D</italic><sub>4,4</sub>, jumps to <italic>M</italic><sub>4,4</sub>, passes through <italic>M</italic><sub>3,3</sub>, jumps to <italic>I</italic><sub>3,3</sub> (left matrix in the figure), passes through <italic>I</italic><sub>3,2</sub>, jumps to <italic>M</italic><sub>3,2</sub> and ends at <italic>M</italic><sub>2,1</sub>. The optimal alignment retrieved is &#x0201c;MDMIM&#x0201d;</p></caption><graphic xlink:href="12864_2019_5468_Fig2_HTML" id="MO2"/></fig></p></sec><sec id="Sec4"><title>Cigar format</title><p>In GATK HC, the goal is to get the optimal semi-global alignments, which are represented in the CIGAR format [<xref ref-type="bibr" rid="CR18">18</xref>], and POS. CIGAR is a string including one or more number-character pair(s). The character, including &#x02018;M&#x02019;, &#x02018;I&#x02019;, &#x02018;D&#x02019;, &#x02018;N&#x02019;, &#x02018;S&#x02019;, &#x02018;H&#x02019;, &#x02018;P&#x02019;, &#x02018;=&#x02019; and &#x02018;X&#x02019;, defines an operation explaining how the base in R2 aligns to the base in R1. Table&#x000a0;<xref rid="Tab1" ref-type="table">1</xref> shows the CIGAR operations used in GATK HC. The number defines the length of the consecutive operations. POS is 0-based left most position of the first matching base of R1, which indicates the position of R1 where the alignment starts.
<table-wrap id="Tab1"><label>Table 1</label><caption><p>CIGAR operations used in GATK HC</p></caption><table frame="hsides" rules="groups"><thead><tr><th align="left">Operation</th><th align="left">Description</th></tr></thead><tbody><tr><td align="left">M</td><td align="justify">Match/mismatch</td></tr><tr><td align="left">I</td><td align="justify">Insertion (gap in R1)</td></tr><tr><td align="left">D</td><td align="justify">Deletion (gap in R2)</td></tr><tr><td align="left">S</td><td align="justify">Soft clipping (base at the beginning or the end of R2 but not in R1)</td></tr></tbody></table></table-wrap></p><p>Take the alignment in Fig.&#x000a0;<xref rid="Fig1" ref-type="fig">1</xref> for example. The CIGAR representation of the alignment is &#x0201c;3M2D1M2I2M1S&#x0201d; and POS of the alignment is 1.</p></sec><sec id="Sec5"><title>GPU architecture</title><p>Modern GPUs are widely used to accelerate computationally intensive algorithms. A GPU consists of thousands of small cores capable of executing one thread at a time. On NVIDIA GPUs, threads are grouped into <italic>blocks</italic> and these blocks are grouped into <italic>grids</italic>. Furthermore, consecutive threads in the same block are grouped into <italic>warps</italic>. The size of a warp is usually 32. The memory hierarchy includes registers, shared memory, global memory, cache and so on. Each thread is assigned a set of registers. The shared memory is accessed by all threads in a block. Using the shared memory, the threads in a block can exchange data at a very fast rate. The global memory is accessed by all the threads on the GPU. The latency of the global memory access is high since it resides on the device DRAM. If the data accessed by each thread in the same warp are stored at consecutive addresses, the global memory accesses of these threads can be coalesced. Usually, the width of one global memory access is 128 bytes. If the global memory accesses of threads in a warp are coalesced, there will be only one global memory access when the data accessed by each thread is not more than 4 bytes. Otherwise, there would be 32 sequential global memory accesses in the worst-case situation.</p></sec><sec id="Sec6"><title>Semi-global alignment in GATK HC</title><sec id="Sec7"><title>Implementation of alignment in GATK HC</title><p>In GATK HC, the semi-global pairwise alignment is performed in two stages.</p><p>The implementation of the first stage is realized with a two-layer loop, which results in the <italic>O</italic>(<italic>m</italic><italic>n</italic>) computational complexity. The results of the first stage are two matrices: the score matrix <italic>sw</italic>, which stores matrix <italic>M</italic>, and the backtracking matrix <italic>btrack</italic>. In <italic>btrack</italic>, the value of each element can be classified into three kinds, which is defined as follows: 
<list list-type="bullet"><list-item><p>&#x0003e;0 - indicates a deletion and the length of the consecutive deletion(s) is the value of the element</p></list-item><list-item><p>=0 - indicates a match or mismatch and the length of the consecutive match(es)/mismatch(es) is increased by 1</p></list-item><list-item><p>&#x0003c;0 - indicates an insertion and the length of the consecutive insertion(s) is the absolute value of the element</p></list-item></list></p><p>The absolute values of the elements in the backtracking matrix are calculated by recording the length of the consecutive deletion(s) and consecutive insertion(s) when calculating the score matrix.</p><p>The implementation of the second stage is to calculate the optimal alignment in CIGAR format and POS. The score matrix sw is first used to find the optimal alignment score and the backtracking matrix <italic>btrack</italic> is then used to obtain the optimal alignment and POS. The optimal alignment is calculated in linear time. The backtracking matrix in GATK HC is helpful during backtracking. It is much easier to identify the next move compared with other methods since it does not need to jump among several backtracking matrices (shown in Fig.&#x000a0;<xref rid="Fig1" ref-type="fig">1</xref>) or calculate the next move based on the current move [<xref ref-type="bibr" rid="CR12">12</xref>]. Moreover, the lengths of the consecutive deletion(s) and consecutive insertion(s) are given by the element of the <italic>btrack</italic> matrix. However, the length of the consecutive match(es)/mismatch(es) is not given, which is increased by one instead.</p></sec><sec id="Sec8"><title>Data analysis</title><p>In GATK HC, the semi-global alignment is performed in three situations: 
<list list-type="order"><list-item><p>Align the reference path with the dangling path to recover dangling branches for the local assembly.</p></list-item><list-item><p>Align the read with the assembled haplotype.</p></list-item><list-item><p>Align the assembled haplotype with the reference to decide whether the assembled haplotype satisfied the defined requirements.</p></list-item></list></p><p>We profiled GPU-based GATK HC [<xref ref-type="bibr" rid="CR3">3</xref>] with a typical workload (Chromosome 10 of the whole human genome dataset G15512.HCC1954.1 [<xref ref-type="bibr" rid="CR19">19</xref>]) to investigate which situation is most time-consuming. The profiling results in single-threaded mode are shown in Table&#x000a0;<xref rid="Tab2" ref-type="table">2</xref>, which specifies the relative execution time and the number of the semi-global alignments in each situation. As shown in the table, the execution time of all the semi-global alignment accounts for 34.5% of the total execution time. Moreover, situation 2 and 3 consumes around 100% of the semi-global alignment execution time and the execution time in situation 1 is negligible. However, although the number of semi-global alignments in situation 2 is much larger than that in situation 3, the execution time in situation 2 is smaller than that in situation 3.
<table-wrap id="Tab2"><label>Table 2</label><caption><p>Execution time of the semi-global alignment in three situations of GATK HC</p></caption><table frame="hsides" rules="groups"><thead><tr><th align="left">Situation</th><th align="left">Number of alignments</th><th align="left">Execution time</th></tr></thead><tbody><tr><td align="left">1</td><td align="left">3529</td><td align="left">0.03%</td></tr><tr><td align="left">2</td><td align="left">850376</td><td align="left">14.58%</td></tr><tr><td align="left">3</td><td align="left">54802</td><td align="left">19.89%</td></tr><tr><td align="left">Total</td><td align="left">908707</td><td align="left">34.5%</td></tr></tbody></table></table-wrap></p><p>We then analyzed the lengths of the sequence pairs in situation 2 and 3. In situation 2, let R1 be the assembled haplotype and R2 be the read. In situation 3, let R1 be the assembled haplotype and R2 be the reference. Figure&#x000a0;<xref rid="Fig3" ref-type="fig">3</xref> shows a scatter plot of the lengths of the sequence pairs in these two situations. As shown in Fig.&#x000a0;<xref rid="Fig3" ref-type="fig">3</xref>, the lengths of the sequence pairs in situation 2 (40 &#x0223c;350) are shorter than those in situation 3 (300 &#x0223c;520). Since the computation complexity is <italic>O</italic>(<italic>m</italic><italic>n</italic>), the execution time of each semi-global alignment in situation 3 is bigger than that in situation 2. This explains why the total execution time of situation 3 is bigger than that of situation 2, which is shown in Table&#x000a0;<xref rid="Tab2" ref-type="table">2</xref>. Moreover, in situation 2, the length of R2 (the read) is shorter than the length of R1 (the assembled haplotype).
<fig id="Fig3"><label>Fig. 3</label><caption><p>Lengths of sequence pairs in situation 2 and 3. The lengths of the sequence pairs in situation 2 (40 &#x0223c;350) are shorter than those in situation 3 (300 &#x0223c;520)</p></caption><graphic xlink:href="12864_2019_5468_Fig3_HTML" id="MO3"/></fig></p><p>In addition, we investigated the optimal alignments achieved in situation 2 and 3 and added up the number of M/I/D/S operations in each optimal alignment. Figure&#x000a0;<xref rid="Fig4" ref-type="fig">4</xref> shows that the number of <italic>M</italic> operations is the largest. Especially in situation 2, the number of <italic>M</italic> operations accounts for 99.65% of the total operations. Moreover, we found that most of <italic>M</italic> operations are consecutive in each optimal alignment. However, the length of the consecutive match(es)/mismatch(es) is increased by one during the optimal alignment retrieval.
<fig id="Fig4"><label>Fig. 4</label><caption><p>Numbers of M/I/D/S in situation 2 and 3. The number of <italic>M</italic> operations is the largest. Especially in situation 2, the number of <italic>M</italic> operations accounts for 99.65% of the total operations</p></caption><graphic xlink:href="12864_2019_5468_Fig4_HTML" id="MO4"/></fig></p><p>Hence, although the computation complexity of the optimal alignment is linear, most of its execution time is used to calculate the length of the consecutive match(es)/mismatch(es).</p><p>We last studied the source code of GATK HC version 3.7 and found that the semi-global alignments in situation 2 and 3 can be grouped into many batches without big modifications of the source code. Each batch consists of many semi-global alignments of sequence pairs. The numbers of batches in situation 2 and 3 are 13,142 and 13,977, respectively. Figure&#x000a0;<xref rid="Fig5" ref-type="fig">5</xref> shows the number of sequence pairs of each batch in situation 2 and 3. The biggest number of sequence pairs in all the batches in situation 2 and 3 are 293 and 192, respectively. Furthermore, the majority of batches in situation 2 include 25 &#x0223c;125 of sequence pairs while the majority of batches in situation 3 include 1 &#x0223c;8 of sequence pairs.
<fig id="Fig5"><label>Fig. 5</label><caption><p>Numbers of batches including different number of sequence pairs in situation 2 and 3. The biggest number of sequence pairs in all the batches in situation 2 and 3 are 293 and 192, respectively. Furthermore, the majority of batches in situation 2 include 25 &#x0223c;125 of sequence pairs while the majority of batches in situation 3 include 1 &#x0223c;8 of sequence pairs</p></caption><graphic xlink:href="12864_2019_5468_Fig5_HTML" id="MO5"/></fig></p></sec></sec><sec id="Sec9"><title>Implementation on GPUs</title><p>The implementation of the semi-global pairwise alignment for GATK HC on GPUs is performed in two stages. In the first stage, it performs the modified Needleman-Wunsch algorithm in order to obtain the backtracking matrix and the position of the optimal alignment score. In the second stage, it retrieves the backtracking matrix in order to obtain the optimal alignment in CIGAR format and POS.</p><p>
<graphic position="anchor" xlink:href="12864_2019_5468_Figa_HTML" id="MO6"/>
</p><sec id="Sec10"><title>First stage implementation</title><sec id="Sec11"><title>Intra-task parallelization</title><p>As mentioned in &#x0201c;<xref rid="Sec8" ref-type="sec">Data analysis</xref>&#x0201d; subsection, the number of sequence pairs in each batch is less than 300. In order to effectively use the resources on GPUs, the intra-task parallelization model is employed to implement the modified Needleman-Wunsch algorithm on GPUs. For the implementation on GPUs, the elements on the same anti-diagonal of the score matrix M, I and D and backtracking matrix are calculated in parallel, reducing the computational complexity to <italic>O</italic>(<italic>m</italic>+<italic>n</italic>). Figure&#x000a0;<xref rid="Fig6" ref-type="fig">6</xref> shows the calculation of matrix <italic>M</italic> as an example to explain the implementation. Let R1 and R2 be the two sequences. There are in total 6 threads in the block and the size of matrix M is 6&#x000d7;6. At each step, the elements on an anti-diagonal are calculated in parallel and every element is calculated by one thread. For example, at step 5 (S5), <italic>M</italic><sub>5,1</sub>, <italic>M</italic><sub>4,2</sub>, <italic>M</italic><sub>3,3</sub>, <italic>M</italic><sub>2,4</sub> and <italic>M</italic><sub>1,5</sub>, which are on the same anti-diagonal, are calculated by thread 0 (T0), thread 1 (T1), thread 2 (T2), thread 3 (T3) and thread 4 (T4), respectively. These elements are then used in the next step to calculate the elements on the next anti-diagonal. Moreover, each thread is responsible to calculate the elements in one column of matrix <italic>M</italic>. For example, the elements in the second column are calculated by thread 1 (T1). The goal of the first stage is to obtain the backtracking matrix and the position of the optimal alignment score. Therefore, elements of the score matrix <italic>M</italic>, <italic>I</italic> and <italic>D</italic> are not stored. Instead, two vectors in the shared memory and three registers of each thread are used to store the intermediate results of the three score matrices. During the calculation of elements of the last column and the last row of matrix M, the optimal alignment score and its position are obtained. However, the drawback of the implementation is that some threads remain idle at the beginning or at the end of the calculation procedure, resulting in low thread utilization. If the length of R2 is smaller than the number of threads in a block, the execution is similar to Fig.&#x000a0;<xref rid="Fig6" ref-type="fig">6</xref> while some threads would remain idle during the whole calculation procedure. If the length of R2 is bigger than the number of threads in a block, there are two solutions to deal with it. One is to increase the size of a block until the number of threads in a block is equal to or bigger than the length of R2. The other is to divide the calculation into several passes. In each pass, the execution is similar to Fig.&#x000a0;<xref rid="Fig6" ref-type="fig">6</xref>. Three vectors in the global memory are used to store the intermediate results produced by the last thread of each pass, which would be used in the next pass. The advantage of the second solution is that it increases efficiency by reducing idle percentage of threads during the calculation procedure while its disadvantage is that it increases global memory accesses.
<fig id="Fig6"><label>Fig. 6</label><caption><p>Calculation of matrix M on GPUs</p></caption><graphic xlink:href="12864_2019_5468_Fig6_HTML" id="MO7"/></fig></p></sec><sec id="Sec12"><title>Recording the length of consecutive match(es)/mismatch(es)</title><p>Besides recording the length of the consecutive deletion(es)/insertion(es), we also record the length of the consecutive match(es)/mismatch(es) in the first stage. The backtracking matrix on GPUs is stored in a <italic>s</italic><italic>h</italic><italic>o</italic><italic>r</italic><italic>t</italic>2 matrix. Each element of the matrix has two values, which are x and y. The value of x and y are defined as follows: 
<list list-type="bullet"><list-item><p><italic>x</italic>&#x0003e;0 - indicates a deletion and the length of the consecutive deletion(s) is the value of the element</p></list-item><list-item><p><italic>x</italic>=0 - indicates a match or mismatch and the length of the consecutive match(es)/mismatch(es) is y.</p></list-item><list-item><p><italic>x</italic>&#x0003c;0 - indicates an insertion and the length of the consecutive insertion(s) is the absolute value of the element</p></list-item></list></p><p>The data type of x and y is <italic>short</italic>, of which the minimum value and maximum value are &#x02212;32768 and 32767, respectively. The absolute values of the minimum value and maximum value are bigger than the theoretical maximum length of the consecutive operations, which is the length of R1 or R2. In order to calculate the backtracking matrix, a <italic>s</italic><italic>h</italic><italic>o</italic><italic>r</italic><italic>t</italic>2 vector in the shared memory and two registers of each thread are used.</p><p>Moreover, Since the backtracking matrix will be used in the next stage and the shared memory is not big enough to store it, the backtracking matrix is stored in the global memory. Similar to calculation of the matrix <italic>M</italic> shown in Fig.&#x000a0;<xref rid="Fig6" ref-type="fig">6</xref>, elements of the backtracking matrix are calculated in anti-diagonal order. Thus, the backtracking matrices are stored in the diagonal-major data format (Fig.&#x000a0;<xref rid="Fig7" ref-type="fig">7</xref>b), which is proposed in [<xref ref-type="bibr" rid="CR20">20</xref>], instead of the row-major data format (Fig.&#x000a0;<xref rid="Fig7" ref-type="fig">7</xref>a) to avoid non-coalesced global memory accesses of 32 threads in a warp and reduce global memory accesses.
<fig id="Fig7"><label>Fig. 7</label><caption><p>Layout of the backtracking matrix in the global memory. Elements of different backtracking matrices are marked with different colors. <bold>a</bold> is the backtracking matrices stored in the row-major data format. <bold>b</bold> is the backtracking matrices stored in the diagonal-major data format</p></caption><graphic xlink:href="12864_2019_5468_Fig7_HTML" id="MO8"/></fig></p></sec></sec><sec id="Sec13"><title>Second stage implementation</title><p>In the second stage, we use the backtracking matrix <italic>btrack</italic> to obtain the optimal alignment and POS. Algorithm 1 presents the pseudo code of the optimal alignment retrieval on GPUs. <italic>P</italic>1 and <italic>P</italic>2 describe the position of the optimal alignment score. Algorithm 1 first checks whether there are soft clippings at the end of R2, and then computes the optimal alignment in a <italic>while</italic> loop. At the end, it checks whether there are soft clippings at the beginning of R2. The backtracking starts from (<italic>P</italic>1,<italic>P</italic>2) and finishes when <italic>i</italic>&#x02264;0 or <italic>j</italic>&#x02264;0, which is calculated in linear time. POS is the value of (<italic>i</italic>&#x02212;1) at the end of the <italic>while</italic> loop. In addition, the position of each element in the backtracking matrix is calculated by <italic>i</italic>, <italic>j</italic> and <italic>m</italic><italic>a</italic><italic>x</italic>_<italic>c</italic><italic>o</italic><italic>l</italic>, as shown in the 9th line in Algorithm 1. <italic>m</italic><italic>a</italic><italic>x</italic>_<italic>c</italic><italic>o</italic><italic>l</italic> is the column size of the maximum backtracking matrix of all sequence pairs.</p><p>The length of the deletion, insertion and match/mismatch is given by the value of an element of the backtracking matrix, as shown in the 13th, 18th and 23rd line, respectively. This reduces the global memory accesses used to calculate the length of the operations.</p></sec></sec></sec><sec id="Sec14" sec-type="results"><title>Results</title><p>All the experiments are performed on IBM Power System S823L (82478-42L), which has 2 IBM Power8 processors (10 cores each) running at 3.6 GHz, 256 GB of DDR3 memory, and an NVIDIA Tesla K40 card. The NVIDIA Tesla K40 card has 2880 cores that run at up to 745 MHz and has a CUDA compute capability of 3.5.</p><p>We first compare the performance of the GPU-based semi-global alignment implementation with different techniques using the synthetic datasets. The synthetic datasets are created based on the output of Wgsim [<xref ref-type="bibr" rid="CR21">21</xref>] with default parameters. We then compare the performance of GPU-based semi-global alignment implementation with gpu-pairAlign implementation using synthetic datasets. Next, we compare the performance of GPU-based semi-global alignment implementation with CPU-based implementation using synthetic and real datasets. We last integrate the GPU-based semi-global alignment implementation into GATK HC 3.7 and compare the overall performance.</p><p>Throughput is used as a performance metric of the first stage of the GPU-based implementation, which is measured by giga cell updates per second (GCUPS). Note that it is not fair to compare the throughput of the first stage of the semi-global alignment with traceback with that of the score-only alignments since the former needs to store backtracking matrices in the global memory.</p><sec id="Sec15"><title>Performance comparison of multi-pass</title><p>There are two solutions to implement the first stage of the semi-global alignment on GPUs if the length of R2 is bigger than the number of threads in a block. We realized these two solutions and used different synthetic datasets to compare the performance of the two solutions.</p><p>Figure&#x000a0;<xref rid="Fig8" ref-type="fig">8</xref> shows the performance of the two solutions with different synthetic datasets. There are 9 datasets each with a different length of R1/R2, namely: 64, 128, 192, 256, 320, 384, 448, 512 and 576. In each dataset, the lengths of R1 and R2 are the same. The number of sequence pairs in the 9 datasets is 25, 100 and 1000.
<fig id="Fig8"><label>Fig. 8</label><caption><p>Performance comparison of implementations for two solutions on synthetic datasets</p></caption><graphic xlink:href="12864_2019_5468_Fig8_HTML" id="MO9"/></fig></p><p>For the first solution, which is to increase the block size, there are in total 9 implementations for 9 datasets. The differences of these implementations are the block size and the sizes of vectors in the shared memory which store the intermediate results. For the second solution, which employs multi-pass, there is 1 implementation with block size of 128.</p><p>As shown by Fig.&#x000a0;<xref rid="Fig8" ref-type="fig">8</xref>, the throughput of the first solution is higher than that of the second solution when the number of sequence pairs of the datasets is 25 and 100. However, when the number of sequence pairs of the datasets is 1000, the throughput of the second solution is higher in most cases. This is because the efficiency of the implementations for the first solution is smaller than that of the implementation for the second solution and the advantage of the second solution overweighs its disadvantage when the number of sequence pairs of the dataset is big. Thus, we can choose the implementation of these two solutions based on the number of sequence pairs of the dataset.</p></sec><sec id="Sec16"><title>Performance comparison of recording match/mismatch lengths</title><p>In this section, we analyze the impact of recording the length of consecutive matches/mismatches on the performance of the second stage of the alignment on GPUs. We realized two implementations. The first implementation is our approach shown in Algorithm 1 in which the length of consecutive matches/mismatches is recorded in the backtrack matrix. The second implementation is similar to Algorithm 1 except that the length of M is increased by one and the coordinates (<italic>i</italic>, <italic>j</italic>) of M are decreased by 1. The backtracking matrices are produced by 9 implementations for the first solution using 9 synthetic datasets. Here, the synthetic datasets are not based on the output of Wgsim since we consider the best case, in which only many M operations exist in the optimal alignment. The lengths of R1/R2 in the 9 synthetic datasets are 64, 128, 192, 256, 320, 384, 448, 512 and 576. The number of sequence pairs in the 9 datasets is 100.</p><p>Figure&#x000a0;<xref rid="Fig9" ref-type="fig">9</xref> shows the execution time of the two implementations. The implementation which records match/mismatch lengths is faster. Moreover, its execution time remains nearly constant with increasing length of R1 and R2 as it only requires a single global memory access per R1 and R2 pair. The execution time of the implementation without recording match/mismatch lengths increases linearly with the length of R1 and R2. This is because the number of global memory accesses increases linearly with the number of <italic>M</italic> operations in the optimal alignment, which in turn increases linearly with the length of R1 and R2.
<fig id="Fig9"><label>Fig. 9</label><caption><p>Execution time of GPU-based optimal alignment backtracking implementations (not) recording match/mismatch lengths on synthetic datasets</p></caption><graphic xlink:href="12864_2019_5468_Fig9_HTML" id="MO10"/></fig></p></sec><sec id="Sec17"><title>Performance comparison with gpu-pairAlign</title><p>As mentioned in &#x0201c;<xref rid="Sec1" ref-type="sec">Background</xref>&#x0201d; section, there are two methods to implement the second stage on GPUs: the method based on the Myers-Miller algorithm and the method based on backtracking matrices. The method based on the Myers-Miller algorithm is only suitable for the pairwise alignment of very long DNA and protein sequences. Thus, we compared our implementation with gpu-pairAlign [<xref ref-type="bibr" rid="CR12">12</xref>], which uses backtracking matrices to obtain the optimal alignments. gpu-pairAlign is designed to perform alignment of every given sequence pair on GPUs, especially for protein sequence pairs. It includes algorithms for global alignment, semi-global alignment and local alignment. We compare with its semi-global alignment algorithm. The semi-global alignment algorithm of gpu-pairAlign is also performed in two stages: the optimal alignment score and the backtracking matrices are computed in the first stage; the backtracking is performed in the second stage.</p><p>There are two main differences between the gpu-pairAlign implementation and our implementation: (1) In the first stage, our implementation employs the intra-task parallelization model, while the gpu-pairAlign implementation employs the inter-task parallelization model; (2) The backtracking matrix of our implementation is a short2 matrix, elements of which are the length of consecutive deletion(es), insertion(es) and match(es)/mismatch(es), while the backtracking matrices of the gpu-pairAlign implementation are four Boolean matrices, elements of which indicate the proper direction of backtracking moves.</p><p>We modified the gpu-pairAlign implementation to make it to deal with the data produced by GATK HC: (1) Since the input data of our implementation is a set of sequence pairs instead of a set of sequences, the way in which the gpu-pairAlign implementation handles input data is modified; (2) Integer arrays are used to store the intermediate results instead of short arrays since the intermediate results are bigger than the maximum value of the short data type; (3) The alignments are modified to be represented using the CIGAR format and POS.</p><p>We first used the synthetic datasets described in &#x0201c;<xref rid="Sec15" ref-type="sec">Performance comparison of multi-pass</xref>&#x0201d; subsection to compare the performance of the first stage of the two implementations, which is shown in Fig.&#x000a0;<xref rid="Fig10" ref-type="fig">10</xref>. The performance of gpu-pairAlign implementation is much smaller than our implementation. The main reason is that when the size of the synthetic datasets is small, the resource on the GPU cannot be fully utilized for the inter-task parallelization model. The second reason is that the intermediate results are stored in integer arrays, which increases the size of shared memory of each block and the number of global memory accesses.
<fig id="Fig10"><label>Fig. 10</label><caption><p>Performance comparison of the first stage of two implementations on synthetic datasets</p></caption><graphic xlink:href="12864_2019_5468_Fig10_HTML" id="MO11"/></fig></p><p>We then compared the performance of the second stage of the two implementations using the synthetic datasets described in &#x0201c;<xref rid="Sec16" ref-type="sec">Performance comparison of recording match/mismatch lengths</xref>&#x0201d; subsection, which is shown in Fig.&#x000a0;<xref rid="Fig11" ref-type="fig">11</xref>. The execution time of the second stage of our implementation remains nearly constant when the length of R1 and R2 increases, while the execution time of the second stage of the gpu-pairAlign implementation increases linearly with the length of R1 and R2. Although the gpu-pairAlign implementation reduces the global memory space by using four Boolean matrices, it still needs to calculate each move one by one, which is avoided in our implementation through storing the length of consecutive deletion(es), insertion(es) and match(es)/mismatch(es).
<fig id="Fig11"><label>Fig. 11</label><caption><p>Execution time of the second stage of two implementations on synthetic datasets</p></caption><graphic xlink:href="12864_2019_5468_Fig11_HTML" id="MO12"/></fig></p></sec><sec id="Sec18"><title>Performance comparison with CPU-based implementation</title><p>In this section, we compare the performance of our GPU-based semi-global alignment with traceback implementation with the CPU-based implementation using synthetic and real datasets. We used the first solution which increases the block size when the length of R2 is bigger than the block size and records the length of consecutive matches/mismatches. The CPU-based implementation is written in the C++ programming language and compiled with gcc O3 optimization, running on one Power8 core. The real datasets are produced by using a typical workload (Chromosome 10 of the whole human genome dataset G15512.HCC1954.1).</p><p>Figure&#x000a0;<xref rid="Fig12" ref-type="fig">12</xref> shows the speedup of the GPU-based implementations compared with the CPU-based implementation using the synthetic datasets described in &#x0201c;<xref rid="Sec15" ref-type="sec">Performance comparison of multi-pass</xref>&#x0201d; subsection. There are in total 9 GPU-based implementations for 9 datasets, block size of which are 64, 128, 192, 256, 320, 384, 448, 512 and 576. The GPU-based implementations is up to 80x faster than the CPU-based implementation. Moreover, the speedup of the datasets with 1000 sequence pairs is bigger than the speedup of the datasets with 25 and 100 sequence pairs.
<fig id="Fig12"><label>Fig. 12</label><caption><p>Speedup of the GPU-based implementations compared with CPU-based implementation on synthetic datasets</p></caption><graphic xlink:href="12864_2019_5468_Fig12_HTML" id="MO13"/></fig></p><p>Table&#x000a0;<xref rid="Tab3" ref-type="table">3</xref> shows the execution time of GPU-based implementations with the real datasets. As shown by Fig.&#x000a0;<xref rid="Fig3" ref-type="fig">3</xref>, the length of R2 in situation 2 is 40 &#x0223c;120 and the length of R2 in situation 3 is 300 &#x0223c;520. Thus, we used two GPU-based implementations with block size of 128 and 576 to execute the real datasets produced in situation 2 and 3, respectively. The GPU-based implementation of situation 2 is 14.14x faster than the CPU-based implementation, while the GPU-based implementation of situation 3 is 4.89x faster than the CPU-based implementation. The throughput of the first stage of the GPU-based implementation for situation 2 is 1.86 GCUPS, while that for situation 3 is 0.64 GCUPS. The throughput of situation 3 is much smaller than the throughput for the synthetic datasets with size 25. This is because the number of sequence pairs of batches in situation 3 is extremely small (1&#x0223c;8 in most cases).
<table-wrap id="Tab3"><label>Table 3</label><caption><p>Performance of GPU-based implementations on real datasets</p></caption><table frame="hsides" rules="groups"><thead><tr><th align="left"/><th align="left">Throughput (GCUPS)</th><th align="left">GPU (sec)</th><th align="left">CPU (sec)</th><th align="left">Speedup</th></tr></thead><tbody><tr><td align="left">Stage 1 of S2</td><td align="left">1.86</td><td align="left">2.32</td><td align="left">43.93</td><td align="left">18.94x</td></tr><tr><td align="left">Stage 2 of S2</td><td align="left">-</td><td align="left">0.14</td><td align="left">0.62</td><td align="left">4.43x</td></tr><tr><td align="left">
<bold>Overall of S2</bold>
</td><td align="left">-</td><td align="left">3.15</td><td align="left">44.55</td><td align="left">14.14x</td></tr><tr><td align="left">Stage 1 of S3</td><td align="left">0.64</td><td align="left">10.20</td><td align="left">53.29</td><td align="left">5.22x</td></tr><tr><td align="left">Stage 2 of S3</td><td align="left">-</td><td align="left">0.09</td><td align="left">0.17</td><td align="left">1.89x</td></tr><tr><td align="left">
<bold>Overall of S3</bold>
</td><td align="left">-</td><td align="left">10.93</td><td align="left">53.46</td><td align="left">4.89x</td></tr></tbody></table><table-wrap-foot><p>S2 and S3 stand for situation 2 and 3, respectively. &#x0201c;Overall of S2&#x0201d; and &#x0201c;Overall of S3&#x0201d; represent the overall GPU execution time? CPU execution time and speedup of situation 2 and 3, respectively</p></table-wrap-foot></table-wrap></p></sec><sec id="Sec19"><title>Integration into GATK HC</title><p>The two GPU-based implementations with block size of 128 and 576 are integrated into GATK 3.7 to accelerate the semi-global alignment with traceback of situation 2 and situation 3, respectively. The GATK HC implementation with both GPU-based pair-HMMs forward algorithm and GPU-based semi-global alignment with traceback is compared with other two GATK HC implementations: GATK HC (referred to as baseline), which is downloaded from the GATK website, and GATK HC with only GPU-based pair-HMMs forward algorithm. The dataset is Chromosome 10 of the whole human genome dataset (G15512.HCC1954.1). All the GATK HC implementations are performed in single thread mode.</p><p>Table&#x000a0;<xref rid="Tab4" ref-type="table">4</xref> shows the overall execution time of these three implementations. The implementation with both GPU-based pair-HMMs forward algorithm and GPU-based semi-global alignment with traceback is 2.30x faster than the baseline implementation. Moreover, it is 1.34x faster than the implementation with only GPU-based pair-HMMs forward algorithm.
<table-wrap id="Tab4"><label>Table 4</label><caption><p>Execution time of GATK HC implementations</p></caption><table frame="hsides" rules="groups"><thead><tr><th align="left"/><th align="left">Total time (s)</th><th align="left">Speedup</th></tr></thead><tbody><tr><td align="justify">Baseline</td><td align="left">8034.05</td><td align="left">-</td></tr><tr><td align="justify">GPU (only pair-HMMs)</td><td align="left">4687.08</td><td align="left">1.71x</td></tr><tr><td align="justify">GPU (pair-HMMs + semi-global alignment with traceback)</td><td align="left">3490.70</td><td align="left">2.30x</td></tr></tbody></table></table-wrap></p><p>Note that the number of sequence pairs of each batch produced by GATK HC is small, leading to under utilization of the GPU resources. It is better to launch multiple GATK HC processes at the same time to fully utilize the GPU resources.</p></sec></sec><sec id="Sec20" sec-type="conclusion"><title>Conclusion</title><p>This paper presents an implementation of the semi-global alignment with traceback on GPUs to improve the performance of GATK HC. Semi-global alignment with traceback has two stages: in the first stage, a backtracking matrix is computed; in the second stage, the optimal alignment is calculated using the backtracking matrix. Based on the characteristics of the semi-global alignment with traceback in GATK HC, the intra-task parallelization model is chosen. The first stage of our GPU implementation is up to 18.94x faster than CPU. Moreover, our GPU implementation also records the length of consecutive matches/mismatches in addition to lengths of consecutive insertions and deletions as in the CPU implementation. This helps to reduce global memory accesses and provides a speedup of up to 4.43x in the second stage. Experimental results show that our alignment kernel with traceback is up to 80x and 14.14x faster than its CPU counterpart with synthetic datasets and real datasets, respectively. The GATK HC implementation with both GPU-based pair-HMMs forward algorithm and GPU-based semi-global alignment with traceback is 2.30x faster than the baseline GATK HC. It is 1.34x faster than the GATK HC implementation with only GPU-based pair-HMMs forward algorithm.</p></sec></body><back><glossary><title>Abbreviations</title><def-list><def-item><term>HC</term><def><p>HaplotypeCaller</p></def></def-item><def-item><term>NGS</term><def><p>Next Generation Sequencing</p></def></def-item></def-list></glossary><ack><title>Acknowledgements</title><p>The authors wish to thank the Texas Advanced Computing Center (TACC) at the University of Texas at Austin and IBM for the giving access to the IBM Power8 machines used in this paper.</p><sec id="d29e1903"><title>Funding</title><p>This work was supported by CSC (Chinese Scholarship Council) grant and Delft University of Technology. Publication of this article was sponsored by Delft University of Technology.</p></sec><sec id="d29e1908" sec-type="data-availability"><title>Availability of data and materials</title><p>The algorithm generated in this manuscript as well as all input datasets are publicly available on a publicly available repository: <ext-link ext-link-type="uri" xlink:href="https://github.com/ShanshanRen/semi-global-alignment-with-traceback">https://github.com/ShanshanRen/semi-global-alignment-with-traceback</ext-link>.</p></sec><sec id="d29e1918"><title>About this supplement</title><p>This article has been published as part of BMC Genomics Volume 20 Supplement 2, 2019: Selected articles from the 17th Asia Pacific Bioinformatics Conference (APBC 2019): genomics. The full contents of the supplement are available online at <ext-link ext-link-type="uri" xlink:href="https://bmcgenomics.biomedcentral.com/articles/supplements/volume-20-supplement-2">https://bmcgenomics.biomedcentral.com/articles/supplements/volume-20-supplement-2</ext-link>.</p></sec></ack><notes notes-type="author-contribution"><title>Authors&#x02019; contributions</title><p>SR designed and performed the experiments, analyzed the data, and wrote the manuscript. All the authors jointly developed the structure and arguments for the paper, made critical revisions and approved final version.</p></notes><notes notes-type="COI-statement"><sec><title>Ethics approval and consent to participate</title><p>Not applicable.</p></sec><sec><title>Consent for publication</title><p>Not Applicable.</p></sec><sec><title>Competing interests</title><p>The authors declare that they have no competing interests.</p></sec></notes><ref-list id="Bib1"><title>References</title><ref id="CR1"><label>1</label><mixed-citation publication-type="other">Takeshi O, Yinhe C, Kathy T. Performance optimization of Broad Institute GATK Best Practices on IBM reference architecture for healthcare and life sciences. IBM Systems Technical White Paper. 2017. <ext-link ext-link-type="uri" xlink:href="https://www.ibm.com/downloads/cas/LY1OY9XJ">https://www.ibm.com/downloads/cas/LY1OY9XJ</ext-link>.</mixed-citation></ref><ref id="CR2"><label>2</label><mixed-citation publication-type="other">Proffitt A. Broad, Intel Announce Speed Improvements to GATK Powered by Intel Optimizations. Bio-IT World. 2014. <ext-link ext-link-type="uri" xlink:href="http://www.bio-itworld.com/2014/3/20/broad-intel-announce-speed-improvements-gatk-powered-by-intel-optimizations.html">http://www.bio-itworld.com/2014/3/20/broad-intel-announce-speed-improvements-gatk-powered-by-intel-optimizations.html</ext-link>.</mixed-citation></ref><ref id="CR3"><label>3</label><mixed-citation publication-type="other">Ren S, Bertels K, Al-Ars Z. GPU-Accelerated GATK HaplotypeCaller with Load-Balanced Multi-Process Optimization. In: IEEE International Conference on Bioinformatics and Bioengineering: 2017. p. 497&#x02013;502.</mixed-citation></ref><ref id="CR4"><label>4</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Ren</surname><given-names>S</given-names></name><name><surname>Bertels</surname><given-names>K</given-names></name><name><surname>Al-Ars</surname><given-names>Z</given-names></name></person-group><article-title>Efficient Acceleration of the Pair-HMMs Forward Algorithm for GATK HaplotypeCaller on Graphics Processing Units</article-title><source>Evol Bioinform Online</source><year>2018</year><volume>14</volume><fpage>1176934318760543</fpage><pub-id pub-id-type="doi">10.1177/1176934318760543</pub-id><pub-id pub-id-type="pmid">29568218</pub-id></element-citation></ref><ref id="CR5"><label>5</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Li</surname><given-names>IT</given-names></name><name><surname>Shum</surname><given-names>W</given-names></name><name><surname>Truong</surname><given-names>AK</given-names></name></person-group><article-title>160-fold acceleration of the Smith-Waterman algorithm using a field programmable gate array (FPGA)</article-title><source>BMC Bioinforma</source><year>2007</year><volume>8</volume><issue>1</issue><fpage>1</fpage><lpage>7</lpage><pub-id pub-id-type="doi">10.1186/s12859-016-1414-x</pub-id></element-citation></ref><ref id="CR6"><label>6</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Benkrid</surname><given-names>K</given-names></name><name><surname>Liu</surname><given-names>Y</given-names></name><name><surname>Benkrid</surname><given-names>AS</given-names></name></person-group><article-title>A Highly Parameterized and Efficient FPGA-Based Skeleton for Pairwise Biological Sequence Alignment</article-title><source>IEEE Trans Very Large Scale Integr Syst</source><year>2009</year><volume>17</volume><issue>4</issue><fpage>561</fpage><lpage>70</lpage><pub-id pub-id-type="doi">10.1109/TVLSI.2008.2005314</pub-id></element-citation></ref><ref id="CR7"><label>7</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Hasan</surname><given-names>L</given-names></name><name><surname>Kentie</surname><given-names>M</given-names></name><name><surname>Al-Ars</surname><given-names>Z</given-names></name></person-group><article-title>DOPA: GPU-based protein alignment using database and memory access optimizations</article-title><source>BMC Res Notes</source><year>2011</year><volume>4</volume><issue>1</issue><fpage>261</fpage><pub-id pub-id-type="doi">10.1186/1756-0500-4-261</pub-id><pub-id pub-id-type="pmid">21798061</pub-id></element-citation></ref><ref id="CR8"><label>8</label><mixed-citation publication-type="other">Ahmed N, Mushtaq H, Bertels K, Al-Ars Z. GPU accelerated API for alignment of genomics sequencing data. In: IEEE International Conference on Bioinformatics and Biomedicine: 2017. p. 510&#x02013;5.</mixed-citation></ref><ref id="CR9"><label>9</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Maskell</surname><given-names>DL</given-names></name><name><surname>Liu</surname><given-names>Y</given-names></name><name><surname>Bertil</surname><given-names>S</given-names></name></person-group><article-title>CUDASW++: optimizing Smith-Waterman sequence database searches for CUDA-enabled graphics processing units</article-title><source>BMC Res Notes</source><year>2009</year><volume>2</volume><issue>1</issue><fpage>73</fpage><pub-id pub-id-type="doi">10.1186/1756-0500-2-73</pub-id><pub-id pub-id-type="pmid">19416548</pub-id></element-citation></ref><ref id="CR10"><label>10</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Liu</surname><given-names>Y</given-names></name><name><surname>Schmidt</surname><given-names>B</given-names></name><name><surname>Maskell</surname><given-names>DL</given-names></name></person-group><article-title>CUDASW++2.0: enhanced Smith-Waterman protein database search on CUDA-enabled GPUs based on SIMT and virtualized SIMD abstractions</article-title><source>BMC Res Notes</source><year>2010</year><volume>3</volume><issue>1</issue><fpage>93</fpage><pub-id pub-id-type="doi">10.1186/1756-0500-3-93</pub-id><pub-id pub-id-type="pmid">20370891</pub-id></element-citation></ref><ref id="CR11"><label>11</label><mixed-citation publication-type="other">Liu Y, Huang W, Johnson J, Vaidya S. GPU Accelerated Smith-Waterman. In: International Conference on Computational Science: 2006. p. 188&#x02013;95.</mixed-citation></ref><ref id="CR12"><label>12</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Blazewicz</surname><given-names>J</given-names></name><name><surname>Frohmberg</surname><given-names>W</given-names></name><name><surname>Kierzynka</surname><given-names>M</given-names></name><name><surname>Pesch</surname><given-names>E</given-names></name><name><surname>Wojciechowski</surname><given-names>P</given-names></name></person-group><article-title>Protein alignment algorithms with an efficient backtracking routine on multiple GPUs</article-title><source>BMC Bioinforma</source><year>2011</year><volume>12</volume><issue>1</issue><fpage>181</fpage><pub-id pub-id-type="doi">10.1186/1471-2105-12-181</pub-id></element-citation></ref><ref id="CR13"><label>13</label><mixed-citation publication-type="other">Liu Y, Schmidt B, Maskell DL. MSA-CUDA: Multiple Sequence Alignment on Graphics Processing Units with CUDA. In: IEEE International Conference on Application-Specific Systems, Architectures and Processors: 2009. p. 121&#x02013;8.</mixed-citation></ref><ref id="CR14"><label>14</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Korpar</surname><given-names>M</given-names></name><name><surname>Sikic</surname><given-names>M</given-names></name></person-group><article-title>SW#-GPU-enabled exact alignments on genome scale</article-title><source>Bioinformatics</source><year>2013</year><volume>29</volume><issue>19</issue><fpage>2494</fpage><lpage>5</lpage><pub-id pub-id-type="doi">10.1093/bioinformatics/btt410</pub-id><pub-id pub-id-type="pmid">23864730</pub-id></element-citation></ref><ref id="CR15"><label>15</label><mixed-citation publication-type="other">de O Sandes EF, de Melo ACMA. Smith-Waterman Alignment of Huge Sequences with GPU in Linear Space. In: 2011 IEEE International Parallel Distributed Processing Symposium: 2011. p. 1199&#x02013;211.</mixed-citation></ref><ref id="CR16"><label>16</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Sandes</surname><given-names>EFO</given-names></name><name><surname>Miranda</surname><given-names>G</given-names></name><name><surname>Martorell</surname><given-names>X</given-names></name><name><surname>Ayguade</surname><given-names>E</given-names></name><name><surname>Teodoro</surname><given-names>G</given-names></name><name><surname>Melo</surname><given-names>ACMA</given-names></name></person-group><article-title>CUDAlign 4.0: Incremental Speculative Traceback for Exact Chromosome-Wide Alignment in GPU Clusters</article-title><source>IEEE Trans Parallel Distrib Syst</source><year>2016</year><volume>27</volume><issue>10</issue><fpage>2838</fpage><lpage>50</lpage><pub-id pub-id-type="doi">10.1109/TPDS.2016.2515597</pub-id></element-citation></ref><ref id="CR17"><label>17</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Myers</surname><given-names>EW</given-names></name><name><surname>Miller</surname><given-names>W</given-names></name></person-group><article-title>Optimal alignments in linear space</article-title><source>Comput Appl Biosci Cabios</source><year>1988</year><volume>4</volume><issue>1</issue><fpage>11</fpage><lpage>7</lpage><?supplied-pmid 3382986?><pub-id pub-id-type="pmid">3382986</pub-id></element-citation></ref><ref id="CR18"><label>18</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Li</surname><given-names>H</given-names></name><name><surname>Handsaker</surname><given-names>B</given-names></name><name><surname>Wysoker</surname><given-names>A</given-names></name><name><surname>Fennell</surname><given-names>T</given-names></name><name><surname>Ruan</surname><given-names>J</given-names></name><name><surname>Homer</surname><given-names>N</given-names></name><etal/></person-group><article-title>The Sequence Alignment/Map format and SAMtools</article-title><source>Bioinformatics</source><year>2009</year><volume>25</volume><issue>16</issue><fpage>2078</fpage><lpage>9</lpage><pub-id pub-id-type="doi">10.1093/bioinformatics/btp352</pub-id><pub-id pub-id-type="pmid">19505943</pub-id></element-citation></ref><ref id="CR19"><label>19</label><mixed-citation publication-type="other">TCGA Mutation Calling Benchmark 4 Files. <ext-link ext-link-type="uri" xlink:href="https://gdc.cancer.gov/resources-tcga-users/tcga-mutation-calling-benchmark-4-files">https://gdc.cancer.gov/resources-tcga-users/tcga-mutation-calling-benchmark-4-files</ext-link>. G15512.HCC1954.1.</mixed-citation></ref><ref id="CR20"><label>20</label><mixed-citation publication-type="other">Xiao S, Aji AM, Feng W. On the Robust Mapping of Dynamic Programming onto a Graphics Processing Unit. In: International Conference on Parallel and Distributed Systems: 2009. p. 26&#x02013;33.</mixed-citation></ref><ref id="CR21"><label>21</label><mixed-citation publication-type="other">Wgsim. <ext-link ext-link-type="uri" xlink:href="https://github.com/lh3/wgsim">https://github.com/lh3/wgsim</ext-link>.</mixed-citation></ref></ref-list></back></article>