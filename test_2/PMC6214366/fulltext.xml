<!DOCTYPE article PUBLIC "-//NLM//DTD JATS (Z39.96) Journal Archiving and Interchange DTD v1.1 20151215//EN" "JATS-archivearticle1.dtd"> 
<article xmlns:xlink="http://www.w3.org/1999/xlink" xmlns:mml="http://www.w3.org/1998/Math/MathML" article-type="research-article"><?all-math-mml yes?><?use-mml?><?properties open_access?><?properties manuscript?><?origin nihpa?><?iso-abbr Cell Syst?><?submitter-system nihms?><?submitter-canonical-name Elsevier?><?submitter-canonical-id ELSEVIERAM?><?submitter-userid 8068823?><?submitter-authority myNCBI?><?submitter-login elsevieram?><?submitter-name Author support, Elsevier?><?domain nihpa?><front><journal-meta><journal-id journal-id-type="nlm-journal-id">101656080</journal-id><journal-id journal-id-type="pubmed-jr-id">43733</journal-id><journal-id journal-id-type="nlm-ta">Cell Syst</journal-id><journal-id journal-id-type="iso-abbrev">Cell Syst</journal-id><journal-title-group><journal-title>Cell systems</journal-title></journal-title-group><issn pub-type="ppub">2405-4712</issn><issn pub-type="epub">2405-4720</issn></journal-meta><article-meta><article-id pub-id-type="pmcid">6214366</article-id><article-id pub-id-type="pmid">30138581</article-id><article-id pub-id-type="doi">10.1016/j.cels.2018.07.005</article-id><article-id pub-id-type="manuscript">nihpa986152</article-id><article-categories><subj-group subj-group-type="heading"><subject>Article</subject></subj-group></article-categories><title-group><article-title>Statistical Binning for Barcoded Reads Improves Downstream Analyses</article-title></title-group><contrib-group><contrib contrib-type="author"><name><surname>Shajii</surname><given-names>Ariya</given-names></name><xref ref-type="aff" rid="A1">1</xref></contrib><contrib contrib-type="author"><name><surname>Numanagi&#x00107;</surname><given-names>Ibrahim</given-names></name><xref ref-type="aff" rid="A1">1</xref><xref ref-type="aff" rid="A2">2</xref></contrib><contrib contrib-type="author"><name><surname>Whelan</surname><given-names>Christopher</given-names></name><xref ref-type="aff" rid="A3">3</xref><xref ref-type="aff" rid="A4">4</xref><xref ref-type="aff" rid="A5">5</xref><xref ref-type="aff" rid="A6">6</xref></contrib><contrib contrib-type="author"><name><surname>Berger</surname><given-names>Bonnie</given-names></name><xref ref-type="aff" rid="A1">1</xref><xref ref-type="aff" rid="A2">2</xref><xref ref-type="aff" rid="A7">7</xref><xref rid="CR1" ref-type="corresp">*</xref></contrib></contrib-group><aff id="A1"><label>1</label>Computer Science and AI Lab, Massachusetts Institute of Technology, Cambridge, MA, USA</aff><aff id="A2"><label>2</label>Department of Mathematics, Massachusetts Institute of Technology, Cambridge, MA, USA</aff><aff id="A3"><label>3</label>Data Sciences Platform, Broad Institute, Cambridge, MA, USA</aff><aff id="A4"><label>4</label>Program in Medical and Population Genetics, Broad Institute, Cambridge, MA, USA</aff><aff id="A5"><label>5</label>Stanley Center for Psychiatric Research, Broad Institute, Cambridge, MA, USA</aff><aff id="A6"><label>6</label>Department of Genetics, Harvard Medical School, Boston, MA, USA</aff><aff id="A7"><label>7</label>Lead Contact</aff><author-notes><fn fn-type="con" id="FN1"><p id="P1">AUTHOR CONTRIBUTIONS</p><p id="P2">A.S. and I.N. developed the core methods and performed the experiments. B.B. oversaw and guided the method development process and experimentation. A.S., I.N., and B.B. collectively wrote the manuscript. C.W. provided expertise on 10x data and rare variants, as well as several datasets for experimentation.</p></fn><corresp id="CR1"><label>*</label>Correspondence: <email>bab@mit.edu</email></corresp></author-notes><pub-date pub-type="nihms-submitted"><day>21</day><month>8</month><year>2018</year></pub-date><pub-date pub-type="ppub"><day>22</day><month>8</month><year>2018</year></pub-date><pub-date pub-type="pmc-release"><day>02</day><month>11</month><year>2018</year></pub-date><volume>7</volume><issue>2</issue><fpage>219</fpage><lpage>226.e5</lpage><!--elocation-id from pubmed: 10.1016/j.cels.2018.07.005--><permissions><license><license-p>This is an open access article under the CC BY-NC-ND license (<ext-link ext-link-type="uri" xlink:href="http://creativecommons.org/licenses/by-nc-nd/4.0/">http://creativecommons.org/licenses/by-nc-nd/4.0/</ext-link>).</license-p></license></permissions><abstract id="ABS1"><title>SUMMARY</title><p id="P3">Sequencing technologies are capturing longer-range genomic information at lower error rates, enabling alignment to genomic regions that are inaccessible with short reads. However, many methods are unable to align reads to much of the genome, recognized as important in disease, and thus report erroneous results in downstream analyses. We introduce EMA, a novel two-tiered statistical binning model for bar-coded read alignment, that first probabilistically maps reads to potentially multiple &#x0201c;read clouds&#x0201d; and then within clouds by newly exploiting the nonuniform read densities characteristic of barcoded read sequencing. EMA substantially improves downstream accuracy over existing methods, including phasing and genotyping on 10x data, with fewer false variant calls in nearly half the time. EMA effectively resolves particularly challenging alignments in genomic regions that contain nearby homologous elements, uncovering variants in the pharmacogenomically important <italic>CYP2D</italic> region, and clinically important genes <italic>C4</italic> (schizophrenia) and <italic>AMY1A</italic> (obesity), which go undetected by existing methods. Our work provides a framework for future generation sequencing.</p></abstract><abstract id="ABS2" abstract-type="summary"><title>In Brief</title><p id="P4">Researchers are applying barcoded read sequencing to capture longer-range information in the genome at low error rates. We introduce a two-tiered statistical binning model, named EMA, which probabilistically assigns reads to &#x0201c;clouds&#x0201d; and then optimizes read assignments within clouds based on read densities. Unlike previous approaches, our efficient method enables alignment to highly homologous regions of the genome important in disease and substantially improves downstream genotyping and haplotyping. Our method also uncovers rare variants in clinically important genes.</p></abstract></article-meta></front><body><sec id="S1"><title>INTRODUCTION</title><p id="P6">Sequencing is the most fundamental operation in genomics, transcriptomics, and metagenomics. As sequencing technologies continue to advance beyond the initial introduction of next-generation sequencing (NGS), we have begun to see the emergence of the so-called &#x0201c;third-generation&#x0201d; sequencing platforms, which seek to improve on the standard short-read sequencing that has thus far been at the heart of most NGS (<xref rid="R19" ref-type="bibr">Mardis, 2017</xref>). Several organizations are at the center of this new sequencing revolution, including Pacific Biosciences (<xref rid="R9" ref-type="bibr">Eid et al., 2009</xref>), Oxford Nanopore (<xref rid="R28" ref-type="bibr">Wang et al., 2014</xref>), and 10x Genomics (<xref rid="R30" ref-type="bibr">Zheng et al., 2016</xref>). While the former two have developed sequencing technologies that produce much longer physical reads (e.g., 10&#x02013;200 kb) at typically higher error rates, the latter is an example of a barcoded sequencing technology, which typically produces short reads (up to 300 bp) with low error rates (<xref rid="R11" ref-type="bibr">Goodwin et al., 2016</xref>).</p><p id="P7">At a high level, barcoded sequencing is any sequencing method where long DNA fragments are sheared and the sheared pieces have some identifier (&#x0201c;barcode&#x0201d;) relating them back to the source fragment. These barcodes can be explicit (a physical barcode is ligated to each sheared piece, e.g., as in 10x sequencing) or implicit (the fragments are distributed to identifiable wells, e.g., as in Illumina&#x02019;s TruSeq Synthetic Long-Read sequencing, henceforth referred to as TruSeq SLR). These sheared pieces are then sequenced using standard short-read sequencing, thereby producing barcoded short reads (<xref rid="F1" ref-type="fig">Figure 1A</xref>). Other barcoded sequencing technologies include Illumina&#x02019;s Continuity Preserving Transposition technology (CPT-seq), Complete Genomics&#x02019; Long Fragment Read technology, Drop-seq, and CEL-Seq2 (<xref rid="R30" ref-type="bibr">Zheng et al., 2016</xref>; <xref rid="R20" ref-type="bibr">McCoy et al., 2014</xref>; <xref rid="R18" ref-type="bibr">Macosko et al., 2015</xref>; <xref rid="R12" ref-type="bibr">Hashimshony et al., 2016</xref>; <xref rid="R2" ref-type="bibr">10x Genomics, 2018</xref>). Because they help identify the original source fragment, these barcodes implicitly carry long-range information, which can have a significant impact on alignment and many downstream analyses such as structural variation detection and phasing.</p><p id="P8">Barcoded reads have several advantages over physically long reads. First, and perhaps most important, barcoded read sequencing is substantially cheaper than long-read sequencing; whereas PacBio&#x02019;s and Oxford Nanopore&#x02019;s sequencing platforms currently cost anywhere from $750 to $1,000 per GB of data, barcoded sequencing is a comparatively cheap add-on to standard short-read sequencing and therefore bears the same cost (e.g., 10x sequencing costs $30 per GB plus a $500 overhead per sample) (<xref rid="R11" ref-type="bibr">Goodwin et al., 2016</xref>). Second, the error profile of barcoded reads is very similar to that of standard short reads (roughly 0.1% substitution errors), which enables us to augment the tools and algorithms that have been developed for regular short reads to handle their barcoded counterparts. By contrast, long-read sequencing typically produces high rates of erroneous indels (ranging from 12%&#x02013;13%), which presents a challenge when trying to use preexisting algorithms. Beyond these advantages, barcoded reads are compatible with doing hybrid capture exome sequencing, and not sequencing introns (which is not possible with long-read sequencing technologies, as a contiguous long-read cannot only sequence the exons in a gene). This is a very substantial additional cost-advantage for barcoded reads (exome sequencing can mean a 10- to 20-fold reduction in sequencing cost over whole genome sequencing) (<xref rid="R25" ref-type="bibr">Schwarze et al., 2018</xref>). These and other benefits have led to the recent proliferation of barcoded sequencing technologies for various use cases; for example, 10x and TruSeq SLR sequencing for whole genome sequencing, as well as Drop-seq and CEL-Seq2 for single-cell RNA sequencing (RNA-seq), 10x for single-cell VDJ sequencing and so on (<xref rid="R30" ref-type="bibr">Zheng et al., 2016</xref>; <xref rid="R20" ref-type="bibr">McCoy et al., 2014</xref>; <xref rid="R18" ref-type="bibr">Macosko et al., 2015</xref>; <xref rid="R12" ref-type="bibr">Hashimshony et al., 2016</xref>; <xref rid="R2" ref-type="bibr">10x Genomics, 2018</xref>). A comprehensive review of many of these methods is available (<xref rid="R31" ref-type="bibr">Ziegenhain et al., 2017</xref>). Furthermore, barcoded sequencing is also playing a greater role in downstream applications such as the generation of transcriptomic profiles (<xref rid="R5" ref-type="bibr">Cleary et al., 2017</xref>).</p><p id="P9">As with virtually all sequencing data, the first step in the analysis pipeline for barcoded reads is typically alignment. While barcoded reads can, in theory, be aligned by a standard short-read aligner (e.g., CORA [<xref rid="R29" ref-type="bibr">Yorukoglu et al., 2016</xref>] (COmpressive Read-mapping Accelerator), BWA (Burrows-Wheeler Aligner) [<xref rid="R16" ref-type="bibr">Li and Durbin, 2009</xref>], Bowtie2 [<xref rid="R15" ref-type="bibr">Langmead and Salzberg, 2012</xref>]), this would fail to take advantage of the information provided by the barcodes. An alternative approach (<xref rid="R20" ref-type="bibr">McCoy et al., 2014</xref>) is to assemble the reads for each particular barcode and to treat the result as a single &#x0201c;synthetic long read.&#x0201d; While this strategy works well for technologies such as TruSeq SLR, in which source fragments are generally sequenced with high coverage, it is not practical when fragments are shallowly sequenced as with 10x, which achieves high coverage not by having high per-barcode coverage but rather by having many barcodes. Also worth noting is the fact that TruSeq SLR&#x02019;s sequencing fragments at high coverage inflate their sequencing costs to be on par with PacBio&#x02019;s and Oxford Nanopore&#x02019;s, whereas 10x circumvents this high cost via shallow fragment sequencing (<xref rid="R11" ref-type="bibr">Goodwin et al., 2016</xref>).</p><p id="P10">Currently, the state-of-the-art in terms of barcoded read alignment employs &#x0201c;read clouds&#x0201d;&#x02014;groups of reads that share the same barcode and map to the same genomic region&#x02014;to choose the most likely alignment from a set of candidate alignments for each read. Intuitively, read clouds represent the possible source fragments from which the barcoded reads are derived. The read cloud approach to alignment effectively begins with a standard all-mapping to a reference genome to identify these clouds, followed by an iterative update of the reads&#x02019; assignments to one of their possible alignments, guided by a Markov random field that is used to evaluate the probability of a given read-to-cloud configuration (taking into account the alignment scores, clouds, etc.). This method was first implemented for Moleculo data as Random Field Aligner (RFA) and was subsequently the foundation for the 10x aligner Lariat, which we compare to extensively in this work (<xref rid="R4" ref-type="bibr">Bishara et al., 2015</xref>). Notably, in this framework, clouds are inherently fixed entities to which some number of reads are assigned at any given point, which does not take into account the fact that reads can have suitable alignments in several different clouds. Since this information can be valuable in downstream analyses such as genotyping, phasing, and structural variation detection, we wish to account for it.</p><p id="P11">Confounding barcoded read alignment is the fact that multiple fragments can share the same barcode; it is in general not possible to infer the source fragment of a read (and thus its correct alignment within a reference genome) merely by looking at its barcode. In order to deduce the correct placement of a read, and thus its unknown source fragment, all possible alignments of that read need to be examined. Even then, it can be difficult to determine the correct alignment, particularly in homologous regions of the genome that result in multi-mappings within a single cloud.</p><p id="P12">Here, we propose a general paradigm for barcoded read alignment that newly employs a probabilistic interpretation of clouds: EMerAld, or EMA for short (<xref rid="F1" ref-type="fig">Figure 1</xref>). Our two-tiered statistical binning approach enables the more accurate placement of reads in and within read clouds, which is the critical step in barcoded read alignment. The two tiers consist of (1) a novel latent variable model to probabilistically assign reads to clouds, which introduces the notion of clouds as distributions over generated reads rather than simply fixed groups of reads; and (2) newly exploiting expected read coverage (read density) to resolve the difficult case of multiple alignments of reads <italic>within</italic> clouds. The idea and subsequent observation of the fixed read density distribution within source fragments are novel to EMA and can be utilized by many barcoded read analysis tools: for example, an assembler might use our idea to model the distance between reads within the same source fragment and thus break ties, if any. Note that these ambiguous alignments account for a large fraction of the rare variants that currently cannot be resolved and are of great interest to biologists (<xref rid="R13" ref-type="bibr">Ingelman-Sundberg, 2004</xref>; <xref rid="R26" ref-type="bibr">Sekar et al., 2016</xref>; <xref rid="R10" ref-type="bibr">Falchi et al., 2014</xref>).</p><p id="P13">By thinking of clouds not as arbitrary clusters of reads but rather as distributions, EMA&#x02019;s latent variable model (tier I) is able to generate more accurate alignments and to newly assign interpretable probabilities to its alignments, which greatly improves downstream analyses. Genotyping improvements and, more generally, the resolution of distant homologs (e.g., longer than fragment length or interchromosomol) stem from our probabilistic interpretation. We demonstrate EMA&#x02019;s performance by evaluating downstream genotyping and phasing accuracy first using real 10x data. We discovered that roughly 20% of all reads in our datasets had multiple suitable alignments and were therefore able to be targeted by EMA&#x02019;s optimization algorithm. We also found that genotypes called from EMA&#x02019;s alignments contained over 30% fewer false positives than those called from 10x&#x02019;s Lariat aligner&#x02014;and at the same time contained fewer false negatives&#x02014;on independent 10x datasets of NA12878, NA24149, NA24143, and NA24385. The National Institute of Science and Technology&#x02019;s &#x0201c;Genome in a Bottle&#x0201d; high-confidence variant calls were used as a gold standard. EMA also improved phasing performance by reducing switch errors and producing larger phased blocks.</p><p id="P14">Focusing on uncovering novel biology, we additionally demonstrate that&#x02014;through its read density optimization (tier II)&#x02014;EMA improves alignments in several clinically important and highly homologous genes: <italic>CYP2D6</italic>/<italic>CYP2D7</italic> (of great pharmacogenomic importance [<xref rid="R13" ref-type="bibr">Ingelman-Sundberg, 2004</xref>]), <italic>C4</italic> (linked to schizophrenia [<xref rid="R26" ref-type="bibr">Sekar et al., 2016</xref>]), and <italic>AMY1A</italic> (conjectured association with obesity [<xref rid="R10" ref-type="bibr">Falchi et al., 2014</xref>]). We discovered using EMA and validated through published studies (<xref rid="R14" ref-type="bibr">Jain et al., 2017</xref>; <xref rid="R22" ref-type="bibr">Mostovoy et al., 2016</xref>; <xref rid="R24" ref-type="bibr">Pendleton et al., 2015</xref>) several variants in these regions that go undetected by Lariat and BWA. Moreover, we sought to demonstrate that our approach generalizes to other barcoded sequencing technologies by applying it to TruSeq SLR data as well as CPT-seq data, where we observe similar results. Intuitively, EMA&#x02019;s ability to handle shorter homologies (i.e., those within a cloud) leads to these novel findings.</p><p id="P15">In addition to achieving superior accuracy, providing interpretable probabilities, and uncovering novel biology, the EMA pipeline is up to 2&#x000d7; faster than Lariat&#x02014;which translates into days faster for typical 10x datasets&#x02014;and does not add any memory overhead to the alignment process. Thus, we expect the algorithms introduced here to be a fundamental component of barcoded read methods in the future.</p></sec><sec id="S2"><title>RESULTS</title><sec id="S3"><title>Experimental Setting</title><p id="P16">We first compared the performance of EMA against Lariat (<xref rid="R1" ref-type="bibr">10x Genomics, 2017</xref>) (10x&#x02019;s own aligner and a component of the Long Ranger software suite) and BWA-MEM (&#x0201c;Maximal Exact Matches&#x0201d;) (<xref rid="R16" ref-type="bibr">Li and Durbin, 2009</xref>) (which does not take advantage of barcoded data and was therefore used as a baseline for what can be achieved with standard short reads). In order to benchmark the quality of the aligners, we examined downstream genotyping accuracy, alignments in highly homologous regions, and downstream phasing accuracy.</p><p id="P17">We ran each tool on four 10x <italic>Homo sapiens</italic> datasets for NA12878, NA24149, NA24143, and NA24385 and used the corresponding latest NIST GIAB (<xref rid="R33" ref-type="bibr">Zook et al., 2014</xref>, <xref rid="R32" ref-type="bibr">2016</xref>) high-confidence variant calls as a gold standard for each. For both EMA and BWA, we performed duplicate marking after alignment using Picard&#x02019;s MarkDuplicates tool (URL: <ext-link ext-link-type="uri" xlink:href="https://broadinstitute.github.io/picard/">https://broadinstitute.github.io/picard/</ext-link>), with barcode-aware mode enabled in the case of EMA; Long Ranger performs duplicate marking automatically. Genotypes were called by HaplotypeCaller from the Genome Analysis Toolkit (GATK) (<xref rid="R21" ref-type="bibr">McKenna et al., 2010</xref>; <xref rid="R7" ref-type="bibr">DePristo et al., 2011</xref>) with default settings, while phasing was done by HapCUT2 (<xref rid="R8" ref-type="bibr">Edge et al., 2016</xref>) in barcode-aware mode. Genotyping accuracies were computed using RTG (&#x0201c;Real Time Genomics&#x0201d;) Tools (<xref rid="R6" ref-type="bibr">Cleary et al., 2014</xref>). We also ran EMA and Lariat on a much higher coverage NA12878 dataset (&#x0201c;NA12878 v2&#x0201d;) to test genotyping accuracy at high coverage as well as scalability.</p><p id="P18">To test EMA&#x02019;s improvements on other barcoded read sequencing technologies, we ran EMA and BWA on an NA12878 TruSeq SLR dataset (<xref rid="R4" ref-type="bibr">Bishara et al., 2015</xref>) as well as an NA12878 CPT-seq dataset (<xref rid="R3" ref-type="bibr">Amini et al., 2014</xref>). All analyses in this paper were performed with respect to the GRCh37 human reference genome.</p></sec><sec id="S4"><title>EMA Improves Downstream Genotyping Accuracy</title><p id="P19">EMA&#x02019;s genotyping accuracy surpasses that of other aligners (<xref rid="F2" ref-type="fig">Figure 2</xref>). We found that for each of the four 10x <italic>H. sapiens</italic> datasets, EMA produced 30% fewer false positive variant calls compared to Lariat and produced fewer false negative calls as well. Interestingly, BWA-MEM (which does not take barcodes into account) performed marginally better than Lariat here. Nevertheless, EMA also outperforms BWA-MEM, attaining the fewest false positive and false negative variant calls between the three aligners on each dataset. To verify that EMA&#x02019;s superior accuracy scales to higher coverage datasets, we tested it on a high-coverage NA12878 dataset (Supplementary <xref rid="SD1" ref-type="supplementary-material">Figure S3</xref>). EMA attains an even more substantial improvement on the high-coverage dataset, eliminating nearly 37% of Lariat&#x02019;s false positives and 6% of its false negatives.</p><p id="P20">When run on TruSeq SLR and CPT-seq data, we did not observe any significant differences in genotyping accuracy between EMA and BWA. This finding is likely due to the fact that these platforms divide the source fragments into just 384 and 9,128 wells (&#x0201c;barcodes&#x0201d;), respectively, limiting the utility of the barcodes in unambiguous regions of the genome, which is primarily what our NIST GIAB gold standard consists of. However, for both technologies, we did observe improvements in resolving ambiguous regions of the genome, which we detail below.</p><p id="P21">Overall, we found that typically ~20% of all reads in our various datasets had multiple suitable alignments and were therefore able to be targeted by EMA&#x02019;s two-tiered statistical binning optimization algorithm. These are precisely those reads that are most challenging to align and can occur in clinically important regions of the genome, as we next demonstrate.</p></sec><sec id="S5"><title>EMA Improves Alignments and Analysis of Highly Homologous Regions</title><p id="P22">Among the principal promises of barcoded read sequencing is better structural variation detection, which invariably requires resolving alignments in homologous regions. One such important region is the <italic>CYP2D</italic> region in chromosome 22, which hosts <italic>CYP2D6</italic>&#x02014;a gene of great pharmacogenomic importance (<xref rid="R13" ref-type="bibr">Ingelman-Sundberg, 2004</xref>)&#x02014;and the two related and highly homologous regions <italic>CYP2D7</italic> and <italic>CYP2D8</italic>. The high homology between <italic>CYP2D6</italic> and <italic>CYP2D7</italic> makes copy number estimation and variant calling in this region particularly challenging. Indeed, the majority of aligners misalign reads in this region. The difficulty is especially evident in NA12878, which, in addition to the two copies of both <italic>CYP2D6</italic> and <italic>CYP2D7</italic>, contains an additional copy that is a fusion between these two genes (<xref rid="R27" ref-type="bibr">Twist et al., 2016</xref>), as well as <italic>CYP2D7</italic> mutations that introduce even higher homology with the corresponding <italic>CYP2D6</italic> region. Especially problematic is exon/intron 8 of <italic>CYP2D6</italic>, where many reads originating from <italic>CYP2D7</italic> end up mapping erroneously (see <xref rid="F3" ref-type="fig">Figure 3</xref> for a visualization). Even the naive use of barcoded reads is not sufficient: both homologous regions in <italic>CYP2D</italic> are typically covered by a single cloud. For example, Lariat performs no better than BWA in this region (<xref rid="F3" ref-type="fig">Figure 3</xref>). For these reasons, we chose to evaluate EMA in <italic>CYP2D</italic> to benchmark its accuracy in such highly homologous regions.</p><p id="P23">As can be seen in <xref rid="F3" ref-type="fig">Figure 3</xref>, EMA&#x02019;s statistical binning strategy significantly smooths out the two problematic peaks in <italic>CYP2D6</italic> and <italic>CYP2D7</italic>. This technique enabled us to detect three novel mutations in <italic>CYP2D7</italic> (<xref rid="F3" ref-type="fig">Figure 3</xref>), which exhibit high homology with the corresponding region in <italic>CYP2D6</italic>. Thus, all reads originating from these loci get misaligned to <italic>CYP2D6</italic>, especially if one only considers edit distance during the alignment (as Lariat and BWA do). Such misalignments are evident in the &#x0201c;peaks&#x0201d; and &#x0201c;holes&#x0201d; shown in <xref rid="F3" ref-type="fig">Figure 3</xref>. We additionally cross-validated this region with the consensus sequence obtained from available NA12878 assemblies (<xref rid="R14" ref-type="bibr">Jain et al., 2017</xref>; <xref rid="R22" ref-type="bibr">Mostovoy et al., 2016</xref>; <xref rid="R24" ref-type="bibr">Pendleton et al., 2015</xref>) and confirmed the presence of novel mutations. Notably, we found similar enhancements in other clinically important and highly homologous genes: <italic>C4</italic> and <italic>AMY1A</italic>, as depicted in the same figure.</p><p id="P24">In addition, the copy number derived from EMA&#x02019;s alignments in this problematic region (spanning from exon 7 up to exon 9 in <italic>CYP2D6</italic> and <italic>CYP2D7</italic>) was closer to the &#x0201c;expected&#x0201d; copy number by 20% compared to the copy number derived from Lariat&#x02019;s alignments (we used Aldy [<xref rid="R23" ref-type="bibr">Numanagi&#x00107; et al., 2018</xref>] to obtain this data). We further ran Aldy on our high-coverage NA12878 v2 dataset, where it correctly detected the *3/*68+*4 allelic combination on both EMA&#x02019;s and Lariat&#x02019;s alignments, and EMA&#x02019;s overall copy number error over the whole region was around 4% better than Lariat&#x02019;s. Finally, statistical binning did not adversely impact phasing performance in this region as we were able to correctly phase <italic>CYP2D6*4A</italic> alleles in our NA12878 sample from EMA&#x02019;s alignments.</p><p id="P25">To demonstrate the generalizability of our paradigm to other similar barcoded sequencing technologies, we tested it on TruSeq SLR (BioProject: PRJNA287848) and CPT-seq (BioProject: PRJNA241346) data, where the bin distributions follow a similar pattern as 10x&#x02019;s. We alone were able to detect the same novel <italic>CYP2D7</italic>, <italic>C4</italic>, and <italic>AMY1A</italic> variants in an NA12878 TruSeq SLR dataset (even with shallow coverage) and to detect the <italic>CYP2D7</italic> variants in an NA12878 CPT-seq dataset, as shown in the right-hand side of <xref rid="F3" ref-type="fig">Figure 3</xref>.</p></sec><sec id="S6"><title>EMA Improves Downstream Phasing</title><p id="P26">We applied the state-of-the-art phasing algorithm HapCUT2 (<xref rid="R8" ref-type="bibr">Edge et al., 2016</xref>), which supports 10x barcoded reads, to phase (i.e., link variants into haplotypes) the variants called by GATK for both EMA&#x02019;s and Lariat&#x02019;s alignments. We evaluated our results with the phasing metrics defined in the HapCUT2 manuscript. As shown in <xref rid="F2" ref-type="fig">Figure 2</xref>, EMA provides more accurate phasing with respect to every metric in comparison to Lariat.</p></sec><sec id="S7"><title>EMA Is Computationally More Efficient</title><p id="P27">Runtimes and memory usage for each aligner are provided in <xref rid="T2" ref-type="table">Table 1</xref> for our small and large NA12878 datasets. These times include alignment, duplicate marking, and any other data post processing (e.g., BAM sorting and merging). The reported memory usages are per each instance of the given mapper. We found that EMA scales better than Lariat: specifically, we observe a 1.5x speedup on our smaller dataset and a nearly 2x speedup on our larger one, over Lariat&#x02019;s runtimes. We ran EMA on a total of four high-coverage datasets and have observed that EMA scales linearly in the size of the dataset.</p><p id="P28">Runtime and memory usages on two NA12878 datasets (&#x0201c;NA12878&#x0201d;&#x02014;used also in <xref rid="F2" ref-type="fig">Figure 2</xref>&#x02014;is about 287 GB of raw data; &#x0201c;NA12878 v2&#x0201d; is about 823 GB). Numbers in parentheses indicate the performance of the aligner alone (i.e., without sorting, merging, or duplicate marking). For the small dataset, each mapper was allocated 40 Intel Xeon E5&#x02013;2650 CPUs @ 2.30 GHz. For the large dataset, each was allocated 48 Intel Xeon E5&#x02013;2695 CPUs @ 2.40 GHz. Memory measurements include only the actual aligner&#x02019;s memory usage and do not include the memory requirements of pre- and post-processing steps as they are virtually the same for all methods. BWAMEM was used only as a baseline on the smaller dataset.</p></sec></sec><sec id="S8"><title>DISCUSSION</title><p id="P29">EMA&#x02019;s unique ability to assign interpretable probabilities to alignments has several benefits, the most immediate of which is that it enables us to set a meaningful confidence threshold on alignments. Additionally, these alignment probabilities can be incorporated into downstream applications such as genotyping, phasing, and structural variation detection. We demonstrate this feature here by computing mapping qualities based on these probabilities, which consequently enhance genotyping and phasing. Nevertheless, specialized algorithms centered around these probabilities are also conceivable.</p><p id="P30">Moreover, EMA is able to effectively discern between multiple alignments of a read in a single cloud through its read density optimization algorithm. This capability addresses one of the weaknesses of barcoded read sequencing as compared to long-read sequencing; namely, that only a relatively small subset of the original source fragment is observed&#x02014;and, more specifically, that the order of reads within the fragment is not known&#x02014;making it difficult to produce accurate alignments if the fragment spans homologous elements. By exploiting the insight that read densities within a fragment follow a particular distribution, EMA more effectively aligns the reads produced by such fragments, which can overlap regions of phenotypic or pharmacogenomic importance, such as <italic>CYP2D</italic>, <italic>C4</italic>, or <italic>AMY1</italic>, as we demonstrated. In summary, EMA&#x02019;s first tier (latent variable model) helps resolve the case of distant homologs, and its second tier, the case of proximal homologs.</p><p id="P31">As we usher in the next wave of the NGS technologies, barcoded read sequencing will undoubtedly play a central role, and fast and accurate methods for aligning barcoded reads, such as EMA, will ultimately prove invaluable in downstream analyses.</p></sec><sec id="S9"><title>STAR*METHODS</title><sec id="S10"><title>KEY RESOURCES TABLE</title><table-wrap id="T1" position="anchor" orientation="portrait"><table frame="hsides" rules="groups"><colgroup span="1"><col align="left" valign="middle" span="1"/><col align="left" valign="middle" span="1"/><col align="left" valign="middle" span="1"/></colgroup><thead><tr><th align="left" valign="bottom" rowspan="1" colspan="1">REAGENT or RESOURCE</th><th align="left" valign="bottom" rowspan="1" colspan="1">SOURCE</th><th align="left" valign="bottom" rowspan="1" colspan="1">IDENTIFIER</th></tr></thead><tbody><tr style="border-bottom: solid 1px"><td colspan="3" align="left" valign="middle" rowspan="1">Deposited Data</td></tr><tr><td align="left" valign="top" rowspan="1" colspan="1">NA12878 WGS (10x)</td><td align="left" valign="top" rowspan="1" colspan="1">10x Genomics</td><td align="left" valign="top" rowspan="1" colspan="1"><ext-link ext-link-type="uri" xlink:href="https://support.10xgenomics.com/genome-exome/datasets/2.1.0/NA12878_WGS_210">https://support.10xgenomics.com/genome-exome/</ext-link><ext-link ext-link-type="uri" xlink:href="https://support.10xgenomics.com/genome-exome/datasets/2.1.0/NA12878_WGS_210">datasets/2.1.0/NA12878_WGS_210</ext-link></td></tr><tr><td align="left" valign="top" rowspan="1" colspan="1">NA12878 WGS v2 (10x)</td><td align="left" valign="top" rowspan="1" colspan="1">10x Genomics</td><td align="left" valign="top" rowspan="1" colspan="1"><ext-link ext-link-type="uri" xlink:href="https://support.10xgenomics.com/genome-exome/datasets/2.2.1/NA12878_WGS_v2">https://support.10xgenomics.com/genome-exome/</ext-link><ext-link ext-link-type="uri" xlink:href="https://support.10xgenomics.com/genome-exome/datasets/2.2.1/NA12878_WGS_v2">datasets/2.2.1/NA12878_WGS_v2</ext-link></td></tr><tr><td align="left" valign="top" rowspan="1" colspan="1">NA12878 WGS (Illumina TruSeq Synthetic Long-Read)</td><td align="left" valign="top" rowspan="1" colspan="1"><xref rid="R4" ref-type="bibr">Bishara et al. (2015)</xref></td><td align="left" valign="top" rowspan="1" colspan="1">BioProject: PRJNA287848</td></tr><tr style="border-bottom: solid 1px"><td align="left" valign="top" rowspan="1" colspan="1">NA12878 WGS (CPT-seq)</td><td align="left" valign="top" rowspan="1" colspan="1"><xref rid="R3" ref-type="bibr">Amini et al. (2014)</xref></td><td align="left" valign="top" rowspan="1" colspan="1">BioProject: PRJNA241346</td></tr><tr style="border-bottom: solid 1px"><td colspan="3" align="left" valign="middle" rowspan="1">Software and Algorithms</td></tr><tr><td align="left" valign="top" rowspan="1" colspan="1">Long Ranger</td><td align="left" valign="top" rowspan="1" colspan="1">10x Genomics</td><td align="left" valign="top" rowspan="1" colspan="1"><ext-link ext-link-type="uri" xlink:href="https://support.10xgenomics.com/genome-exome/software/downloads/latest">https://support.10xgenomics.com/genome-exome/</ext-link><ext-link ext-link-type="uri" xlink:href="https://support.10xgenomics.com/genome-exome/software/downloads/latest">software/downloads/latest</ext-link></td></tr><tr><td align="left" valign="top" rowspan="1" colspan="1">BWA</td><td align="left" valign="top" rowspan="1" colspan="1"><xref rid="R16" ref-type="bibr">Li and Durbin (2009)</xref></td><td align="left" valign="top" rowspan="1" colspan="1"><ext-link ext-link-type="uri" xlink:href="https://github.com/lh3/bwa">https://github.com/lh3/bwa</ext-link></td></tr><tr><td align="left" valign="top" rowspan="1" colspan="1">GATK</td><td align="left" valign="top" rowspan="1" colspan="1">Broad Institute</td><td align="left" valign="top" rowspan="1" colspan="1"><ext-link ext-link-type="uri" xlink:href="https://software.broadinstitute.org/gatk/">https://software.broadinstitute.org/gatk/</ext-link></td></tr><tr><td align="left" valign="top" rowspan="1" colspan="1">HapCUT2</td><td align="left" valign="top" rowspan="1" colspan="1"><xref rid="R8" ref-type="bibr">Edge etal. (2016)</xref></td><td align="left" valign="top" rowspan="1" colspan="1"><ext-link ext-link-type="uri" xlink:href="https://github.com/vibansal/HapCUT2">https://github.com/vibansal/HapCUT2</ext-link></td></tr><tr><td align="left" valign="top" rowspan="1" colspan="1">Picard</td><td align="left" valign="top" rowspan="1" colspan="1">Broad Institute</td><td align="left" valign="top" rowspan="1" colspan="1"><ext-link ext-link-type="uri" xlink:href="https://broadinstitute.github.io/picard/">https://broadinstitute.github.io/picard/</ext-link></td></tr><tr><td align="left" valign="top" rowspan="1" colspan="1">Samtools</td><td align="left" valign="top" rowspan="1" colspan="1"><xref rid="R17" ref-type="bibr">Li et al. (2009)</xref></td><td align="left" valign="top" rowspan="1" colspan="1"><ext-link ext-link-type="uri" xlink:href="https://github.com/samtools/samtools">https://github.com/samtools/samtools</ext-link></td></tr><tr><td align="left" valign="top" rowspan="1" colspan="1">RTG Tools</td><td align="left" valign="top" rowspan="1" colspan="1"><xref rid="R6" ref-type="bibr">Cleary et al. (2014)</xref></td><td align="left" valign="top" rowspan="1" colspan="1"><ext-link ext-link-type="uri" xlink:href="https://github.com/RealTimeGenomics/rtg-tools">https://github.com/RealTimeGenomics/rtg-tools</ext-link></td></tr><tr style="border-bottom: solid 1px"><td align="left" valign="top" rowspan="1" colspan="1">EMA</td><td align="left" valign="top" rowspan="1" colspan="1">This paper</td><td align="left" valign="top" rowspan="1" colspan="1"><ext-link ext-link-type="uri" xlink:href="https://github.com/arshajii/ema">https://github.com/arshajii/ema</ext-link></td></tr><tr style="border-bottom: solid 1px"><td colspan="3" align="left" valign="middle" rowspan="1">Other</td></tr><tr><td align="left" valign="top" rowspan="1" colspan="1">NISTGIAB</td><td align="left" valign="top" rowspan="1" colspan="1"><xref rid="R32" ref-type="bibr">Zook etal. (2016)</xref></td><td align="left" valign="top" rowspan="1" colspan="1"><ext-link ext-link-type="uri" xlink:href="http://jimb.stanford.edu/giab/">http://jimb.stanford.edu/giab/</ext-link></td></tr><tr><td align="left" valign="top" rowspan="1" colspan="1">NA24149, NA24143 and NA24385 WGS (10x)</td><td align="left" valign="top" rowspan="1" colspan="1">Broad Institute</td><td align="left" valign="top" rowspan="1" colspan="1"><ext-link ext-link-type="uri" xlink:href="http://ema.csail.mit.edu/">http://ema.csail.mit.edu</ext-link></td></tr></tbody></table></table-wrap></sec><sec id="S11"><title>CONTACT FOR REAGENT AND RESOURCE SHARING</title><p id="P32">Further information and requests for resources and reagents should be directed to and will be fulfilled by the Lead Contact, Bonnie Berger (<email>bab@mit.edu</email>).</p></sec><sec id="S12"><title>METHOD DETAILS</title><p id="P33">General barcoded read sequencing begins with splitting the source DNA into long fragments (10&#x02013;200kb) where each such fragment is assigned some barcode (e.g. a short 16bp DNA sequence in 10x sequencing). These fragments are sheared and each sheared piece has the assigned barcode ligated to it (or, alternatively, resides in an identifiable well), whereupon standard short-read sequencing is applied to the sheared pieces. As a result, barcoded reads have the same low error rates as typical Illumina whole-genome sequencing reads. An idealization of this process is illustrated in <xref rid="F1" ref-type="fig">Figure 1A</xref>.</p></sec><sec id="S13"><title>Standard Data Preprocessing</title><p id="P34">The first stage in the alignment process is to preprocess the data and to identify the barcodes. Currently, EMA uses an in-house 10x barcode preprocessor, which extracts and corrects the barcodes from the raw data. Data from many other barcoded read technologies (e.g. TruSeq SLR) can be preprocessed in a more straightforward manner, as the barcodes are given as well identifiers for each read, meaning the preprocessing stage consists of a simple demultiplexing step.</p><p id="P35">For 10x data preprocessing we largely follow the same practices used by 10x Genomics&#x02019; WGS software suite, Long Ranger. The purpose of this preprocessing is to:</p><list list-type="bullet" id="L2"><list-item><p id="P36">extract the barcode from the read sequence,</p></list-item><list-item><p id="P37">error-correct the barcode based on quality scores and a list of known barcode sequences,</p></list-item><list-item><p id="P38">and group reads by barcode into &#x0201c;barcode buckets&#x0201d; to enable parallelism during alignment.</p></list-item></list><p id="P39">In summary, in the barcode extraction stage, we remove the 16bp barcode from the first mate of each read pair, and trim an additional 7bp to account for potential ligation artifacts resulting from the barcode ligation process during sequencing (the second mate shares the same barcode as the first mate). Subsequently, we compare each barcode to a list <italic>B</italic> of known barcodes to produce a count for each barcode in <italic>B</italic>, and compute a prior probability for each based on these counts (specifically, this prior is proportional to the fraction of times we see the given barcode in our data). Note that this list is provided by 10x Genomics, and is designed so that no two barcodes are Hamming-neighbors of one another. Now for each barcode <italic>b</italic> not appearing in <italic>B</italic>, we examine each of its Hamming-1 neighbors <italic>b</italic>&#x02032; and, if <italic>b</italic>&#x02032; appears in <italic>B</italic>, compute the probability that <italic>b</italic>&#x02032; was the true barcode based on its prior and the quality score of the changed base. Similarly, for each <italic>b</italic> appearing in <italic>B</italic>, we consider each Hamming-2 neighbor <italic>b</italic>&#x02032; and compute the probability that <italic>b</italic>&#x02032; was the true barcode in an analogous way. The reason we examine the Hamming-2 neighbors of barcodes that are already in our whitelist is because it is possible, albeit unlikely, that two sequencing errors in the barcode changed it from a barcode on the list to another <italic>also</italic> on the list (in practice we found this Hamming-2 correction step to be largely unnecessary as described below, but it is performed in Lariat&#x02019;s data preprocessing nonetheless). Lastly, we employ a probability cutoff on the barcodes, and thereby omit the barcodes of reads that do not meet this cutoff. Any read not carrying a barcode after this stage is aligned with a standard WGS mapper such as CORA or BWA.</p><p id="P40">While in standard read alignment parallelism can be achieved at the read-level, for barcoded read alignment we can only achieve parallelism at the barcode-level. Therefore, the last preprocessing step is to group reads by barcode into some number of buckets. Each such bucket contains some range of barcodes from <italic>B</italic>, which are all grouped together within the bucket. This enables us to align the reads from each bucket in parallel, and to merge the outputs in a post-processing step.</p><p id="P41">We note that the Hamming-2 search takes a substantial fraction of the total time, but is often unnecessary: on a large 980GB 10x dataset, only 276 out of almost 1.5 billion reads are affected by the Hamming-2 correction (amounting to <italic>&#x0003c;</italic>0:0001% overall effect). Thus, it is safe to skip the Hamming-2 correction step. Nevertheless, we applied Hamming-2 correction on all our datasets for the sake of consistency with Lariat. Finally, EMA offers a parallelized barcode correction implementation, which significantly speeds up the overall pipeline.</p></sec><sec id="S14"><title>Latent Variable Model for Aligning Barcoded Reads to Clouds</title><p id="P42">Here we employ a latent variable model for determining the optimal assignment of reads to their possible clouds. A &#x0201c;cloud&#x0201d; is defined to be a group of nearby alignments of reads with a common barcode, thereby representing a possible source fragment (<xref rid="R4" ref-type="bibr">Bishara et al., 2015</xref>). We consider all the reads for an individual barcode simultaneously, all-mapping and grouping them to produce a set of clouds for that barcode (<xref rid="F1" ref-type="fig">Figure 1B</xref>). The clouds are deduced from the all-mappings by grouping any two alignments that are on the same chromosome and within 50kb of one another into the same cloud, which is the same approach employed by Lariat (for TruSeq SLR or CPT-seq data, we use 15kb as a cutoff; this is a tuneable parameter that can be adjusted depending on the underlying technology). While this heuristic works well in the majority of cases, it can evidently run into issues if, for example, a single read aligns multiple times to the same cloud. We address such cases below, but assume in the subsequent analysis that clouds consist of at most one alignment of a given read.</p><p id="P43">As notation, we will denote by <italic>c</italic> the set of alignments contained in a given cloud. We restrict our analysis to a single set of clouds <inline-formula><mml:math display="inline" id="M1" overflow="scroll"><mml:mrow><mml:mi mathvariant="script">C</mml:mi><mml:mo>=</mml:mo><mml:mrow><mml:mo>{</mml:mo><mml:mrow><mml:msub><mml:mi>c</mml:mi><mml:mn>1</mml:mn></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>c</mml:mi><mml:mn>2</mml:mn></mml:msub><mml:mo>,</mml:mo><mml:mo>&#x02026;</mml:mo><mml:mo>,</mml:mo><mml:msub><mml:mi>c</mml:mi><mml:mi>n</mml:mi></mml:msub></mml:mrow><mml:mo>}</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula> that corresponds to a connected component in the disjoint-set over clouds induced by alignments, as shown in <xref rid="F1" ref-type="fig">Figure 1B</xref> (i.e. two clouds <italic>c</italic><sub><italic>i</italic></sub> and <italic>c</italic><sub><italic>j</italic></sub> will be connected if there is a read that has an alignment to both <italic>c</italic><sub><italic>i</italic></sub> and <italic>c</italic><sub><italic>j</italic></sub>). Conceptually, the clouds in <inline-formula><mml:math display="inline" id="M2" overflow="scroll"><mml:mi mathvariant="script">C</mml:mi></mml:math></inline-formula> can be thought of as alternate possibilities for the <italic>same</italic> latent source fragment. By definition, for any given read aligning to some cloud in <inline-formula><mml:math display="inline" id="M3" overflow="scroll"><mml:mi mathvariant="script">C</mml:mi></mml:math></inline-formula>, we will have to consider only the clouds in <inline-formula><mml:math display="inline" id="M4" overflow="scroll"><mml:mi mathvariant="script">C</mml:mi></mml:math></inline-formula> when determining the best alignment for that read, so we focus on each such set of clouds separately. Note that we make the same implicit assumption made by Lariat: namely that distinct fragments sharing a common barcode (i.e. fragments in the same droplet/well) do not overlap on the genome. In reality, there is nothing preventing this from happening, but we can see that it occurs rarely since fragments are effectively sampled uniformly from the entire genome. If we partition the 3Gb genome into 100kb bins (as a reasonable upper bound on mean fragment length) and assume a droplet/well contains about 10 fragments (also a reasonable bound), we can observe that only about <inline-formula><mml:math display="inline" id="M5" overflow="scroll"><mml:mrow><mml:mn>1</mml:mn><mml:mo>&#x02212;</mml:mo><mml:munderover><mml:mstyle displaystyle="true"><mml:mo>&#x0220f;</mml:mo></mml:mstyle><mml:mrow><mml:mi>i</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mn>10</mml:mn></mml:mrow></mml:munderover><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mn>1</mml:mn><mml:mo>&#x02212;</mml:mo><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>i</mml:mi><mml:mo>&#x02212;</mml:mo><mml:mn>1</mml:mn><mml:mo>/</mml:mo><mml:mn>3</mml:mn><mml:mtext>Gb</mml:mtext><mml:mo>/</mml:mo><mml:mn>100</mml:mn><mml:mtext>kb</mml:mtext></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>&#x02248;</mml:mo><mml:mn>0.15</mml:mn><mml:mi>%</mml:mi></mml:mrow></mml:math></inline-formula> will contain overlapping fragments, where (as an approximation) we assume fragments overlap Q if they are contained in the same bin. By comparison, about 5%&#x02013;6% of all 10x reads are usually left without a barcode after standard barcode correction, so the additional 0.15% is rather marginal. A second possible undesirable scenario would be if two fragments with the same barcode originated from distinct but homologous regions. In this case, we would find two connected clouds in the disjoint-set that we would wrongly consider to be alternate possibilities of a <italic>single</italic> fragment. Nevertheless, we expect our optimization algorithm to handle this situation gracefully, assigning some probability to each read of mapping to either homolog (arguably, this is more of a problem with the previously employed read cloud methods wherein reads are only ever assigned to a single cloud).</p><p id="P44">For <inline-formula><mml:math display="inline" id="M6" overflow="scroll"><mml:mrow><mml:mi mathvariant="script">C</mml:mi><mml:mo>=</mml:mo><mml:mrow><mml:mo>{</mml:mo><mml:mrow><mml:msub><mml:mi>c</mml:mi><mml:mn>1</mml:mn></mml:msub><mml:mo>,</mml:mo><mml:mo>&#x02026;</mml:mo><mml:mo>,</mml:mo><mml:msub><mml:mi>c</mml:mi><mml:mi>n</mml:mi></mml:msub></mml:mrow><mml:mo>}</mml:mo></mml:mrow><mml:mo>,</mml:mo></mml:mrow></mml:math></inline-formula> let <italic>C</italic><sub><italic>i</italic></sub> denote the event that cloud <italic>c</italic><sub><italic>i</italic></sub> represents the true source fragment. Since the clouds <italic>c</italic><sub>1</sub>,&#x02026;,<italic>c</italic><sub><italic>n</italic></sub> are different possibilities for the same source fragment, we have Pr(<italic>C</italic><sub><italic>i</italic></sub> &#x02229; <italic>C</italic><sub><italic>j</italic></sub>) = 0 (<italic>i</italic> &#x02260; <italic>j</italic>) and <inline-formula><mml:math display="inline" id="M7" overflow="scroll"><mml:mrow><mml:munderover><mml:mstyle displaystyle="true"><mml:mo>&#x02211;</mml:mo></mml:mstyle><mml:mrow><mml:mi>i</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mi>n</mml:mi></mml:munderover><mml:mn>1</mml:mn><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mi>C</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:math></inline-formula> (where 1(&#x000b7;) &#x02208; {0, 1} is an indicator for the specified event). We assume uniform priors on the clouds so that Pr <italic>(C</italic><sub><italic>i</italic></sub><italic>)</italic> = (1/<italic>n)</italic> (while it is possible to devise a prior that takes into account features such as cloud length, we observed a large variance between clouds in our datasets that renders this unhelpful). Now, a cloud <italic>c</italic><sub><italic>i</italic></sub> can be conceptualized as an entity that generates some number of reads <italic>K</italic><sub><italic>i</italic></sub>, parameterized by some weight <inline-formula><mml:math display="inline" id="M8" overflow="scroll"><mml:mrow><mml:msub><mml:mi>&#x003b8;</mml:mi><mml:mrow><mml:msub><mml:mi>c</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:mrow></mml:msub><mml:mo>,</mml:mo></mml:mrow></mml:math></inline-formula> so that we can say <inline-formula><mml:math display="inline" id="M9" overflow="scroll"><mml:mrow><mml:msub><mml:mi>K</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>~</mml:mo><mml:mtext>Cloud</mml:mtext><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mi>&#x003b8;</mml:mi><mml:mrow><mml:msub><mml:mi>c</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:mrow></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula> for some unknown &#x0201c;cloud&#x0201d; distribution over generated reads. We make the key assumption that, in expectation, <inline-formula><mml:math display="inline" id="M10" overflow="scroll"><mml:mrow><mml:mi>Pr</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mi>C</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>|</mml:mo><mml:msub><mml:mi>&#x003b8;</mml:mi><mml:mrow><mml:msub><mml:mi>c</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:mrow></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>&#x0221d;</mml:mo><mml:msub><mml:mi>K</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>&#x0221d;</mml:mo><mml:msub><mml:mi>&#x003b8;</mml:mi><mml:mrow><mml:msub><mml:mi>c</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:mrow></mml:msub></mml:mrow></mml:math></inline-formula> for all <inline-formula><mml:math display="inline" id="M11" overflow="scroll"><mml:mrow><mml:msub><mml:mi>c</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>&#x02208;</mml:mo><mml:mi mathvariant="script">C</mml:mi><mml:mo>.</mml:mo></mml:mrow></mml:math></inline-formula> In other words, if a cloud is expected to have generated a large number of reads, then the probability that the cloud represents a true source fragment is high. Let <inline-formula><mml:math display="inline" id="M12" overflow="scroll"><mml:mrow><mml:mi>&#x003b8;</mml:mi><mml:mo>=</mml:mo><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mi>&#x003b8;</mml:mi><mml:mrow><mml:msub><mml:mi>c</mml:mi><mml:mn>1</mml:mn></mml:msub></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:mo>&#x02026;</mml:mo><mml:mo>,</mml:mo><mml:msub><mml:mi>&#x003b8;</mml:mi><mml:mrow><mml:msub><mml:mi>c</mml:mi><mml:mi>n</mml:mi></mml:msub></mml:mrow></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula> be the vector of cloud weights. We assume the cloud weights are normalized so that <inline-formula><mml:math display="inline" id="M13" overflow="scroll"><mml:mrow><mml:mi>Pr</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mi>C</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>/</mml:mo><mml:msub><mml:mi>&#x003b8;</mml:mi><mml:mrow><mml:msub><mml:mi>c</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:mrow></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:msub><mml:mi>&#x003b8;</mml:mi><mml:mrow><mml:msub><mml:mi>c</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:mrow></mml:msub><mml:mo>,</mml:mo></mml:mrow></mml:math></inline-formula> and that they are drawn from a uniform Dirichlet distribution so that <bold><italic>&#x003b8;</italic></bold> ~ Dir(1). Consider now the probability <inline-formula><mml:math display="inline" id="M14" overflow="scroll"><mml:mrow><mml:msub><mml:mi>&#x003b3;</mml:mi><mml:mrow><mml:mi>r</mml:mi><mml:mo>,</mml:mo><mml:msub><mml:mi>c</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:mrow></mml:msub></mml:mrow></mml:math></inline-formula> that a read <italic>r</italic> truly originates from cloud <italic>c</italic><sub><italic>i</italic></sub> (denoted as an event by <inline-formula><mml:math display="inline" id="M15" overflow="scroll"><mml:mrow><mml:msub><mml:mo>&#x00393;</mml:mo><mml:mrow><mml:mi>r</mml:mi><mml:mo>,</mml:mo><mml:msub><mml:mi>c</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:mrow></mml:msub></mml:mrow></mml:math></inline-formula>) given the cloud parameters <bold><italic>&#x003b8;</italic></bold> (i.e. <inline-formula><mml:math display="inline" id="M16" overflow="scroll"><mml:mrow><mml:msub><mml:mo>&#x00393;</mml:mo><mml:mrow><mml:mi>r</mml:mi><mml:mo>,</mml:mo><mml:msub><mml:mi>c</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:mrow></mml:msub><mml:mo>/</mml:mo><mml:mi>&#x003b8;</mml:mi><mml:mo>~</mml:mo><mml:mtext>Ber</mml:mtext><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mi>&#x003b3;</mml:mi><mml:mrow><mml:mi>r</mml:mi><mml:mo>,</mml:mo><mml:msub><mml:mi>c</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:mrow></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>,</mml:mo></mml:mrow></mml:math></inline-formula> where Ber(<italic>p</italic>) is the Bernoulli distribution with parameter <italic>p</italic>). By Bayes&#x02019; rule, we can say:
<disp-formula id="FD1"><mml:math display="block" id="M17" overflow="scroll"><mml:mrow><mml:msub><mml:mi>&#x003b3;</mml:mi><mml:mrow><mml:mi>r</mml:mi><mml:mo>,</mml:mo><mml:msub><mml:mi>c</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mi>Pr</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mo>&#x00393;</mml:mo><mml:mrow><mml:mi>r</mml:mi><mml:mo>,</mml:mo><mml:msub><mml:mi>c</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:mrow></mml:msub><mml:mo>/</mml:mo><mml:mi>&#x003b8;</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mfrac><mml:mn>1</mml:mn><mml:mrow><mml:msub><mml:mi>Z</mml:mi><mml:mi mathvariant="script">C</mml:mi></mml:msub></mml:mrow></mml:mfrac><mml:mi>Pr</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>&#x003b8;</mml:mi><mml:mo>/</mml:mo><mml:msub><mml:mo>&#x00393;</mml:mo><mml:mrow><mml:mi>r</mml:mi><mml:mo>,</mml:mo><mml:msub><mml:mi>c</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:mrow></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mi>Pr</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mo>&#x00393;</mml:mo><mml:mrow><mml:mi>r</mml:mi><mml:mo>,</mml:mo><mml:msub><mml:mi>c</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:mrow></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>,</mml:mo></mml:mrow></mml:math></disp-formula>
where <inline-formula><mml:math display="inline" id="M57" overflow="scroll"><mml:mrow><mml:msub><mml:mi>Z</mml:mi><mml:mi mathvariant="script">C</mml:mi></mml:msub><mml:mtext>s</mml:mtext></mml:mrow></mml:math></inline-formula> (and variants thereof) are normalization constants that are the same for each <inline-formula><mml:math display="inline" id="M18" overflow="scroll"><mml:mrow><mml:mi>c</mml:mi><mml:mo>&#x02208;</mml:mo><mml:mi mathvariant="script">C</mml:mi><mml:mo>.</mml:mo></mml:mrow></mml:math></inline-formula> Since <inline-formula><mml:math display="inline" id="M19" overflow="scroll"><mml:mrow><mml:msub><mml:mo>&#x00393;</mml:mo><mml:mrow><mml:mi>r</mml:mi><mml:mo>,</mml:mo><mml:msub><mml:mi>c</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:mrow></mml:msub></mml:mrow></mml:math></inline-formula> occurs if and only if <italic>C</italic><sub><italic>i</italic></sub> occurs, we have
<disp-formula id="FD2"><mml:math display="block" id="M20" overflow="scroll"><mml:mrow><mml:msub><mml:mi>&#x003b3;</mml:mi><mml:mrow><mml:mi>r</mml:mi><mml:mo>,</mml:mo><mml:msub><mml:mi>c</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mfrac><mml:mn>1</mml:mn><mml:mrow><mml:msub><mml:mi>Z</mml:mi><mml:mi mathvariant="script">C</mml:mi></mml:msub></mml:mrow></mml:mfrac><mml:mi>Pr</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>&#x003b8;</mml:mi><mml:mo>/</mml:mo><mml:msub><mml:mi>C</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mi>Pr</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mo>&#x00393;</mml:mo><mml:mrow><mml:mi>r</mml:mi><mml:mo>,</mml:mo><mml:msub><mml:mi>c</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:mrow></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>.</mml:mo></mml:mrow></mml:math></disp-formula></p><p id="P45">Applying Bayes&#x02019; rule again to Pr(<bold><italic>&#x003b8;</italic></bold>/<italic>C</italic><sub><italic>i</italic></sub>) and using the fact that both Pr(<bold><italic>&#x003b8;</italic></bold>) and Pr(<italic>C</italic><sub><italic>i</italic></sub>) are uniform, we obtain
<disp-formula id="FD3"><mml:math display="block" id="M21" overflow="scroll"><mml:mrow><mml:msub><mml:mi>&#x003b3;</mml:mi><mml:mrow><mml:mi>r</mml:mi><mml:mo>,</mml:mo><mml:msub><mml:mi>c</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mfrac><mml:mn>1</mml:mn><mml:mrow><mml:msub><mml:mi>Z</mml:mi><mml:mi mathvariant="script">C</mml:mi></mml:msub></mml:mrow></mml:mfrac><mml:mfrac><mml:mrow><mml:mi>Pr</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mi>&#x003b8;</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:mi>Pr</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mi>C</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>/</mml:mo><mml:mi>&#x003b8;</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mrow><mml:mi>Pr</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mi>C</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mfrac><mml:mi>Pr</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mo>&#x00393;</mml:mo><mml:mrow><mml:mi>r</mml:mi><mml:mo>,</mml:mo><mml:msub><mml:mi>c</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:mrow></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mfrac><mml:mn>1</mml:mn><mml:mrow><mml:msub><mml:msup><mml:mi>Z</mml:mi><mml:mo>&#x02032;</mml:mo></mml:msup><mml:mi mathvariant="script">C</mml:mi></mml:msub></mml:mrow></mml:mfrac><mml:mi>Pr</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mi>C</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>/</mml:mo><mml:mi>&#x003b8;</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mi>Pr</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mo>&#x00393;</mml:mo><mml:mrow><mml:mi>r</mml:mi><mml:mo>,</mml:mo><mml:msub><mml:mi>c</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:mrow></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:msub><mml:mi>&#x003b8;</mml:mi><mml:mrow><mml:msub><mml:mi>c</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:mrow></mml:msub></mml:mrow><mml:mrow><mml:msub><mml:msup><mml:mi>Z</mml:mi><mml:mo>&#x02032;</mml:mo></mml:msup><mml:mi mathvariant="script">C</mml:mi></mml:msub></mml:mrow></mml:mfrac><mml:mi>Pr</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mo>&#x00393;</mml:mo><mml:mrow><mml:mi>r</mml:mi><mml:mo>,</mml:mo><mml:msub><mml:mi>c</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:mrow></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>,</mml:mo></mml:mrow></mml:math></disp-formula>
where <inline-formula><mml:math display="inline" id="M22" overflow="scroll"><mml:mrow><mml:msub><mml:msup><mml:mi>Z</mml:mi><mml:mo>&#x02032;</mml:mo></mml:msup><mml:mi mathvariant="script">C</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:mrow><mml:mo>[</mml:mo><mml:mrow><mml:mi>Pr</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mi>C</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>/</mml:mo><mml:mi>Pr</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mtext>&#x003b8;</mml:mtext><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mo>]</mml:mo></mml:mrow><mml:msub><mml:mi>Z</mml:mi><mml:mi mathvariant="script">C</mml:mi></mml:msub><mml:mo>.</mml:mo></mml:mrow></mml:math></inline-formula> Note that <inline-formula><mml:math display="inline" id="M23" overflow="scroll"><mml:mrow><mml:mi>Pr</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mo>&#x00393;</mml:mo><mml:mrow><mml:mi>r</mml:mi><mml:mo>,</mml:mo><mml:msub><mml:mi>c</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:mrow></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula> is a prior on the probability that <italic>r</italic> truly originates from <italic>c</italic><sub><italic>i</italic></sub>, which is not dependent on the barcode but rather only on edit distance, mate alignment, and mapping quality as in standard short-read alignment. Henceforth, we refer to <inline-formula><mml:math display="inline" id="M24" overflow="scroll"><mml:mrow><mml:mi>Pr</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mo>&#x00393;</mml:mo><mml:mrow><mml:mi>r</mml:mi><mml:mo>,</mml:mo><mml:msub><mml:mi>c</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:mrow></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula> as <inline-formula><mml:math display="inline" id="M25" overflow="scroll"><mml:mrow><mml:msubsup><mml:mi>&#x003b3;</mml:mi><mml:mrow><mml:mi>r</mml:mi><mml:mo>,</mml:mo><mml:msub><mml:mi>c</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:mrow><mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mn>0</mml:mn><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:msubsup><mml:mo>,</mml:mo></mml:mrow></mml:math></inline-formula> so that <inline-formula><mml:math display="inline" id="M26" overflow="scroll"><mml:mrow><mml:msub><mml:mo>&#x00393;</mml:mo><mml:mrow><mml:mi>r</mml:mi><mml:mo>,</mml:mo><mml:msub><mml:mi>c</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:mrow></mml:msub><mml:mo>~</mml:mo><mml:mtext>Ber</mml:mtext><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msubsup><mml:mi>&#x003b3;</mml:mi><mml:mrow><mml:mi>r</mml:mi><mml:mo>,</mml:mo><mml:msub><mml:mi>c</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:mrow><mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mn>0</mml:mn><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:msubsup></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>.</mml:mo></mml:mrow></mml:math></inline-formula></p><p id="P46">Now we can form a prior <inline-formula><mml:math display="inline" id="M27" overflow="scroll"><mml:mrow><mml:msup><mml:mi>&#x003b8;</mml:mi><mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mn>0</mml:mn><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:msup><mml:mo>=</mml:mo><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msubsup><mml:mi>&#x003b8;</mml:mi><mml:mrow><mml:msub><mml:mi>c</mml:mi><mml:mn>1</mml:mn></mml:msub></mml:mrow><mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mn>0</mml:mn><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:msubsup><mml:mo>,</mml:mo><mml:mo>&#x02026;</mml:mo><mml:mo>,</mml:mo><mml:msubsup><mml:mi>&#x003b8;</mml:mi><mml:mrow><mml:msub><mml:mi>c</mml:mi><mml:mi>n</mml:mi></mml:msub></mml:mrow><mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mn>0</mml:mn><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:msubsup></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>,</mml:mo></mml:mrow></mml:math></inline-formula> which is intuitively the initial vector of cloud weights. If we are given a set of alignment probabilities and a &#x0201c;current&#x0201d; <bold><italic>&#x003b8;</italic></bold> estimate <inline-formula><mml:math display="inline" id="M28" overflow="scroll"><mml:mrow><mml:msup><mml:mi>&#x003b8;</mml:mi><mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mi>t</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:msup><mml:mo>=</mml:mo><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msubsup><mml:mi>&#x003b8;</mml:mi><mml:mrow><mml:msub><mml:mi>c</mml:mi><mml:mn>1</mml:mn></mml:msub></mml:mrow><mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mi>t</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:msubsup><mml:mo>,</mml:mo><mml:mo>&#x02026;</mml:mo><mml:mo>,</mml:mo><mml:msubsup><mml:mi>&#x003b8;</mml:mi><mml:mrow><mml:msub><mml:mi>c</mml:mi><mml:mi>n</mml:mi></mml:msub></mml:mrow><mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mi>t</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:msubsup></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula> (initially <italic>t</italic> = 0), we can iteratively compute a better estimate <bold><italic>&#x003b8;</italic></bold><sup>(<italic>t</italic> + 1)</sup> using the fact that <inline-formula><mml:math display="inline" id="M29" overflow="scroll"><mml:mrow><mml:msub><mml:mi>&#x003b8;</mml:mi><mml:mrow><mml:msub><mml:mi>c</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:mrow></mml:msub><mml:mo>&#x0221d;</mml:mo><mml:msub><mml:mi>K</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:mrow></mml:math></inline-formula> in expectation:
<disp-formula id="FD4"><mml:math display="block" id="M30" overflow="scroll"><mml:mrow><mml:msubsup><mml:mi>&#x003b8;</mml:mi><mml:mrow><mml:msub><mml:mi>C</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:mrow><mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>t</mml:mi><mml:mo>+</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:msubsup><mml:mo>=</mml:mo><mml:mfrac><mml:mn>1</mml:mn><mml:mrow><mml:mrow><mml:mo>|</mml:mo><mml:mi mathvariant="script">R</mml:mi><mml:mo>|</mml:mo></mml:mrow></mml:mrow></mml:mfrac><mml:mi mathvariant="double-struck">E</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mi>K</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mfrac><mml:mn>1</mml:mn><mml:mrow><mml:mrow><mml:mo>|</mml:mo><mml:mi mathvariant="script">R</mml:mi><mml:mo>|</mml:mo></mml:mrow></mml:mrow></mml:mfrac><mml:mi mathvariant="double-struck">E</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:munder><mml:mstyle displaystyle="true"><mml:mo>&#x02211;</mml:mo></mml:mstyle><mml:mrow><mml:mi>r</mml:mi><mml:mo>&#x02208;</mml:mo><mml:mi mathvariant="script">R</mml:mi></mml:mrow></mml:munder><mml:mn>1</mml:mn><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mo>&#x00393;</mml:mo><mml:mrow><mml:mi>r</mml:mi><mml:mo>,</mml:mo><mml:msub><mml:mi>c</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:mrow></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>/</mml:mo><mml:msup><mml:mi>&#x003b8;</mml:mi><mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mi>t</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:msup></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mspace linebreak="newline"/><mml:mo>=</mml:mo><mml:mfrac><mml:mn>1</mml:mn><mml:mrow><mml:mrow><mml:mo>|</mml:mo><mml:mi mathvariant="script">R</mml:mi><mml:mo>|</mml:mo></mml:mrow></mml:mrow></mml:mfrac><mml:munder><mml:mstyle displaystyle="true"><mml:mo>&#x02211;</mml:mo></mml:mstyle><mml:mrow><mml:mi>r</mml:mi><mml:mo>&#x02208;</mml:mo><mml:mi mathvariant="script">R</mml:mi></mml:mrow></mml:munder><mml:mi>Pr</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mo>&#x00393;</mml:mo><mml:mrow><mml:mi>r</mml:mi><mml:mo>,</mml:mo><mml:msub><mml:mi>c</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:mrow></mml:msub><mml:mo>|</mml:mo><mml:msup><mml:mi>&#x003b8;</mml:mi><mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mi>t</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:msup></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mspace linebreak="newline"/><mml:mo>=</mml:mo><mml:mfrac><mml:mn>1</mml:mn><mml:mrow><mml:mrow><mml:mo>|</mml:mo><mml:mi mathvariant="script">R</mml:mi><mml:mo>|</mml:mo></mml:mrow></mml:mrow></mml:mfrac><mml:munder><mml:mstyle displaystyle="true"><mml:mo>&#x02211;</mml:mo></mml:mstyle><mml:mrow><mml:mi>r</mml:mi><mml:mo>&#x02208;</mml:mo><mml:mi mathvariant="script">R</mml:mi></mml:mrow></mml:munder><mml:msubsup><mml:mi>&#x003b3;</mml:mi><mml:mrow><mml:mi>r</mml:mi><mml:mo>,</mml:mo><mml:msub><mml:mi>c</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:mrow><mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mi>t</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:msubsup><mml:mo>,</mml:mo></mml:mrow></mml:math></disp-formula>
where <inline-formula><mml:math display="inline" id="M31" overflow="scroll"><mml:mi mathvariant="script">R</mml:mi></mml:math></inline-formula> is the set of reads mapping to any cloud in <inline-formula><mml:math display="inline" id="M32" overflow="scroll"><mml:mrow><mml:mi mathvariant="script">C</mml:mi><mml:mo>,</mml:mo></mml:mrow></mml:math></inline-formula> and the <inline-formula><mml:math display="inline" id="M33" overflow="scroll"><mml:mrow><mml:mn>1</mml:mn><mml:mo>/</mml:mo><mml:mrow><mml:mo>|</mml:mo><mml:mi mathvariant="script">R</mml:mi><mml:mo>|</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula> factor ensures that <inline-formula><mml:math display="inline" id="M34" overflow="scroll"><mml:mrow><mml:munder><mml:mo>&#x02211;</mml:mo><mml:mrow><mml:mi>c</mml:mi><mml:mo>&#x02208;</mml:mo><mml:mi mathvariant="script">C</mml:mi></mml:mrow></mml:munder><mml:msub><mml:mi>&#x003b8;</mml:mi><mml:mi>c</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:math></inline-formula> This latent variable model formulation naturally to an expectation-maximization algorithm&#x02014;one of the widely used ways of maximizing likelihood in such models&#x02014;for determining the cloud weights and, thereby, the final alignment probabilities <inline-formula><mml:math display="inline" id="M35" overflow="scroll"><mml:mrow><mml:msubsup><mml:mi>&#x003b3;</mml:mi><mml:mrow><mml:mi>r</mml:mi><mml:mo>,</mml:mo><mml:msub><mml:mi>c</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:mrow><mml:mo>&#x02605;</mml:mo></mml:msubsup><mml:mo>.</mml:mo></mml:mrow></mml:math></inline-formula> An implementation of this algorithm is given in Algorithm 1 (in practice we use <italic>T</italic> = 5 EM iterations).</p></sec><sec id="S15"><title>Algorithm 1</title><p id="P47">Barcoded read alignment via expectation &#x02013; maximization</p><p id="P48"><bold>Require</bold>:<inline-formula><mml:math display="inline" id="M36" overflow="scroll"><mml:mi mathvariant="script">R</mml:mi></mml:math></inline-formula>, <inline-formula><mml:math display="inline" id="M56" overflow="scroll"><mml:mi mathvariant="script">C</mml:mi></mml:math></inline-formula></p><p id="P49"><bold>Ensure :</bold>
<inline-formula><mml:math display="inline" id="M37" overflow="scroll"><mml:mrow><mml:msubsup><mml:mi>&#x003b3;</mml:mi><mml:mrow><mml:mi>r</mml:mi><mml:mo>,</mml:mo><mml:mi>c</mml:mi></mml:mrow><mml:mo>&#x02605;</mml:mo></mml:msubsup></mml:mrow></mml:math></inline-formula> for each <inline-formula><mml:math display="inline" id="M38" overflow="scroll"><mml:mrow><mml:mi>r</mml:mi><mml:mo>&#x02208;</mml:mo><mml:mi mathvariant="script">R</mml:mi><mml:mo>,</mml:mo></mml:mrow></mml:math></inline-formula>
<inline-formula><mml:math display="inline" id="M39" overflow="scroll"><mml:mrow><mml:mi>c</mml:mi><mml:mo>&#x02208;</mml:mo><mml:mi mathvariant="script">C</mml:mi></mml:mrow></mml:math></inline-formula></p><p id="P83"><inline-formula><mml:math display="inline" id="M40" overflow="scroll"><mml:mrow><mml:msubsup><mml:mi>&#x003b3;</mml:mi><mml:mrow><mml:mi>r</mml:mi><mml:mo>,</mml:mo><mml:mi>c</mml:mi></mml:mrow><mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mn>0</mml:mn><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:msubsup><mml:mo>&#x02190;</mml:mo><mml:mi>Pr</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>r</mml:mi><mml:mo>&#x02208;</mml:mo><mml:mi>c</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>,</mml:mo><mml:mtext>&#x000a0;</mml:mtext><mml:mo>&#x02200;</mml:mo><mml:mspace width="4pt"/><mml:mi>r</mml:mi><mml:mo>&#x02208;</mml:mo><mml:mi mathvariant="script">R</mml:mi><mml:mo>,</mml:mo><mml:mtext>&#x000a0;</mml:mtext><mml:mi>c</mml:mi><mml:mo>&#x02208;</mml:mo><mml:mi mathvariant="script">C</mml:mi></mml:mrow></mml:math></inline-formula></p><p id="P85"><inline-formula><mml:math display="inline" id="M41" overflow="scroll"><mml:mrow><mml:msubsup><mml:mi>&#x003b8;</mml:mi><mml:mi>c</mml:mi><mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mn>0</mml:mn><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:msubsup><mml:mo>&#x02190;</mml:mo><mml:mfrac><mml:mn>1</mml:mn><mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mi mathvariant="script">C</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mfrac><mml:mo>,</mml:mo><mml:mo>&#x02200;</mml:mo><mml:mspace width="4pt"/><mml:mi>c</mml:mi><mml:mo>&#x02208;</mml:mo><mml:mi mathvariant="script">C</mml:mi></mml:mrow></mml:math></inline-formula></p><p id="P84"><bold>for</bold>
<italic>t</italic> &#x02208; {0, 1, &#x02026;, <italic>T</italic> &#x02212; 1} <bold>do</bold></p><p id="P50"><bold>E step</bold>: <inline-formula><mml:math display="inline" id="M42" overflow="scroll"><mml:mrow><mml:msubsup><mml:mi>&#x003b3;</mml:mi><mml:mrow><mml:mi>r</mml:mi><mml:mo>,</mml:mo><mml:mi>c</mml:mi></mml:mrow><mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>t</mml:mi><mml:mo>+</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:msubsup><mml:mo>&#x02190;</mml:mo><mml:mi>Pr</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>r</mml:mi><mml:mo>&#x02208;</mml:mo><mml:msub><mml:mi>c</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>|</mml:mo><mml:msubsup><mml:mi>&#x003b8;</mml:mi><mml:mi>c</mml:mi><mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mi>t</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:msubsup></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>&#x02200;</mml:mo><mml:mspace width="4pt"/><mml:mi>r</mml:mi><mml:mo>&#x02208;</mml:mo><mml:mi mathvariant="script">R</mml:mi><mml:mo>,</mml:mo><mml:mi>c</mml:mi><mml:mo>&#x02208;</mml:mo><mml:mi mathvariant="script">C</mml:mi></mml:mrow></mml:math></inline-formula></p><p id="P91"><bold>M step</bold> : <inline-formula><mml:math display="inline" id="M43" overflow="scroll"><mml:mrow><mml:msubsup><mml:mi>&#x003b8;</mml:mi><mml:mi>c</mml:mi><mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>t</mml:mi><mml:mo>+</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:msubsup><mml:mo>&#x02190;</mml:mo><mml:mfrac><mml:mn>1</mml:mn><mml:mrow><mml:mrow><mml:mo>|</mml:mo><mml:mi mathvariant="script">R</mml:mi><mml:mo>|</mml:mo></mml:mrow></mml:mrow></mml:mfrac><mml:munder><mml:mstyle displaystyle="true"><mml:mo>&#x02211;</mml:mo></mml:mstyle><mml:mrow><mml:mi>r</mml:mi><mml:mo>&#x02208;</mml:mo><mml:mi mathvariant="script">R</mml:mi></mml:mrow></mml:munder><mml:msubsup><mml:mi>&#x003b3;</mml:mi><mml:mrow><mml:mi>r</mml:mi><mml:mo>,</mml:mo><mml:mi>c</mml:mi></mml:mrow><mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mi>t</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:msubsup><mml:mo>&#x02200;</mml:mo><mml:mspace width="4pt"/><mml:mi>r</mml:mi><mml:mo>&#x02208;</mml:mo><mml:mi mathvariant="script">R</mml:mi></mml:mrow></mml:math></inline-formula></p><p id="P51"><bold>end for</bold></p><p id="P52"><inline-formula><mml:math display="inline" id="M44" overflow="scroll"><mml:mrow><mml:msubsup><mml:mi>&#x003b3;</mml:mi><mml:mrow><mml:mi>r</mml:mi><mml:mo>,</mml:mo><mml:mi>c</mml:mi></mml:mrow><mml:mo>&#x02605;</mml:mo></mml:msubsup><mml:mo>&#x02190;</mml:mo><mml:msubsup><mml:mi>&#x003b3;</mml:mi><mml:mrow><mml:mi>r</mml:mi><mml:mo>,</mml:mo><mml:mi>c</mml:mi></mml:mrow><mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mi>T</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:msubsup><mml:mo>&#x02200;</mml:mo><mml:mspace width="4pt"/><mml:mi>r</mml:mi><mml:mo>&#x02208;</mml:mo><mml:mtext>R</mml:mtext><mml:mo>,</mml:mo><mml:mi>c</mml:mi><mml:mo>&#x02208;</mml:mo><mml:mtext>C</mml:mtext></mml:mrow></mml:math></inline-formula></p><p id="P86">Each of the described variables and their interactions with one another is summarized in Supplementary <xref rid="SD1" ref-type="supplementary-material">Figure S1</xref>. Once we determine the final alignment probabilities through this method (as in <xref rid="F1" ref-type="fig">Figure 1D</xref>), we use them to compute mapping qualities (&#x0201c;MAPQs&#x0201d;), which are a standard per-alignment metric reported by all aligners and are frequently used by downstream analysis pipelines. Specifically, we take the MAPQ to be the minimum of the alignment probability, the barcode-oblivious alignment score and the MAPQ reported by BWA-MEM&#x02019;s API (which is used in EMA&#x02019;s current implementation to find candidate alignments). Importantly, we also report the actual alignment probabilities determined by EMA via a special standard-compliant SAM tag, so that they are available to downstream applications.</p></sec><sec id="S16"><title>Read Density Optimization to Handle Multi-Mappings in a Single Cloud</title><p id="P53">While the 50kb-heuristic described above is typically effective at determining the clouds, it does not take into account the fact that a single read may align multiple times to the same cloud (which can occur if a cloud spans two or more homologous regions). In such cases, rather than simply picking the alignment with lowest edit distance within the cloud, as is the current practice, we propose a novel alternative approach that takes into account not only edit distance but also read <italic>density</italic>. We take advantage of the insight that there is typically only a single read pair per 1kb bin in each cloud; the exact distribution of read counts per 1kb bin is shown in Supplementary <xref rid="SD1" ref-type="supplementary-material">Figure S2</xref>. Now consider the case where one of our source fragments spans two highly similar (homologous) regions, and thereby produces a cloud with multi-mappings, as depicted in <xref rid="F1" ref-type="fig">Figure 1C</xref>. If we pick alignments solely by edit distance, we may observe an improbable increase in read density (as shown in the figure). Consequently, we select alignments for the reads so as to minimize a combination of edit distance <italic>and</italic> abnormal density deviations.</p><p id="P54">Specifically, consider any cloud with multi-mappings consisting of a set of reads <italic>R</italic> ={<italic>r</italic><sub>1</sub>,&#x02026;,<italic>r</italic><sub><italic>n</italic></sub>}, and denote by <italic>A</italic><sub><italic>r</italic></sub> the set of alignments for read r &#x02208;<italic>R</italic> in the cloud. Additionally, let a<sub>r</sub>&#x02208;A<sub><italic>r</italic></sub> denote the currently &#x0201c;selected&#x0201d;falignment for <italic>r</italic>. We will initially partition the cloud, spanning the region from its leftmost to its rightmost alignment, into the set of bins <italic>B</italic> ={<italic>b</italic><sub>1</sub>,&#x02026;, <italic>b</italic><sub><italic>n</italic></sub>} of equal width <italic>w</italic>, where each bin <italic>b</italic><sub><italic>i</italic></sub> covers the alignments whose starting positions are located in the interval <inline-formula><mml:math display="inline" id="M45" overflow="scroll"><mml:mrow><mml:mrow><mml:mo>[</mml:mo><mml:mrow><mml:mi>i</mml:mi><mml:mo>&#x022c5;</mml:mo><mml:mi>w</mml:mi><mml:mo>,</mml:mo><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>i</mml:mi><mml:mo>+</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>&#x022c5;</mml:mo><mml:mi>w</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>,</mml:mo></mml:mrow></mml:math></inline-formula> as shown in <xref rid="F1" ref-type="fig">Figure 1C</xref>. In practice, we set <italic>w</italic> to 1kb. Denote by <italic>C</italic><sub><italic>bi</italic></sub> the random variable representing the number of reads in bin <italic>b</italic><sub><italic>i</italic></sub>, where <italic>C</italic><sub><italic>bi</italic></sub> is drawn from the bin density distribution CloudBin(i). Lastly, let <inline-formula><mml:math display="inline" id="M46" overflow="scroll"><mml:mrow><mml:msub><mml:mi>&#x003b3;</mml:mi><mml:mrow><mml:msub><mml:mi>a</mml:mi><mml:mi>r</mml:mi></mml:msub></mml:mrow></mml:msub></mml:mrow></mml:math></inline-formula> denote the prior probability that alignment <italic>a</italic><sub><italic>r</italic></sub> is the true alignment of read <italic>r</italic> based on edit distance and mate alignments alone. Our goal is to maximize the objective:
<disp-formula id="FD5"><mml:math display="block" id="M47" overflow="scroll"><mml:mrow><mml:mrow><mml:mo>[</mml:mo><mml:mrow><mml:munder><mml:mstyle displaystyle="true"><mml:mo>&#x0220f;</mml:mo></mml:mstyle><mml:mrow><mml:mi>r</mml:mi><mml:mo>&#x02208;</mml:mo><mml:mi>R</mml:mi></mml:mrow></mml:munder><mml:msub><mml:mi>&#x003b3;</mml:mi><mml:mrow><mml:msub><mml:mi>a</mml:mi><mml:mi>r</mml:mi></mml:msub></mml:mrow></mml:msub></mml:mrow><mml:mo>]</mml:mo></mml:mrow><mml:mo>&#x022c5;</mml:mo><mml:mrow><mml:mo>[</mml:mo><mml:mrow><mml:munder><mml:mstyle displaystyle="true"><mml:mo>&#x0220f;</mml:mo></mml:mstyle><mml:mrow><mml:msub><mml:mi>b</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>&#x02208;</mml:mo><mml:mi>B</mml:mi></mml:mrow></mml:munder><mml:mi>Pr</mml:mi><mml:msup><mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mi>C</mml:mi><mml:mrow><mml:msub><mml:mi>b</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:munder><mml:mstyle displaystyle="true"><mml:mo>&#x02211;</mml:mo></mml:mstyle><mml:mrow><mml:mi>r</mml:mi><mml:mo>&#x02208;</mml:mo><mml:mi>R</mml:mi></mml:mrow></mml:munder><mml:mn>1</mml:mn><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mi>a</mml:mi><mml:mi>r</mml:mi></mml:msub><mml:mo>&#x02208;</mml:mo><mml:msub><mml:mi>b</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mi>&#x003b1;</mml:mi></mml:msup></mml:mrow><mml:mo>]</mml:mo></mml:mrow><mml:mo>,</mml:mo></mml:mrow></mml:math></disp-formula>
where &#x003b1; is a parameter that dictates the relative importance of the density probabilities compared to the alignment probabilities (we use a = 0:05 in practice). We determine the distribution CloudBin(<italic>i</italic>) of each <italic>C</italic><sub><italic>bi</italic></sub> beforehand by examining uniquely-mapping clouds that we are confident represent the true source fragment. Taking the logarithm, this objective becomes:
<disp-formula id="FD6"><mml:math display="block" id="M48" overflow="scroll"><mml:mrow><mml:mi>J</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mi>a</mml:mi><mml:mrow><mml:msub><mml:mi>r</mml:mi><mml:mn>1</mml:mn></mml:msub></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:mo>&#x02026;</mml:mo><mml:mo>,</mml:mo><mml:msub><mml:mi>a</mml:mi><mml:mrow><mml:msub><mml:mi>r</mml:mi><mml:mi>n</mml:mi></mml:msub></mml:mrow></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:munder><mml:mstyle displaystyle="true"><mml:mo>&#x02211;</mml:mo></mml:mstyle><mml:mrow><mml:mi>r</mml:mi><mml:mo>&#x02208;</mml:mo><mml:mi>R</mml:mi></mml:mrow></mml:munder><mml:mi>log</mml:mi><mml:msub><mml:mi>&#x003b3;</mml:mi><mml:mrow><mml:msub><mml:mi>a</mml:mi><mml:mi>r</mml:mi></mml:msub></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:mi>&#x003b1;</mml:mi><mml:munder><mml:mstyle displaystyle="true"><mml:mo>&#x02211;</mml:mo></mml:mstyle><mml:mrow><mml:msub><mml:mi>b</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>&#x02208;</mml:mo><mml:mi>B</mml:mi></mml:mrow></mml:munder><mml:mi>log</mml:mi><mml:mi>Pr</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mi>C</mml:mi><mml:mrow><mml:msub><mml:mi>b</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:munder><mml:mstyle displaystyle="true"><mml:mo>&#x02211;</mml:mo></mml:mstyle><mml:mrow><mml:mi>r</mml:mi><mml:mo>&#x02208;</mml:mo><mml:mi>R</mml:mi></mml:mrow></mml:munder><mml:mn>1</mml:mn><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mi>a</mml:mi><mml:mi>r</mml:mi></mml:msub><mml:mo>&#x02208;</mml:mo><mml:msub><mml:mi>b</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>.</mml:mo></mml:mrow></mml:math></disp-formula></p><p id="P55">We optimize <italic>J</italic> through simulated annealing by repeatedly proposing random changes to <italic>a</italic><sub><italic>r</italic></sub> and accepting them probabilistically based on the change in our objective (the corresponding algorithm is described in Algorithm 2, in which <italic>K</italic> is the number of simulated annealing iterations, and &#x003c4;(&#x022c5;) defines the annealing schedule, which can be taken to be an exponentially decreasing function).</p></sec><sec id="S17"><title>Algorithm 2</title><p id="P56">Read density optimization via simulated annealing</p><p id="P57"><bold>Require</bold> : <inline-formula><mml:math display="inline" id="M49" overflow="scroll"><mml:mrow><mml:mtable columnalign="left"><mml:mtr columnalign="left"><mml:mtd columnalign="left"><mml:mrow><mml:mi>R</mml:mi><mml:mo>;</mml:mo><mml:msub><mml:mi>A</mml:mi><mml:mi>r</mml:mi></mml:msub></mml:mrow></mml:mtd><mml:mtd columnalign="left"><mml:mrow><mml:mo>&#x02200;</mml:mo><mml:mspace width="4pt"/><mml:mi>r</mml:mi><mml:mo>&#x02208;</mml:mo><mml:mi>R</mml:mi></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:mrow></mml:math></inline-formula></p><p id="P87"><bold>Ensure</bold> : <italic><inline-formula><mml:math display="inline" id="M50" overflow="scroll"><mml:mrow><mml:mtable columnalign="left"><mml:mtr columnalign="left"><mml:mtd columnalign="left"><mml:mrow><mml:msubsup><mml:mi>a</mml:mi><mml:mi>r</mml:mi><mml:mo>&#x02605;</mml:mo></mml:msubsup></mml:mrow></mml:mtd><mml:mtd columnalign="left"><mml:mrow><mml:mo>&#x02200;</mml:mo><mml:mspace width="4pt"/><mml:mi>r</mml:mi><mml:mo>&#x02208;</mml:mo><mml:mi>R</mml:mi></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:mrow></mml:math></inline-formula></italic></p><p id="P58"><italic>a</italic><sub><italic>r</italic></sub> &#x02190; random(<italic>A</italic><sub><italic>r</italic></sub>) &#x02200;<italic>r</italic> &#x02208; <italic>R</italic></p><p id="P59"><inline-formula><mml:math display="inline" id="M51" overflow="scroll"><mml:mrow><mml:mi>z</mml:mi><mml:mo>&#x02190;</mml:mo><mml:mi>J</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mi>a</mml:mi><mml:mrow><mml:msub><mml:mi>r</mml:mi><mml:mn>1</mml:mn></mml:msub></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:mo>&#x02026;</mml:mo><mml:mo>,</mml:mo><mml:msub><mml:mi>a</mml:mi><mml:mrow><mml:msub><mml:mi>r</mml:mi><mml:mi>n</mml:mi></mml:msub></mml:mrow></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula></p><p id="P88"><bold>for</bold>
<italic>k</italic> &#x02208; {1,&#x02026;,<italic>K</italic>} <bold>do</bold></p><p id="P60"><italic>r</italic>&#x02032; &#x02190; random({<italic>r</italic> &#x02208; <italic>R</italic> : |<italic>A</italic><sub><italic>r</italic></sub>|&#x0003e;1})</p><p id="P61"><inline-formula><mml:math display="inline" id="M52" overflow="scroll"><mml:mrow><mml:msub><mml:msup><mml:mi>a</mml:mi><mml:mo>&#x02032;</mml:mo></mml:msup><mml:mi>r</mml:mi></mml:msub><mml:mo>&#x02190;</mml:mo><mml:mtext>random</mml:mtext><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mi>A</mml:mi><mml:mi>r</mml:mi></mml:msub><mml:mo>\</mml:mo><mml:mrow><mml:mo>{</mml:mo><mml:mrow><mml:msub><mml:mi>a</mml:mi><mml:mi>r</mml:mi></mml:msub></mml:mrow><mml:mo>}</mml:mo></mml:mrow></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula></p><p id="P90"><inline-formula><mml:math display="inline" id="M53" overflow="scroll"><mml:mrow><mml:msup><mml:mi>z</mml:mi><mml:mo>&#x02032;</mml:mo></mml:msup><mml:mo>&#x02190;</mml:mo><mml:mi>J</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mi>a</mml:mi><mml:mrow><mml:msub><mml:mi>r</mml:mi><mml:mn>1</mml:mn></mml:msub></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:mo>&#x02026;</mml:mo><mml:mo>,</mml:mo><mml:msub><mml:mi>a</mml:mi><mml:msup><mml:mi>r</mml:mi><mml:mo>&#x02032;</mml:mo></mml:msup></mml:msub><mml:mo>,</mml:mo><mml:mo>&#x02026;</mml:mo><mml:mo>,</mml:mo><mml:msub><mml:mi>a</mml:mi><mml:mrow><mml:msub><mml:mi>r</mml:mi><mml:mi>n</mml:mi></mml:msub></mml:mrow></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula></p><p id="P89"><bold>if</bold>
<italic>z</italic>&#x02032;&#x0003e;z <bold>or</bold>
<inline-formula><mml:math display="inline" id="M54" overflow="scroll"><mml:mrow><mml:mi>exp</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mo>&#x02212;</mml:mo><mml:mfrac><mml:mrow><mml:mi>z</mml:mi><mml:mo>&#x02212;</mml:mo><mml:msup><mml:mi>z</mml:mi><mml:mo>&#x02032;</mml:mo></mml:msup></mml:mrow><mml:mrow><mml:mi>&#x003c4;</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mi>k</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mfrac></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>&#x0003e;</mml:mo><mml:mtext>random</mml:mtext><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mrow><mml:mo>[</mml:mo><mml:mrow><mml:mn>0</mml:mn><mml:mo>,</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula>
<bold>then</bold></p><p id="P62"><italic>a</italic><sub><italic>r</italic></sub> &#x02190; <italic>a</italic>&#x02032;<sub><italic>r</italic></sub></p><p id="P63"><italic>z</italic> &#x02190; <italic>z</italic>&#x02032;</p><p id="P64"><bold>end if end for</bold></p><p id="P65"><inline-formula><mml:math display="inline" id="M55" overflow="scroll"><mml:mrow><mml:mtable columnalign="left"><mml:mtr columnalign="left"><mml:mtd columnalign="left"><mml:mrow><mml:msubsup><mml:mi>a</mml:mi><mml:mi>r</mml:mi><mml:mo>&#x02605;</mml:mo></mml:msubsup><mml:mo>&#x02190;</mml:mo><mml:msub><mml:mi>a</mml:mi><mml:mi>r</mml:mi></mml:msub></mml:mrow></mml:mtd><mml:mtd columnalign="left"><mml:mrow><mml:mo>&#x02200;</mml:mo><mml:mspace width="4pt"/><mml:mi>r</mml:mi><mml:mo>&#x02208;</mml:mo><mml:mtext>R</mml:mtext></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:mrow></mml:math></inline-formula></p><p id="P66">We apply the preceding latent variable optimization algorithm to deduce optimal alignments <italic>between</italic> clouds and, if necessary, use this statistical binning algorithm to find the best alignments <italic>within</italic> a given cloud.</p></sec><sec id="S18"><title>DATA AND SOFTWARE AVAILABILITY</title><p id="P67">EMA&#x02019;s full source, links to all datasets used and detailed guidelines for reproducing our results are available online at <ext-link ext-link-type="uri" xlink:href="http://ema.csail.mit.edu/">http://ema.csail.mit.edu</ext-link> and <ext-link ext-link-type="uri" xlink:href="https://github.com/arshajii/ema">https://github.com/arshajii/ema</ext-link>.</p></sec></sec><sec sec-type="supplementary-material" id="SM1"><title>Supplementary Material</title><supplementary-material content-type="local-data" id="SD1"><label>1</label><media xlink:href="NIHMS986152-supplement-1.pdf" orientation="portrait" xlink:type="simple" id="d36e3709" position="anchor"/></supplementary-material></sec></body><back><ack id="S19"><title>ACKNOWLEDGMENTS</title><p id="P68">We thank Chad Nusbaum, Eric Banks, as well as the rest of the GATK SV Group from the Broad Institute for providing us with data samples and many valuable suggestions. Also, we thank Jian Peng for helpful discussions, as well as Lillian Zhang for her help in evaluating EMA&#x02019;s performance. Finally, we thank the Vancouver Prostate Centre for providing infrastructure to evaluate EMA. A.S., I.N., and B.B. are partially funded by the NIH grant GM108348. This content is solely the responsibility of the authors and does not reflect the official views of the NIH.Editor&#x02019;s note: An early version of this paper was submitted to and peer reviewed at the 2018 Annual International Conference on Research in Computational Molecular Biology (RECOMB). The manuscript was revised and then independently further reviewed at Cell Systems.</p></ack><fn-group><fn fn-type="COI-statement" id="FN3"><p id="P69">DECLARATION OF INTERESTS</p><p id="P70">The authors declare no competing interests.</p></fn></fn-group><ref-list><title>REFERENCES</title><ref id="R1"><mixed-citation publication-type="web"><collab>10x Genomics</collab> (<year>2017</year>). <source>What is long ranger?</source>, <comment><ext-link ext-link-type="uri" xlink:href="https://support.10xgenomics.com/genome-exome/software/pipelines/latest/what-is-long-ranger/">https://support.10xgenomics.com/genome-exome/software/pipelines/latest/what-is-long-ranger/</ext-link>.</comment></mixed-citation></ref><ref id="R2"><mixed-citation publication-type="web"><collab>10x Genomics</collab> (<year>2018</year>). <source>Sequencing</source>. <comment><ext-link ext-link-type="uri" xlink:href="https://www.10xgenomics.com/solutions/vdj/">https://www.10xgenomics.com/solutions/vdj/</ext-link></comment>, <comment>2018. V(d)j.</comment></mixed-citation></ref><ref id="R3"><mixed-citation publication-type="journal"><name><surname>Amini</surname><given-names>S</given-names></name>, <name><surname>Pushkarev</surname><given-names>D</given-names></name>, <name><surname>Christiansen</surname><given-names>L</given-names></name>, <name><surname>Kostem</surname><given-names>E</given-names></name>, <name><surname>Royce</surname><given-names>T</given-names></name>, <name><surname>Turk</surname><given-names>C</given-names></name>, <name><surname>Pignatelli</surname><given-names>N</given-names></name>, <name><surname>Adey</surname><given-names>A</given-names></name>, <name><surname>Kitzman</surname><given-names>JO</given-names></name>, <name><surname>Vijayan</surname><given-names>K</given-names></name>, <etal/> (<year>2014</year>). <article-title>Haplotype-resolved whole-genome sequencing by contiguity-preserving transposition and combinatorial indexing</article-title>. <source>Nat.Genet</source>
<volume>46</volume>, <fpage>1343</fpage>&#x02013;<lpage>1349</lpage>.<pub-id pub-id-type="pmid">25326703</pub-id></mixed-citation></ref><ref id="R4"><mixed-citation publication-type="journal"><name><surname>Bishara</surname><given-names>A</given-names></name>, <name><surname>Liu</surname><given-names>Y</given-names></name>, <name><surname>Weng</surname><given-names>Z</given-names></name>, <name><surname>Kashef-Haghighi</surname><given-names>D</given-names></name>, <name><surname>Newburger</surname><given-names>DE</given-names></name>, <name><surname>West</surname><given-names>R</given-names></name>, <name><surname>Sidow</surname><given-names>A</given-names></name>, and <name><surname>Batzoglou</surname><given-names>S</given-names></name> (<year>2015</year>). <article-title>Read clouds uncover variation in complex regions of the human genome</article-title>. <source>Genome Res</source>
<volume>25</volume>, <fpage>1570</fpage>&#x02013;<lpage>1580</lpage>.<pub-id pub-id-type="pmid">26286554</pub-id></mixed-citation></ref><ref id="R5"><mixed-citation publication-type="journal"><name><surname>Cleary</surname><given-names>B</given-names></name>, <name><surname>Cong</surname><given-names>L</given-names></name>, <name><surname>Cheung</surname><given-names>A</given-names></name>, <name><surname>Lander</surname><given-names>ES</given-names></name>, and <name><surname>Regev</surname><given-names>A</given-names></name> (<year>2017</year>). <article-title>Efficient generation of transcriptomic profiles by random composite measurements</article-title>. <source>Cell</source>
<volume>171</volume>, <fpage>1424</fpage>&#x02013;<lpage>1436</lpage>.<pub-id pub-id-type="pmid">29153835</pub-id></mixed-citation></ref><ref id="R6"><mixed-citation publication-type="journal"><name><surname>Cleary</surname><given-names>JG</given-names></name>, <name><surname>Braithwaite</surname><given-names>R</given-names></name>, <name><surname>Gaastra</surname><given-names>K</given-names></name>, <name><surname>Hilbush</surname><given-names>BS</given-names></name>, <name><surname>Inglis</surname><given-names>S</given-names></name>, <name><surname>Irvine</surname><given-names>SA</given-names></name>, <name><surname>Jackson</surname><given-names>A</given-names></name>, <name><surname>Littin</surname><given-names>R</given-names></name>, <name><surname>Nohzadeh-Malakshah</surname><given-names>S</given-names></name>, <name><surname>Rathod</surname><given-names>M</given-names></name>, <etal/> (<year>2014</year>). <article-title>Joint variant and de novo mutation identification on pedigrees from high-throughput sequencing data</article-title>. <source>J. Comput. Biol</source>
<volume>21</volume>, <fpage>405</fpage>&#x02013;<lpage>419</lpage>.<pub-id pub-id-type="pmid">24874280</pub-id></mixed-citation></ref><ref id="R7"><mixed-citation publication-type="journal"><name><surname>DePristo</surname><given-names>MA</given-names></name>, <name><surname>Banks</surname><given-names>E</given-names></name>, <name><surname>Poplin</surname><given-names>R</given-names></name>, <name><surname>Garimella</surname><given-names>KV</given-names></name>, <name><surname>Maguire</surname><given-names>JR</given-names></name>, <name><surname>Hartl</surname><given-names>C</given-names></name>, <name><surname>Philippakis</surname><given-names>AA</given-names></name>, <name><surname>del Angel</surname><given-names>G</given-names></name>, <name><surname>Rivas</surname><given-names>MA</given-names></name>, <name><surname>Hanna</surname><given-names>M</given-names></name>, <name><surname>McKenna</surname><given-names>A</given-names></name>, <etal/> (<year>2011</year>). <article-title>A framework for variation discovery and genotyping using next-generation DNA sequencing data</article-title>. <source>Nat. Genet</source>
<volume>43</volume>, <fpage>491</fpage>&#x02013;<lpage>498</lpage>.<pub-id pub-id-type="pmid">21478889</pub-id></mixed-citation></ref><ref id="R8"><mixed-citation publication-type="journal"><name><surname>Edge</surname><given-names>P</given-names></name>, <name><surname>Bafna</surname><given-names>V</given-names></name>, and <name><surname>Bansal</surname><given-names>V</given-names></name> (<year>2016</year>). <article-title>Hapcut2: robust and accurate haplotype assembly for diverse sequencing technologies</article-title>. <source>Genome Res</source>
<volume>27</volume>, <fpage>801</fpage>&#x02013;<lpage>812</lpage>.<pub-id pub-id-type="pmid">27940952</pub-id></mixed-citation></ref><ref id="R9"><mixed-citation publication-type="journal"><name><surname>Eid</surname><given-names>J</given-names></name>, <name><surname>Fehr</surname><given-names>A</given-names></name>, <name><surname>Gray</surname><given-names>J</given-names></name>, <name><surname>Luong</surname><given-names>K</given-names></name>, <name><surname>Lyle</surname><given-names>John</given-names></name>, <name><surname>Otto</surname><given-names>G</given-names></name>, <name><surname>Peluso</surname><given-names>P</given-names></name>, <name><surname>Rank</surname><given-names>D</given-names></name>, <name><surname>Baybayan</surname><given-names>P</given-names></name>, <name><surname>Bettman</surname><given-names>B</given-names></name>, <etal/> (<year>2009</year>). <article-title>Real-time DNA sequencing from single polymerase molecules</article-title>. <source>Science</source>
<volume>323</volume>, <fpage>133</fpage>&#x02013;<lpage>138</lpage>.<pub-id pub-id-type="pmid">19023044</pub-id></mixed-citation></ref><ref id="R10"><mixed-citation publication-type="journal"><name><surname>Falchi</surname><given-names>M</given-names></name>, <name><surname>El-Sayed Moustafa</surname><given-names>JS</given-names></name>, <name><surname>Takousis</surname><given-names>P</given-names></name>, <name><surname>Pesce</surname><given-names>F</given-names></name>, <name><surname>Bonnefond</surname><given-names>A</given-names></name>, <name><surname>Andersson-Assarsson</surname><given-names>JC</given-names></name>, <name><surname>Sudmant</surname><given-names>PH</given-names></name>, <name><surname>Dorajoo</surname><given-names>R</given-names></name>, <name><surname>Al-Shafai</surname><given-names>MN</given-names></name>, <name><surname>Bottolo</surname><given-names>L</given-names></name>, <etal/> (<year>2014</year>). <article-title>Low copy number of the salivary amylase gene pre-disposes to obesity</article-title>. <source>Nat. Genet</source>
<volume>46</volume>, <fpage>492</fpage>&#x02013;<lpage>497</lpage>.<pub-id pub-id-type="pmid">24686848</pub-id></mixed-citation></ref><ref id="R11"><mixed-citation publication-type="journal"><name><surname>Goodwin</surname><given-names>S</given-names></name>, <name><surname>McPherson</surname><given-names>JD</given-names></name>, and <name><surname>McCombie</surname><given-names>WR</given-names></name> (<year>2016</year>). <article-title>Coming of age: ten years of next-generation sequencing technologies</article-title>. <source>Nat. Rev. Genet</source>
<volume>17</volume>, <fpage>333</fpage>&#x02013;<lpage>351</lpage>.<pub-id pub-id-type="pmid">27184599</pub-id></mixed-citation></ref><ref id="R12"><mixed-citation publication-type="journal"><name><surname>Hashimshony</surname><given-names>T</given-names></name>, <name><surname>Senderovich</surname><given-names>N</given-names></name>, <name><surname>Avital</surname><given-names>G</given-names></name>, <name><surname>Klochendler</surname><given-names>A</given-names></name>, <name><surname>de Leeuw</surname><given-names>Y</given-names></name>, <name><surname>Anavy</surname><given-names>L</given-names></name>, <name><surname>Gennert</surname><given-names>D</given-names></name>, <name><surname>Li</surname><given-names>S</given-names></name>, <name><surname>Livak</surname><given-names>KJ</given-names></name>, <name><surname>Rozenblatt-Rosen</surname><given-names>O</given-names></name>, <etal/> (<year>2016</year>). <article-title>Cel-seq2: sensitive highly-multiplexed single-cell rna-seq</article-title>. <source>Genome Biol</source>
<volume>17</volume>, <fpage>77</fpage>.<pub-id pub-id-type="pmid">27121950</pub-id></mixed-citation></ref><ref id="R13"><mixed-citation publication-type="journal"><name><surname>Ingelman-Sundberg</surname><given-names>M</given-names></name> (<year>2004</year>). <article-title>Genetic polymorphisms of cytochrome P450 2D6 (CYP2D6): Clinical consequences, evolutionary aspects and functional diversity</article-title>. <source>Pharmacogenomics J</source>
<volume>5</volume>, <fpage>6</fpage>&#x02013;<lpage>13</lpage>.</mixed-citation></ref><ref id="R14"><mixed-citation publication-type="journal"><name><surname>Jain</surname><given-names>M</given-names></name>, <name><surname>Koren</surname><given-names>S</given-names></name>, <name><surname>Quick</surname><given-names>J</given-names></name>, <name><surname>Rand</surname><given-names>AC</given-names></name>, <name><surname>Sasani</surname><given-names>TA</given-names></name>, <name><surname>Tyson</surname><given-names>JR</given-names></name>, <name><surname>Beggs</surname><given-names>AD</given-names></name>, <name><surname>Dilthey</surname><given-names>AT</given-names></name>, <name><surname>Fiddes</surname><given-names>IT</given-names></name>, <name><surname>Malla</surname><given-names>S</given-names></name>, <etal/> (<year>2017</year>). <article-title>Nanopore sequencing and assembly of a human genome with ultra-long reads</article-title>. <source>Nat. Biotechnol</source>
<volume>36</volume>, <fpage>338</fpage>&#x02013;<lpage>345</lpage>.</mixed-citation></ref><ref id="R15"><mixed-citation publication-type="journal"><name><surname>Langmead</surname><given-names>B</given-names></name>, and <name><surname>Salzberg</surname><given-names>SL</given-names></name> (<year>2012</year>). <article-title>Fast gapped-read alignment with Bowtie 2</article-title>. <source>Nat. Methods</source>
<volume>9</volume>, <fpage>357</fpage>&#x02013;<lpage>359</lpage>.<pub-id pub-id-type="pmid">22388286</pub-id></mixed-citation></ref><ref id="R16"><mixed-citation publication-type="journal"><name><surname>Li</surname><given-names>H</given-names></name>, and <name><surname>Durbin</surname><given-names>R</given-names></name> (<year>2009</year>). <article-title>Fast and accurate short read alignment with Burrows-Wheeler transform</article-title>. <source>Bioinformatics</source>
<volume>25</volume>, <fpage>1754</fpage>&#x02013;<lpage>1760</lpage>.<pub-id pub-id-type="pmid">19451168</pub-id></mixed-citation></ref><ref id="R17"><mixed-citation publication-type="journal"><name><surname>Li</surname><given-names>H</given-names></name>, <name><surname>Handsaker</surname><given-names>B</given-names></name>, <name><surname>Wysoker</surname><given-names>A</given-names></name>, <name><surname>Fennell</surname><given-names>T</given-names></name>, <name><surname>Ruan</surname><given-names>J</given-names></name>, <name><surname>Homer</surname><given-names>N</given-names></name>, <name><surname>Marth</surname><given-names>G</given-names></name>, <name><surname>Abecasis</surname><given-names>G</given-names></name>, <name><surname>Durbin</surname><given-names>R</given-names></name>, and <name><surname>Subgroup</surname><given-names>GPDP</given-names></name> (<year>2009</year>). <article-title>The sequence alignment/map format and samtools</article-title>,. <source>Bioinformatics</source>
<volume>25</volume>, <fpage>2078</fpage>&#x02013;<lpage>2079</lpage>.<pub-id pub-id-type="pmid">19505943</pub-id></mixed-citation></ref><ref id="R18"><mixed-citation publication-type="journal"><name><surname>Macosko</surname><given-names>EZ</given-names></name>, <name><surname>Basu</surname><given-names>A</given-names></name>, <name><surname>Satija</surname><given-names>R</given-names></name>, <name><surname>Nemesh</surname><given-names>J</given-names></name>, <name><surname>Shekhar</surname><given-names>K</given-names></name>, <name><surname>Goldman</surname><given-names>M</given-names></name>, <name><surname>Tirosh</surname><given-names>I</given-names></name>, <name><surname>Bialas</surname><given-names>AR</given-names></name>, <name><surname>Kamitaki</surname><given-names>N</given-names></name>, <name><surname>Martersteck</surname><given-names>EM</given-names></name>, <etal/> (<year>2015</year>). <article-title>Highly parallel genome-wide expression profiling of individual cells using nanoliter droplets</article-title>. <source>Cell</source>
<volume>161</volume>, <fpage>1202</fpage>&#x02013;<lpage>1214</lpage>.<pub-id pub-id-type="pmid">26000488</pub-id></mixed-citation></ref><ref id="R19"><mixed-citation publication-type="journal"><name><surname>Mardis</surname><given-names>ER</given-names></name> (<year>2017</year>). <article-title>DNA sequencing technologies: 2006&#x02013;2016</article-title>. <source>Nat. Protoc</source>
<volume>12</volume>, <fpage>213</fpage>&#x02013;<lpage>218</lpage>.<pub-id pub-id-type="pmid">28055035</pub-id></mixed-citation></ref><ref id="R20"><mixed-citation publication-type="journal"><name><surname>McCoy</surname><given-names>RC</given-names></name>, <name><surname>Taylor</surname><given-names>RW</given-names></name>, <name><surname>Blauwkamp</surname><given-names>TA</given-names></name>, <name><surname>Kelley</surname><given-names>JL</given-names></name>, <name><surname>Kertesz</surname><given-names>M</given-names></name>, <name><surname>Pushkarev</surname><given-names>D</given-names></name>, <name><surname>Petrov</surname><given-names>DA</given-names></name>, and <name><surname>Fiston-Lavier</surname><given-names>AS</given-names></name> (<year>2014</year>). <article-title>Illumina truseq synthetic long-reads empower de novo assembly and resolve complex, highly-repetitive transposable elements</article-title>. <source>PloS ONE</source>
<volume>9</volume>, <fpage>e106689</fpage>.<pub-id pub-id-type="pmid">25188499</pub-id></mixed-citation></ref><ref id="R21"><mixed-citation publication-type="journal"><name><surname>McKenna</surname><given-names>A</given-names></name>, <name><surname>Hanna</surname><given-names>M</given-names></name>, <name><surname>Banks</surname><given-names>E</given-names></name>, <name><surname>Sivachenko</surname><given-names>A</given-names></name>, <name><surname>Cibulskis</surname><given-names>K</given-names></name>, <name><surname>Kernytsky</surname><given-names>A</given-names></name>, <name><surname>Garimella</surname><given-names>K</given-names></name>, <name><surname>Altshuler</surname><given-names>D</given-names></name>, <name><surname>Gabriel</surname><given-names>S</given-names></name>, <name><surname>Daly</surname><given-names>M</given-names></name>, <etal/> (<year>2010</year>). <article-title>The Genome Analysis Toolkit: A MapReduce framework for analyzing next-generation DNA sequencing data</article-title>. <source>Genome Res</source>
<volume>20</volume>, <fpage>1297</fpage>&#x02013;<lpage>1303</lpage>.<pub-id pub-id-type="pmid">20644199</pub-id></mixed-citation></ref><ref id="R22"><mixed-citation publication-type="journal"><name><surname>Mostovoy</surname><given-names>Y</given-names></name>, <name><surname>Levy-Sakin</surname><given-names>M</given-names></name>, <name><surname>Lam</surname><given-names>J</given-names></name>, <name><surname>Lam</surname><given-names>ET</given-names></name>, <name><surname>Hastie</surname><given-names>AR</given-names></name>, <name><surname>Marks</surname><given-names>P</given-names></name>, <name><surname>Lee</surname><given-names>J</given-names></name>, <name><surname>Chu</surname><given-names>C</given-names></name>, <name><surname>Lin</surname><given-names>C</given-names></name>, <name><surname>Dakula</surname><given-names>Z</given-names></name>, <etal/> (<year>2016</year>). <article-title>A hybrid approach for de novo human genome sequence assembly and phasing</article-title>. <source>Nat. Methods</source>
<volume>13</volume>, <fpage>587</fpage>&#x02013;<lpage>590</lpage>.<pub-id pub-id-type="pmid">27159086</pub-id></mixed-citation></ref><ref id="R23"><mixed-citation publication-type="journal"><name><surname>Numanagi&#x00107;</surname><given-names>I</given-names></name>, <name><surname>Maliki&#x00107;</surname><given-names>S</given-names></name>, <name><surname>Ford</surname><given-names>M</given-names></name>, <name><surname>Qin</surname><given-names>X</given-names></name>, <name><surname>Toji</surname><given-names>L</given-names></name>, <name><surname>Radovich</surname><given-names>M</given-names></name>, <name><surname>Skaar</surname><given-names>TC</given-names></name>, <name><surname>Pratt</surname><given-names>VM</given-names></name>, <name><surname>Berger</surname><given-names>B</given-names></name>, <name><surname>Scherer</surname><given-names>S</given-names></name>, <etal/> (<year>2018</year>). <article-title>Allelic decomposition and exact genotyping of highly polymorphic and structurally variant genes</article-title>. <source>Nat. Commun</source>
<volume>9</volume>, <fpage>828</fpage>.<pub-id pub-id-type="pmid">29483503</pub-id></mixed-citation></ref><ref id="R24"><mixed-citation publication-type="journal"><name><surname>Pendleton</surname><given-names>M</given-names></name>, <name><surname>Sebra</surname><given-names>R</given-names></name>, <name><surname>Pang</surname><given-names>AWC</given-names></name>, <name><surname>Ummat</surname><given-names>A</given-names></name>, <name><surname>Franzen</surname><given-names>O</given-names></name>, <name><surname>Rausch</surname><given-names>T</given-names></name>, <name><surname>St&#x000fc;tz</surname><given-names>AM</given-names></name>, <name><surname>Stedman</surname><given-names>W</given-names></name>, <name><surname>Anantharaman</surname><given-names>T</given-names></name>, <name><surname>Hastie</surname><given-names>A</given-names></name>, <etal/> (<year>2015</year>). <article-title>Assembly and diploid architecture of an individual human genome via single-molecule technologies</article-title>. <source>Nat. Methods</source>
<volume>12</volume>, <fpage>780</fpage>&#x02013;<lpage>786</lpage>.<pub-id pub-id-type="pmid">26121404</pub-id></mixed-citation></ref><ref id="R25"><mixed-citation publication-type="journal"><name><surname>Schwarze</surname><given-names>K</given-names></name>, <name><surname>Buchanan</surname><given-names>J</given-names></name>, <name><surname>Taylor</surname><given-names>JC</given-names></name>, and <name><surname>Wordsworth</surname><given-names>S</given-names></name> (<year>2018</year>). <article-title>Are whole-exome and whole-genome sequencing approaches cost-effective? A systematic review of the literature</article-title>. <source>Genet. Med</source></mixed-citation></ref><ref id="R26"><mixed-citation publication-type="journal"><name><surname>Sekar</surname><given-names>A</given-names></name>, <name><surname>Bialas</surname><given-names>AR</given-names></name>, <name><surname>de Rivera</surname><given-names>H</given-names></name>, <name><surname>Davis</surname><given-names>A</given-names></name>, <name><surname>Hammond</surname><given-names>TR</given-names></name>, <name><surname>Kamitaki</surname><given-names>N</given-names></name>, <name><surname>Tooley</surname><given-names>K</given-names></name>, <name><surname>Presumey</surname><given-names>J</given-names></name>, <name><surname>Baum</surname><given-names>M</given-names></name>, <name><surname>Van Doren</surname><given-names>V</given-names></name>, <etal/> (<year>2016</year>). <article-title>Schizophrenia risk from complex variation of complement component 4</article-title>. <source>Nature</source>
<volume>530</volume>, <fpage>177</fpage>.<pub-id pub-id-type="pmid">26814963</pub-id></mixed-citation></ref><ref id="R27"><mixed-citation publication-type="journal"><name><surname>Twist</surname><given-names>GP</given-names></name>, <name><surname>Gaedigk</surname><given-names>A</given-names></name>, <name><surname>Miller</surname><given-names>NA</given-names></name>, <name><surname>Farrow</surname><given-names>EG</given-names></name>, <name><surname>Willig</surname><given-names>LK</given-names></name>, <name><surname>Dinwiddie</surname><given-names>DL</given-names></name>, <name><surname>Petrikin</surname><given-names>JE</given-names></name>, <name><surname>Soden</surname><given-names>SE</given-names></name>, <name><surname>Herd</surname><given-names>S</given-names></name>, <name><surname>Gibson</surname><given-names>M</given-names></name>, <etal/> (<year>2016</year>). <article-title>Constellation: A tool for rapid, automated phenotype assignment of a highly polymorphic pharmacogene, CYP2D6, from whole-genome sequences</article-title>. <source>NPJ Genom. Med</source>
<volume>1</volume>, <fpage>15007</fpage>.<pub-id pub-id-type="pmid">29263805</pub-id></mixed-citation></ref><ref id="R28"><mixed-citation publication-type="journal"><name><surname>Wang</surname><given-names>Y</given-names></name>, <name><surname>Yang</surname><given-names>Q</given-names></name>, and <name><surname>Wang</surname><given-names>Z</given-names></name> (<year>2014</year>). <article-title>The evolution of nanopore sequencing</article-title>. <source>Front. Genet</source>
<volume>5</volume>, <fpage>449</fpage>.<pub-id pub-id-type="pmid">25610451</pub-id></mixed-citation></ref><ref id="R29"><mixed-citation publication-type="journal"><name><surname>Yorukoglu</surname><given-names>D</given-names></name>, <name><surname>Yu</surname><given-names>YW</given-names></name>, <name><surname>Peng</surname><given-names>J</given-names></name>, and <name><surname>Berger</surname><given-names>B</given-names></name> (<year>2016</year>). <article-title>Compressive mapping for next-generation sequencing</article-title>. <source>Nat. Biotech</source>
<volume>34</volume>, <fpage>374</fpage>&#x02013;<lpage>376</lpage>.</mixed-citation></ref><ref id="R30"><mixed-citation publication-type="journal"><name><surname>Zheng</surname><given-names>GX</given-names></name>, <name><surname>Lau</surname><given-names>BT</given-names></name>, <name><surname>Schnall-Levin</surname><given-names>M</given-names></name>, <name><surname>Jarosz</surname><given-names>M</given-names></name>, <name><surname>Bell</surname><given-names>JM</given-names></name>, <name><surname>Hindson</surname><given-names>CM</given-names></name>, <name><surname>Kyriazopoulou-Panagiotopoulou</surname><given-names>S</given-names></name>, <name><surname>Masquelier</surname><given-names>DA</given-names></name>, <name><surname>Merrill</surname><given-names>L</given-names></name>, <name><surname>Terry</surname><given-names>JM</given-names></name>, <etal/> (<year>2016</year>). <article-title>Haplotyping germline and cancer genomes using high-throughput linked-read sequencing</article-title>. <source>Nat. Biotechnol</source>
<volume>34</volume>, <fpage>303</fpage>&#x02013;<lpage>311</lpage>.<pub-id pub-id-type="pmid">26829319</pub-id></mixed-citation></ref><ref id="R31"><mixed-citation publication-type="journal"><name><surname>Ziegenhain</surname><given-names>C</given-names></name>, <name><surname>Vieth</surname><given-names>B</given-names></name>, <name><surname>Parekh</surname><given-names>S</given-names></name>, <name><surname>Reinius</surname><given-names>B</given-names></name>, <name><surname>Guillaumet-Adkins</surname><given-names>A</given-names></name>, <name><surname>Smets</surname><given-names>M</given-names></name>, <name><surname>Leonhardt</surname><given-names>H</given-names></name>, <name><surname>Heyn</surname><given-names>H</given-names></name>, <name><surname>Hellmann</surname><given-names>I</given-names></name>, and <name><surname>Enard</surname><given-names>W</given-names></name> (<year>2017</year>). <article-title>Comparative analysis of single-cell rna sequencing methods</article-title>. <source>Mol. Cell</source>
<volume>65</volume>, <fpage>631</fpage>&#x02013;<lpage>643</lpage>.<pub-id pub-id-type="pmid">28212749</pub-id></mixed-citation></ref><ref id="R32"><mixed-citation publication-type="journal"><name><surname>Zook</surname><given-names>JM</given-names></name>, <name><surname>Catoe</surname><given-names>D</given-names></name>, <name><surname>McDaniel</surname><given-names>J</given-names></name>, <name><surname>Vang</surname><given-names>L</given-names></name>, <name><surname>Spies</surname><given-names>N</given-names></name>, <name><surname>Sidow</surname><given-names>A</given-names></name>, <name><surname>Weng</surname><given-names>Z</given-names></name>, <name><surname>Liu</surname><given-names>Y</given-names></name>, <name><surname>Mason</surname><given-names>CE</given-names></name>, <name><surname>Alexander</surname><given-names>N</given-names></name>, <etal/> (<year>2016</year>). <article-title>Extensive sequencing of seven human genomes to characterize benchmark reference materials</article-title>. <source>Scientific Data</source>
<volume>3</volume>, <fpage>160025</fpage>.<pub-id pub-id-type="pmid">27271295</pub-id></mixed-citation></ref><ref id="R33"><mixed-citation publication-type="journal"><name><surname>Zook</surname><given-names>JM</given-names></name>, <name><surname>Chapman</surname><given-names>B</given-names></name>, <name><surname>Wang</surname><given-names>J</given-names></name>, <name><surname>Mittelman</surname><given-names>D</given-names></name>, <name><surname>Hofmann</surname><given-names>O</given-names></name>, <name><surname>Hide</surname><given-names>W</given-names></name>, and <name><surname>Salit</surname><given-names>M</given-names></name> (<year>2014</year>). <article-title>Integrating human sequence data sets provides a resource of benchmark SNP and indel genotype calls</article-title>. <source>Nat. Biotech</source>
<volume>32</volume>, <fpage>246</fpage>&#x02013;<lpage>251</lpage>.</mixed-citation></ref></ref-list></back><floats-group><fig id="F1" orientation="portrait" position="float"><label>Figure 1.</label><caption><title>Overview of EMA Pipeline</title><p id="P71">(A) An idealized model of barcoded read sequencing, wherein some number of unknown source fragments in a single droplet or well are sheared, barcoded, and sequenced to produce barcoded reads.</p><p id="P72">(B) EMA&#x02019;s &#x0201c;read clouds&#x0201d; are constructed by grouping nearby-mapping reads sharing the same barcode; these clouds represent possible source fragments. EMA then partitions the clouds into a disjoint-set induced by the alignments, where two clouds are connected if there is a read aligning to both; connected components in this disjoint-set (enclosed by dashed boxes) correspond to alternate possibilities for the <italic>same</italic> unknown source fragment. EMA&#x02019;s latent variable model optimization is subsequently applied to each of these connected components individually to deduce each of the potentially many fragments sharing this barcode.</p><p id="P73">(C) EMA applies a novel read density optimization algorithm to clouds containing multiple alignments of the same read to pick out the most likely alignment, by optimizing a combination of alignment edit distances and read densities within the cloud. The green regions of the genome are homologous, thereby resulting in multi-mappings within a single cloud.</p><p id="P74">(D) While the read density optimization operates within a single cloud, EMA&#x02019;s latent variable model optimization determines the best alignment of a given read between different clouds and produces not only the final alignment for each read but also interpretable alignment <italic>probabilities</italic> (see <xref rid="SD1" ref-type="supplementary-material">Figure S1</xref>).</p></caption><graphic xlink:href="nihms-986152-f0001"/></fig><fig id="F2" orientation="portrait" position="float"><label>Figure 2.</label><caption><title>Genotyping and Phasing Results for Each Aligner</title><p id="P75">The top row shows true positive variant calls as a function of false positives for alignments produced by EMA (turquoise), Lariat (orange), and BWA-MEM (gray) on the well-studied samples NA12878, NA24149, NA24143, and NA24385. Genotype confidences are determined by the genotype quality (GQ) annotations generated by GATK&#x02019;s HaplotypeCaller. The middle two rows contain cumulative histograms of false positives (top) and false negatives (bottom) throughout chromosome 1 for each dataset, for both EMA (turquoise) and Lariat (orange). EMA achieves more than a 30% average improvement over the other methods in terms of eliminating erroneous variant calls. The bottom row shows EMA and Lariat&#x02019;s phasing results for several metrics: switch errors, mismatch errors, flat errors (<xref rid="R8" ref-type="bibr">Edge et al., 2016</xref>), and phase block N50 (lower is better for the first three, while higher is better for the last). EMA outperforms Lariat in phasing on every metric.</p></caption><graphic xlink:href="nihms-986152-f0002"/></fig><fig id="F3" orientation="portrait" position="float"><label>Figure 3.</label><caption><title>Positive Effect of EMA&#x02019;s Statistical Binning in the Clinically Important Genes <italic>CYP2D6, CYP2D7, C4</italic>, and <italic>AMY1A</italic></title><p id="P76">The green inset shows the read coverage for the region around exon/intron 8 of <italic>CYP2D6</italic> (top row) and <italic>CYP2D7</italic> (bottom row). Spurious coverage peaks (i.e., increases in observed coverage likely to be false) in <italic>CYP2D6</italic> are shaded black. EMA is clearly able to remove the problematic peaks and correctly assign them to <italic>CYP2D7</italic>. The insets below show the newly assigned mappings to <italic>CYP2D7</italic>: EMA&#x02019;s alignments agree with the assembly consensus sequence (observe the insertion and two neighboring SNPs detected by EMA). By contrast, both Lariat and BWA-MEM aligned virtually no reads to this region and were thus unable to call these mutations. Analogous images are shown for <italic>C4</italic> and <italic>AMY1A</italic>, as well as for TruSeq SLR and CPT-seq data.</p></caption><graphic xlink:href="nihms-986152-f0003"/></fig><table-wrap id="T2" position="float" orientation="portrait"><label>Table 1.</label><caption><p id="P77">Runtime and Memory Usages on Two NA12878 Datasets</p></caption><table frame="hsides" rules="groups"><colgroup span="1"><col align="left" valign="middle" span="1"/><col align="left" valign="middle" span="1"/><col align="left" valign="middle" span="1"/><col align="left" valign="middle" span="1"/><col align="left" valign="middle" span="1"/></colgroup><thead><tr><th align="left" valign="middle" rowspan="1" colspan="1"/><th align="left" valign="middle" style="border-bottom: solid 1px" rowspan="1" colspan="1"><italic>NA12878</italic></th><th align="left" valign="middle" style="border-bottom: solid 1px" rowspan="1" colspan="1"/><th align="left" valign="middle" style="border-bottom: solid 1px" rowspan="1" colspan="1"><italic>NA12878 v2</italic></th><th align="left" valign="middle" style="border-bottom: solid 1px" rowspan="1" colspan="1"/></tr><tr><th align="left" valign="middle" rowspan="1" colspan="1">Tool</th><th align="left" valign="middle" rowspan="1" colspan="1">Time (hh:mm)</th><th align="left" valign="middle" rowspan="1" colspan="1">Mem./core (GB)</th><th align="left" valign="middle" rowspan="1" colspan="1">Time (hh:mm)</th><th align="left" valign="middle" rowspan="1" colspan="1">Mem./core (GB)</th></tr></thead><tbody><tr><td align="left" valign="middle" rowspan="1" colspan="1">EMA</td><td align="left" valign="middle" rowspan="1" colspan="1">14:58 (10:40)</td><td align="left" valign="middle" rowspan="1" colspan="1">5.4</td><td align="left" valign="middle" rowspan="1" colspan="1">28:30 (17:45)</td><td align="left" valign="middle" rowspan="1" colspan="1">8.7</td></tr><tr><td align="left" valign="middle" rowspan="1" colspan="1">Lariat</td><td align="left" valign="middle" rowspan="1" colspan="1">21:49 (12:45)</td><td align="left" valign="middle" rowspan="1" colspan="1">7.0</td><td align="left" valign="middle" rowspan="1" colspan="1">54:53 (26:01)</td><td align="left" valign="middle" rowspan="1" colspan="1">8.2</td></tr><tr><td align="left" valign="middle" rowspan="1" colspan="1">BWA-MEM</td><td align="left" valign="middle" rowspan="1" colspan="1">14:49 (9:52)</td><td align="left" valign="middle" rowspan="1" colspan="1">5.5</td><td align="left" valign="middle" rowspan="1" colspan="1"/><td align="left" valign="middle" rowspan="1" colspan="1"/></tr></tbody></table><table-wrap-foot><fn id="TFN1"><p id="P78">&#x0201c;NA12878&#x0201d;&#x02014;used also in <xref rid="F2" ref-type="fig">Figure 2</xref>&#x02014;is about 287 GB of raw data; &#x0201c;NA12878 v2&#x0201d; is about 823 GB. Numbers in parenthesis indicate the performance of the aligner alone (i.e., without sorting, merging, or duplicate marking). For the small dataset, each mapper was allocated 40 Intel Xeon E5&#x02013;2650 CPUs @2.30GHz. For the large dataset, each was allocated 48 Intel Xeon E5&#x02013;2695 CPUs @ 2.40GHz. Memory measurements include only the actual aligner&#x02019;s memory usage and do not include the memory requirements of pre- and post-processing steps, as they are virtually the same for all methods. BWA-MEM was used only as a baseline on the smaller dataset.</p></fn></table-wrap-foot></table-wrap><boxed-text id="BX1" position="float" orientation="portrait"><caption><title>Highlights</title></caption><list list-type="bullet" id="L1"><list-item><p id="P79">We devise a two-tiered statistical binning model to align barcoded reads to the genome</p></list-item><list-item><p id="P80">We can map highly homologous regions to uncover rare variants important in disease</p></list-item><list-item><p id="P81">Our method greatly improves downstream genotyping and haplotyping accuracy</p></list-item><list-item><p id="P82">We determine not only alignments but also interpretable alignment <italic>probabilities</italic></p></list-item></list></boxed-text></floats-group></article>