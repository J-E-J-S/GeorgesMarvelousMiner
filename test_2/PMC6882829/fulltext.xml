<!DOCTYPE article PUBLIC "-//NLM//DTD JATS (Z39.96) Journal Archiving and Interchange DTD with MathML3 v1.2 20190208//EN" "JATS-archivearticle1-mathml3.dtd"> 
<article xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink" article-type="research-article"><?properties open_access?><?DTDIdentifier.IdentifierValue -//Springer-Verlag//DTD A++ V2.4//EN?><?DTDIdentifier.IdentifierType public?><?SourceDTD.DTDName A++V2.4.dtd?><?SourceDTD.Version 2.4?><?ConverterInfo.XSLTName springer2nlmx2.xsl?><?ConverterInfo.Version 1?><front><journal-meta><journal-id journal-id-type="nlm-ta">Nat Commun</journal-id><journal-id journal-id-type="iso-abbrev">Nat Commun</journal-id><journal-title-group><journal-title>Nature Communications</journal-title></journal-title-group><issn pub-type="epub">2041-1723</issn><publisher><publisher-name>Nature Publishing Group UK</publisher-name><publisher-loc>London</publisher-loc></publisher></journal-meta><article-meta><article-id pub-id-type="pmcid">6882829</article-id><article-id pub-id-type="publisher-id">13056</article-id><article-id pub-id-type="doi">10.1038/s41467-019-13056-x</article-id><article-categories><subj-group subj-group-type="heading"><subject>Article</subject></subj-group></article-categories><title-group><article-title>The art of using t-SNE for single-cell transcriptomics</article-title></title-group><contrib-group><contrib contrib-type="author" corresp="yes"><contrib-id contrib-id-type="orcid">http://orcid.org/0000-0002-5639-7209</contrib-id><name><surname>Kobak</surname><given-names>Dmitry</given-names></name><address><email>dmitry.kobak@uni-tuebingen.de</email></address><xref ref-type="aff" rid="Aff1">1</xref></contrib><contrib contrib-type="author" corresp="yes"><contrib-id contrib-id-type="orcid">http://orcid.org/0000-0002-0199-4727</contrib-id><name><surname>Berens</surname><given-names>Philipp</given-names></name><address><email>philipp.berens@uni-tuebingen.de</email></address><xref ref-type="aff" rid="Aff1">1</xref><xref ref-type="aff" rid="Aff2">2</xref><xref ref-type="aff" rid="Aff3">3</xref><xref ref-type="aff" rid="Aff4">4</xref></contrib><aff id="Aff1"><label>1</label><institution-wrap><institution-id institution-id-type="ISNI">0000 0001 2190 1447</institution-id><institution-id institution-id-type="GRID">grid.10392.39</institution-id><institution>Institute for Ophthalmic Research, </institution><institution>University of T&#x000fc;bingen, </institution></institution-wrap>T&#x000fc;bingen, Germany </aff><aff id="Aff2"><label>2</label><institution-wrap><institution-id institution-id-type="ISNI">0000 0001 2190 1447</institution-id><institution-id institution-id-type="GRID">grid.10392.39</institution-id><institution>Bernstein Center for Computational Neuroscience, </institution><institution>University of T&#x000fc;bingen, </institution></institution-wrap>T&#x000fc;bingen, Germany </aff><aff id="Aff3"><label>3</label><institution-wrap><institution-id institution-id-type="ISNI">0000 0001 2190 1447</institution-id><institution-id institution-id-type="GRID">grid.10392.39</institution-id><institution>Center for Integrative Neuroscience, </institution><institution>University of T&#x000fc;bingen, </institution></institution-wrap>T&#x000fc;bingen, Germany </aff><aff id="Aff4"><label>4</label><institution-wrap><institution-id institution-id-type="ISNI">0000 0001 2190 1447</institution-id><institution-id institution-id-type="GRID">grid.10392.39</institution-id><institution>Institute for Bioinformatics and Medical Informatics, </institution><institution>University of T&#x000fc;bingen, </institution></institution-wrap>T&#x000fc;bingen, Germany </aff></contrib-group><pub-date pub-type="epub"><day>28</day><month>11</month><year>2019</year></pub-date><pub-date pub-type="pmc-release"><day>28</day><month>11</month><year>2019</year></pub-date><pub-date pub-type="collection"><year>2019</year></pub-date><volume>10</volume><elocation-id>5416</elocation-id><history><date date-type="received"><day>20</day><month>11</month><year>2018</year></date><date date-type="accepted"><day>30</day><month>8</month><year>2019</year></date></history><permissions><copyright-statement>&#x000a9; The Author(s) 2019</copyright-statement><license license-type="OpenAccess"><license-p><bold>Open Access</bold> This article is licensed under a Creative Commons Attribution 4.0 International License, which permits use, sharing, adaptation, distribution and reproduction in any medium or format, as long as you give appropriate credit to the original author(s) and the source, provide a link to the Creative Commons license, and indicate if changes were made. The images or other third party material in this article are included in the article&#x02019;s Creative Commons license, unless indicated otherwise in a credit line to the material. If material is not included in the article&#x02019;s Creative Commons license and your intended use is not permitted by statutory regulation or exceeds the permitted use, you will need to obtain permission directly from the copyright holder. To view a copy of this license, visit <ext-link ext-link-type="uri" xlink:href="http://creativecommons.org/licenses/by/4.0/">http://creativecommons.org/licenses/by/4.0/</ext-link>.</license-p></license></permissions><abstract id="Abs1"><p id="Par1">Single-cell transcriptomics yields ever growing data sets containing RNA expression levels for thousands of genes from up to millions of cells. Common data analysis pipelines include a dimensionality reduction step for visualising the data in two dimensions, most frequently performed using t-distributed stochastic neighbour embedding (t-SNE). It excels at revealing local structure in high-dimensional data, but naive applications often suffer from severe shortcomings, e.g. the global structure of the data is not represented accurately. Here we describe how to circumvent such pitfalls, and develop a protocol for creating more faithful t-SNE visualisations. It includes PCA initialisation, a high learning rate, and multi-scale similarity kernels; for very large data sets, we additionally use exaggeration and downsampling-based initialisation. We use published single-cell RNA-seq data sets to demonstrate that this protocol yields superior results compared to the naive application of t-SNE.</p></abstract><abstract id="Abs2" abstract-type="web-summary"><p id="Par2">t-SNE is widely used for dimensionality reduction and visualization of high-dimensional single-cell data. Here, the authors introduce a protocol to help avoid common shortcomings of t-SNE, for example, enabling preservation of the global structure of the data.</p></abstract><kwd-group kwd-group-type="npg-subject"><title>Subject terms</title><kwd>RNA sequencing</kwd><kwd>Statistics</kwd></kwd-group><funding-group><award-group><funding-source><institution>This work was supported by the Deutsche Forschungsgemeinschaft (BE5601/4- 1 and the Cluster of Excellence &#x0201c;Machine Learning &#x02014; New Perspectives for Science, EXC 2064, project number 390727645), the Federal Ministry of Education and Research (FKZ 01GQ1601 and 01IS18039A) and the National Institute Of Mental Health of the National Institutes of Health under Award Number U19MH114830. The content is solely the responsibility of the authors and does not necessarily represent the official views of the National Institutes of Health.</institution></funding-source></award-group></funding-group><custom-meta-group><custom-meta><meta-name>issue-copyright-statement</meta-name><meta-value>&#x000a9; The Author(s) 2019</meta-value></custom-meta></custom-meta-group></article-meta></front><body><sec id="Sec1" sec-type="introduction"><title>Introduction</title><p id="Par3">Recent years have seen a rapid growth of interest in single-cell RNA sequencing (scRNA-seq), or single-cell transcriptomics<sup><xref ref-type="bibr" rid="CR1">1</xref>,<xref ref-type="bibr" rid="CR2">2</xref></sup>. Through improved experimental techniques it has become possible to obtain gene expression data from thousands or even millions of cells<sup><xref ref-type="bibr" rid="CR3">3</xref>&#x02013;<xref ref-type="bibr" rid="CR8">8</xref></sup>. Computational analysis of such data sets often entails unsupervised, exploratory steps including dimensionality reduction for visualisation. To this end, many studies today are using t-distributed stochastic neighbour embedding, or t-SNE<sup><xref ref-type="bibr" rid="CR9">9</xref></sup>.</p><p id="Par4">This technique maps a set of high-dimensional points to two dimensions, such that ideally, close neighbours remain close and distant points remain distant. Informally, the algorithm places all points on the 2D plane, initially at random positions, and lets them interact as if they were physical particles. The interaction is governed by two laws: first, all points are repelled from each other; second, each point is attracted to its nearest neighbours (see Methods for a mathematical description). The most important parameter of t-SNE, called perplexity, controls the width of the Gaussian kernel used to compute similarities between points and effectively governs how many of its nearest neighbours each point is attracted to. The default value of perplexity in existing implementations is 30 or 50 and the common wisdom is that &#x0201c;the performance of t-SNE is fairly robust to changes in the perplexity&#x0201d;<sup><xref ref-type="bibr" rid="CR9">9</xref></sup>.</p><p id="Par5">When applied to high-dimensional but well-clustered data, t-SNE tends to produce a visualisation with distinctly isolated clusters, which often are in good agreement with the clusters found by a dedicated clustering algorithm. This attractive property as well as the lack of serious competitors until very recently<sup><xref ref-type="bibr" rid="CR10">10</xref>,<xref ref-type="bibr" rid="CR11">11</xref></sup> made t-SNE the de facto standard for visual exploration of scRNA-seq data. At the same time, t-SNE has well known, but frequently overlooked weaknesses<sup><xref ref-type="bibr" rid="CR12">12</xref></sup>. Most importantly, it often fails to preserve the global geometry of the data. This means that the relative position of clusters on the t-SNE plot is almost arbitrary and depends on random initialisation more than on anything else. While this may not be a problem in some situations, scRNA-seq data sets often exhibit biologically meaningful hierarchical structure, e.g. encompass several very different cell classes, each further divided into various types. Typical t-SNE plots do not capture such global structure, yielding a suboptimal and potentially misleading visualisation. In our experience, the larger the data set, the more severe this problem becomes. Other notable challenges include performing t-SNE visualisations for very large data sets (e.g. a million of cells or more), or mapping cells collected in follow-up experiments onto an existing t-SNE visualisation.</p><p id="Par6">Here we explain how to achieve improved t-SNE visualisations that preserve the global geometry of the data. Our method relies on providing PCA initialisation, employing multi-scale similarities<sup><xref ref-type="bibr" rid="CR13">13</xref>,<xref ref-type="bibr" rid="CR14">14</xref></sup>, increasing the learning rate<sup><xref ref-type="bibr" rid="CR15">15</xref></sup>, and for very large data sets, additionally using the so called exaggeration and downsampling-based initialisation. To demonstrate these techniques we use several full-length and UMI-based data sets with up to two million cells (Table&#x000a0;<xref rid="Tab1" ref-type="table">1</xref>). We use FIt-SNE<sup><xref ref-type="bibr" rid="CR16">16</xref></sup>, a recently developed fast t-SNE implementation, for all experiments.<table-wrap id="Tab1"><label>Table 1</label><caption><p>Data sets used in this study, listed in the order of appearance in the text. In all cases, we relied on quality control and clustering performed in the original publications. For the 10x Genomics data set we used cluster labels from ref. <sup><xref ref-type="bibr" rid="CR23">23</xref></sup>.</p></caption><table frame="hsides" rules="groups"><thead><tr><th>Data set name</th><th>Protocol</th><th>Organism and tissue</th><th>No. of cells</th><th>No. of classes</th></tr></thead><tbody><tr><td>Tasic et al.<sup><xref ref-type="bibr" rid="CR3">3</xref></sup></td><td>Smart-seq2</td><td>adult mouse cortex</td><td>23,822</td><td>133</td></tr><tr><td>Macosko et al.<sup><xref ref-type="bibr" rid="CR24">24</xref></sup></td><td>Drop-seq</td><td>mouse retina</td><td>44,808</td><td>39</td></tr><tr><td>Shekhar et al.<sup><xref ref-type="bibr" rid="CR25">25</xref></sup></td><td>Drop-seq</td><td>mouse retina</td><td>27,499</td><td>26</td></tr><tr><td>Harris et al.<sup><xref ref-type="bibr" rid="CR26">26</xref></sup></td><td>10x Chromium</td><td>mouse hippocampus</td><td>3663</td><td>49</td></tr><tr><td>Cadwell et al.<sup><xref ref-type="bibr" rid="CR27">27</xref></sup></td><td>Smart-seq2 (Patch-seq)</td><td>adult mouse cortex</td><td>46</td><td>2</td></tr><tr><td>Tasic et al.<sup><xref ref-type="bibr" rid="CR31">31</xref></sup></td><td>SMARTer</td><td>adult mouse cortex</td><td>1679</td><td>49</td></tr><tr><td>10x Genomics</td><td>10x Chromium</td><td>mouse embryonic brain</td><td>1,306,127</td><td>39</td></tr><tr><td>Cao et al.<sup><xref ref-type="bibr" rid="CR8">8</xref></sup></td><td>sci-RNA-seq3</td><td>mouse embryo</td><td>2,058,652</td><td>38</td></tr></tbody></table></table-wrap></p><p id="Par7">In many challenging cases, our t-SNE pipeline yields visualisations that are better than the state of the art. We discuss its advantages and disadvantages compared to UMAP<sup><xref ref-type="bibr" rid="CR10">10</xref></sup>, a recent dimensionality reduction method that is gaining popularity in the scRNA-seq community<sup><xref ref-type="bibr" rid="CR11">11</xref></sup>. We also describe how to position new cells on an existing t-SNE reference atlas and how to visualise multiple related data sets side by side in a consistent fashion. We focus on single-cell transcriptomics but our recommendations are more generally applicable to any data set that has hierarchical organisation, which is often the case e.g. in single-cell flow or mass cytometry<sup><xref ref-type="bibr" rid="CR17">17</xref>,<xref ref-type="bibr" rid="CR18">18</xref></sup>, whole-genome sequencing<sup><xref ref-type="bibr" rid="CR19">19</xref>,<xref ref-type="bibr" rid="CR20">20</xref></sup>, as well as outside of biology<sup><xref ref-type="bibr" rid="CR21">21</xref></sup>.</p></sec><sec id="Sec2" sec-type="results"><title>Results</title><sec id="Sec3"><title>Preserving global geometry with t-SNE</title><p id="Par8">To illustrate that the default t-SNE tends to misrepresent the global geometry, we first consider a toy example (Fig.&#x000a0;<xref rid="Fig1" ref-type="fig">1</xref>). This synthetic data set consists of points sampled from fifteen 50-dimensional spherical Gaussian distributions, grouped into three distinct and non-overlapping classes. The data are generated such that the types within two classes (<inline-formula id="IEq1"><alternatives><tex-math id="M1">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$n=100$$\end{document}</tex-math><mml:math id="M2"><mml:mi>n</mml:mi><mml:mo>=</mml:mo><mml:mn>100</mml:mn></mml:math><inline-graphic xlink:href="41467_2019_13056_Article_IEq1.gif"/></alternatives></inline-formula> and <inline-formula id="IEq2"><alternatives><tex-math id="M3">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$n=1000$$\end{document}</tex-math><mml:math id="M4"><mml:mi>n</mml:mi><mml:mo>=</mml:mo><mml:mn>1000</mml:mn></mml:math><inline-graphic xlink:href="41467_2019_13056_Article_IEq2.gif"/></alternatives></inline-formula> per type, respectively) do not overlap, and the types within the third class (<inline-formula id="IEq3"><alternatives><tex-math id="M5">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$n=2000$$\end{document}</tex-math><mml:math id="M6"><mml:mi>n</mml:mi><mml:mo>=</mml:mo><mml:mn>2000</mml:mn></mml:math><inline-graphic xlink:href="41467_2019_13056_Article_IEq3.gif"/></alternatives></inline-formula> per type) are partially overlapping. As a result, this data set exhibits hierarchical structure, typical for scRNA-seq data.<fig id="Fig1"><label>Fig. 1</label><caption><p>Synthetic data set. The points were sampled from a mixture of fifteen 50-dimensional Gaussian distributions. Total sample size <italic>n</italic>&#x02009;=&#x02009;15,500. <bold>a</bold> Multidimensional scaling of 15 class means. Point sizes are proportional to the number of points per class. <bold>b</bold> The first two principal components of the data. Point colours denote class membership. KNN: <inline-formula id="IEq4"><alternatives><tex-math id="M7">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$10$$\end{document}</tex-math><mml:math id="M8"><mml:mn>10</mml:mn></mml:math><inline-graphic xlink:href="41467_2019_13056_Article_IEq4.gif"/></alternatives></inline-formula>-nearest neighbour preservation, KNC: <inline-formula id="IEq5"><alternatives><tex-math id="M9">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$4$$\end{document}</tex-math><mml:math id="M10"><mml:mn>4</mml:mn></mml:math><inline-graphic xlink:href="41467_2019_13056_Article_IEq5.gif"/></alternatives></inline-formula>-nearest classes preservation, CPD: Spearman correlation between pairwise distances. <bold>c</bold> Default t-SNE with perplexity 30, random initialisation, and learning rate 200. <bold>d</bold> T-SNE with perplexity <inline-formula id="IEq6"><alternatives><tex-math id="M11">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$n/100=155$$\end{document}</tex-math><mml:math id="M12"><mml:mi>n</mml:mi><mml:mo>&#x02215;</mml:mo><mml:mn>100</mml:mn><mml:mo>=</mml:mo><mml:mn>155</mml:mn></mml:math><inline-graphic xlink:href="41467_2019_13056_Article_IEq6.gif"/></alternatives></inline-formula>. <bold>e</bold> T-SNE with PCA initialisation. <bold>f</bold> T-SNE with multi-scale similarities (perplexity combination of 30 and <inline-formula id="IEq7"><alternatives><tex-math id="M13">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$n/100=155$$\end{document}</tex-math><mml:math id="M14"><mml:mi>n</mml:mi><mml:mo>&#x02215;</mml:mo><mml:mn>100</mml:mn><mml:mo>=</mml:mo><mml:mn>155</mml:mn></mml:math><inline-graphic xlink:href="41467_2019_13056_Article_IEq7.gif"/></alternatives></inline-formula>), PCA initialisation, and learning rate <inline-formula id="IEq8"><alternatives><tex-math id="M15">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$n/12 \approx 1300$$\end{document}</tex-math><mml:math id="M16"><mml:mi>n</mml:mi><mml:mo>&#x02215;</mml:mo><mml:mn>12</mml:mn><mml:mo>&#x02248;</mml:mo><mml:mn>1300</mml:mn></mml:math><inline-graphic xlink:href="41467_2019_13056_Article_IEq8.gif"/></alternatives></inline-formula>.</p></caption><graphic xlink:href="41467_2019_13056_Fig1_HTML" id="d29e659"/></fig></p><p id="Par9">Two classical methods to visualise high-dimensional data are multidimensional scaling (MDS) and principal component analysis (PCA). MDS is difficult to compute with a large number of points (here <italic>n</italic>&#x02009;=&#x02009;15,500), but can be easily applied to class means (<inline-formula id="IEq9"><alternatives><tex-math id="M17">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$n=15$$\end{document}</tex-math><mml:math id="M18"><mml:mi>n</mml:mi><mml:mo>=</mml:mo><mml:mn>15</mml:mn></mml:math><inline-graphic xlink:href="41467_2019_13056_Article_IEq9.gif"/></alternatives></inline-formula>), clearly showing the three distinct classes (Fig.&#x000a0;<xref rid="Fig1" ref-type="fig">1</xref>a). PCA can be applied to the whole data set and demonstrates the same large-scale structure of the data (Fig.&#x000a0;<xref rid="Fig1" ref-type="fig">1</xref>b), but no within-class structure can be seen in the first two PCs. In contrast, t-SNE clearly shows all 15 types, correctly displaying ten of them as fully isolated and five as partially overlapping (Fig.&#x000a0;<xref rid="Fig1" ref-type="fig">1</xref>c). However, the isolated types end up arbitrarily placed, with their positions mostly depending on the random seed used for initialisation.</p><p id="Par10">In order to quantify numerically the quality, or faithfulness, of a given embedding, we used three different metrics:<list list-type="simple"><list-item><label>KNN</label><p id="Par11">The fraction of <inline-formula id="IEq10"><alternatives><tex-math id="M19">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$k$$\end{document}</tex-math><mml:math id="M20"><mml:mi>k</mml:mi></mml:math><inline-graphic xlink:href="41467_2019_13056_Article_IEq10.gif"/></alternatives></inline-formula>-nearest neighbours in the original high-dimensional data that are preserved as <inline-formula id="IEq11"><alternatives><tex-math id="M21">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$k$$\end{document}</tex-math><mml:math id="M22"><mml:mi>k</mml:mi></mml:math><inline-graphic xlink:href="41467_2019_13056_Article_IEq11.gif"/></alternatives></inline-formula>-nearest neighbours in the embedding<sup><xref ref-type="bibr" rid="CR22">22</xref></sup>. We used <inline-formula id="IEq12"><alternatives><tex-math id="M23">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$k=10$$\end{document}</tex-math><mml:math id="M24"><mml:mi>k</mml:mi><mml:mo>=</mml:mo><mml:mn>10</mml:mn></mml:math><inline-graphic xlink:href="41467_2019_13056_Article_IEq12.gif"/></alternatives></inline-formula> and computed the average across all <inline-formula id="IEq13"><alternatives><tex-math id="M25">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$n$$\end{document}</tex-math><mml:math id="M26"><mml:mi>n</mml:mi></mml:math><inline-graphic xlink:href="41467_2019_13056_Article_IEq13.gif"/></alternatives></inline-formula> points. KNN quantifies preservation of the local, or microscopic structure.</p></list-item><list-item><label>KNC</label><p id="Par12">The fraction of <inline-formula id="IEq14"><alternatives><tex-math id="M27">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$k$$\end{document}</tex-math><mml:math id="M28"><mml:mi>k</mml:mi></mml:math><inline-graphic xlink:href="41467_2019_13056_Article_IEq14.gif"/></alternatives></inline-formula>-nearest class means in the original data that are preserved as <inline-formula id="IEq15"><alternatives><tex-math id="M29">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$k$$\end{document}</tex-math><mml:math id="M30"><mml:mi>k</mml:mi></mml:math><inline-graphic xlink:href="41467_2019_13056_Article_IEq15.gif"/></alternatives></inline-formula>-nearest class means in the embedding. This is computed for class means only and averaged across all classes. For the synthetic data set we used <inline-formula id="IEq16"><alternatives><tex-math id="M31">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$k=4$$\end{document}</tex-math><mml:math id="M32"><mml:mi>k</mml:mi><mml:mo>=</mml:mo><mml:mn>4</mml:mn></mml:math><inline-graphic xlink:href="41467_2019_13056_Article_IEq16.gif"/></alternatives></inline-formula>, and for the real data sets analysed below we used <inline-formula id="IEq17"><alternatives><tex-math id="M33">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$k=10$$\end{document}</tex-math><mml:math id="M34"><mml:mi>k</mml:mi><mml:mo>=</mml:mo><mml:mn>10</mml:mn></mml:math><inline-graphic xlink:href="41467_2019_13056_Article_IEq17.gif"/></alternatives></inline-formula>. KNC quantifies preservation of the mesoscopic structure.</p></list-item><list-item><label>CPD</label><p id="Par13">Spearman correlation between pairwise distances in the high-dimensional space and in the embedding<sup><xref ref-type="bibr" rid="CR11">11</xref></sup>. Computed across all 499,500 pairs among 1000 randomly chosen points. CPD quantifies preservation of the global, or macroscropic structure.</p></list-item></list></p><p id="Par013">Applying these metrics to the PCA and t-SNE embeddings (Fig.&#x000a0;<xref rid="Fig1" ref-type="fig">1</xref>b, c) shows that t-SNE is much better than PCA in preserving the local structure (KNN 0.13 vs. 0.00) but much worse in preserving the global structure (KNC 0.23 vs. 1.00 and CPD 0.51 vs. 0.85). Our recipe for a more faithful t-SNE visualisation is based on three ideas that have been previously suggested in various contexts: multi-scale similarities<sup><xref ref-type="bibr" rid="CR13">13</xref>,<xref ref-type="bibr" rid="CR14">14</xref></sup>, PCA initialisation, and increased learning rate<sup><xref ref-type="bibr" rid="CR15">15</xref></sup>.</p><p id="Par14">Fig.&#x000a0;<xref rid="Fig1" ref-type="fig">1</xref>c used perplexity 30, which is the default value in most t-SNE implementations. Much larger values can yield qualitatively different outcomes. As large perplexity yields longer-ranging attractive forces during t-SNE optimisation, the visualisation loses some fine detail but pulls larger structures together. As a simple rule of thumb, we take 1% of the sample size as a large perplexity for any given data set; this corresponds to perplexity 155 for our simulated data and results in five small clusters belonging to the same class attracted together (Fig.&#x000a0;<xref rid="Fig1" ref-type="fig">1</xref>d). Our metrics confirmed that, compared to the standard perplexity value, the local structure (KNN) deteriorates but the global structure (KNC and CPD) improves. A multi-scale approach, using multiple perplexity values at the same time, has been previously suggested to preserve both local and global structure<sup><xref ref-type="bibr" rid="CR13">13</xref>,<xref ref-type="bibr" rid="CR14">14</xref></sup>. We adopt this approach in our final pipeline and, whenever <inline-formula id="IEq18"><alternatives><tex-math id="M35">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$n/100\gg 30$$\end{document}</tex-math><mml:math id="M36"><mml:mi>n</mml:mi><mml:mo>&#x02215;</mml:mo><mml:mn>100</mml:mn><mml:mo>&#x0226b;</mml:mo><mml:mn>30</mml:mn></mml:math><inline-graphic xlink:href="41467_2019_13056_Article_IEq18.gif"/></alternatives></inline-formula>, combine perplexity 30 with the large perplexity <inline-formula id="IEq19"><alternatives><tex-math id="M37">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$n/100$$\end{document}</tex-math><mml:math id="M38"><mml:mi>n</mml:mi><mml:mo>&#x02215;</mml:mo><mml:mn>100</mml:mn></mml:math><inline-graphic xlink:href="41467_2019_13056_Article_IEq19.gif"/></alternatives></inline-formula> (see below; separate evaluation not shown here).</p><p id="Par15">Another approach to preserve global structure is to use an informative initialisation, e.g. the first two PCs (after appropriate scaling, see Methods). This injects the global structure into the t-SNE embedding which is then preserved during the course of t-SNE optimisation while the algorithm optimises the fine structure (Fig.&#x000a0;<xref rid="Fig1" ref-type="fig">1</xref>e). Indeed, KNN did not depend on initialisation, but both KNC and CPD markedly improved when using PCA initialisation. PCA initialisation is also convenient because it makes the t-SNE outcome reproducible and not dependent on a random seed.</p><p id="Par16">The third ingredient in our t-SNE protocol is to increase the learning rate. The default learning rate in most t-SNE implementations is <inline-formula id="IEq20"><alternatives><tex-math id="M39">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\eta =200$$\end{document}</tex-math><mml:math id="M40"><mml:mi>&#x003b7;</mml:mi><mml:mo>=</mml:mo><mml:mn>200</mml:mn></mml:math><inline-graphic xlink:href="41467_2019_13056_Article_IEq20.gif"/></alternatives></inline-formula> which is not enough for large data sets and can lead to poor convergence and/or convergence to a suboptimal local minimum<sup><xref ref-type="bibr" rid="CR15">15</xref></sup>. A recent Python library for scRNA-seq analysis, scanpy, increased the default learning rate to 1000<sup><xref ref-type="bibr" rid="CR23">23</xref></sup>, whereas ref. <sup><xref ref-type="bibr" rid="CR15">15</xref></sup> suggested to use <inline-formula id="IEq21"><alternatives><tex-math id="M41">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\eta =n/12$$\end{document}</tex-math><mml:math id="M42"><mml:mi>&#x003b7;</mml:mi><mml:mo>=</mml:mo><mml:mi>n</mml:mi><mml:mo>&#x02215;</mml:mo><mml:mn>12</mml:mn></mml:math><inline-graphic xlink:href="41467_2019_13056_Article_IEq21.gif"/></alternatives></inline-formula>. We adopt the latter suggestion and use <inline-formula id="IEq22"><alternatives><tex-math id="M43">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\eta =n/12$$\end{document}</tex-math><mml:math id="M44"><mml:mi>&#x003b7;</mml:mi><mml:mo>=</mml:mo><mml:mi>n</mml:mi><mml:mo>&#x02215;</mml:mo><mml:mn>12</mml:mn></mml:math><inline-graphic xlink:href="41467_2019_13056_Article_IEq22.gif"/></alternatives></inline-formula> whenever it is above 200. This does not have a major influence on our synthetic data set (because its sample size is not large enough for this to matter), but will be important later on.</p><p id="Par17">Putting all three modifications together, we obtain the visualisation shown in Fig.&#x000a0;<xref rid="Fig1" ref-type="fig">1</xref>f. The quantitative evaluation confirmed that in terms of the mesoscopic/macroscopic structure, our suggested pipeline strongly outperformed the default t-SNE and was better than large perplexity or PCA initialisation on their own. At the same time, in terms of the miscroscopic structure, it achieved a compromise between the small and the large perplexities.</p></sec><sec id="Sec4"><title>Faithful t-SNE of transcriptomic data sets</title><p id="Par18">To demonstrate these ideas on a real-life data set, we chose to focus on the data set&#x000a0;from Tasic et al.<sup><xref ref-type="bibr" rid="CR3">3</xref></sup>. It encompasses 23,822 cells from adult mouse cortex, split by the authors into 133 clusters with strong hierarchical organisation. Here and below we used a standard preprocessing pipeline consisting of sequencing depth normalisation, feature selection, log-transformation, and reducing the dimensionality to 50 PCs (see Methods).</p><p id="Par19">In the Tasic et al. data, three well-separated groups of clusters are apparent in the MDS (Fig.&#x000a0;<xref rid="Fig2" ref-type="fig">2</xref>a) and PCA (Fig.&#x000a0;<xref rid="Fig2" ref-type="fig">2</xref>b) plots, corresponding to excitatory neurons (cold colours), inhibitory neurons (warm colours), and non-neural cells such as astrocytes or microglia (grey/brown colours). Performing PCA on these three data subsets separately (Supplementary Fig.&#x000a0;<xref rid="MOESM1" ref-type="media">1</xref>) reveals further structure inside each of them: e.g. inhibitory neurons are well separated into two groups, <italic>Pvalb/SSt</italic>-expressing (red/yellow) and <italic>Vip/Lamp5</italic>-expressing (purple/salmon), as can also be seen in Fig.&#x000a0;<xref rid="Fig2" ref-type="fig">2</xref>a. This demonstrates the hierarchical organisation of the data.<fig id="Fig2"><label>Fig. 2</label><caption><p>Tasic et al. data set. Sample size <inline-formula id="IEq23"><alternatives><tex-math id="M45">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$n=23,\!822$$\end{document}</tex-math><mml:math id="M46"><mml:mi>n</mml:mi><mml:mo>=</mml:mo><mml:mn>23</mml:mn><mml:mo>,</mml:mo><mml:mspace width="0.3em"/><mml:mn>822</mml:mn></mml:math><inline-graphic xlink:href="41467_2019_13056_Article_IEq23.gif"/></alternatives></inline-formula>. Cluster assignments and cluster colours are taken from the original publication<sup><xref ref-type="bibr" rid="CR3">3</xref></sup>. Warm colours correspond to inhibitory neurons, cold colours correspond to excitatory neurons, brown/grey colours correspond to non-neural cells. <bold>a</bold> MDS on class means (<inline-formula id="IEq24"><alternatives><tex-math id="M47">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$n=133$$\end{document}</tex-math><mml:math id="M48"><mml:mi>n</mml:mi><mml:mo>=</mml:mo><mml:mn>133</mml:mn></mml:math><inline-graphic xlink:href="41467_2019_13056_Article_IEq24.gif"/></alternatives></inline-formula>). Point sizes are proportional to the number of points per class. <bold>b</bold> The first two principal components of the data. KNN: 10-nearest neighbour preservation, KNC: 10-nearest classes preservation, CPD: Spearman correlation between pairwise distances. <bold>c</bold> Default t-SNE with perplexity 30, random initialisation, and learning rate 200. <bold>d</bold> T-SNE with perplexity <inline-formula id="IEq25"><alternatives><tex-math id="M49">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$n/100=238$$\end{document}</tex-math><mml:math id="M50"><mml:mi>n</mml:mi><mml:mo>&#x02215;</mml:mo><mml:mn>100</mml:mn><mml:mo>=</mml:mo><mml:mn>238</mml:mn></mml:math><inline-graphic xlink:href="41467_2019_13056_Article_IEq25.gif"/></alternatives></inline-formula>. Labels denote large groups of clusters. <bold>e</bold> T-SNE with PCA initialisation. <bold>f</bold> T-SNE with multi-scale similarities (perplexity combination of 30 and <inline-formula id="IEq26"><alternatives><tex-math id="M51">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$n/100=238$$\end{document}</tex-math><mml:math id="M52"><mml:mi>n</mml:mi><mml:mo>&#x02215;</mml:mo><mml:mn>100</mml:mn><mml:mo>=</mml:mo><mml:mn>238</mml:mn></mml:math><inline-graphic xlink:href="41467_2019_13056_Article_IEq26.gif"/></alternatives></inline-formula>, PCA initialisation, and learning rate <inline-formula id="IEq27"><alternatives><tex-math id="M53">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$n/12 \approx 2000$$\end{document}</tex-math><mml:math id="M54"><mml:mi>n</mml:mi><mml:mo>&#x02215;</mml:mo><mml:mn>12</mml:mn><mml:mo>&#x02248;</mml:mo><mml:mn>2000</mml:mn></mml:math><inline-graphic xlink:href="41467_2019_13056_Article_IEq27.gif"/></alternatives></inline-formula>.</p></caption><graphic xlink:href="41467_2019_13056_Fig2_HTML" id="d29e1099"/></fig></p><p id="Par20">This global structure is missing from a standard t-SNE visualisation (Fig.&#x000a0;<xref rid="Fig2" ref-type="fig">2</xref>c): excitatory neurons, inhibitory neurons, and non-neural cells are all split into multiple islands that are shuffled among each other. For example, the group of purple clusters (<italic>Vip</italic> interneurons) is separated from a group of salmon clusters (a closely related group of <italic>Lamp5</italic> interneurons) by some excitatory clusters, misrepresenting the hierarchy of cell types. This outcome is not a strawman: the original paper<sup><xref ref-type="bibr" rid="CR3">3</xref></sup> features a t-SNE figure qualitatively very similar to our visualisation. Perplexity values in the common range (e.g. 20, 50, 80) yield similar results, confirming that t-SNE is not very sensitive to the exact value of perplexity.</p><p id="Par21">In contrast, setting perplexity to 1% of the sample size, in this case to 238, pulls together large groups of related types, improving the global structure (KNC and CPD increase), at the expense of losing some of the fine structure (KNN decreases, Fig.&#x000a0;<xref rid="Fig2" ref-type="fig">2</xref>d). PCA initialisation with default perplexity also improves the global structure (KNC and CPD increase, compared to the default t-SNE, Fig.&#x000a0;<xref rid="Fig2" ref-type="fig">2</xref>e). Finally, our suggested pipeline with multi-scale similarities (perplexity combination of 30 and <inline-formula id="IEq28"><alternatives><tex-math id="M55">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$n/100=238$$\end{document}</tex-math><mml:math id="M56"><mml:mi>n</mml:mi><mml:mo>&#x02215;</mml:mo><mml:mn>100</mml:mn><mml:mo>=</mml:mo><mml:mn>238</mml:mn></mml:math><inline-graphic xlink:href="41467_2019_13056_Article_IEq28.gif"/></alternatives></inline-formula>), PCA initialisation, and learning rate <inline-formula id="IEq29"><alternatives><tex-math id="M57">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$n/12 \approx 2000$$\end{document}</tex-math><mml:math id="M58"><mml:mi>n</mml:mi><mml:mo>&#x02215;</mml:mo><mml:mn>12</mml:mn><mml:mo>&#x02248;</mml:mo><mml:mn>2000</mml:mn></mml:math><inline-graphic xlink:href="41467_2019_13056_Article_IEq29.gif"/></alternatives></inline-formula> yields an embedding with high values of all three metrics (Fig.&#x000a0;<xref rid="Fig2" ref-type="fig">2</xref>f). Compared to the default parameters, these settings slowed down FIt-SNE from <inline-formula id="IEq30"><alternatives><tex-math id="M59">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\sim$$\end{document}</tex-math><mml:math id="M60"><mml:mo>~</mml:mo></mml:math><inline-graphic xlink:href="41467_2019_13056_Article_IEq30.gif"/></alternatives></inline-formula>30 s to <inline-formula id="IEq31"><alternatives><tex-math id="M61">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\sim$$\end{document}</tex-math><mml:math id="M62"><mml:mo>~</mml:mo></mml:math><inline-graphic xlink:href="41467_2019_13056_Article_IEq31.gif"/></alternatives></inline-formula>2&#x000a0;m, which we still find to be an acceptable runtime.</p><p id="Par22">It is instructive to study systematically how the choice of parameters influences the embedding quality (Fig.&#x000a0;<xref rid="Fig3" ref-type="fig">3</xref>). We found that the learning rate only influences KNN: the higher the learning rate, the better preserved is the local structure, until is saturates at around <inline-formula id="IEq32"><alternatives><tex-math id="M63">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$n/10$$\end{document}</tex-math><mml:math id="M64"><mml:mi>n</mml:mi><mml:mo>&#x02215;</mml:mo><mml:mn>10</mml:mn></mml:math><inline-graphic xlink:href="41467_2019_13056_Article_IEq32.gif"/></alternatives></inline-formula> (Fig.&#x000a0;<xref rid="Fig3" ref-type="fig">3</xref>a), in agreement with the results of ref. <sup><xref ref-type="bibr" rid="CR15">15</xref></sup>. The other two metrics, KNC and CPD, are not affected by the learning rate (Fig.&#x000a0;<xref rid="Fig3" ref-type="fig">3</xref>c, e). The perplexity controls the trade-off between KNN and KNC: the higher the perplexity combined with 30, the worse is the microscropic structure (Fig.&#x000a0;<xref rid="Fig3" ref-type="fig">3</xref>b) but the better is the mesoscopic structure (Fig.&#x000a0;<xref rid="Fig3" ref-type="fig">3</xref>d). Our choice of <inline-formula id="IEq33"><alternatives><tex-math id="M65">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$n/100$$\end{document}</tex-math><mml:math id="M66"><mml:mi>n</mml:mi><mml:mo>&#x02215;</mml:mo><mml:mn>100</mml:mn></mml:math><inline-graphic xlink:href="41467_2019_13056_Article_IEq33.gif"/></alternatives></inline-formula> provides a reasonable compromise. Finally, the PCA initialisation strongly improves the macroscopic structure as measured by the CPD (Fig.&#x000a0;<xref rid="Fig3" ref-type="fig">3</xref>e, f), while the other two parameters have little influence on it.<fig id="Fig3"><label>Fig. 3</label><caption><p>The influence of parameter values on embedding quality. All panels show quality assessments of various t-SNE embeddings of the Tasic et al. data set. <bold>a</bold> 10-nearest neighbours preservation (KNN) as a function of learning rate. Black line shows PCA initialisation, grey lines show random initialisations with three different random seeds. Large black dot denotes our preferred parameter values. Perplexity combination of 30 and <inline-formula id="IEq34"><alternatives><tex-math id="M67">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$n/100$$\end{document}</tex-math><mml:math id="M68"><mml:mi>n</mml:mi><mml:mo>&#x02215;</mml:mo><mml:mn>100</mml:mn></mml:math><inline-graphic xlink:href="41467_2019_13056_Article_IEq34.gif"/></alternatives></inline-formula>. <bold>b</bold> 10-nearest neighbours preservation as a function of perplexity used in combination with perplexity 30. Learning rate <inline-formula id="IEq35"><alternatives><tex-math id="M69">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$n/12$$\end{document}</tex-math><mml:math id="M70"><mml:mi>n</mml:mi><mml:mo>&#x02215;</mml:mo><mml:mn>12</mml:mn></mml:math><inline-graphic xlink:href="41467_2019_13056_Article_IEq35.gif"/></alternatives></inline-formula>. <bold>c</bold>&#x02013;<bold>d</bold> The same for 10-nearest classes preservation (KNC). <bold>e</bold>&#x02013;<bold>f</bold> The same for Spearman correlation between pairwise distances (CPD).</p></caption><graphic xlink:href="41467_2019_13056_Fig3_HTML" id="d29e1291"/></fig></p><p id="Par23">To demonstrate that our approach is equally well applicable to UMI-based transcriptomic data, we considered three further data sets. First, we analysed a <italic>n</italic>&#x02009;=&#x02009;44,808 mouse retina data set from ref. <sup><xref ref-type="bibr" rid="CR24">24</xref></sup>. Our t-SNE result preserved much of the global geometry (Fig.&#x000a0;<xref rid="Fig4" ref-type="fig">4</xref>a): e.g. multiple amacrine cell clusters (green), bipolar cell clusters (blue), and non-neural clusters (magenta) were placed close together. The t-SNE analysis performed by the authors in the original publication relied on downsampling and had a worse representation of the cluster hierarchy.<fig id="Fig4"><label>Fig. 4</label><caption><p>UMI-based data sets. Cluster assignments and cluster colours are taken from the original publications. <bold>a</bold> Macosko et al.<sup><xref ref-type="bibr" rid="CR24">24</xref></sup>, n&#x02009;=&#x02009;44,808 cells from the mouse retina. Bipolar cells comprise eight clusters, amacrine cells comprise 21 clusters. Non-neural clusters are abbreviated (MG Mueller glia, A astrocytes, F fibroblasts, P pericytes, E endothelium, M microglia). <bold>b</bold> Shekhar et al.<sup><xref ref-type="bibr" rid="CR25">25</xref></sup>, <italic>n</italic>&#x02009;=&#x02009;27,499 cells from the mouse retina, mostly bipolar cells. BC bipolar cell, RBC rod bipolar cell. Putative doublets/contaminants shown in grey. Yellow: rod and cone photoreceptors; cyan: amacrine cells. Some clusters appear to consist of two parts; this is due to an experimental batch effect that we did not remove. <bold>c</bold> Harris et al.<sup><xref ref-type="bibr" rid="CR26">26</xref></sup>, <italic>n</italic>&#x02009;=&#x02009;3663 hippocampal interneurons. Circles denote cluster centroids. The centroid of one cluster (<italic>Sst Cryab</italic>) is not shown because its cells were scattered all over the embedding (as they did in the original publication as well). Cluster labels not shown for visual clarity.</p></caption><graphic xlink:href="41467_2019_13056_Fig4_HTML" id="d29e1343"/></fig></p><p id="Par24">Second, we analysed a <italic>n</italic>&#x02009;=&#x02009;27,499 data set from ref. <sup><xref ref-type="bibr" rid="CR25">25</xref></sup> that sequenced cells from mouse retina targeting bipolar neurons. Here again, our t-SNE result (Fig.&#x000a0;<xref rid="Fig4" ref-type="fig">4</xref>b) is consistent with the global structure of the data: for example, OFF bipolar cells (types 1&#x02013;4, warm colours) and ON bipolar cells (types 5&#x02013;9, cold colours) are located close to each other, and four subtypes of type 5 are also close together. This was not true for the t-SNE shown in the original publication. This data set shows one limitation of our method: the data contain several very distinct but very rare clusters and those appear in the middle of the embedding, instead of being placed far out on the periphery (see Discussion).</p><p id="Par25">Finally, we analysed a <inline-formula id="IEq36"><alternatives><tex-math id="M71">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$n=3663$$\end{document}</tex-math><mml:math id="M72"><mml:mi>n</mml:mi><mml:mo>=</mml:mo><mml:mn>3663</mml:mn></mml:math><inline-graphic xlink:href="41467_2019_13056_Article_IEq36.gif"/></alternatives></inline-formula> data set of hippocampal interneurons from ref. <sup><xref ref-type="bibr" rid="CR26">26</xref></sup> . The original publication introduced a novel clustering and feature selection method based on the negative binomial distribution, and used a modified negative binomial t-SNE procedure. Our t-SNE visualisation (Fig.&#x000a0;<xref rid="Fig4" ref-type="fig">4</xref>c) did not use any of that but nevertheless led to an embedding very similar to the one shown in the original paper. Note that for data sets of this size, our method uses perplexity and learning rate that are close to the default ones.</p></sec><sec id="Sec5"><title>Positioning new points on an existing t-SNE atlas</title><p id="Par26">A common task in single-cell transcriptomics is to match a given cell to an existing reference data set. For example, introducing a protocol called Patch-seq, ref. <sup><xref ref-type="bibr" rid="CR27">27</xref></sup> performed patch-clamp electrophysiological recordings followed by RNA sequencing of inhibitory cells in layer 1 of mouse visual cortex. Given the existence of the much larger Tasic et al. data set described above, it is natural to ask where on the Fig.&#x000a0;<xref rid="Fig2" ref-type="fig">2</xref>f, taken as a reference atlas, these Patch-seq cells should be positioned.</p><p id="Par27">It is often claimed that t-SNE does not allow out-of-sample mapping, i.e. no new points can be put on a t-SNE atlas after it is constructed. What this means is that t-SNE is a nonparametric method that does not construct any mapping <inline-formula id="IEq37"><alternatives><tex-math id="M73">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${\mathrm{f}}({\boldsymbol{x}})$$\end{document}</tex-math><mml:math id="M74"><mml:mi mathvariant="normal">f</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi mathvariant="bold-italic">x</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:math><inline-graphic xlink:href="41467_2019_13056_Article_IEq37.gif"/></alternatives></inline-formula> from a high-dimensional to the low-dimensional space (parametric t-SNE is possible but is out of scope of this paper, see Discussion). Nevertheless, there is a straightforward way to position a new <inline-formula id="IEq38"><alternatives><tex-math id="M75">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${\boldsymbol{x}}$$\end{document}</tex-math><mml:math id="M76"><mml:mi mathvariant="bold-italic">x</mml:mi></mml:math><inline-graphic xlink:href="41467_2019_13056_Article_IEq38.gif"/></alternatives></inline-formula> on an existing t-SNE atlas. For each Cadwell et al. cell (<inline-formula id="IEq39"><alternatives><tex-math id="M77">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$n=46$$\end{document}</tex-math><mml:math id="M78"><mml:mi>n</mml:mi><mml:mo>=</mml:mo><mml:mn>46</mml:mn></mml:math><inline-graphic xlink:href="41467_2019_13056_Article_IEq39.gif"/></alternatives></inline-formula>), we found its <inline-formula id="IEq40"><alternatives><tex-math id="M79">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$k=10$$\end{document}</tex-math><mml:math id="M80"><mml:mi>k</mml:mi><mml:mo>=</mml:mo><mml:mn>10</mml:mn></mml:math><inline-graphic xlink:href="41467_2019_13056_Article_IEq40.gif"/></alternatives></inline-formula> nearest neighbours among the Tasic et al. reference cells, using Pearson correlation across the log-transformed counts of the most variable Tasic et al. genes as distance<sup><xref ref-type="bibr" rid="CR28">28</xref></sup>. Then we positioned the cell at the median t-SNE location of these <inline-formula id="IEq41"><alternatives><tex-math id="M81">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$k$$\end{document}</tex-math><mml:math id="M82"><mml:mi>k</mml:mi></mml:math><inline-graphic xlink:href="41467_2019_13056_Article_IEq41.gif"/></alternatives></inline-formula> reference cells (Fig.&#x000a0;<xref rid="Fig5" ref-type="fig">5</xref>a). The result agreed very well with the assignment of Cadwell et al. cells to the Tasic et al. clusters performed in ref. <sup><xref ref-type="bibr" rid="CR3">3</xref></sup>.<fig id="Fig5"><label>Fig. 5</label><caption><p>Out-of-sample mapping. <bold>a</bold> Interneurons from ref. <sup><xref ref-type="bibr" rid="CR27">27</xref></sup> positioned on the reference t-SNE atlas<sup><xref ref-type="bibr" rid="CR3">3</xref></sup> from Fig.&#x000a0;<xref rid="Fig2" ref-type="fig">2</xref>f. Only <italic>Vip/Lamp5</italic> continent from Fig.&#x000a0;<xref rid="Fig2" ref-type="fig">2</xref>f is shown here, as no cells mapped elsewhere. Cluster labels are given only for clusters where at least one cell mapped to. NGC neurogliaform cells; SBC single bouquet cells. Two cells out of 46 are not shown because they had an ambiguous class assignment. <bold>b</bold> A cross-validation approach: 100 random <italic>Vip/Lamp5</italic> cells from the Tasic et al. data set were removed from the t-SNE embedding and then positioned back on it using our method. Black dots show new positions, black lines connect them to the original t-SNE locations of the same cells. <bold>c</bold> Positioning uncertainty for several exemplary cells from panel <bold>a</bold>. Polygons are convex hulls covering 95% of bootstrap repetitions.</p></caption><graphic xlink:href="41467_2019_13056_Fig5_HTML" id="d29e1512"/></fig></p><p id="Par28">An important caveat is that this method assumes that for each new cell there are cells of the same type in the reference data set. Cells that do not have a good match in the reference data can end up positioned in a misleading way. However, this assumption is justified whenever cells are mapped to a comprehensive reference atlas covering the same tissue, as in the example case shown here.</p><p id="Par29">In a more sophisticated approach<sup><xref ref-type="bibr" rid="CR24">24</xref>,<xref ref-type="bibr" rid="CR29">29</xref>,<xref ref-type="bibr" rid="CR30">30</xref></sup>, each new cell is initially positioned as outlined above but then its position is optimised using the t-SNE loss function: the cell is attracted to its nearest neighbours in the reference set, with the effective number of nearest neighbours determined by the perplexity. We found that the simpler procedure without this additional optimisation step worked well for our data; the additional optimisation usually has only a minor effect<sup><xref ref-type="bibr" rid="CR30">30</xref></sup>.</p><p id="Par30">We can demonstrate the consistency of our method by a procedure similar to a leave-one-out cross-validation. We repeatedly removed one random Tasic et al. cell from the <italic>Vip/Lamp5</italic> clusters, and positioned it back on the same reference t-SNE atlas (excluding the same cell from the <inline-formula id="IEq42"><alternatives><tex-math id="M83">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$k=10$$\end{document}</tex-math><mml:math id="M84"><mml:mi>k</mml:mi><mml:mo>=</mml:mo><mml:mn>10</mml:mn></mml:math><inline-graphic xlink:href="41467_2019_13056_Article_IEq42.gif"/></alternatives></inline-formula> nearest neighbours). Across 100 repetitions, the average distance between the original cell location and the test positioning was <inline-formula id="IEq43"><alternatives><tex-math id="M85">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$3.2\pm 2.4$$\end{document}</tex-math><mml:math id="M86"><mml:mn>3.2</mml:mn><mml:mo>&#x000b1;</mml:mo><mml:mn>2.4</mml:mn></mml:math><inline-graphic xlink:href="41467_2019_13056_Article_IEq43.gif"/></alternatives></inline-formula> (mean<inline-formula id="IEq44"><alternatives><tex-math id="M87">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\pm$$\end{document}</tex-math><mml:math id="M88"><mml:mo>&#x000b1;</mml:mo></mml:math><inline-graphic xlink:href="41467_2019_13056_Article_IEq44.gif"/></alternatives></inline-formula>SD; see Fig.&#x000a0;<xref rid="Fig5" ref-type="fig">5</xref>b for a scale bar), and most test cells stayed within their clusters.</p><p id="Par31">Positioning uncertainty can be estimated using bootstrapping across genes (inspired by ref. <sup><xref ref-type="bibr" rid="CR3">3</xref></sup>). For each of the Patch-seq cells, we repeatedly selected a bootstrapped sample from the set of highly variable genes and repeated the positioning procedure (100 times). This yielded a set of bootstrapped mapping locations; the larger the variability in this set, the larger the uncertainty. To visualise the uncertainty, we show a convex hull covering 95% of the bootstrap repetitions (Fig.&#x000a0;<xref rid="Fig5" ref-type="fig">5</xref>c), which can be interpreted as a 2D confidence interval. A large polygon means high uncertainty; a small polygon means high precision. For some cells the polygons are so small that they are barely visible in Fig.&#x000a0;<xref rid="Fig5" ref-type="fig">5</xref>c. For some other cells the polygons are larger and sometimes spread across the border of two adjacent clusters. This suggests that the cluster assignments for these cells are not certain.</p></sec><sec id="Sec6"><title>Aligning two t-SNE visualisations</title><p id="Par32">Tasic et al.<sup><xref ref-type="bibr" rid="CR3">3</xref></sup> is a follow-up to Tasic et al.<sup><xref ref-type="bibr" rid="CR31">31</xref></sup> where <inline-formula id="IEq45"><alternatives><tex-math id="M89">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$n=1679$$\end{document}</tex-math><mml:math id="M90"><mml:mi>n</mml:mi><mml:mo>=</mml:mo><mml:mn>1679</mml:mn></mml:math><inline-graphic xlink:href="41467_2019_13056_Article_IEq45.gif"/></alternatives></inline-formula> cells from mouse visual cortex were sequenced with an earlier sequencing protocol. If one excludes from the new data set all clusters that have cells mostly from outside of the visual cortex, then the remaining data set has <inline-formula id="IEq46"><alternatives><tex-math id="M91">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$n=19,\!366$$\end{document}</tex-math><mml:math id="M92"><mml:mi>n</mml:mi><mml:mo>=</mml:mo><mml:mn>19</mml:mn><mml:mo>,</mml:mo><mml:mspace width="0.3em"/><mml:mn>366</mml:mn></mml:math><inline-graphic xlink:href="41467_2019_13056_Article_IEq46.gif"/></alternatives></inline-formula> cells. How similar is the cluster structure of this newer and larger data set compared to the older and smaller one? One way to approach this question is through aligned t-SNE visualisations.</p><p id="Par33">To obtain aligned t-SNE visualisations, we first performed t-SNE of the older&#x000a0;data set<sup><xref ref-type="bibr" rid="CR31">31</xref></sup> using PCA initialisation and perplexity 50 (Fig.&#x000a0;<xref rid="Fig6" ref-type="fig">6</xref>a). We then positioned cells of the newer&#x000a0;data set<sup><xref ref-type="bibr" rid="CR3">3</xref></sup> on this reference using the procedure described above and used the resulting layout as initialisation for t-SNE (with learning rate <inline-formula id="IEq47"><alternatives><tex-math id="M93">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$n/12$$\end{document}</tex-math><mml:math id="M94"><mml:mi>n</mml:mi><mml:mo>&#x02215;</mml:mo><mml:mn>12</mml:mn></mml:math><inline-graphic xlink:href="41467_2019_13056_Article_IEq47.gif"/></alternatives></inline-formula> and perplexity combination of 30 and <inline-formula id="IEq48"><alternatives><tex-math id="M95">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$n/100$$\end{document}</tex-math><mml:math id="M96"><mml:mi>n</mml:mi><mml:mo>&#x02215;</mml:mo><mml:mn>100</mml:mn></mml:math><inline-graphic xlink:href="41467_2019_13056_Article_IEq48.gif"/></alternatives></inline-formula>, as elsewhere). The resulting t-SNE embedding is aligned to the previous one (Fig.&#x000a0;<xref rid="Fig6" ref-type="fig">6</xref>b).<fig id="Fig6"><label>Fig. 6</label><caption><p>Aligned embeddings. <bold>a</bold> T-SNE visualisation of the data set&#x000a0;from ref. <sup><xref ref-type="bibr" rid="CR31">31</xref></sup>. Cluster assignments and cluster colours are taken from the original publication. Circles show cluster centroids. Numbers highlight some noteworthy cases, see text. <bold>b</bold> T-SNE visualisation of the data set&#x000a0;from ref. <sup><xref ref-type="bibr" rid="CR3">3</xref></sup> after excluding all clusters that mostly consisted of cells from anterior lateral motor cortex (23 clusters that had &#x0201c;ALM&#x0201d; in the cluster name). This t-SNE analysis was initialised by positioning all cells on the reference atlas from panel <bold>a</bold>, ensuring that the two panels are aligned with each other.</p></caption><graphic xlink:href="41467_2019_13056_Fig6_HTML" id="d29e1705"/></fig></p><p id="Par34">Several observations are highlighted in Fig.&#x000a0;<xref rid="Fig6" ref-type="fig">6</xref>. (1) and (2) are examples of well-isolated clusters in the 2016 data that remained well-isolated in the 2018 data (<italic>Sst Chodl</italic> and <italic>Pvalb Vipr2</italic>; here and below we use the 2018 nomenclature). (3) is an example of a small group of cells that was not assigned to a separate cluster back in 2016, became separate on the basis of the 2018 data, but in retrospect appears well-isolated already in the 2016 t-SNE plot (two <italic>L5 LP VISp Trhr</italic> clusters). Finally, (4) shows an example of several clusters in the 2016 data merging together into one cluster based on the 2018 data (<italic>L4 IT VISp Rspo1</italic>). These observations are in good correspondence with the conclusions of ref. <sup><xref ref-type="bibr" rid="CR3">3</xref></sup>, but we find that t-SNE adds a valuable perspective and allows for an intuitive comparison.</p></sec><sec id="Sec7"><title>Performing t-SNE on large data sets</title><p id="Par35">Large data sets with <inline-formula id="IEq49"><alternatives><tex-math id="M97">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$n\gg 100,000$$\end{document}</tex-math><mml:math id="M98"><mml:mi>n</mml:mi><mml:mo>&#x0226b;</mml:mo><mml:mn>100</mml:mn><mml:mo>,</mml:mo><mml:mn>000</mml:mn></mml:math><inline-graphic xlink:href="41467_2019_13056_Article_IEq49.gif"/></alternatives></inline-formula> present several additional challenges to those already discussed above. First, vanilla t-SNE<sup><xref ref-type="bibr" rid="CR9">9</xref></sup> is slow for <inline-formula id="IEq50"><alternatives><tex-math id="M99">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$n\gg 1000$$\end{document}</tex-math><mml:math id="M100"><mml:mi>n</mml:mi><mml:mo>&#x0226b;</mml:mo><mml:mn>1000</mml:mn></mml:math><inline-graphic xlink:href="41467_2019_13056_Article_IEq50.gif"/></alternatives></inline-formula> and computationally unfeasible for <inline-formula id="IEq51"><alternatives><tex-math id="M101">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$n\gg 10,\!000$$\end{document}</tex-math><mml:math id="M102"><mml:mi>n</mml:mi><mml:mo>&#x0226b;</mml:mo><mml:mn>10</mml:mn><mml:mo>,</mml:mo><mml:mspace width="0.3em"/><mml:mn>000</mml:mn></mml:math><inline-graphic xlink:href="41467_2019_13056_Article_IEq51.gif"/></alternatives></inline-formula> (see Methods). A widely used approximation called Barnes-Hut t-SNE<sup><xref ref-type="bibr" rid="CR32">32</xref></sup> in turn becomes very slow for <inline-formula id="IEq52"><alternatives><tex-math id="M103">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$n\gg 100,\!000$$\end{document}</tex-math><mml:math id="M104"><mml:mi>n</mml:mi><mml:mo>&#x0226b;</mml:mo><mml:mn>100</mml:mn><mml:mo>,</mml:mo><mml:mspace width="0.3em"/><mml:mn>000</mml:mn></mml:math><inline-graphic xlink:href="41467_2019_13056_Article_IEq52.gif"/></alternatives></inline-formula>. For larger data sets a faster approximation scheme is needed. This challenge was effectively solved by ref. <sup><xref ref-type="bibr" rid="CR16">16</xref></sup> who developed a novel t-SNE approximation called FIt-SNE, based on an interpolation scheme accelerated by the fast Fourier transform. Using FIt-SNE, we were able to process a data set with 1 million points and 50 dimensions (perplexity 30) in 29&#x02009;min on a computer with four 3.4&#x02009;GHz double-threaded cores, and in 11&#x02009;min on a server with twenty 2.2&#x02009;GHz double-threaded cores.</p><p id="Par36">Second, for <inline-formula id="IEq53"><alternatives><tex-math id="M105">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$n\gg 100,\!000$$\end{document}</tex-math><mml:math id="M106"><mml:mi>n</mml:mi><mml:mo>&#x0226b;</mml:mo><mml:mn>100</mml:mn><mml:mo>,</mml:mo><mml:mspace width="0.3em"/><mml:mn>000</mml:mn></mml:math><inline-graphic xlink:href="41467_2019_13056_Article_IEq53.gif"/></alternatives></inline-formula>, t-SNE with default optimisation parameters tends to produce poorly converged solutions and embeddings with continuous clusters fragmented into several parts. Various groups<sup><xref ref-type="bibr" rid="CR16">16</xref>,<xref ref-type="bibr" rid="CR23">23</xref></sup> have noticed that these problems can be alleviated by increasing the number of iterations, the length or strength of the early exaggeration (see Methods), or the learning rate. Ref. <sup><xref ref-type="bibr" rid="CR15">15</xref></sup> demonstrated in a thorough investigation that dramatically increasing the learning rate from the default value <inline-formula id="IEq54"><alternatives><tex-math id="M107">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\eta =200$$\end{document}</tex-math><mml:math id="M108"><mml:mi>&#x003b7;</mml:mi><mml:mo>=</mml:mo><mml:mn>200</mml:mn></mml:math><inline-graphic xlink:href="41467_2019_13056_Article_IEq54.gif"/></alternatives></inline-formula> to <inline-formula id="IEq55"><alternatives><tex-math id="M109">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\eta =n/12$$\end{document}</tex-math><mml:math id="M110"><mml:mi>&#x003b7;</mml:mi><mml:mo>=</mml:mo><mml:mi>n</mml:mi><mml:mo>&#x02215;</mml:mo><mml:mn>12</mml:mn></mml:math><inline-graphic xlink:href="41467_2019_13056_Article_IEq55.gif"/></alternatives></inline-formula> (where 12 is the early exaggeration coefficient<sup><xref ref-type="bibr" rid="CR33">33</xref></sup>) prevents cluster fragmentation during the early exaggeration phase and yields a well-converged solution within the default 1000 iterations.</p><p id="Par37">Third, for <inline-formula id="IEq56"><alternatives><tex-math id="M111">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$n\gg 100,\!000$$\end{document}</tex-math><mml:math id="M112"><mml:mi>n</mml:mi><mml:mo>&#x0226b;</mml:mo><mml:mn>100</mml:mn><mml:mo>,</mml:mo><mml:mspace width="0.3em"/><mml:mn>000</mml:mn></mml:math><inline-graphic xlink:href="41467_2019_13056_Article_IEq56.gif"/></alternatives></inline-formula>, t-SNE embeddings tend to become very crowded, with little white space even between well-separated clusters<sup><xref ref-type="bibr" rid="CR18">18</xref></sup>. The exact mathematical reason for this is not fully understood, but the intuition is that the default perplexity becomes too small compared to the sample size, repulsive forces begin to dominate, and clusters blow up and coalesce like adjacent soap bubbles. While so far there is no principled solution for this in the t-SNE framework, a very practical trick suggested by ref. <sup><xref ref-type="bibr" rid="CR34">34</xref></sup> is to increase the strength of all attractive forces by a small constant exaggeration factor between 1 and <inline-formula id="IEq57"><alternatives><tex-math id="M113">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\sim$$\end{document}</tex-math><mml:math id="M114"><mml:mo>~</mml:mo></mml:math><inline-graphic xlink:href="41467_2019_13056_Article_IEq57.gif"/></alternatives></inline-formula>10 (see Methods). This counteracts the expansion of the clusters.</p><p id="Par38">Fourth, our approach to preserve global geometry relies on using large perplexity <inline-formula id="IEq58"><alternatives><tex-math id="M115">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$n/100$$\end{document}</tex-math><mml:math id="M116"><mml:mi>n</mml:mi><mml:mo>&#x02215;</mml:mo><mml:mn>100</mml:mn></mml:math><inline-graphic xlink:href="41467_2019_13056_Article_IEq58.gif"/></alternatives></inline-formula> and becomes computationally unfeasible for <inline-formula id="IEq59"><alternatives><tex-math id="M117">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$n\gg 100,\!000$$\end{document}</tex-math><mml:math id="M118"><mml:mi>n</mml:mi><mml:mo>&#x0226b;</mml:mo><mml:mn>100</mml:mn><mml:mo>,</mml:mo><mml:mspace width="0.3em"/><mml:mn>000</mml:mn></mml:math><inline-graphic xlink:href="41467_2019_13056_Article_IEq59.gif"/></alternatives></inline-formula> because FIt-SNE runtime grows linearly with perplexity. For such sample sizes, the only practical possibility is to use perplexity values in the standard range 10&#x02013;100. To address this challenge, we make an assumption that global geometry should be detectable even after strong downsampling of the data set. This suggests the following pipeline: (i) downsample a large data set to some manageable size; (ii) run t-SNE on the subsample using our approach to preserve global geometry; (iii) position all the remaining points on the resulting t-SNE plot using nearest neighbours; (iv) use the result as initialisation to run t-SNE on the whole data set.</p><p id="Par39">We demonstrate these ideas using two currently largest scRNA-seq data sets. The first one is a 10x Genomics data set with <inline-formula id="IEq60"><alternatives><tex-math id="M119">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$n=1,\!306,\!127$$\end{document}</tex-math><mml:math id="M120"><mml:mi>n</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn><mml:mo>,</mml:mo><mml:mspace width="0.3em"/><mml:mn>306</mml:mn><mml:mo>,</mml:mo><mml:mspace width="0.3em"/><mml:mn>127</mml:mn></mml:math><inline-graphic xlink:href="41467_2019_13056_Article_IEq60.gif"/></alternatives></inline-formula> cells from mouse embryonic brain. We first created a t-SNE embedding of a randomly selected subset of <inline-formula id="IEq61"><alternatives><tex-math id="M121">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$n=25,\!000$$\end{document}</tex-math><mml:math id="M122"><mml:mi>n</mml:mi><mml:mo>=</mml:mo><mml:mn>25</mml:mn><mml:mo>,</mml:mo><mml:mspace width="0.3em"/><mml:mn>000</mml:mn></mml:math><inline-graphic xlink:href="41467_2019_13056_Article_IEq61.gif"/></alternatives></inline-formula> cells (Fig.&#x000a0;<xref rid="Fig7" ref-type="fig">7</xref>a). As above, we used PCA initialisation, perplexity combination of 30 and <inline-formula id="IEq62"><alternatives><tex-math id="M123">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$n/100=250$$\end{document}</tex-math><mml:math id="M124"><mml:mi>n</mml:mi><mml:mo>&#x02215;</mml:mo><mml:mn>100</mml:mn><mml:mo>=</mml:mo><mml:mn>250</mml:mn></mml:math><inline-graphic xlink:href="41467_2019_13056_Article_IEq62.gif"/></alternatives></inline-formula>, and learning rate <inline-formula id="IEq63"><alternatives><tex-math id="M125">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$n/12$$\end{document}</tex-math><mml:math id="M126"><mml:mi>n</mml:mi><mml:mo>&#x02215;</mml:mo><mml:mn>12</mml:mn></mml:math><inline-graphic xlink:href="41467_2019_13056_Article_IEq63.gif"/></alternatives></inline-formula>. We then positioned all the remaining cells on this t-SNE embedding using their nearest neighbours (here we used Euclidean distance in the PCA space, and <inline-formula id="IEq64"><alternatives><tex-math id="M127">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$k=10$$\end{document}</tex-math><mml:math id="M128"><mml:mi>k</mml:mi><mml:mo>=</mml:mo><mml:mn>10</mml:mn></mml:math><inline-graphic xlink:href="41467_2019_13056_Article_IEq64.gif"/></alternatives></inline-formula> as above; this took <inline-formula id="IEq65"><alternatives><tex-math id="M129">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\sim$$\end{document}</tex-math><mml:math id="M130"><mml:mo>~</mml:mo></mml:math><inline-graphic xlink:href="41467_2019_13056_Article_IEq65.gif"/></alternatives></inline-formula>10&#x02009;&#x000a0;min). Finally, we used the result as initialisation to run t-SNE on all points using perplexity 30, exaggeration coefficient 4, and learning rate <inline-formula id="IEq66"><alternatives><tex-math id="M131">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$n/12$$\end{document}</tex-math><mml:math id="M132"><mml:mi>n</mml:mi><mml:mo>&#x02215;</mml:mo><mml:mn>12</mml:mn></mml:math><inline-graphic xlink:href="41467_2019_13056_Article_IEq66.gif"/></alternatives></inline-formula> (Fig.&#x000a0;<xref rid="Fig7" ref-type="fig">7</xref>b).<fig id="Fig7"><label>Fig. 7</label><caption><p>10x Genomics data set. Sample size <inline-formula id="IEq67"><alternatives><tex-math id="M133">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$n=1,\!306,\!127$$\end{document}</tex-math><mml:math id="M134"><mml:mi>n</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn><mml:mo>,</mml:mo><mml:mspace width="0.3em"/><mml:mn>306</mml:mn><mml:mo>,</mml:mo><mml:mspace width="0.3em"/><mml:mn>127</mml:mn></mml:math><inline-graphic xlink:href="41467_2019_13056_Article_IEq67.gif"/></alternatives></inline-formula>. Cluster assignments and cluster colours are taken from ref. <sup><xref ref-type="bibr" rid="CR23">23</xref></sup>. <bold>a</bold> T-SNE of a random subsample of <inline-formula id="IEq68"><alternatives><tex-math id="M135">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$25,\!000$$\end{document}</tex-math><mml:math id="M136"><mml:mn>25</mml:mn><mml:mo>,</mml:mo><mml:mspace width="0.3em"/><mml:mn>000</mml:mn></mml:math><inline-graphic xlink:href="41467_2019_13056_Article_IEq68.gif"/></alternatives></inline-formula> cells (PCA initialisation, perplexity combination of 30 and 250, learning rate <inline-formula id="IEq69"><alternatives><tex-math id="M137">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$25,\!000/12$$\end{document}</tex-math><mml:math id="M138"><mml:mn>25</mml:mn><mml:mo>,</mml:mo><mml:mspace width="0.3em"/><mml:mn>000</mml:mn><mml:mo>&#x02215;</mml:mo><mml:mn>12</mml:mn></mml:math><inline-graphic xlink:href="41467_2019_13056_Article_IEq69.gif"/></alternatives></inline-formula>). Cluster labels for several small clusters (30, 35, 36, and 38) are not shown here and in <bold>b</bold> because these clusters were very dispersed in the embeddings. <bold>b</bold> T-SNE of the full data set. All cells were positioned on the embedding in panel <bold>a</bold> and this was used as initialisation. Perplexity 30, exaggeration 4, learning rate <inline-formula id="IEq70"><alternatives><tex-math id="M139">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$n/12$$\end{document}</tex-math><mml:math id="M140"><mml:mi>n</mml:mi><mml:mo>&#x02215;</mml:mo><mml:mn>12</mml:mn></mml:math><inline-graphic xlink:href="41467_2019_13056_Article_IEq70.gif"/></alternatives></inline-formula>. <bold>c</bold> The same as in <bold>b</bold> but without exaggeration. <bold>d</bold> The same as in <bold>b</bold> but with PCA initialisation, i.e. without using the downsampling step. <bold>e</bold> Default t-SNE with learning rate set to <inline-formula id="IEq71"><alternatives><tex-math id="M141">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\eta =1000$$\end{document}</tex-math><mml:math id="M142"><mml:mi>&#x003b7;</mml:mi><mml:mo>=</mml:mo><mml:mn>1000</mml:mn></mml:math><inline-graphic xlink:href="41467_2019_13056_Article_IEq71.gif"/></alternatives></inline-formula>: random initialisation, no exaggeration.</p></caption><graphic xlink:href="41467_2019_13056_Fig7_HTML" id="d29e2208"/></fig></p><p id="Par40">To validate this procedure, we identified meaningful biological structures in the embedding using developmental marker genes<sup><xref ref-type="bibr" rid="CR35">35</xref>&#x02013;<xref ref-type="bibr" rid="CR37">37</xref></sup>. The left part of the main continent is composed of radial glial cells expressing <italic>Aldoc</italic> and <italic>Slc1a3</italic> (Fig.&#x000a0;<xref rid="Fig8" ref-type="fig">8</xref>a). The neighbouring areas consist of neural progenitors (neuroblasts) expressing <italic>Eomes</italic>, previously known as <italic>Tbr2</italic> (Fig.&#x000a0;<xref rid="Fig8" ref-type="fig">8</xref>b). The right part of the main continent consists of mature excitatory neurons expressing pan-neuronal markers such as <italic>Stmn2</italic> and <italic>Tubb3</italic> (Fig.&#x000a0;<xref rid="Fig8" ref-type="fig">8</xref>c) but not expressing inhibitory neuron markers <italic>Gad1</italic> or <italic>Gad2</italic> (Fig.&#x000a0;<xref rid="Fig8" ref-type="fig">8</xref>d), whereas the upper part of the embedding is occupied by several inhibitory neuron clusters (Fig.&#x000a0;<xref rid="Fig8" ref-type="fig">8</xref>d). This confirms that our t-SNE embedding shows meaningful topology and is able to capture the developmental trajectories: from radial glia, to excitatory/inhibitory neural progenitors, to excitatory/inhibitory mature neurons.<fig id="Fig8"><label>Fig. 8</label><caption><p>Developmental marker genes. Overlay over t-SNE embeddings from Fig.&#x000a0;<xref rid="Fig7" ref-type="fig">7</xref>. <bold>a</bold> Expression of <italic>Aldoc</italic> gene (marker of radial glia) on the t-SNE embedding from Fig.&#x000a0;<xref rid="Fig7" ref-type="fig">7</xref>b. Any cell with <italic>Aldoc</italic> detected (UMI count above zero) was coloured in red. Another radial glia marker, <italic>Slc1a3</italic>, had similar but a bit broader expression. <bold>b</bold> Expression of <italic>Eomes</italic>, marker of neural progenitors (neuroblasts). <bold>c</bold> Expression of <italic>Stmn2</italic>, marker of mature neurons. A pan-neuronal marker <italic>Tubb3</italic> had similar but a bit broader expression. <bold>d</bold> Expression of <italic>Gad1</italic> and <italic>Gad2</italic> (either of them), markers of inhibitory neurons. <bold>e</bold>&#x02013;<bold>h</bold> The same genes overlayed over the default t-SNE embedding from Fig.&#x000a0;<xref rid="Fig7" ref-type="fig">7</xref>e.</p></caption><graphic xlink:href="41467_2019_13056_Fig8_HTML" id="d29e2320"/></fig></p><p id="Par41">We illustrate the importance of the components of our pipeline by a series of control experiments. Omitting exaggeration yielded over-expanded clusters and less discernible global structure (Fig.&#x000a0;<xref rid="Fig7" ref-type="fig">7</xref>c). Without downsampling, the global geometry was preserved worse (Fig.&#x000a0;<xref rid="Fig7" ref-type="fig">7</xref>d): e.g. most of the interneuron clusters are in the lower part of the figure, but clusters 17 and 19 (developing interneurons) are located in the upper part. Finally, the default t-SNE with random initialisation and no exaggeration (but learning rate set to <inline-formula id="IEq72"><alternatives><tex-math id="M143">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\eta =1000$$\end{document}</tex-math><mml:math id="M144"><mml:mi>&#x003b7;</mml:mi><mml:mo>=</mml:mo><mml:mn>1000</mml:mn></mml:math><inline-graphic xlink:href="41467_2019_13056_Article_IEq72.gif"/></alternatives></inline-formula>) yielded a poor embedding that fragmented some of the clusters and misrepresented global geometry (Fig.&#x000a0;<xref rid="Fig7" ref-type="fig">7</xref>e). Indeed, overlaying the same marker genes showed that developmental trajectories were not preserved and related groups of cells, e.g. interneurons, were dispersed across the embedding (Fig.&#x000a0;<xref rid="Fig8" ref-type="fig">8</xref>e&#x02013;h). Again, this is not a strawman: this embedding is qualitatively similar to the ones shown in the literature<sup><xref ref-type="bibr" rid="CR23">23</xref>,<xref ref-type="bibr" rid="CR38">38</xref></sup>.</p><p id="Par42">In addition, we analysed a data set encompassing <inline-formula id="IEq73"><alternatives><tex-math id="M145">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$n=2,\!058,652$$\end{document}</tex-math><mml:math id="M146"><mml:mi>n</mml:mi><mml:mo>=</mml:mo><mml:mn>2</mml:mn><mml:mo>,</mml:mo><mml:mspace width="0.3em"/><mml:mn>058</mml:mn><mml:mo>,</mml:mo><mml:mn>652</mml:mn></mml:math><inline-graphic xlink:href="41467_2019_13056_Article_IEq73.gif"/></alternatives></inline-formula> cells from mouse embryo at several developmental stages<sup><xref ref-type="bibr" rid="CR8">8</xref></sup>. The original publication showed a t-SNE embedding that we reproduced in Fig.&#x000a0;<xref rid="Fig9" ref-type="fig">9</xref>a. Whereas it showed a lot of structure, it visibly suffered from all the problems mentioned above: some clusters were fragmented into parts (e.g. clusters 13 and 15), there was little separation between distinct cell types, and global structure was grossly misrepresented. The authors annotated all clusters and split them into ten biologically meaningful developmental trajectories; these trajectories were intermingled in their embedding. In contrast, our t-SNE embedding (Fig.&#x000a0;<xref rid="Fig9" ref-type="fig">9</xref>b) neatly separated all ten developmental trajectories and arranged clusters within major trajectories in a meaningful developmental order: e.g. there was a continuous progression from radial glia (cluster 7), to neural progenitors (9), to postmitotic premature neurons (10), to mature excitatory (5) and inhibitory (15) neurons.<fig id="Fig9"><label>Fig. 9</label><caption><p>Cao et al. data set. Sample size <inline-formula id="IEq74"><alternatives><tex-math id="M147">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$n=2,\!058,\!652$$\end{document}</tex-math><mml:math id="M148"><mml:mi>n</mml:mi><mml:mo>=</mml:mo><mml:mn>2</mml:mn><mml:mo>,</mml:mo><mml:mspace width="0.3em"/><mml:mn>058</mml:mn><mml:mo>,</mml:mo><mml:mspace width="0.3em"/><mml:mn>652</mml:mn></mml:math><inline-graphic xlink:href="41467_2019_13056_Article_IEq74.gif"/></alternatives></inline-formula>. Cluster assignments and cluster colours are taken from the original publication<sup><xref ref-type="bibr" rid="CR8">8</xref></sup>. <bold>a</bold> T-SNE embedding from the original publication. The authors ran t-SNE in scanpy with default settings, i.e. with random initialisation, perplexity 30, and learning rate 1000. For cluster annotations, see original publication. <bold>b</bold> T-SNE embedding produced with our pipeline for large data sets: a random sample of <inline-formula id="IEq75"><alternatives><tex-math id="M149">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$25,\!000$$\end{document}</tex-math><mml:math id="M150"><mml:mn>25</mml:mn><mml:mo>,</mml:mo><mml:mspace width="0.3em"/><mml:mn>000</mml:mn></mml:math><inline-graphic xlink:href="41467_2019_13056_Article_IEq75.gif"/></alternatives></inline-formula> cells was embedded using PCA initialisation, learning rate <inline-formula id="IEq76"><alternatives><tex-math id="M151">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$25,\!000/12$$\end{document}</tex-math><mml:math id="M152"><mml:mn>25</mml:mn><mml:mo>,</mml:mo><mml:mspace width="0.3em"/><mml:mn>000</mml:mn><mml:mo>&#x02215;</mml:mo><mml:mn>12</mml:mn></mml:math><inline-graphic xlink:href="41467_2019_13056_Article_IEq76.gif"/></alternatives></inline-formula>, and perplexity combination of 30 and 250; all other cells were positioned on resulting embedding and this was used to initialise t-SNE with learning rate <inline-formula id="IEq77"><alternatives><tex-math id="M153">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$2,\!058,\!652/12$$\end{document}</tex-math><mml:math id="M154"><mml:mn>2</mml:mn><mml:mo>,</mml:mo><mml:mspace width="0.3em"/><mml:mn>058</mml:mn><mml:mo>,</mml:mo><mml:mspace width="0.3em"/><mml:mn>652</mml:mn><mml:mo>&#x02215;</mml:mo><mml:mn>12</mml:mn></mml:math><inline-graphic xlink:href="41467_2019_13056_Article_IEq77.gif"/></alternatives></inline-formula>, perplexity 30, and exaggeration 4. Labels correspond to the ten developmental trajectories identified in the original publication. Labels in capital letters denote trajectories consisting of multiple clusters. 32,011 putative doublet cells are not shown in either panel.</p></caption><graphic xlink:href="41467_2019_13056_Fig9_HTML" id="d29e2496"/></fig></p></sec><sec id="Sec8"><title>Comparison with UMAP</title><p id="Par43">A promising dimensionality reduction method called UMAP<sup><xref ref-type="bibr" rid="CR10">10</xref></sup> has recently attracted considerable attention in the transcriptomics community<sup><xref ref-type="bibr" rid="CR11">11</xref></sup>. Technically, UMAP is very similar to an earlier method called largeVis<sup><xref ref-type="bibr" rid="CR39">39</xref></sup>, but ref. <sup><xref ref-type="bibr" rid="CR10">10</xref></sup> provided a mathematical foundation and a convenient Python implementation. LargeVis and UMAP use the same attractive forces as t-SNE does, but change the nature of the repulsive forces and use a different, sampling-based approach to optimisation. UMAP has been claimed to be faster than t-SNE and to outperform it in terms of preserving the global structure of the data<sup><xref ref-type="bibr" rid="CR10">10</xref>,<xref ref-type="bibr" rid="CR11">11</xref></sup>.</p><p id="Par44">While UMAP is indeed much faster than Barnes-Hut t-SNE, FIt-SNE<sup><xref ref-type="bibr" rid="CR16">16</xref></sup> is at least as fast as UMAP. We found FIt-SNE 1.1 with default settings to be <inline-formula id="IEq78"><alternatives><tex-math id="M155">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\sim$$\end{document}</tex-math><mml:math id="M156"><mml:mo>~</mml:mo></mml:math><inline-graphic xlink:href="41467_2019_13056_Article_IEq78.gif"/></alternatives></inline-formula>4 times faster than UMAP 0.3 with default settings when analysing the 10x Genomics (14&#x000a0;m vs. 56&#x000a0;m) and the Cao et al. (31&#x02009;m vs. 126&#x02009;m) data sets on a server with twenty 2.2&#x02009;GHz double-threaded cores (for this experiment, the input dimensionality was 50 and the output dimensionality was 2; UMAP may be more competitive in other settings). That said, the exact runtime will depend on the details of implementation, and both methods may be further accelerated in future releases, or by using GPU parallelisation<sup><xref ref-type="bibr" rid="CR40">40</xref></sup>.</p><p id="Par45">To compare UMAP with our t-SNE approach in terms of preservation of global structure, we first ran UMAP on the synthetic and on the Tasic et al.<sup><xref ref-type="bibr" rid="CR3">3</xref></sup> data sets (Supplementary Fig.&#x000a0;<xref rid="MOESM1" ref-type="media">2</xref>). We used the default UMAP parameters, and also modified the two key parameters (number of neighbours and tightness of the embedding) to produce a more t-SNE-like embedding. In both cases and for both data sets, all three metrics (KNN, KNC, and CPD) were considerably lower than with our t-SNE approach. Notably, we observed that in some cases the global structure of UMAP embeddings strongly depended on the random seed. Next, we applied UMAP with default parameters to the 10x Genomics and the Cao et al. data sets. Here UMAP embeddings were qualitatively similar to our t-SNE embeddings, but arguably misrepresented some aspects of the global topology (Supplementary Fig.&#x000a0;<xref rid="MOESM1" ref-type="media">3</xref>).</p><p id="Par46">An in-depth comparison of t-SNE and UMAP is beyond the scope of our paper, but this analysis suggests that previous claims that UMAP vastly outperforms t-SNE<sup><xref ref-type="bibr" rid="CR11">11</xref></sup> might have been partially due to t-SNE being applied in a suboptimal way. Our analysis also indicates that UMAP does not necessarily solve t-SNE&#x02019;s problems out of the box and might require as many careful parameter and/or initialisation choices as t-SNE does. Many recommendations for running t-SNE that we made in this manuscript can likely be adapted for UMAP.</p></sec></sec><sec id="Sec9" sec-type="discussion"><title>Discussion</title><p id="Par47">The fact that t-SNE does not always preserve global structure is one of its well-known limitations<sup><xref ref-type="bibr" rid="CR12">12</xref></sup>. Indeed, the algorithm, by construction, only cares about preserving local neighbourhoods. We showed that using informative initialisation (such as PCA initialisation, or downsampling-based initialisation) can substantially improve the global structure of the final embedding because it survives through the optimisation process. Importantly, a custom initialisation does not interfere with t-SNE optimisation and does not yield a worse solution compared to a random initiliasation used by default (Fig.&#x000a0;<xref rid="Fig3" ref-type="fig">3</xref>a, b). A possible concern is that a custom initialisation might bias the resulting embedding by injecting some artefact global structure. However, if anything can be seen as injecting artefactual structure, it is rather the random initialisation: the global arrangement of clusters in a standard t-SNE embedding often strongly depends on the random seed.</p><p id="Par48">We also showed that using large perplexity values (<inline-formula id="IEq79"><alternatives><tex-math id="M157">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\sim$$\end{document}</tex-math><mml:math id="M158"><mml:mo>~</mml:mo></mml:math><inline-graphic xlink:href="41467_2019_13056_Article_IEq79.gif"/></alternatives></inline-formula>1% of the sample size)&#x02014;substantially larger than the commonly used ones&#x02014;can be useful in the scRNA-seq context. Our experiments suggest that whereas PCA initialisation helps preserving the macroscropic structure, large perplexity (either on its own or as part of a perplexity combination) helps preserving the mesoscopic structure (Fig.&#x000a0;<xref rid="Fig3" ref-type="fig">3</xref>d, f).</p><p id="Par49">It has recently been claimed that UMAP preserves the global geometry better than t-SNE<sup><xref ref-type="bibr" rid="CR11">11</xref></sup>. However, UMAP operates on the <inline-formula id="IEq80"><alternatives><tex-math id="M159">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$k$$\end{document}</tex-math><mml:math id="M160"><mml:mi>k</mml:mi></mml:math><inline-graphic xlink:href="41467_2019_13056_Article_IEq80.gif"/></alternatives></inline-formula>-nearest neighbour graph, exactly as t-SNE does, and is therefore not designed to preserve large distances any more than t-SNE. To give a specific example, ref. <sup><xref ref-type="bibr" rid="CR8">8</xref></sup>, performed both t-SNE and UMAP and observed that &#x0201c;unlike t-SNE, UMAP places related cell types near one another&#x0201d;. We demonstrated that this is largely because t-SNE parameters were not set appropriately. Simply using high learning rate <inline-formula id="IEq81"><alternatives><tex-math id="M161">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$n/12$$\end{document}</tex-math><mml:math id="M162"><mml:mi>n</mml:mi><mml:mo>&#x02215;</mml:mo><mml:mn>12</mml:mn></mml:math><inline-graphic xlink:href="41467_2019_13056_Article_IEq81.gif"/></alternatives></inline-formula> places related cell types near one another as well as UMAP does, and additionally using exaggeration factor <inline-formula id="IEq82"><alternatives><tex-math id="M163">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$4$$\end{document}</tex-math><mml:math id="M164"><mml:mn>4</mml:mn></mml:math><inline-graphic xlink:href="41467_2019_13056_Article_IEq82.gif"/></alternatives></inline-formula> separates clusters into more compact groups, similar to UMAP.</p><p id="Par50">T-SNE is often perceived as having only one free parameter to tune, perplexity. Under the hood, however, there are also various optimisation parameters (such as the learning rate, the number of iterations, early exaggeration factor, etc.) and we showed above that they can have a dramatic effect on the quality of the visualisation. Here we have argued that exaggeration can be used as another useful parameter when embedding large data sets. In addition, while the low-dimensional similarity kernel in t-SNE has traditionally been fixed as the t-distribution with <inline-formula id="IEq83"><alternatives><tex-math id="M165">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\nu =1$$\end{document}</tex-math><mml:math id="M166"><mml:mi>&#x003bd;</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:math><inline-graphic xlink:href="41467_2019_13056_Article_IEq83.gif"/></alternatives></inline-formula> degree of freedom, we showed in a parallel work that modifying <inline-formula id="IEq84"><alternatives><tex-math id="M167">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\nu$$\end{document}</tex-math><mml:math id="M168"><mml:mi>&#x003bd;</mml:mi></mml:math><inline-graphic xlink:href="41467_2019_13056_Article_IEq84.gif"/></alternatives></inline-formula> can uncover additional fine structure in the data<sup><xref ref-type="bibr" rid="CR41">41</xref></sup>.</p><p id="Par51">One may worry that this gives a researcher too many knobs to turn. However, here we gave clear guidelines on how to set these parameters for effective visualisations. As argued above and in ref. <sup><xref ref-type="bibr" rid="CR15">15</xref></sup>, setting the learning rate to <inline-formula id="IEq85"><alternatives><tex-math id="M169">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$n/12$$\end{document}</tex-math><mml:math id="M170"><mml:mi>n</mml:mi><mml:mo>&#x02215;</mml:mo><mml:mn>12</mml:mn></mml:math><inline-graphic xlink:href="41467_2019_13056_Article_IEq85.gif"/></alternatives></inline-formula> ensures good convergence and automatically takes care of the optimisation issues. Perplexity should be left at the default value 30 for very large data sets, but can be combined with <inline-formula id="IEq86"><alternatives><tex-math id="M171">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$n/100$$\end{document}</tex-math><mml:math id="M172"><mml:mi>n</mml:mi><mml:mo>&#x02215;</mml:mo><mml:mn>100</mml:mn></mml:math><inline-graphic xlink:href="41467_2019_13056_Article_IEq86.gif"/></alternatives></inline-formula> for smaller data sets. Exaggeration can be increased to <inline-formula id="IEq87"><alternatives><tex-math id="M173">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\sim$$\end{document}</tex-math><mml:math id="M174"><mml:mo>~</mml:mo></mml:math><inline-graphic xlink:href="41467_2019_13056_Article_IEq87.gif"/></alternatives></inline-formula>4 for very large data sets, but is not needed for smaller data sets.</p><p id="Par52">In comparison, UMAP has two main adjustable parameters (and many further optimisation parameters): n_neighbors, corresponding to perplexity, and min_dist, controlling how tight the clusters become. The latter parameter sets the shape of the low-dimensional similarity kernel<sup><xref ref-type="bibr" rid="CR10">10</xref></sup> and is therefore analogous to <inline-formula id="IEq88"><alternatives><tex-math id="M175">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\nu$$\end{document}</tex-math><mml:math id="M176"><mml:mi>&#x003bd;</mml:mi></mml:math><inline-graphic xlink:href="41467_2019_13056_Article_IEq88.gif"/></alternatives></inline-formula> mentioned above. Our experiments with UMAP suggest that its repulsive forces roughly correspond to t-SNE with exaggeration <inline-formula id="IEq89"><alternatives><tex-math id="M177">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\sim$$\end{document}</tex-math><mml:math id="M178"><mml:mo>~</mml:mo></mml:math><inline-graphic xlink:href="41467_2019_13056_Article_IEq89.gif"/></alternatives></inline-formula>4 (Supplementary Figs.&#x000a0;<xref rid="MOESM1" ref-type="media">2</xref>, <xref rid="MOESM1" ref-type="media">3</xref>). Whether this is desirable, depends on the application. With t-SNE, one can choose to switch exaggeration off and e.g. use the embedding shown in Fig.&#x000a0;<xref rid="Fig7" ref-type="fig">7</xref>c instead of Fig.&#x000a0;<xref rid="Fig7" ref-type="fig">7</xref>b.</p><p id="Par53">Several variants of t-SNE have been recently proposed in the literature. One important example is parametric t-SNE, where a neural network is used to create a mapping <inline-formula id="IEq90"><alternatives><tex-math id="M179">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${\mathrm{f}}({\boldsymbol{x}})$$\end{document}</tex-math><mml:math id="M180"><mml:mi mathvariant="normal">f</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi mathvariant="bold-italic">x</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:math><inline-graphic xlink:href="41467_2019_13056_Article_IEq90.gif"/></alternatives></inline-formula> from high-dimensional input space to two dimensions and is trained using standard deep learning techniques to yield an optimal t-SNE result<sup><xref ref-type="bibr" rid="CR42">42</xref></sup>. Parametric t-SNE has been recently applied to transcriptomic data under the names net-SNE<sup><xref ref-type="bibr" rid="CR43">43</xref></sup> and scvis<sup><xref ref-type="bibr" rid="CR44">44</xref></sup>. The latter method combined parametric t-SNE with a variational autoencoder, and was claimed to yield more interpretable visualisations than standard t-SNE due to better preserving the global structure. Indeed, the network architecture limits the form that the mapping <inline-formula id="IEq91"><alternatives><tex-math id="M181">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${\mathrm{f}}({\boldsymbol{x}})$$\end{document}</tex-math><mml:math id="M182"><mml:mi mathvariant="normal">f</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi mathvariant="bold-italic">x</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:math><inline-graphic xlink:href="41467_2019_13056_Article_IEq91.gif"/></alternatives></inline-formula> can take; this implicit constraint on the complexity of the mapping prevents similar clusters from ending up in very different parts of the resulting embedding. Also, in this approach the most appropriate perplexity does not need to grow with the sample size, as long as the mini-batch size remains constant. By default scvis uses mini-batch size of 512 and perplexity 10, which likely corresponds to the effective perplexity of <inline-formula id="IEq92"><alternatives><tex-math id="M183">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$10/512\cdot n$$\end{document}</tex-math><mml:math id="M184"><mml:mn>10</mml:mn><mml:mo>&#x02215;</mml:mo><mml:mn>512</mml:mn><mml:mo>&#x022c5;</mml:mo><mml:mi>n</mml:mi></mml:math><inline-graphic xlink:href="41467_2019_13056_Article_IEq92.gif"/></alternatives></inline-formula>, i.e. <inline-formula id="IEq93"><alternatives><tex-math id="M185">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\sim$$\end{document}</tex-math><mml:math id="M186"><mml:mo>~</mml:mo></mml:math><inline-graphic xlink:href="41467_2019_13056_Article_IEq93.gif"/></alternatives></inline-formula>2% of the sample size, similar to our 1% suggestion here.</p><p id="Par54">Another important development is hierarchical t-SNE, or HSNE<sup><xref ref-type="bibr" rid="CR45">45</xref></sup>. The key idea is to use random walks on the <inline-formula id="IEq94"><alternatives><tex-math id="M187">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$k$$\end{document}</tex-math><mml:math id="M188"><mml:mi>k</mml:mi></mml:math><inline-graphic xlink:href="41467_2019_13056_Article_IEq94.gif"/></alternatives></inline-formula>-nearest neighbours graph of the data to find a smaller set of landmarks, which are points that can serve as representatives of the surrounding points. In the next round, the <inline-formula id="IEq95"><alternatives><tex-math id="M189">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$k$$\end{document}</tex-math><mml:math id="M190"><mml:mi>k</mml:mi></mml:math><inline-graphic xlink:href="41467_2019_13056_Article_IEq95.gif"/></alternatives></inline-formula>-nearest neighbours graph on the level of landmarks is constructed. This operation can reduce the size of the data set by an order of magnitude, and can be repeated until the data set becomes small enough to be analysed with t-SNE. Each level of the landmarks hierarchy can be explored separately. Ref. <sup><xref ref-type="bibr" rid="CR18">18</xref></sup> successfully applied this method to mass cytometry data sets with up to 15 million cells. However, HSNE does not allow to embed all <inline-formula id="IEq96"><alternatives><tex-math id="M191">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$n$$\end{document}</tex-math><mml:math id="M192"><mml:mi>n</mml:mi></mml:math><inline-graphic xlink:href="41467_2019_13056_Article_IEq96.gif"/></alternatives></inline-formula> points in a way that would preserve the geometry on the level of landmarks.</p><p id="Par55">Our approach to preserving global geometry of the data is based on using PCA initialisation and large perplexity values. It can fail if some aspects of the global geometry are not adequately captured in the first two PCs or by the similarities computed using a large perplexity. This may happen when the data set contains very isolated but rare cell types. Indeed, a small isolated cluster might not appear isolated in the first two PCs because it would not have enough cells to contribute much to the explained variance. At the same time, large perplexity will make the points in that cluster be attracted to some arbitrary, unrelated, clusters. As a result, a small cluster can get sucked into the middle of the embedding even if it is initialised on the periphery.</p><p id="Par56">This is what happened in the Shekhar et al. data set (Fig.&#x000a0;<xref rid="Fig4" ref-type="fig">4</xref>b): cone and rod photoreceptor (yellow) and amacrine cell (cyan) clusters ended up in the middle of the embedding despite being very different from all the bipolar cell clusters. This can be seen in the MDS embedding of the cluster means which is unaffected by the relative abundances of the clusters; thus, when t-SNE is done together with clustering, we recommend to supplement a t-SNE visualisation with a MDS visualisation of cluster means (as in Fig.&#x000a0;<xref rid="Fig2" ref-type="fig">2</xref>a). Alternatively, one could use PAGA<sup><xref ref-type="bibr" rid="CR46">46</xref></sup>, a recent method specifically designed to visualise the relationships between clusters in scRNA-seq data.</p><p id="Par57">This example highlights that our approach is not a final solution to preserving the global structure of the data. A principled approach would incorporate some terms ensuring adequate global geometry directly into the loss function, while making sure that the resulting algorithm is scalable to millions of points. We consider it an important direction for future work. In the meantime, we believe that our recommendations will strongly improve t-SNE visualisations used in the current single-cell transcriptomic studies, and may be useful in other application domains as well.</p></sec><sec id="Sec10"><title>Methods</title><sec id="Sec11"><title>The t-SNE loss function</title><p id="Par58">The t-SNE algorithm<sup><xref ref-type="bibr" rid="CR9">9</xref></sup> is based on the SNE framework<sup><xref ref-type="bibr" rid="CR47">47</xref></sup>. SNE introduced a notion of directional similarity of point <inline-formula id="IEq97"><alternatives><tex-math id="M193">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$j$$\end{document}</tex-math><mml:math id="M194"><mml:mi>j</mml:mi></mml:math><inline-graphic xlink:href="41467_2019_13056_Article_IEq97.gif"/></alternatives></inline-formula> to point <inline-formula id="IEq98"><alternatives><tex-math id="M195">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$i$$\end{document}</tex-math><mml:math id="M196"><mml:mi>i</mml:mi></mml:math><inline-graphic xlink:href="41467_2019_13056_Article_IEq98.gif"/></alternatives></inline-formula>,<disp-formula id="Equ1"><label>1</label><alternatives><tex-math id="M197">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${p}_{j| i}={{\exp (-\parallel {{\bf{x}}}_{i}-{{\bf{x}}}_{j}{\parallel }^{2}/2{\sigma }_{i}^{2})}\over{{\sum }_{k\ne i}\exp (-\parallel {{\bf{x}}}_{i}-{{\bf{x}}}_{k}{\parallel }^{2}/2{\sigma }_{i}^{2})}},$$\end{document}</tex-math><mml:math id="M198"><mml:msub><mml:mrow><mml:mi>p</mml:mi></mml:mrow><mml:mrow><mml:mi>j</mml:mi><mml:mo>&#x02223;</mml:mo><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:mi>exp</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mo>&#x02212;</mml:mo><mml:mo>&#x02225;</mml:mo><mml:msub><mml:mrow><mml:mi mathvariant="bold">x</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>&#x02212;</mml:mo><mml:msub><mml:mrow><mml:mi mathvariant="bold">x</mml:mi></mml:mrow><mml:mrow><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:msup><mml:mrow><mml:mo>&#x02225;</mml:mo></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup><mml:mo>&#x02215;</mml:mo><mml:mn>2</mml:mn><mml:msubsup><mml:mrow><mml:mi>&#x003c3;</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msubsup></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mo mathsize="big">&#x02211;</mml:mo></mml:mrow><mml:mrow><mml:mi>k</mml:mi><mml:mo>&#x02260;</mml:mo><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mi>exp</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mo>&#x02212;</mml:mo><mml:mo>&#x02225;</mml:mo><mml:msub><mml:mrow><mml:mi mathvariant="bold">x</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>&#x02212;</mml:mo><mml:msub><mml:mrow><mml:mi mathvariant="bold">x</mml:mi></mml:mrow><mml:mrow><mml:mi>k</mml:mi></mml:mrow></mml:msub><mml:msup><mml:mrow><mml:mo>&#x02225;</mml:mo></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup><mml:mo>&#x02215;</mml:mo><mml:mn>2</mml:mn><mml:msubsup><mml:mrow><mml:mi>&#x003c3;</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msubsup></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mfrac><mml:mo>,</mml:mo></mml:math><graphic xlink:href="41467_2019_13056_Article_Equ1.gif" position="anchor"/></alternatives></disp-formula>defining, for every given point <inline-formula id="IEq99"><alternatives><tex-math id="M199">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$i$$\end{document}</tex-math><mml:math id="M200"><mml:mi>i</mml:mi></mml:math><inline-graphic xlink:href="41467_2019_13056_Article_IEq99.gif"/></alternatives></inline-formula>, a probability distribution over all points <inline-formula id="IEq100"><alternatives><tex-math id="M201">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$j\ne i$$\end{document}</tex-math><mml:math id="M202"><mml:mi>j</mml:mi><mml:mo>&#x02260;</mml:mo><mml:mi>i</mml:mi></mml:math><inline-graphic xlink:href="41467_2019_13056_Article_IEq100.gif"/></alternatives></inline-formula> (all <inline-formula id="IEq101"><alternatives><tex-math id="M203">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${p}_{i| i}$$\end{document}</tex-math><mml:math id="M204"><mml:msub><mml:mrow><mml:mi>p</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mo>&#x02223;</mml:mo><mml:mi>i</mml:mi></mml:mrow></mml:msub></mml:math><inline-graphic xlink:href="41467_2019_13056_Article_IEq101.gif"/></alternatives></inline-formula> are set to zero). The variance of the Gaussian kernel <inline-formula id="IEq102"><alternatives><tex-math id="M205">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${\sigma }_{i}^{2}$$\end{document}</tex-math><mml:math id="M206"><mml:msubsup><mml:mrow><mml:mi>&#x003c3;</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msubsup></mml:math><inline-graphic xlink:href="41467_2019_13056_Article_IEq102.gif"/></alternatives></inline-formula> is chosen such that the perplexity of this probability distribution<disp-formula id="Equ2"><label>2</label><alternatives><tex-math id="M207">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${{\mathcal{P}}}_{i}=\exp \left(-\log(2)\cdot \sum _{j\ne i}{p}_{j| i}{\mathrm{log}}_{2}{p}_{j| i}\right)$$\end{document}</tex-math><mml:math id="M208"><mml:msub><mml:mrow><mml:mi class="MJX-tex-caligraphic" mathvariant="script">P</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mi>exp</mml:mi><mml:mfenced close=")" open="(" separators=""><mml:mrow><mml:mo>&#x02212;</mml:mo><mml:mi>log</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mn>2</mml:mn></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>&#x022c5;</mml:mo><mml:munder><mml:mrow><mml:mo mathsize="big">&#x02211;</mml:mo></mml:mrow><mml:mrow><mml:mi>j</mml:mi><mml:mo>&#x02260;</mml:mo><mml:mi>i</mml:mi></mml:mrow></mml:munder><mml:msub><mml:mrow><mml:mi>p</mml:mi></mml:mrow><mml:mrow><mml:mi>j</mml:mi><mml:mo>&#x02223;</mml:mo><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:msub><mml:mrow><mml:mi mathvariant="normal">log</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msub><mml:msub><mml:mrow><mml:mi>p</mml:mi></mml:mrow><mml:mrow><mml:mi>j</mml:mi><mml:mo>&#x02223;</mml:mo><mml:mi>i</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mfenced></mml:math><graphic xlink:href="41467_2019_13056_Article_Equ2.gif" position="anchor"/></alternatives></disp-formula>has some pre-specified value. The larger the perplexity, the larger the variance of the kernel, with the largest possible perplexity value equal to <inline-formula id="IEq103"><alternatives><tex-math id="M209">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$n-1$$\end{document}</tex-math><mml:math id="M210"><mml:mi>n</mml:mi><mml:mo>&#x02212;</mml:mo><mml:mn>1</mml:mn></mml:math><inline-graphic xlink:href="41467_2019_13056_Article_IEq103.gif"/></alternatives></inline-formula> corresponding to <inline-formula id="IEq104"><alternatives><tex-math id="M211">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${\sigma }_{i}^{2}=\infty$$\end{document}</tex-math><mml:math id="M212"><mml:msubsup><mml:mrow><mml:mi>&#x003c3;</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msubsup><mml:mo>=</mml:mo><mml:mi>&#x0221e;</mml:mi></mml:math><inline-graphic xlink:href="41467_2019_13056_Article_IEq104.gif"/></alternatives></inline-formula> and the uniform probability distribution (<inline-formula id="IEq105"><alternatives><tex-math id="M213">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$n$$\end{document}</tex-math><mml:math id="M214"><mml:mi>n</mml:mi></mml:math><inline-graphic xlink:href="41467_2019_13056_Article_IEq105.gif"/></alternatives></inline-formula> is the number of points in the data set). Importantly, for any given perplexity value <inline-formula id="IEq106"><alternatives><tex-math id="M215">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${\mathcal{P}}$$\end{document}</tex-math><mml:math id="M216"><mml:mi class="MJX-tex-caligraphic" mathvariant="script">P</mml:mi></mml:math><inline-graphic xlink:href="41467_2019_13056_Article_IEq106.gif"/></alternatives></inline-formula>, all but <inline-formula id="IEq107"><alternatives><tex-math id="M217">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\sim {\mathcal{P}}$$\end{document}</tex-math><mml:math id="M218"><mml:mo>~</mml:mo><mml:mi class="MJX-tex-caligraphic" mathvariant="script">P</mml:mi></mml:math><inline-graphic xlink:href="41467_2019_13056_Article_IEq107.gif"/></alternatives></inline-formula> nearest neighbours of point <inline-formula id="IEq108"><alternatives><tex-math id="M219">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$i$$\end{document}</tex-math><mml:math id="M220"><mml:mi>i</mml:mi></mml:math><inline-graphic xlink:href="41467_2019_13056_Article_IEq108.gif"/></alternatives></inline-formula> will have <inline-formula id="IEq109"><alternatives><tex-math id="M221">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${p}_{j| i}$$\end{document}</tex-math><mml:math id="M222"><mml:msub><mml:mrow><mml:mi>p</mml:mi></mml:mrow><mml:mrow><mml:mi>j</mml:mi><mml:mo>&#x02223;</mml:mo><mml:mi>i</mml:mi></mml:mrow></mml:msub></mml:math><inline-graphic xlink:href="41467_2019_13056_Article_IEq109.gif"/></alternatives></inline-formula> very close to zero. For mathematical and computational convenience, symmetric SNE defined undirectional similarities<disp-formula id="Equ3"><label>3</label><alternatives><tex-math id="M223">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${p}_{ij}={{{p}_{i| j}+{p}_{j| i}}\over{2n}},$$\end{document}</tex-math><mml:math id="M224"><mml:msub><mml:mrow><mml:mi>p</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:msub><mml:mrow><mml:mi>p</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mo>&#x02223;</mml:mo><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:msub><mml:mrow><mml:mi>p</mml:mi></mml:mrow><mml:mrow><mml:mi>j</mml:mi><mml:mo>&#x02223;</mml:mo><mml:mi>i</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mrow><mml:mn>2</mml:mn><mml:mi>n</mml:mi></mml:mrow></mml:mfrac><mml:mo>,</mml:mo></mml:math><graphic xlink:href="41467_2019_13056_Article_Equ3.gif" position="anchor"/></alternatives></disp-formula>such that <inline-formula id="IEq110"><alternatives><tex-math id="M225">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${\sum }_{i,j}{p}_{ij}=1$$\end{document}</tex-math><mml:math id="M226"><mml:msub><mml:mrow><mml:mo>&#x02211;</mml:mo></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mo>,</mml:mo><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:msub><mml:mrow><mml:mi>p</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:math><inline-graphic xlink:href="41467_2019_13056_Article_IEq110.gif"/></alternatives></inline-formula>, i.e. this is a valid probability distribution on the set of all pairs <inline-formula id="IEq111"><alternatives><tex-math id="M227">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$(i,j)$$\end{document}</tex-math><mml:math id="M228"><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>i</mml:mi><mml:mo>,</mml:mo><mml:mi>j</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:math><inline-graphic xlink:href="41467_2019_13056_Article_IEq111.gif"/></alternatives></inline-formula>.</p><p id="Par59">The main idea of SNE and its modifications is to arrange the <inline-formula id="IEq112"><alternatives><tex-math id="M229">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$n$$\end{document}</tex-math><mml:math id="M230"><mml:mi>n</mml:mi></mml:math><inline-graphic xlink:href="41467_2019_13056_Article_IEq112.gif"/></alternatives></inline-formula> points in a low-dimensional space such that the similarities <inline-formula id="IEq113"><alternatives><tex-math id="M231">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${q}_{ij}$$\end{document}</tex-math><mml:math id="M232"><mml:msub><mml:mrow><mml:mi>q</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mi>j</mml:mi></mml:mrow></mml:msub></mml:math><inline-graphic xlink:href="41467_2019_13056_Article_IEq113.gif"/></alternatives></inline-formula> between low-dimensional points match <inline-formula id="IEq114"><alternatives><tex-math id="M233">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${p}_{ij}$$\end{document}</tex-math><mml:math id="M234"><mml:msub><mml:mrow><mml:mi>p</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mi>j</mml:mi></mml:mrow></mml:msub></mml:math><inline-graphic xlink:href="41467_2019_13056_Article_IEq114.gif"/></alternatives></inline-formula> as close as possible in terms of the Kullback-Leibler divergence. The loss function is thus<disp-formula id="Equ4"><label>4</label><alternatives><tex-math id="M235">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${\cal{L}}=\sum _{i,j}{p}_{ij}\log{{{p}_{ij}}\over{{q}_{ij}}}.$$\end{document}</tex-math><mml:math id="M236"><mml:mi class="MJX-tex-caligraphic" mathvariant="script">L</mml:mi><mml:mo>=</mml:mo><mml:munder><mml:mrow><mml:mo mathsize="big"> &#x02211;</mml:mo></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mo>,</mml:mo><mml:mi>j</mml:mi></mml:mrow></mml:munder><mml:msub><mml:mrow><mml:mi>p</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mi>log</mml:mi><mml:mfrac><mml:mrow><mml:msub><mml:mrow><mml:mi>p</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mi>j</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mi>q</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mi>j</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mfrac><mml:mo>.</mml:mo></mml:math><graphic xlink:href="41467_2019_13056_Article_Equ4.gif" position="anchor"/></alternatives></disp-formula></p><p id="Par60">The main idea of t-SNE was to use a t-distribution with one degree of freedom (also known as Cauchy distribution) as the low-dimensional similarity kernel:<disp-formula id="Equ5"><label>5</label><alternatives><tex-math id="M237">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${q}_{ij}={{{w}_{ij}}\over{Z}},\ {w}_{ij}={1\over{1+\| {{\bf{y}}}_{i}-{{\bf{y}}}_{j}{\| }^{2}}},\ Z=\sum _{k\ne l}{w}_{kl},$$\end{document}</tex-math><mml:math id="M238"><mml:msub><mml:mrow><mml:mi>q</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:msub><mml:mrow><mml:mi>w</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mi>j</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mrow><mml:mi>Z</mml:mi></mml:mrow></mml:mfrac><mml:mo>,</mml:mo><mml:mspace width="0.33em"/><mml:msub><mml:mrow><mml:mi>w</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mn>1</mml:mn><mml:mo>+</mml:mo><mml:mo>&#x02225;</mml:mo><mml:msub><mml:mrow><mml:mi mathvariant="bold">y</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>&#x02212;</mml:mo><mml:msub><mml:mrow><mml:mi mathvariant="bold">y</mml:mi></mml:mrow><mml:mrow><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:msup><mml:mrow><mml:mo>&#x02225;</mml:mo></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup></mml:mrow></mml:mfrac><mml:mo>,</mml:mo><mml:mspace width="0.33em"/><mml:mi>Z</mml:mi><mml:mo>=</mml:mo><mml:munder><mml:mrow><mml:mo mathsize="big"> &#x02211;</mml:mo></mml:mrow><mml:mrow><mml:mi>k</mml:mi><mml:mo>&#x02260;</mml:mo><mml:mi>l</mml:mi></mml:mrow></mml:munder><mml:msub><mml:mrow><mml:mi>w</mml:mi></mml:mrow><mml:mrow><mml:mi>k</mml:mi><mml:mi>l</mml:mi></mml:mrow></mml:msub><mml:mo>,</mml:mo></mml:math><graphic xlink:href="41467_2019_13056_Article_Equ5.gif" position="anchor"/></alternatives></disp-formula>where <inline-formula id="IEq115"><alternatives><tex-math id="M239">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${{\bf{y}}}_{i}$$\end{document}</tex-math><mml:math id="M240"><mml:msub><mml:mrow><mml:mi mathvariant="bold">y</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub></mml:math><inline-graphic xlink:href="41467_2019_13056_Article_IEq115.gif"/></alternatives></inline-formula> are low-dimensional coordinates (and <inline-formula id="IEq116"><alternatives><tex-math id="M241">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${q}_{ii}=0$$\end{document}</tex-math><mml:math id="M242"><mml:msub><mml:mrow><mml:mi>q</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mn>0</mml:mn></mml:math><inline-graphic xlink:href="41467_2019_13056_Article_IEq116.gif"/></alternatives></inline-formula>). As a matter of definition, we consider any method that uses the t-distribution as the output kernel and Kullback-Leibler divergence as the loss function to be t-SNE; similarities <inline-formula id="IEq117"><alternatives><tex-math id="M243">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${p}_{j| i}$$\end{document}</tex-math><mml:math id="M244"><mml:msub><mml:mrow><mml:mi>p</mml:mi></mml:mrow><mml:mrow><mml:mi>j</mml:mi><mml:mo>&#x02223;</mml:mo><mml:mi>i</mml:mi></mml:mrow></mml:msub></mml:math><inline-graphic xlink:href="41467_2019_13056_Article_IEq117.gif"/></alternatives></inline-formula> can in principle be computed using non-Euclidean distances instead of <inline-formula id="IEq118"><alternatives><tex-math id="M245">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\| {{\bf{x}}}_{i}-{{\bf{x}}}_{j}\|$$\end{document}</tex-math><mml:math id="M246"><mml:mo>&#x02225;</mml:mo><mml:msub><mml:mrow><mml:mi mathvariant="bold">x</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>&#x02212;</mml:mo><mml:msub><mml:mrow><mml:mi mathvariant="bold">x</mml:mi></mml:mrow><mml:mrow><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mo>&#x02225;</mml:mo></mml:math><inline-graphic xlink:href="41467_2019_13056_Article_IEq118.gif"/></alternatives></inline-formula> or can use non-perplexity-based calibrations.</p><p id="Par61">To justify our intuitive explanation in terms of attractive and repulsive forces, we can rewrite the loss function as follows:<disp-formula id="Equ6"><label>6</label><alternatives><tex-math id="M247">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${\cal{L}}=\sum _{i,j}{p}_{ij}\log {{{p}_{ij}}\over {{q}_{ij}}}=\,{\text{const}}\,-\sum _{i,j}{p}_{ij}{\mathrm{log}}{q}_{ij},$$\end{document}</tex-math><mml:math id="M248"><mml:mi class="MJX-tex-caligraphic" mathvariant="script">L</mml:mi><mml:mo>=</mml:mo><mml:munder><mml:mrow><mml:mo mathsize="big"> &#x02211;</mml:mo></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mo>,</mml:mo><mml:mi>j</mml:mi></mml:mrow></mml:munder><mml:msub><mml:mrow><mml:mi>p</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mi>log</mml:mi><mml:mfrac><mml:mrow><mml:msub><mml:mrow><mml:mi>p</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mi>j</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mi>q</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mi>j</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mfrac><mml:mo>=</mml:mo><mml:mspace width="0.25em"/><mml:mi mathvariant="normal">const</mml:mi><mml:mspace width="0.25em"/><mml:mo>&#x02212;</mml:mo><mml:munder><mml:mrow><mml:mo mathsize="big">&#x02211;</mml:mo></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mo>,</mml:mo><mml:mi>j</mml:mi></mml:mrow></mml:munder><mml:msub><mml:mrow><mml:mi>p</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mi mathvariant="normal">log</mml:mi><mml:msub><mml:mrow><mml:mi>q</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mo>,</mml:mo></mml:math><graphic xlink:href="41467_2019_13056_Article_Equ6.gif" position="anchor"/></alternatives></disp-formula>and dropping the constant,<disp-formula id="Equ7"><label>7</label><alternatives><tex-math id="M249">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$- \sum_{i,j} {p}_{ij}\log {{w}_{ij}\over{Z}} =-\sum _{i,j}{p}_{ij} \, {{\log}} \, {w}_{ij}+\sum _{i,j}{p}_{ij}\,{{\log}} \, Z=-\sum _{i,j}{p}_{ij}\,{{\log}} \, {w}_{ij}+{{\log}}\sum _{i,j}{w}_{ij}.$$\end{document}</tex-math><mml:math id="M250"><mml:mo>&#x02212;</mml:mo><mml:munder><mml:mrow><mml:mo mathsize="big">&#x02211;</mml:mo></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mo>,</mml:mo><mml:mi>j</mml:mi></mml:mrow></mml:munder><mml:msub><mml:mrow><mml:mi>p</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mi>log</mml:mi><mml:mfrac><mml:mrow><mml:msub><mml:mrow><mml:mi>w</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mi>j</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mrow><mml:mi>Z</mml:mi></mml:mrow></mml:mfrac><mml:mo>=</mml:mo><mml:mo>&#x02212;</mml:mo><mml:munder><mml:mrow><mml:mo mathsize="big">&#x02211;</mml:mo></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mo>,</mml:mo><mml:mi>j</mml:mi></mml:mrow></mml:munder><mml:msub><mml:mrow><mml:mi>p</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mspace width="0.25em"/><mml:mi>log</mml:mi><mml:mspace width="0.25em"/><mml:msub><mml:mrow><mml:mi>w</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:munder><mml:mrow><mml:mo mathsize="big"> &#x02211;</mml:mo></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mo>,</mml:mo><mml:mi>j</mml:mi></mml:mrow></mml:munder><mml:msub><mml:mrow><mml:mi>p</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mspace width="0.25em"/><mml:mi>log</mml:mi><mml:mspace width="0.25em"/><mml:mi>Z</mml:mi><mml:mo>=</mml:mo><mml:mo>&#x02212;</mml:mo><mml:munder><mml:mrow><mml:mo mathsize="big">&#x02211;</mml:mo></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mo>,</mml:mo><mml:mi>j</mml:mi></mml:mrow></mml:munder><mml:msub><mml:mrow><mml:mi>p</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mspace width="0.25em"/><mml:mi>log</mml:mi><mml:mspace width="0.25em"/><mml:msub><mml:mrow><mml:mi>w</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:mi>log</mml:mi><mml:munder><mml:mrow><mml:mo mathsize="big">&#x02211;</mml:mo></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mo>,</mml:mo><mml:mi>j</mml:mi></mml:mrow></mml:munder><mml:msub><mml:mrow><mml:mi>w</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mo>.</mml:mo></mml:math><graphic xlink:href="41467_2019_13056_Article_Equ7.gif" position="anchor"/></alternatives></disp-formula>To minimise <inline-formula id="IEq119"><alternatives><tex-math id="M251">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${\mathcal{L}}$$\end{document}</tex-math><mml:math id="M252"><mml:mi class="MJX-tex-caligraphic" mathvariant="script">L</mml:mi></mml:math><inline-graphic xlink:href="41467_2019_13056_Article_IEq119.gif"/></alternatives></inline-formula>, the first sum should be as large possible, which means large <inline-formula id="IEq120"><alternatives><tex-math id="M253">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${w}_{ij}$$\end{document}</tex-math><mml:math id="M254"><mml:msub><mml:mrow><mml:mi>w</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mi>j</mml:mi></mml:mrow></mml:msub></mml:math><inline-graphic xlink:href="41467_2019_13056_Article_IEq120.gif"/></alternatives></inline-formula>, i.e. small <inline-formula id="IEq121"><alternatives><tex-math id="M255">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\| {{\bf{y}}}_{i}-{{\bf{y}}}_{j}\|$$\end{document}</tex-math><mml:math id="M256"><mml:mo>&#x02225;</mml:mo><mml:msub><mml:mrow><mml:mi mathvariant="bold">y</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>&#x02212;</mml:mo><mml:msub><mml:mrow><mml:mi mathvariant="bold">y</mml:mi></mml:mrow><mml:mrow><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mo>&#x02225;</mml:mo></mml:math><inline-graphic xlink:href="41467_2019_13056_Article_IEq121.gif"/></alternatives></inline-formula>, meaning an attractive force between points <inline-formula id="IEq122"><alternatives><tex-math id="M257">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$i$$\end{document}</tex-math><mml:math id="M258"><mml:mi>i</mml:mi></mml:math><inline-graphic xlink:href="41467_2019_13056_Article_IEq122.gif"/></alternatives></inline-formula> and <inline-formula id="IEq123"><alternatives><tex-math id="M259">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$j$$\end{document}</tex-math><mml:math id="M260"><mml:mi>j</mml:mi></mml:math><inline-graphic xlink:href="41467_2019_13056_Article_IEq123.gif"/></alternatives></inline-formula> whenever <inline-formula id="IEq124"><alternatives><tex-math id="M261">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${p}_{ij}\ne 0$$\end{document}</tex-math><mml:math id="M262"><mml:msub><mml:mrow><mml:mi>p</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mo>&#x02260;</mml:mo><mml:mn>0</mml:mn></mml:math><inline-graphic xlink:href="41467_2019_13056_Article_IEq124.gif"/></alternatives></inline-formula>. At the same time, the second term should be as small as possible, meaning small <inline-formula id="IEq125"><alternatives><tex-math id="M263">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${w}_{ij}$$\end{document}</tex-math><mml:math id="M264"><mml:msub><mml:mrow><mml:mi>w</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mi>j</mml:mi></mml:mrow></mml:msub></mml:math><inline-graphic xlink:href="41467_2019_13056_Article_IEq125.gif"/></alternatives></inline-formula> and a repulsive force between any two points <inline-formula id="IEq126"><alternatives><tex-math id="M265">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$i$$\end{document}</tex-math><mml:math id="M266"><mml:mi>i</mml:mi></mml:math><inline-graphic xlink:href="41467_2019_13056_Article_IEq126.gif"/></alternatives></inline-formula> and <inline-formula id="IEq127"><alternatives><tex-math id="M267">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$j$$\end{document}</tex-math><mml:math id="M268"><mml:mi>j</mml:mi></mml:math><inline-graphic xlink:href="41467_2019_13056_Article_IEq127.gif"/></alternatives></inline-formula>, independent of the value of <inline-formula id="IEq128"><alternatives><tex-math id="M269">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${p}_{ij}$$\end{document}</tex-math><mml:math id="M270"><mml:msub><mml:mrow><mml:mi>p</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mi>j</mml:mi></mml:mrow></mml:msub></mml:math><inline-graphic xlink:href="41467_2019_13056_Article_IEq128.gif"/></alternatives></inline-formula>.</p></sec><sec id="Sec12"><title>The t-SNE optimisation</title><p id="Par62">The original publication<sup><xref ref-type="bibr" rid="CR9">9</xref></sup> suggested optimising <inline-formula id="IEq129"><alternatives><tex-math id="M271">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${\mathcal{L}}$$\end{document}</tex-math><mml:math id="M272"><mml:mi class="MJX-tex-caligraphic" mathvariant="script">L</mml:mi></mml:math><inline-graphic xlink:href="41467_2019_13056_Article_IEq129.gif"/></alternatives></inline-formula> using adaptive gradient descent with momentum. The authors initialised <inline-formula id="IEq130"><alternatives><tex-math id="M273">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${{\bf{y}}}_{i}$$\end{document}</tex-math><mml:math id="M274"><mml:msub><mml:mrow><mml:mi mathvariant="bold">y</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub></mml:math><inline-graphic xlink:href="41467_2019_13056_Article_IEq130.gif"/></alternatives></inline-formula> randomly, using a Gaussian distribution with standard deviation 0.0001. It is important that initial values have small magnitude: otherwise optimisation often fails to converge to a good solution.</p><p id="Par63">To escape bad local minima and allow similar points to be quickly pulled together, the original publication<sup><xref ref-type="bibr" rid="CR9">9</xref></sup> suggested an &#x0201c;early exaggeration&#x0201d; trick: during initial iterations they multiplied all attractive forces by &#x003b1;&#x02009;&#x0003e;&#x02009;1. Later work<sup><xref ref-type="bibr" rid="CR32">32</xref></sup> used&#x000a0;&#x003b1;&#x02009;=&#x02009;12 for the first 250 iterations, which became the default since then.</p><p id="Par64">The exact t-SNE computes <inline-formula id="IEq133"><alternatives><tex-math id="M275">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${n}^{2}$$\end{document}</tex-math><mml:math id="M276"><mml:msup><mml:mrow><mml:mi>n</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup></mml:math><inline-graphic xlink:href="41467_2019_13056_Article_IEq133.gif"/></alternatives></inline-formula> similarities <inline-formula id="IEq134"><alternatives><tex-math id="M277">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${p}_{ij}$$\end{document}</tex-math><mml:math id="M278"><mml:msub><mml:mrow><mml:mi>p</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mi>j</mml:mi></mml:mrow></mml:msub></mml:math><inline-graphic xlink:href="41467_2019_13056_Article_IEq134.gif"/></alternatives></inline-formula> and <inline-formula id="IEq135"><alternatives><tex-math id="M279">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${n}^{2}$$\end{document}</tex-math><mml:math id="M280"><mml:msup><mml:mrow><mml:mi>n</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup></mml:math><inline-graphic xlink:href="41467_2019_13056_Article_IEq135.gif"/></alternatives></inline-formula> pairwise attractive and repulsive forces on each gradient descent step. This becomes unfeasible for <inline-formula id="IEq136"><alternatives><tex-math id="M281">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$n\gg 10,000$$\end{document}</tex-math><mml:math id="M282"><mml:mi>n</mml:mi><mml:mo>&#x0226b;</mml:mo><mml:mn>10</mml:mn><mml:mo>,</mml:mo><mml:mn>000</mml:mn></mml:math><inline-graphic xlink:href="41467_2019_13056_Article_IEq136.gif"/></alternatives></inline-formula>. A follow-up paper<sup><xref ref-type="bibr" rid="CR32">32</xref></sup> suggested two approximations in order to speed up the computations. First, it noticed that for any perplexity value <inline-formula id="IEq137"><alternatives><tex-math id="M283">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${\mathcal{P}}$$\end{document}</tex-math><mml:math id="M284"><mml:mi class="MJX-tex-caligraphic" mathvariant="script">P</mml:mi></mml:math><inline-graphic xlink:href="41467_2019_13056_Article_IEq137.gif"/></alternatives></inline-formula> all but <inline-formula id="IEq138"><alternatives><tex-math id="M285">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${\mathcal{O}}({\mathcal{P}})$$\end{document}</tex-math><mml:math id="M286"><mml:mi class="MJX-tex-caligraphic" mathvariant="script">O</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi class="MJX-tex-caligraphic" mathvariant="script">P</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:math><inline-graphic xlink:href="41467_2019_13056_Article_IEq138.gif"/></alternatives></inline-formula> nearest neighbours of any given point <inline-formula id="IEq139"><alternatives><tex-math id="M287">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$i$$\end{document}</tex-math><mml:math id="M288"><mml:mi>i</mml:mi></mml:math><inline-graphic xlink:href="41467_2019_13056_Article_IEq139.gif"/></alternatives></inline-formula> will have nearly zero values <inline-formula id="IEq140"><alternatives><tex-math id="M289">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${p}_{j| i}$$\end{document}</tex-math><mml:math id="M290"><mml:msub><mml:mrow><mml:mi>p</mml:mi></mml:mrow><mml:mrow><mml:mi>j</mml:mi><mml:mo>&#x02223;</mml:mo><mml:mi>i</mml:mi></mml:mrow></mml:msub></mml:math><inline-graphic xlink:href="41467_2019_13056_Article_IEq140.gif"/></alternatives></inline-formula>. It suggested to only find <inline-formula id="IEq141"><alternatives><tex-math id="M291">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$k=3{\mathcal{P}}$$\end{document}</tex-math><mml:math id="M292"><mml:mi>k</mml:mi><mml:mo>=</mml:mo><mml:mn>3</mml:mn><mml:mi class="MJX-tex-caligraphic" mathvariant="script">P</mml:mi></mml:math><inline-graphic xlink:href="41467_2019_13056_Article_IEq141.gif"/></alternatives></inline-formula> nearest neighbours of each point and set <inline-formula id="IEq142"><alternatives><tex-math id="M293">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${p}_{j| i}=0$$\end{document}</tex-math><mml:math id="M294"><mml:msub><mml:mrow><mml:mi>p</mml:mi></mml:mrow><mml:mrow><mml:mi>j</mml:mi><mml:mo>&#x02223;</mml:mo><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mn>0</mml:mn></mml:math><inline-graphic xlink:href="41467_2019_13056_Article_IEq142.gif"/></alternatives></inline-formula> for the remaining <inline-formula id="IEq143"><alternatives><tex-math id="M295">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$n-3{\mathcal{P}}$$\end{document}</tex-math><mml:math id="M296"><mml:mi>n</mml:mi><mml:mo>&#x02212;</mml:mo><mml:mn>3</mml:mn><mml:mi class="MJX-tex-caligraphic" mathvariant="script">P</mml:mi></mml:math><inline-graphic xlink:href="41467_2019_13056_Article_IEq143.gif"/></alternatives></inline-formula> points. This relied on finding the exact <inline-formula id="IEq144"><alternatives><tex-math id="M297">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$3{\mathcal{P}}$$\end{document}</tex-math><mml:math id="M298"><mml:mn>3</mml:mn><mml:mi class="MJX-tex-caligraphic" mathvariant="script">P</mml:mi></mml:math><inline-graphic xlink:href="41467_2019_13056_Article_IEq144.gif"/></alternatives></inline-formula> nearest neighbours, but in later work various authors<sup><xref ref-type="bibr" rid="CR10">10</xref>,<xref ref-type="bibr" rid="CR16">16</xref>,<xref ref-type="bibr" rid="CR39">39</xref>,<xref ref-type="bibr" rid="CR48">48</xref></sup> started using approximate nearest neighbour algorithms which is much faster and does not seem to make t-SNE results any worse.</p><p id="Par65">Using <inline-formula id="IEq145"><alternatives><tex-math id="M299">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$3{\mathcal{P}}$$\end{document}</tex-math><mml:math id="M300"><mml:mn>3</mml:mn><mml:mi class="MJX-tex-caligraphic" mathvariant="script">P</mml:mi></mml:math><inline-graphic xlink:href="41467_2019_13056_Article_IEq145.gif"/></alternatives></inline-formula> nearest neighbours accelerates computation of the attractive forces. To accelerate the repulsive force computations, ref. <sup><xref ref-type="bibr" rid="CR32">32</xref></sup> used the Barnes-Hut approximation, originally developed for N-body simulations in physics. This reduces computational complexity from <inline-formula id="IEq146"><alternatives><tex-math id="M301">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${\mathcal{O}}({n}^{2})$$\end{document}</tex-math><mml:math id="M302"><mml:mi class="MJX-tex-caligraphic" mathvariant="script">O</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msup><mml:mrow><mml:mi>n</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:math><inline-graphic xlink:href="41467_2019_13056_Article_IEq146.gif"/></alternatives></inline-formula> to <inline-formula id="IEq147"><alternatives><tex-math id="M303">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${\mathcal{O}}(n {\log}n)$$\end{document}</tex-math><mml:math id="M304"><mml:mi class="MJX-tex-caligraphic" mathvariant="script">O</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>n</mml:mi><mml:mi>log</mml:mi><mml:mi>n</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:math><inline-graphic xlink:href="41467_2019_13056_Article_IEq147.gif"/></alternatives></inline-formula>, works reasonably fast for <inline-formula id="IEq148"><alternatives><tex-math id="M305">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$n$$\end{document}</tex-math><mml:math id="M306"><mml:mi>n</mml:mi></mml:math><inline-graphic xlink:href="41467_2019_13056_Article_IEq148.gif"/></alternatives></inline-formula> up to <inline-formula id="IEq149"><alternatives><tex-math id="M307">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\sim 100,000$$\end{document}</tex-math><mml:math id="M308"><mml:mo>~</mml:mo><mml:mn>100</mml:mn><mml:mo>,</mml:mo><mml:mn>000</mml:mn></mml:math><inline-graphic xlink:href="41467_2019_13056_Article_IEq149.gif"/></alternatives></inline-formula>, but becomes too slow for much larger sample sizes. Inspired by the fast multipole method, another technique originally developed for N-body simulations, ref. <sup><xref ref-type="bibr" rid="CR16">16</xref></sup> suggested to interpolate repulsive forces on an equispaced grid and to use fast Fourier transform to accelerate the interpolation (FIt-SNE). This lowers computational complexity to <inline-formula id="IEq150"><alternatives><tex-math id="M309">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${\mathcal{O}}(n)$$\end{document}</tex-math><mml:math id="M310"><mml:mi class="MJX-tex-caligraphic" mathvariant="script">O</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>n</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:math><inline-graphic xlink:href="41467_2019_13056_Article_IEq150.gif"/></alternatives></inline-formula> and works very fast for <inline-formula id="IEq151"><alternatives><tex-math id="M311">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$n$$\end{document}</tex-math><mml:math id="M312"><mml:mi>n</mml:mi></mml:math><inline-graphic xlink:href="41467_2019_13056_Article_IEq151.gif"/></alternatives></inline-formula> into millions. An important limitation is that it is only implemented for 1D and 2D, but not for 3D embeddings, as the interpolation would work much slower in 3D.</p></sec><sec id="Sec13"><title>Synthetic data set</title><p id="Par66">All points were generated from a standard Gaussian distribution in 50 dimensions. All points from each class were shifted by 20 in mutually orthogonal directions. All points from each type in one class (<inline-formula id="IEq152"><alternatives><tex-math id="M313">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$n=2000$$\end{document}</tex-math><mml:math id="M314"><mml:mi>n</mml:mi><mml:mo>=</mml:mo><mml:mn>2000</mml:mn></mml:math><inline-graphic xlink:href="41467_2019_13056_Article_IEq152.gif"/></alternatives></inline-formula> per type) were additionally shifted by 4 in mutually orthogonal directions; in another class (<inline-formula id="IEq153"><alternatives><tex-math id="M315">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$n=1000$$\end{document}</tex-math><mml:math id="M316"><mml:mi>n</mml:mi><mml:mo>=</mml:mo><mml:mn>1000</mml:mn></mml:math><inline-graphic xlink:href="41467_2019_13056_Article_IEq153.gif"/></alternatives></inline-formula> per type)&#x02014;by 10; in the third class (<inline-formula id="IEq154"><alternatives><tex-math id="M317">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$n=100$$\end{document}</tex-math><mml:math id="M318"><mml:mi>n</mml:mi><mml:mo>=</mml:mo><mml:mn>100</mml:mn></mml:math><inline-graphic xlink:href="41467_2019_13056_Article_IEq154.gif"/></alternatives></inline-formula> per type)&#x02014;also by 10. The resulting total sample size was <inline-formula id="IEq155"><alternatives><tex-math id="M319">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$n=15,\!500$$\end{document}</tex-math><mml:math id="M320"><mml:mi>n</mml:mi><mml:mo>=</mml:mo><mml:mn>15</mml:mn><mml:mo>,</mml:mo><mml:mspace width="0.3em"/><mml:mn>500</mml:mn></mml:math><inline-graphic xlink:href="41467_2019_13056_Article_IEq155.gif"/></alternatives></inline-formula>.</p></sec><sec id="Sec14"><title>Data preprocessing</title><p id="Par67">All data sets were downloaded as tables of UMI or read counts. Let <inline-formula id="IEq156"><alternatives><tex-math id="M321">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${\bf{X}}$$\end{document}</tex-math><mml:math id="M322"><mml:mi mathvariant="bold">X</mml:mi></mml:math><inline-graphic xlink:href="41467_2019_13056_Article_IEq156.gif"/></alternatives></inline-formula> be a <inline-formula id="IEq157"><alternatives><tex-math id="M323">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$n\times p$$\end{document}</tex-math><mml:math id="M324"><mml:mi>n</mml:mi><mml:mo>&#x000d7;</mml:mo><mml:mi>p</mml:mi></mml:math><inline-graphic xlink:href="41467_2019_13056_Article_IEq157.gif"/></alternatives></inline-formula> matrix of gene counts, with <inline-formula id="IEq158"><alternatives><tex-math id="M325">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$n$$\end{document}</tex-math><mml:math id="M326"><mml:mi>n</mml:mi></mml:math><inline-graphic xlink:href="41467_2019_13056_Article_IEq158.gif"/></alternatives></inline-formula> and <inline-formula id="IEq159"><alternatives><tex-math id="M327">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$p$$\end{document}</tex-math><mml:math id="M328"><mml:mi>p</mml:mi></mml:math><inline-graphic xlink:href="41467_2019_13056_Article_IEq159.gif"/></alternatives></inline-formula> being the number of cells and the number of genes respectively. We assume that zero columns (if any) have been removed. We used a standard preprocessing pipeline consisting of the following steps: (i) sequencing depth normalisation; (ii) feature selection; (iii) log-transformation; (iv) PCA. Specifically, we normalised the read counts to counts per million (CPM) and UMI counts to counts per median sequencing depth, selected 1000&#x02013;3000 most variable genes using dropout-based feature selection similar to the one suggested in ref. <sup><xref ref-type="bibr" rid="CR49">49</xref></sup>, applied <inline-formula id="IEq160"><alternatives><tex-math id="M329">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${\rm{log}}_{2}(x+1)$$\end{document}</tex-math><mml:math id="M330"><mml:msub><mml:mrow><mml:mi mathvariant="normal">log</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>x</mml:mi><mml:mo>+</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:math><inline-graphic xlink:href="41467_2019_13056_Article_IEq160.gif"/></alternatives></inline-formula> transform, and finally did PCA retaining the 50 leading PCs. We experimented with modifying and omitting any of these steps. Our experiments showed that log-transformation (or a similar nonlinear transformation) and feature selection are the two most important steps for adequate results. PCA mainly improves computational efficiency as it reduces the dimensionality and size of the data set before running t-SNE.</p></sec><sec id="Sec15"><title>Sequencing depth normalisation</title><p id="Par68">We divided the read counts of each cell by the cell&#x02019;s sequencing depth <inline-formula id="IEq161"><alternatives><tex-math id="M331">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${\sum }_{k}{X}_{ik}$$\end{document}</tex-math><mml:math id="M332"><mml:msub><mml:mrow><mml:mo>&#x02211;</mml:mo></mml:mrow><mml:mrow><mml:mi>k</mml:mi></mml:mrow></mml:msub><mml:msub><mml:mrow><mml:mi>X</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mi>k</mml:mi></mml:mrow></mml:msub></mml:math><inline-graphic xlink:href="41467_2019_13056_Article_IEq161.gif"/></alternatives></inline-formula>, and multiplied by 1 million, to obtain CPM. We normalised the UMI counts by the cell&#x02019;s sequencing depth and multiplied by the median sequencing depth across all <inline-formula id="IEq162"><alternatives><tex-math id="M333">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$n$$\end{document}</tex-math><mml:math id="M334"><mml:mi>n</mml:mi></mml:math><inline-graphic xlink:href="41467_2019_13056_Article_IEq162.gif"/></alternatives></inline-formula> cells in the data set<sup><xref ref-type="bibr" rid="CR50">50</xref></sup>. This is more appropriate for UMI counts because multiplying by 1 million can strongly distort the data after the subsequent <inline-formula id="IEq163"><alternatives><tex-math id="M335">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${\rm{log}}(1+x)$$\end{document}</tex-math><mml:math id="M336"><mml:mi mathvariant="normal">log</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mn>1</mml:mn><mml:mo>+</mml:mo><mml:mi>x</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:math><inline-graphic xlink:href="41467_2019_13056_Article_IEq163.gif"/></alternatives></inline-formula> transform<sup><xref ref-type="bibr" rid="CR51">51</xref></sup>.</p></sec><sec id="Sec16"><title>Feature selection</title><p id="Par69">Most studies use the mean-variance relationship to perform feature selection: they select genes that have large variance given their mean. We adopt the approach of ref. <sup><xref ref-type="bibr" rid="CR49">49</xref></sup> that exploited the mean-dropout relationship: the idea is to select genes that have high dropout (i.e. zero count) frequency given their mean expression level. Any gene that has high dropout rate and high mean expression could potentially be a marker of some particular subpopulation. We found it more intuitive to use the mean across non-zero counts instead of the overall mean, because it is computed independently of the fraction of zero counts.</p><p id="Par70">For each gene <inline-formula id="IEq164"><alternatives><tex-math id="M337">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$g$$\end{document}</tex-math><mml:math id="M338"><mml:mi>g</mml:mi></mml:math><inline-graphic xlink:href="41467_2019_13056_Article_IEq164.gif"/></alternatives></inline-formula>, we computed the fraction of near-zero counts<disp-formula id="Equ8"><label>8</label><alternatives><tex-math id="M339">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${d}_{g}=\frac{1}{n}\sum _{i}I({X}_{ig}\le t)$$\end{document}</tex-math><mml:math id="M340"><mml:msub><mml:mrow><mml:mi>d</mml:mi></mml:mrow><mml:mrow><mml:mi>g</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mi>n</mml:mi></mml:mrow></mml:mfrac><mml:munder><mml:mrow><mml:mo mathsize="big">&#x02211;</mml:mo></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:munder><mml:mi>I</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mrow><mml:mi>X</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mi>g</mml:mi></mml:mrow></mml:msub><mml:mo>&#x02264;</mml:mo><mml:mi>t</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:math><graphic xlink:href="41467_2019_13056_Article_Equ8.gif" position="anchor"/></alternatives></disp-formula>and the mean log non-zero expression<disp-formula id="Equ9"><label>9</label><alternatives><tex-math id="M341">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${m}_{g}=\left\langle {\rm{log}}_{2}{X}_{ig}| {X}_{ig}\, &#x0003e; \, t\right\rangle.$$\end{document}</tex-math><mml:math id="M342"><mml:msub><mml:mrow><mml:mi>m</mml:mi></mml:mrow><mml:mrow><mml:mi>g</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mfenced close="&#x027e9;" open="&#x027e8;" separators=""><mml:mrow><mml:msub><mml:mrow><mml:mi mathvariant="normal">log</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msub><mml:msub><mml:mrow><mml:mi>X</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mi>g</mml:mi></mml:mrow></mml:msub><mml:mo>&#x02223;</mml:mo><mml:msub><mml:mrow><mml:mi>X</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mi>g</mml:mi></mml:mrow></mml:msub><mml:mspace width="0.25em"/><mml:mo>&#x0003e;</mml:mo><mml:mspace width="0.25em"/><mml:mi>t</mml:mi></mml:mrow></mml:mfenced><mml:mo>.</mml:mo></mml:math><graphic xlink:href="41467_2019_13056_Article_Equ9.gif" position="anchor"/></alternatives></disp-formula>For all UMI-based data sets we used <inline-formula id="IEq165"><alternatives><tex-math id="M343">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$t=0$$\end{document}</tex-math><mml:math id="M344"><mml:mi>t</mml:mi><mml:mo>=</mml:mo><mml:mn>0</mml:mn></mml:math><inline-graphic xlink:href="41467_2019_13056_Article_IEq165.gif"/></alternatives></inline-formula> and for all Smart-seq2/SMARTer data sets we used <inline-formula id="IEq166"><alternatives><tex-math id="M345">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$t=32$$\end{document}</tex-math><mml:math id="M346"><mml:mi>t</mml:mi><mml:mo>=</mml:mo><mml:mn>32</mml:mn></mml:math><inline-graphic xlink:href="41467_2019_13056_Article_IEq166.gif"/></alternatives></inline-formula> (some known marker genes were not getting selected with <inline-formula id="IEq167"><alternatives><tex-math id="M347">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$t=0$$\end{document}</tex-math><mml:math id="M348"><mml:mi>t</mml:mi><mml:mo>=</mml:mo><mml:mn>0</mml:mn></mml:math><inline-graphic xlink:href="41467_2019_13056_Article_IEq167.gif"/></alternatives></inline-formula>). We discarded all genes that have non-zero expression in less than <inline-formula id="IEq168"><alternatives><tex-math id="M349">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${n}_{\text{min}}=10$$\end{document}</tex-math><mml:math id="M350"><mml:msub><mml:mrow><mml:mi>n</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">min</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mn>10</mml:mn></mml:math><inline-graphic xlink:href="41467_2019_13056_Article_IEq168.gif"/></alternatives></inline-formula> cells. There was a strong negative relationship between <inline-formula id="IEq169"><alternatives><tex-math id="M351">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${d}_{g}$$\end{document}</tex-math><mml:math id="M352"><mml:msub><mml:mrow><mml:mi>d</mml:mi></mml:mrow><mml:mrow><mml:mi>g</mml:mi></mml:mrow></mml:msub></mml:math><inline-graphic xlink:href="41467_2019_13056_Article_IEq169.gif"/></alternatives></inline-formula> and <inline-formula id="IEq170"><alternatives><tex-math id="M353">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${m}_{g}$$\end{document}</tex-math><mml:math id="M354"><mml:msub><mml:mrow><mml:mi>m</mml:mi></mml:mrow><mml:mrow><mml:mi>g</mml:mi></mml:mrow></mml:msub></mml:math><inline-graphic xlink:href="41467_2019_13056_Article_IEq170.gif"/></alternatives></inline-formula> across all the remaining genes (Supplementary Fig.&#x000a0;<xref rid="MOESM1" ref-type="media">4</xref>). In order to select a pre-specified number <inline-formula id="IEq171"><alternatives><tex-math id="M355">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$M$$\end{document}</tex-math><mml:math id="M356"><mml:mi>M</mml:mi></mml:math><inline-graphic xlink:href="41467_2019_13056_Article_IEq171.gif"/></alternatives></inline-formula> of genes (usually <inline-formula id="IEq172"><alternatives><tex-math id="M357">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$M=1000$$\end{document}</tex-math><mml:math id="M358"><mml:mi>M</mml:mi><mml:mo>=</mml:mo><mml:mn>1000</mml:mn></mml:math><inline-graphic xlink:href="41467_2019_13056_Article_IEq172.gif"/></alternatives></inline-formula> or <inline-formula id="IEq173"><alternatives><tex-math id="M359">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$M=3000$$\end{document}</tex-math><mml:math id="M360"><mml:mi>M</mml:mi><mml:mo>=</mml:mo><mml:mn>3000</mml:mn></mml:math><inline-graphic xlink:href="41467_2019_13056_Article_IEq173.gif"/></alternatives></inline-formula>), we used a heuristic approach of finding a value <inline-formula id="IEq174"><alternatives><tex-math id="M361">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$b$$\end{document}</tex-math><mml:math id="M362"><mml:mi>b</mml:mi></mml:math><inline-graphic xlink:href="41467_2019_13056_Article_IEq174.gif"/></alternatives></inline-formula> such that<disp-formula id="Equ10"><label>10</label><alternatives><tex-math id="M363">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${d}_{g}&#x0003e; \exp \left[-a({m}_{g}-b)\right]+0.02$$\end{document}</tex-math><mml:math id="M364"><mml:msub><mml:mrow><mml:mi>d</mml:mi></mml:mrow><mml:mrow><mml:mi>g</mml:mi></mml:mrow></mml:msub><mml:mo>&#x0003e;</mml:mo><mml:mi>exp</mml:mi><mml:mfenced close="]" open="[" separators=""><mml:mrow><mml:mo>&#x02212;</mml:mo><mml:mi>a</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mrow><mml:mi>m</mml:mi></mml:mrow><mml:mrow><mml:mi>g</mml:mi></mml:mrow></mml:msub><mml:mo>&#x02212;</mml:mo><mml:mi>b</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mfenced><mml:mo>+</mml:mo><mml:mn>0.02</mml:mn></mml:math><graphic xlink:href="41467_2019_13056_Article_Equ10.gif" position="anchor"/></alternatives></disp-formula>was true for exactly <inline-formula id="IEq175"><alternatives><tex-math id="M365">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$M$$\end{document}</tex-math><mml:math id="M366"><mml:mi>M</mml:mi></mml:math><inline-graphic xlink:href="41467_2019_13056_Article_IEq175.gif"/></alternatives></inline-formula> genes. This can be done with a binary search. In Supplementary Fig.&#x000a0;<xref rid="MOESM1" ref-type="media">4</xref> this corresponds to moving the red line horizontally until there are exactly <inline-formula id="IEq176"><alternatives><tex-math id="M367">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$M$$\end{document}</tex-math><mml:math id="M368"><mml:mi>M</mml:mi></mml:math><inline-graphic xlink:href="41467_2019_13056_Article_IEq176.gif"/></alternatives></inline-formula> genes to the upper-right of it. These <inline-formula id="IEq177"><alternatives><tex-math id="M369">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$M$$\end{document}</tex-math><mml:math id="M370"><mml:mi>M</mml:mi></mml:math><inline-graphic xlink:href="41467_2019_13056_Article_IEq177.gif"/></alternatives></inline-formula> genes were then selected. We used <inline-formula id="IEq178"><alternatives><tex-math id="M371">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$a=1.5$$\end{document}</tex-math><mml:math id="M372"><mml:mi>a</mml:mi><mml:mo>=</mml:mo><mml:mn>1.5</mml:mn></mml:math><inline-graphic xlink:href="41467_2019_13056_Article_IEq178.gif"/></alternatives></inline-formula> for all data sets apart from Macosko et al. where <inline-formula id="IEq179"><alternatives><tex-math id="M373">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$a=1$$\end{document}</tex-math><mml:math id="M374"><mml:mi>a</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:math><inline-graphic xlink:href="41467_2019_13056_Article_IEq179.gif"/></alternatives></inline-formula> provided a better fit for the distribution.</p><p id="Par71">We performed feature selection using the raw counts (before sequencing depth normalisation). Then we used normalised values for the selected <inline-formula id="IEq180"><alternatives><tex-math id="M375">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$M$$\end{document}</tex-math><mml:math id="M376"><mml:mi>M</mml:mi></mml:math><inline-graphic xlink:href="41467_2019_13056_Article_IEq180.gif"/></alternatives></inline-formula> genes. We used <inline-formula id="IEq181"><alternatives><tex-math id="M377">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$M=3000$$\end{document}</tex-math><mml:math id="M378"><mml:mi>M</mml:mi><mml:mo>=</mml:mo><mml:mn>3000</mml:mn></mml:math><inline-graphic xlink:href="41467_2019_13056_Article_IEq181.gif"/></alternatives></inline-formula> for the Tasic et al. 2018 and for the Macosko et al. data sets, and <inline-formula id="IEq182"><alternatives><tex-math id="M379">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$M=1000$$\end{document}</tex-math><mml:math id="M380"><mml:mi>M</mml:mi><mml:mo>=</mml:mo><mml:mn>1000</mml:mn></mml:math><inline-graphic xlink:href="41467_2019_13056_Article_IEq182.gif"/></alternatives></inline-formula> for the remaining data sets. This feature selection method was not used for the 10x Genomics and the Cao et al. data sets, see below.</p></sec><sec id="Sec17"><title>Nonlinear transformation</title><p id="Par72">We transformed all values in the <inline-formula id="IEq183"><alternatives><tex-math id="M381">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$n\times M$$\end{document}</tex-math><mml:math id="M382"><mml:mi>n</mml:mi><mml:mo>&#x000d7;</mml:mo><mml:mi>M</mml:mi></mml:math><inline-graphic xlink:href="41467_2019_13056_Article_IEq183.gif"/></alternatives></inline-formula> count matrix after feature selection with a <inline-formula id="IEq184"><alternatives><tex-math id="M383">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${\rm{log}}_{2}(x+1)$$\end{document}</tex-math><mml:math id="M384"><mml:msub><mml:mrow><mml:mi mathvariant="normal">log</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>x</mml:mi><mml:mo>+</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:math><inline-graphic xlink:href="41467_2019_13056_Article_IEq184.gif"/></alternatives></inline-formula> transformation. This transformation is standard in the transcriptomics literature. It is convenient because all zeros remain zeros, and at the same time the expression counts of all genes become roughly comparable. Without this transformation, the Euclidean distances between cells are dominated by a handful of genes with very high counts. There are other transformations that can perform similarly well. In the cytometric literature, the inverse hyperbolic sine <inline-formula id="IEq185"><alternatives><tex-math id="M385">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${\mathrm{arsinh}}(x)={\log}\left(x+\sqrt{{x}^{2}+1}\right)$$\end{document}</tex-math><mml:math id="M386"><mml:mi mathvariant="normal">arsinh</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>x</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mi>log</mml:mi><mml:mfenced close=")" open="(" separators=""><mml:mrow><mml:mi>x</mml:mi><mml:mo>+</mml:mo><mml:msqrt><mml:msup><mml:mrow><mml:mi>x</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup><mml:mo>+</mml:mo><mml:mn>1</mml:mn></mml:msqrt></mml:mrow></mml:mfenced></mml:math><inline-graphic xlink:href="41467_2019_13056_Article_IEq185.gif"/></alternatives></inline-formula> is often used, sometimes as <inline-formula id="IEq186"><alternatives><tex-math id="M387">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${\mathrm{arsinh}}(x/r)$$\end{document}</tex-math><mml:math id="M388"><mml:mi mathvariant="normal">arsinh</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>x</mml:mi><mml:mo>&#x02215;</mml:mo><mml:mi>r</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:math><inline-graphic xlink:href="41467_2019_13056_Article_IEq186.gif"/></alternatives></inline-formula> with <inline-formula id="IEq187"><alternatives><tex-math id="M389">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$r=5$$\end{document}</tex-math><mml:math id="M390"><mml:mi>r</mml:mi><mml:mo>=</mml:mo><mml:mn>5</mml:mn></mml:math><inline-graphic xlink:href="41467_2019_13056_Article_IEq187.gif"/></alternatives></inline-formula> or a similar value<sup><xref ref-type="bibr" rid="CR17">17</xref></sup>. Note that <inline-formula id="IEq188"><alternatives><tex-math id="M391">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\mathrm{arsinh}(x/r)$$\end{document}</tex-math><mml:math id="M392"><mml:mi mathvariant="normal">arsinh</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>x</mml:mi><mml:mo>&#x02215;</mml:mo><mml:mi>r</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:math><inline-graphic xlink:href="41467_2019_13056_Article_IEq188.gif"/></alternatives></inline-formula> is the variance-stabilising transformation for the negative binomial distribution with parameter <inline-formula id="IEq189"><alternatives><tex-math id="M393">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$r$$\end{document}</tex-math><mml:math id="M394"><mml:mi>r</mml:mi></mml:math><inline-graphic xlink:href="41467_2019_13056_Article_IEq189.gif"/></alternatives></inline-formula>, which is often taken to model UMI counts well.</p></sec><sec id="Sec18"><title>Standardisation</title><p id="Par73">Many studies standardise the <inline-formula id="IEq190"><alternatives><tex-math id="M395">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$n\times M$$\end{document}</tex-math><mml:math id="M396"><mml:mi>n</mml:mi><mml:mo>&#x000d7;</mml:mo><mml:mi>M</mml:mi></mml:math><inline-graphic xlink:href="41467_2019_13056_Article_IEq190.gif"/></alternatives></inline-formula> matrix after the log-transformation, i.e. centre and scale all columns to have zero mean and unit variance. We prefer not to do this by default. In general, standardisation is recommended when different features are on different scale, but the log-transformed counts of different genes are arguably already on the same scale.</p><p id="Par74">From a more theoretical point of view, if one could assume that the expression counts of each gene for cells of the same type are distributed log-normally, then Euclidean distance after log-transformation would exactly correspond to the log-likelihood. For the UMI-based data, the common assumption is that the expression counts are distributed according to the negative binomial distribution. For large counts, the negative binomial distribution behaves qualitatively similarly to the log-normal (for example, its variance function is <inline-formula id="IEq191"><alternatives><tex-math id="M397">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\mu +{\mu }^{2}/r$$\end{document}</tex-math><mml:math id="M398"><mml:mi>&#x003bc;</mml:mi><mml:mo>+</mml:mo><mml:msup><mml:mrow><mml:mi>&#x003bc;</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup><mml:mo>&#x02215;</mml:mo><mml:mi>r</mml:mi></mml:math><inline-graphic xlink:href="41467_2019_13056_Article_IEq191.gif"/></alternatives></inline-formula> whereas the log-normal has variance function proportional to <inline-formula id="IEq192"><alternatives><tex-math id="M399">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${\mu }^{2}$$\end{document}</tex-math><mml:math id="M400"><mml:msup><mml:mrow><mml:mi>&#x003bc;</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup></mml:math><inline-graphic xlink:href="41467_2019_13056_Article_IEq192.gif"/></alternatives></inline-formula>), so the Euclidean distance after the log-transformation can be thought of as approximating the negative binomial log-likelihood<sup><xref ref-type="bibr" rid="CR26">26</xref></sup>. Standardising all the genes after log-transformation would destroy this relationship.</p><p id="Par75">At the same time, in some data sets we observed a stronger separation between some of the clusters after performing the standardisation step. Here we applied standardisation for those data sets in which it was used by the original authors (Macosko et al., Shekhar et al., 10x Genomics, Cao et al.).</p></sec><sec id="Sec19"><title>Scanpy preprocessing</title><p id="Par76">For the 10x Genomics and the Cao et al. data sets, we used the preprocessing pipeline recipe_zheng17() from scanpy<sup><xref ref-type="bibr" rid="CR23">23</xref></sup> to ease the comparison with clustering and dimensionality reduction performed by ref. <sup><xref ref-type="bibr" rid="CR23">23</xref></sup> and ref. <sup><xref ref-type="bibr" rid="CR8">8</xref></sup>. This pipeline follows ref. <sup><xref ref-type="bibr" rid="CR50">50</xref></sup> and is similar to ours: it performs sequencing depth normalisation to median sequencing depth, selects most variable genes based on the mean-variance relationship, applies the <inline-formula id="IEq193"><alternatives><tex-math id="M401">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${\rm{log}}_{2}(x+1)$$\end{document}</tex-math><mml:math id="M402"><mml:msub><mml:mrow><mml:mi mathvariant="normal">log</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>x</mml:mi><mml:mo>+</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:math><inline-graphic xlink:href="41467_2019_13056_Article_IEq193.gif"/></alternatives></inline-formula> transform and standardises each feature. We used <inline-formula id="IEq194"><alternatives><tex-math id="M403">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$M=1000$$\end{document}</tex-math><mml:math id="M404"><mml:mi>M</mml:mi><mml:mo>=</mml:mo><mml:mn>1000</mml:mn></mml:math><inline-graphic xlink:href="41467_2019_13056_Article_IEq194.gif"/></alternatives></inline-formula> genes for the 10x Genomics data set and <inline-formula id="IEq195"><alternatives><tex-math id="M405">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$M=2000$$\end{document}</tex-math><mml:math id="M406"><mml:mi>M</mml:mi><mml:mo>=</mml:mo><mml:mn>2000</mml:mn></mml:math><inline-graphic xlink:href="41467_2019_13056_Article_IEq195.gif"/></alternatives></inline-formula> for the Cao et al. data set, following the original publication.</p></sec><sec id="Sec20"><title>Principal component analysis</title><p id="Par77">We used PCA to reduce the size of the data matrix from <inline-formula id="IEq196"><alternatives><tex-math id="M407">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$n\times M$$\end{document}</tex-math><mml:math id="M408"><mml:mi>n</mml:mi><mml:mo>&#x000d7;</mml:mo><mml:mi>M</mml:mi></mml:math><inline-graphic xlink:href="41467_2019_13056_Article_IEq196.gif"/></alternatives></inline-formula> to <inline-formula id="IEq197"><alternatives><tex-math id="M409">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$n\times 50$$\end{document}</tex-math><mml:math id="M410"><mml:mi>n</mml:mi><mml:mo>&#x000d7;</mml:mo><mml:mn>50</mml:mn></mml:math><inline-graphic xlink:href="41467_2019_13056_Article_IEq197.gif"/></alternatives></inline-formula> prior to running t-SNE. In our experiments, this did not have much influence on the t-SNE results but is computationally convenient. Some studies (e.g. ref. <sup><xref ref-type="bibr" rid="CR25">25</xref></sup>) estimate the number of significant principal components via shuffling. In our experiments, for the data sets with tens of thousands of cells, the number of significant PCs was usually close to 50 (for example, for the&#x000a0;Tasic et al.<sup><xref ref-type="bibr" rid="CR3">3</xref></sup> data set it was 40, according to the shuffling test). Given that PCA does not have much influence on the t-SNE results, we prefer to use a fixed value of 50.</p></sec><sec id="Sec21"><title>Default parameters for t-SNE optimisation</title><p id="Par78">Unless explicitly stated, we used the default parameters of FIt-SNE. Following ref. <sup><xref ref-type="bibr" rid="CR32">32</xref></sup>, the defaults are 1000 iterations with learning rate <inline-formula id="IEq198"><alternatives><tex-math id="M411">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\eta =200$$\end{document}</tex-math><mml:math id="M412"><mml:mi>&#x003b7;</mml:mi><mml:mo>=</mml:mo><mml:mn>200</mml:mn></mml:math><inline-graphic xlink:href="41467_2019_13056_Article_IEq198.gif"/></alternatives></inline-formula>; momentum 0.5 for the first 250 iterations and 0.8 afterwards; early exaggeration <inline-formula id="IEq199"><alternatives><tex-math id="M413">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\alpha =12$$\end{document}</tex-math><mml:math id="M414"><mml:mi>&#x003b1;</mml:mi><mml:mo>=</mml:mo><mml:mn>12</mml:mn></mml:math><inline-graphic xlink:href="41467_2019_13056_Article_IEq199.gif"/></alternatives></inline-formula> for the first 250 iterations; initialisation drawn from a Gaussian distribution with standard deviation 0.0001. Further input parameters for the nearest neighbour search using the Annoy library (number of trees: 50, number of query nodes: <inline-formula id="IEq200"><alternatives><tex-math id="M415">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$3{\mathcal{P}}\cdot 50$$\end{document}</tex-math><mml:math id="M416"><mml:mn>3</mml:mn><mml:mi class="MJX-tex-caligraphic" mathvariant="script">P</mml:mi><mml:mo>&#x022c5;</mml:mo><mml:mn>50</mml:mn></mml:math><inline-graphic xlink:href="41467_2019_13056_Article_IEq200.gif"/></alternatives></inline-formula> for perplexity <inline-formula id="IEq201"><alternatives><tex-math id="M417">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${\mathcal{P}}$$\end{document}</tex-math><mml:math id="M418"><mml:mi class="MJX-tex-caligraphic" mathvariant="script">P</mml:mi></mml:math><inline-graphic xlink:href="41467_2019_13056_Article_IEq201.gif"/></alternatives></inline-formula>) and for the grid interpolation (number of approximating polynomials: 3, maximum grid spacing: 1, minimum grid size: 50) were always left at the default values. For reproducibility, we always used random seed 42.</p></sec><sec id="Sec22"><title>Initialisation</title><p id="Par79">For PCA initialisation, we divide the first two principal components by the standard deviation of PC1 and multiply them by 0.0001, which is the default standard deviation of the random initialisation. This scaling is important: values used for initialisation should be close to zero, otherwise the algorithm might have problems with convergence (we learned about the importance of scaling from James Melville&#x02019;s notes at <ext-link ext-link-type="uri" xlink:href="https://jlmelville.github.io/smallvis/init.html">https://jlmelville.github.io/smallvis/init.html</ext-link>). The same scaling was used for the downsampling-based initialisation and also for the custom initialisation when creating aligned visualisations.</p><p id="Par80">The sign of the principal components is arbitrary. To increase reproducibility of the figures, we always fixed the sign of the first two PCs such that for each PCA eigenvector the sum of its values were positive.</p></sec><sec id="Sec23"><title>Post-processing</title><p id="Par81">For the t-SNE embeddings of the 10x Genomics data set, we rotated the result 90 degrees clockwise and flipped horizontally, to make it visually more pleasing. Note that t-SNE result can be arbitrarily rotated and flipped as this does not change the distances between points. Caveat: it should not be stretched horizontally or vertically.</p></sec><sec id="Sec24"><title>Multi-scale similarities</title><p id="Par82">We follow ref. <sup><xref ref-type="bibr" rid="CR13">13</xref></sup> in the definition of multi-scale similarities. For example, to combine perplexities 30 and 300, the values <inline-formula id="IEq202"><alternatives><tex-math id="M419">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${p}_{j| i}$$\end{document}</tex-math><mml:math id="M420"><mml:msub><mml:mrow><mml:mi>p</mml:mi></mml:mrow><mml:mrow><mml:mi>j</mml:mi><mml:mo>&#x02223;</mml:mo><mml:mi>i</mml:mi></mml:mrow></mml:msub></mml:math><inline-graphic xlink:href="41467_2019_13056_Article_IEq202.gif"/></alternatives></inline-formula> are computed with perplexity 30 and with perplexity 300 for each cell <inline-formula id="IEq203"><alternatives><tex-math id="M421">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$i$$\end{document}</tex-math><mml:math id="M422"><mml:mi>i</mml:mi></mml:math><inline-graphic xlink:href="41467_2019_13056_Article_IEq203.gif"/></alternatives></inline-formula> and then averaged. This is approximately (but not exactly) equivalent to using a different similarity kernel: instead of the Gaussian kernel <inline-formula id="IEq204"><alternatives><tex-math id="M423">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\exp (-{d}^{2}/2{\sigma }_{i}^{2})$$\end{document}</tex-math><mml:math id="M424"><mml:mi>exp</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mo>&#x02212;</mml:mo><mml:msup><mml:mrow><mml:mi>d</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup><mml:mo>&#x02215;</mml:mo><mml:mn>2</mml:mn><mml:msubsup><mml:mrow><mml:mi>&#x003c3;</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msubsup></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:math><inline-graphic xlink:href="41467_2019_13056_Article_IEq204.gif"/></alternatives></inline-formula> where <inline-formula id="IEq205"><alternatives><tex-math id="M425">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$d$$\end{document}</tex-math><mml:math id="M426"><mml:mi>d</mml:mi></mml:math><inline-graphic xlink:href="41467_2019_13056_Article_IEq205.gif"/></alternatives></inline-formula> is Euclidean distance, a multi-scale kernel<disp-formula id="Equ11"><label>11</label><alternatives><tex-math id="M427">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\frac{1}{{\sigma }_{i}}\exp \left(-\frac{{d}^{2}}{2{\sigma }_{i}^{2}}\right)+\frac{1}{{\tau }_{i}}\exp \left(-\frac{{d}^{2}}{2{\tau }_{i}^{2}}\right),$$\end{document}</tex-math><mml:math id="M428"><mml:mfrac><mml:mrow><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mi>&#x003c3;</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mfrac><mml:mi>exp</mml:mi><mml:mfenced close=")" open="(" separators=""><mml:mrow><mml:mo>&#x02212;</mml:mo><mml:mfrac><mml:mrow><mml:msup><mml:mrow><mml:mi>d</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup></mml:mrow><mml:mrow><mml:mn>2</mml:mn><mml:msubsup><mml:mrow><mml:mi>&#x003c3;</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msubsup></mml:mrow></mml:mfrac></mml:mrow></mml:mfenced><mml:mo>+</mml:mo><mml:mfrac><mml:mrow><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mi>&#x003c4;</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mfrac><mml:mi>exp</mml:mi><mml:mfenced close=")" open="(" separators=""><mml:mrow><mml:mo>&#x02212;</mml:mo><mml:mfrac><mml:mrow><mml:msup><mml:mrow><mml:mi>d</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msup></mml:mrow><mml:mrow><mml:mn>2</mml:mn><mml:msubsup><mml:mrow><mml:mi>&#x003c4;</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msubsup></mml:mrow></mml:mfrac></mml:mrow></mml:mfenced><mml:mo>,</mml:mo></mml:math><graphic xlink:href="41467_2019_13056_Article_Equ11.gif" position="anchor"/></alternatives></disp-formula>with the variances <inline-formula id="IEq206"><alternatives><tex-math id="M429">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${\sigma }_{i}^{2}$$\end{document}</tex-math><mml:math id="M430"><mml:msubsup><mml:mrow><mml:mi>&#x003c3;</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msubsup></mml:math><inline-graphic xlink:href="41467_2019_13056_Article_IEq206.gif"/></alternatives></inline-formula> and <inline-formula id="IEq207"><alternatives><tex-math id="M431">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${\tau }_{i}^{2}$$\end{document}</tex-math><mml:math id="M432"><mml:msubsup><mml:mrow><mml:mi>&#x003c4;</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msubsup></mml:math><inline-graphic xlink:href="41467_2019_13056_Article_IEq207.gif"/></alternatives></inline-formula> selected such that the perplexity of the first Gaussian component is 30 and the perplexity of the second Gaussian component is 300.</p></sec><sec id="Sec25"><title>Learning rate</title><p id="Par83">Following ref. <sup><xref ref-type="bibr" rid="CR15">15</xref></sup>, we used learning rate <inline-formula id="IEq208"><alternatives><tex-math id="M433">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\eta =n/12$$\end{document}</tex-math><mml:math id="M434"><mml:mi>&#x003b7;</mml:mi><mml:mo>=</mml:mo><mml:mi>n</mml:mi><mml:mo>&#x02215;</mml:mo><mml:mn>12</mml:mn></mml:math><inline-graphic xlink:href="41467_2019_13056_Article_IEq208.gif"/></alternatives></inline-formula> as it is defined in FIt-SNE. FIt-SNE (as well as openTSNE) followed the convention of the original<sup><xref ref-type="bibr" rid="CR9">9</xref></sup> and the Barnes-Hut<sup><xref ref-type="bibr" rid="CR32">32</xref></sup> t-SNE implementations and omitted factor 4 in the gradient equation. Some other existing t-SNE implementations such as the one in scikit-learn do include the factor 4. There one would need to use <inline-formula id="IEq209"><alternatives><tex-math id="M435">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\eta =n/48$$\end{document}</tex-math><mml:math id="M436"><mml:mi>&#x003b7;</mml:mi><mml:mo>=</mml:mo><mml:mi>n</mml:mi><mml:mo>&#x02215;</mml:mo><mml:mn>48</mml:mn></mml:math><inline-graphic xlink:href="41467_2019_13056_Article_IEq209.gif"/></alternatives></inline-formula> to achieve the same result.</p></sec><sec id="Sec26"><title>Exaggeration</title><p id="Par84">Early exaggeration means multiplying the attractive term in the loss function (Eq. (<xref rid="Equ7" ref-type="">7</xref>)) by a constant <inline-formula id="IEq210"><alternatives><tex-math id="M437">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\alpha\; &#x0003e; \; 1$$\end{document}</tex-math><mml:math id="M438"><mml:mi>&#x003b1;</mml:mi><mml:mspace width="0.16em"/><mml:mo>&#x0003e;</mml:mo><mml:mspace width="0.16em"/><mml:mn>1</mml:mn></mml:math><inline-graphic xlink:href="41467_2019_13056_Article_IEq210.gif"/></alternatives></inline-formula> during the initial iterations (the default is <inline-formula id="IEq211"><alternatives><tex-math id="M439">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\alpha =12$$\end{document}</tex-math><mml:math id="M440"><mml:mi>&#x003b1;</mml:mi><mml:mo>=</mml:mo><mml:mn>12</mml:mn></mml:math><inline-graphic xlink:href="41467_2019_13056_Article_IEq211.gif"/></alternatives></inline-formula> for 250 iterations). Ref. <sup><xref ref-type="bibr" rid="CR34">34</xref></sup> suggested to use late exaggeration: using some <inline-formula id="IEq212"><alternatives><tex-math id="M441">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\alpha \;&#x0003e; \; 1$$\end{document}</tex-math><mml:math id="M442"><mml:mi>&#x003b1;</mml:mi><mml:mspace width="0.16em"/><mml:mo>&#x0003e;</mml:mo><mml:mspace width="0.16em"/><mml:mn>1</mml:mn></mml:math><inline-graphic xlink:href="41467_2019_13056_Article_IEq212.gif"/></alternatives></inline-formula> for some number of last iterations. Thus, their approach used three stages: early exaggeration, followed by no exaggeration, followed by late exaggeration. We prefer to use two stages only: we keep <inline-formula id="IEq213"><alternatives><tex-math id="M443">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$\alpha$$\end{document}</tex-math><mml:math id="M444"><mml:mi>&#x003b1;</mml:mi></mml:math><inline-graphic xlink:href="41467_2019_13056_Article_IEq213.gif"/></alternatives></inline-formula> constant after the early exaggeration is turned off. This is why we simply call it exaggeration and not late exaggeration. While early exaggeration is essentially an optimisation trick<sup><xref ref-type="bibr" rid="CR9">9</xref></sup>, we consider subsequent exaggeration to be a meaningful change of the loss function.</p></sec><sec id="Sec27"><title>Positioning out-of-sample cells</title><p id="Par85">To position new cells on an existing t-SNE embedding we used the same <inline-formula id="IEq214"><alternatives><tex-math id="M445">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$M$$\end{document}</tex-math><mml:math id="M446"><mml:mi>M</mml:mi></mml:math><inline-graphic xlink:href="41467_2019_13056_Article_IEq214.gif"/></alternatives></inline-formula> most variable genes that were used to create the target embedding. Usually only a subset of <inline-formula id="IEq215"><alternatives><tex-math id="M447">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$L\; &#x0003c;\; M$$\end{document}</tex-math><mml:math id="M448"><mml:mi>L</mml:mi><mml:mspace width="0.16em"/><mml:mo>&#x0003c;</mml:mo><mml:mspace width="0.16em"/><mml:mi>M</mml:mi></mml:math><inline-graphic xlink:href="41467_2019_13056_Article_IEq215.gif"/></alternatives></inline-formula> genes was present in the count table of the new data set; we used <inline-formula id="IEq216"><alternatives><tex-math id="M449">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$${\rm{log}}_{2}(1+x)$$\end{document}</tex-math><mml:math id="M450"><mml:msub><mml:mrow><mml:mi mathvariant="normal">log</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mn>1</mml:mn><mml:mo>+</mml:mo><mml:mi>x</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:math><inline-graphic xlink:href="41467_2019_13056_Article_IEq216.gif"/></alternatives></inline-formula>-transformed counts of these <inline-formula id="IEq217"><alternatives><tex-math id="M451">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$L$$\end{document}</tex-math><mml:math id="M452"><mml:mi>L</mml:mi></mml:math><inline-graphic xlink:href="41467_2019_13056_Article_IEq217.gif"/></alternatives></inline-formula> genes to compute the correlation distances. To position a cell, we used coordinate-wise median among its <inline-formula id="IEq218"><alternatives><tex-math id="M453">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$k$$\end{document}</tex-math><mml:math id="M454"><mml:mi>k</mml:mi></mml:math><inline-graphic xlink:href="41467_2019_13056_Article_IEq218.gif"/></alternatives></inline-formula> nearest neighbours.</p><p id="Par86">We used correlation distances as possibly more robust for batch effects than Euclidean distances: when out-of-sample cells are sequenced with a different protocol, the batch effect can be very strong. This consideration does not apply to positioning cells for a downsampling-based initialisation (without any possible batch effect). For computational simplicity, here we used Euclidean distance in the space of the 50 PCs.</p></sec><sec id="Sec28"><title>Bootstrapping over genes</title><p id="Par87">We used bootstrapping to estimate the uncertainty of the mapping of new cells to the existing t-SNE atlas. Given a set of <inline-formula id="IEq219"><alternatives><tex-math id="M455">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$L$$\end{document}</tex-math><mml:math id="M456"><mml:mi>L</mml:mi></mml:math><inline-graphic xlink:href="41467_2019_13056_Article_IEq219.gif"/></alternatives></inline-formula> genes that are used for the mapping, we selected a bootstrap sample of <inline-formula id="IEq220"><alternatives><tex-math id="M457">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$L$$\end{document}</tex-math><mml:math id="M458"><mml:mi>L</mml:mi></mml:math><inline-graphic xlink:href="41467_2019_13056_Article_IEq220.gif"/></alternatives></inline-formula> genes out of <inline-formula id="IEq221"><alternatives><tex-math id="M459">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$L$$\end{document}</tex-math><mml:math id="M460"><mml:mi>L</mml:mi></mml:math><inline-graphic xlink:href="41467_2019_13056_Article_IEq221.gif"/></alternatives></inline-formula> with repetition and performed the positioning procedure using this sample of genes. This constitutes one bootstrap iteration. We did 100 iterations and, for each cell, obtained 100 positions on the t-SNE atlas. The larger the spread of these positions, the larger the mapping uncertainty.</p><p id="Par88">For Fig.&#x000a0;<xref rid="Fig5" ref-type="fig">5</xref>c, we computed the distances from the original mapping position to the 100 bootstrapped positions and discarded five bootstrap positions with the largest distance. Then we drew a convex hull of the remaining 95 bootstrap positions (using scipy.spatial.ConvexHull).</p></sec><sec id="Sec30"><title>Reporting summary</title><p id="Par90">Further information on research design is available in the&#x000a0;<xref rid="MOESM3" ref-type="media">Nature Research Reporting Summary</xref> linked to this article.</p></sec></sec><sec sec-type="supplementary-material"><title>Supplementary information</title><sec id="Sec31"><p>
<supplementary-material content-type="local-data" id="MOESM1"><media xlink:href="41467_2019_13056_MOESM1_ESM.pdf"><caption><p>Supplementary Information</p></caption></media></supplementary-material>
<supplementary-material content-type="local-data" id="MOESM2"><media xlink:href="41467_2019_13056_MOESM2_ESM.pdf"><caption><p>Peer Review File</p></caption></media></supplementary-material>
<supplementary-material content-type="local-data" id="MOESM3"><media xlink:href="41467_2019_13056_MOESM3_ESM.pdf"><caption><p>Reporting Summary</p></caption></media></supplementary-material>
</p></sec></sec></body><back><fn-group><fn><p><bold>Peer review information</bold>
<italic>Nature Communications</italic> thanks El-ad David Amir and the other, anonymous, reviewer(s) for their contribution to the peer review of this work. Peer reviewer reports are available.</p></fn><fn><p><bold>Publisher&#x02019;s note</bold> Springer Nature remains neutral with regard to jurisdictional claims in published maps and institutional affiliations.</p></fn></fn-group><sec><title>Supplementary information</title><p><bold>Supplementary information</bold> is available for this paper at 10.1038/s41467-019-13056-x.</p></sec><ack><title>Acknowledgements</title><p>The authors thank Anna Belkina, George Linderman, Leland McInnes, James Melville, Pavlin Poli&#x0010d;ar, and Alexander Wolf for discussions of t-SNE and UMAP. The authors thank Andreas Tolias for discussing Patch-seq data. This work was supported by the Deutsche Forschungsgemeinschaft (BE5601/4-1; Cluster of Excellence &#x0201c;Machine Learning&#x02014;New Perspectives for Science&#x0201d;, EXC 2064, project number 390727645), the Federal Ministry of Education and Research (FKZ 01GQ1601 and 01IS18039A) and the National Institute of Mental Health of the National Institutes of Health under Award Number U19MH114830. The content is solely the responsibility of the authors and does not necessarily represent the official views of the National Institutes of Health.</p></ack><notes notes-type="author-contribution"><title>Author contributions</title><p>D.K. and P.B. conceptualised the project, D.K. performed the analysis, D.K. and P.B. wrote the paper.</p></notes><notes notes-type="data-availability"><title>Data availability</title><p>All data were downloaded in the form of count tables following links in the original publications.</p></notes><notes notes-type="data-availability"><title>Code availability</title><p>We prepared a self-contained Jupyter notebook in Python that demonstrates all the techniques presented in this manuscript. It is available at <ext-link ext-link-type="uri" xlink:href="https://github.com/berenslab/rna-seq-tsne">https://github.com/berenslab/rna-seq-tsne</ext-link>. For simplicity, it uses the&#x000a0;Tasic et al.<sup><xref ref-type="bibr" rid="CR3">3</xref></sup> data set for all demonstrations. To show how to map new cells to the reference t-SNE atlas, we split the data into a training set and a test set. To show how to align two t-SNE visualisations, we split the data set into two parts. To show how to process a much larger data set, we replicate each cell 10 times and add noise.</p><p>The code that does the analysis and produces all the figures used in this manuscript is available in form of Python notebooks at <ext-link ext-link-type="uri" xlink:href="https://github.com/berenslab/rna-seq-tsne">https://github.com/berenslab/rna-seq-tsne</ext-link>. We used a C++ implementation of FIt-SNE<sup><xref ref-type="bibr" rid="CR16">16</xref></sup>, version 1.1, available at <ext-link ext-link-type="uri" xlink:href="https://github.com/klugerlab/FIt-SNE">https://github.com/klugerlab/FIt-SNE</ext-link> together with interfaces for R, Matlab, and Python. While working on this paper, we contributed to this package several additional features that were crucial for our pipeline.</p><p>FIt-SNE has been re-implemented as a pure Python package openTSNE<sup><xref ref-type="bibr" rid="CR52">52</xref></sup>, available at <ext-link ext-link-type="uri" xlink:href="https://github.com/pavlin-policar/openTSNE">https://github.com/pavlin-policar/openTSNE</ext-link>. It supports all the features used in this manuscript (and conveniently allows us to position out-of-sample cells, with or without optimisation).</p></notes><notes notes-type="COI-statement"><title>Competing interests</title><p id="Par91">The authors declare no competing interests.</p></notes><ref-list id="Bib1"><title>References</title><ref id="CR1"><label>1.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Sandberg</surname><given-names>R</given-names></name></person-group><article-title>Entering the era of single-cell transcriptomics in biology and medicine</article-title><source>Nat. Methods</source><year>2014</year><volume>11</volume><fpage>22</fpage><pub-id pub-id-type="doi">10.1038/nmeth.2764</pub-id><pub-id pub-id-type="pmid">24524133</pub-id></element-citation></ref><ref id="CR2"><label>2.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Poulin</surname><given-names>JF</given-names></name><name><surname>Tasic</surname><given-names>B</given-names></name><name><surname>Hjerling-Leffler</surname><given-names>J</given-names></name><name><surname>Trimarchi</surname><given-names>JM</given-names></name><name><surname>Awatramani</surname><given-names>R</given-names></name></person-group><article-title>Disentangling neural cell diversity using single-cell transcriptomics</article-title><source>Nat. Neuroscience</source><year>2016</year><volume>19</volume><fpage>1131</fpage><pub-id pub-id-type="doi">10.1038/nn.4366</pub-id><pub-id pub-id-type="pmid">27571192</pub-id></element-citation></ref><ref id="CR3"><label>3.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Tasic</surname><given-names>B</given-names></name><etal/></person-group><article-title>Shared and distinct transcriptomic cell types across neocortical areas</article-title><source>Nature</source><year>2018</year><volume>563</volume><fpage>72</fpage><pub-id pub-id-type="doi">10.1038/s41586-018-0654-5</pub-id><pub-id pub-id-type="pmid">30382198</pub-id></element-citation></ref><ref id="CR4"><label>4.</label><mixed-citation publication-type="other">The Tabula Muris Consortium. Single-cell transcriptomics of 20 mouse organs creates a <italic>Tabula Muris</italic>. <italic>Nature</italic><bold>562</bold>, 367&#x02013;372 (2018).</mixed-citation></ref><ref id="CR5"><label>5.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Zeisel</surname><given-names>A</given-names></name><etal/></person-group><article-title>Molecular architecture of the mouse nervous system</article-title><source>Cell</source><year>2018</year><volume>174</volume><fpage>999</fpage><lpage>1014</lpage><pub-id pub-id-type="doi">10.1016/j.cell.2018.06.021</pub-id><pub-id pub-id-type="pmid">30096314</pub-id></element-citation></ref><ref id="CR6"><label>6.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Han</surname><given-names>X</given-names></name><etal/></person-group><article-title>Mapping the mouse cell atlas by Microwell-seq</article-title><source>Cell</source><year>2018</year><volume>172</volume><fpage>1091</fpage><lpage>1107</lpage><pub-id pub-id-type="doi">10.1016/j.cell.2018.02.001</pub-id><pub-id pub-id-type="pmid">29474909</pub-id></element-citation></ref><ref id="CR7"><label>7.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Saunders</surname><given-names>A</given-names></name><etal/></person-group><article-title>Molecular diversity and specializations among the cells of the adult mouse brain</article-title><source>Cell</source><year>2018</year><volume>174</volume><fpage>1015</fpage><lpage>1030</lpage><pub-id pub-id-type="doi">10.1016/j.cell.2018.07.028</pub-id><pub-id pub-id-type="pmid">30096299</pub-id></element-citation></ref><ref id="CR8"><label>8.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Cao</surname><given-names>J</given-names></name><etal/></person-group><article-title>The single-cell transcriptional landscape of mammalian organogenesis</article-title><source>Nature</source><year>2019</year><volume>566</volume><fpage>496</fpage><pub-id pub-id-type="doi">10.1038/s41586-019-0969-x</pub-id><pub-id pub-id-type="pmid">30787437</pub-id></element-citation></ref><ref id="CR9"><label>9.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>van der Maaten</surname><given-names>L</given-names></name><name><surname>Hinton</surname><given-names>G</given-names></name></person-group><article-title>Visualizing data using t-SNE</article-title><source>J. Mach. Learning Res.</source><year>2008</year><volume>9</volume><fpage>2579</fpage><lpage>2605</lpage></element-citation></ref><ref id="CR10"><label>10.</label><mixed-citation publication-type="other">McInnes, L., Healy, J. &#x00026; Melville, J. UMAP: Uniform manifold approximation and projection for dimension reduction. <ext-link ext-link-type="uri" xlink:href="https://arxiv.org/abs/1802.03426">https://arxiv.org/abs/1802.03426</ext-link> (2018).</mixed-citation></ref><ref id="CR11"><label>11.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Becht</surname><given-names>E</given-names></name><etal/></person-group><article-title>Dimensionality reduction for visualizing single-cell data using UMAP</article-title><source>Nat. Biotechnol.</source><year>2019</year><volume>37</volume><fpage>38</fpage><pub-id pub-id-type="doi">10.1038/nbt.4314</pub-id></element-citation></ref><ref id="CR12"><label>12.</label><mixed-citation publication-type="other">Wattenberg, M., Vi&#x000e9;gas, F., &#x00026; Johnson, I. How to use t-SNE effectively. <italic>Distill,</italic><ext-link ext-link-type="uri" xlink:href="http://distill.pub/2016/misread-tsne">http://distill.pub/2016/misread-tsne</ext-link> (2016).</mixed-citation></ref><ref id="CR13"><label>13.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Lee</surname><given-names>JA</given-names></name><name><surname>Peluffo-Ord&#x000f3;&#x000f1;ez</surname><given-names>DH</given-names></name><name><surname>Verleysen</surname><given-names>M</given-names></name></person-group><article-title>Multi-scale similarities in stochastic neighbour embedding: Reducing dimensionality while preserving both local and global structure</article-title><source>Neurocomputing</source><year>2015</year><volume>169</volume><fpage>246</fpage><lpage>261</lpage><pub-id pub-id-type="doi">10.1016/j.neucom.2014.12.095</pub-id></element-citation></ref><ref id="CR14"><label>14.</label><mixed-citation publication-type="other">Bodt, C. D., Mulders, D., Verleysen, M., &#x00026; Lee, J. A. Perplexity-free t-SNE and twice student tt-SNE. In <italic>European Symposium on Artificial Neural Networks, Computational Intelligence and Machine Learning</italic> 123&#x02013;128 (2018).</mixed-citation></ref><ref id="CR15"><label>15.</label><mixed-citation publication-type="other">Belkina, A. C. et al. Automated optimized parameters for t-distributed stochastic neighbor embedding improve visualization and allow analysis of large datasets. <italic>Nat. Comms</italic>, 10.1038/s41467-019-13055-y&#x000a0;(2019).</mixed-citation></ref><ref id="CR16"><label>16.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Linderman</surname><given-names>GC</given-names></name><name><surname>Rachh</surname><given-names>M</given-names></name><name><surname>Hoskins</surname><given-names>JG</given-names></name><name><surname>Steinerberger</surname><given-names>S</given-names></name><name><surname>Kluger</surname><given-names>Y</given-names></name></person-group><article-title>Fast interpolation-based t-SNE for improved visualization of single-cell RNA-seq data</article-title><source>Nat. Methods</source><year>2019</year><volume>16</volume><fpage>243</fpage><pub-id pub-id-type="doi">10.1038/s41592-018-0308-4</pub-id><pub-id pub-id-type="pmid">30742040</pub-id></element-citation></ref><ref id="CR17"><label>17.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Amir</surname><given-names>ED</given-names></name><etal/></person-group><article-title>viSNE enables visualization of high dimensional single-cell data and reveals phenotypic heterogeneity of leukemia</article-title><source>Nat. Biotechnol.</source><year>2013</year><volume>31</volume><fpage>545</fpage><pub-id pub-id-type="doi">10.1038/nbt.2594</pub-id><pub-id pub-id-type="pmid">23685480</pub-id></element-citation></ref><ref id="CR18"><label>18.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Unen</surname><given-names>V</given-names></name><etal/></person-group><article-title>Visual analysis of mass cytometry data by hierarchical stochastic neighbour embedding reveals rare cell types</article-title><source>Nat. Commun.</source><year>2017</year><volume>8</volume><fpage>1740</fpage><pub-id pub-id-type="doi">10.1038/s41467-017-01689-9</pub-id><pub-id pub-id-type="pmid">29170529</pub-id></element-citation></ref><ref id="CR19"><label>19.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Li</surname><given-names>W</given-names></name><name><surname>Cerise</surname><given-names>JE</given-names></name><name><surname>Yang</surname><given-names>Y</given-names></name><name><surname>Han</surname><given-names>H</given-names></name></person-group><article-title>Application of t-SNE to human genetic data</article-title><source>J. Bioinform. Comput. Biol.</source><year>2017</year><volume>15</volume><fpage>1750017</fpage><pub-id pub-id-type="doi">10.1142/S0219720017500172</pub-id><pub-id pub-id-type="pmid">28718343</pub-id></element-citation></ref><ref id="CR20"><label>20.</label><mixed-citation publication-type="other">Diaz-Papkovich, A., Anderson-Trocme, L. Gravel, S. Revealing multi-scale population structure in large cohorts. <ext-link ext-link-type="uri" xlink:href="https://www.biorxiv.org/content/10.1101/423632v2">https://www.biorxiv.org/content/10.1101/423632v2</ext-link> (2018).</mixed-citation></ref><ref id="CR21"><label>21.</label><mixed-citation publication-type="other">Schmidt, B. Stable random projection: lightweight, general-purpose dimensionality reduction for digitized libraries. <ext-link ext-link-type="uri" xlink:href="http://culturalanalytics.org/2018/09/stable-random-projection-lightweight-general-purpose-dimensionality-reduction-for-digitized-libraries/">http://culturalanalytics.org/2018/09/stable-random-projection-lightweight-general-purpose-dimensionality-reduction-for-digitized-libraries/</ext-link>&#x000a0;(2018).</mixed-citation></ref><ref id="CR22"><label>22.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Lee</surname><given-names>JA</given-names></name><name><surname>Verleysen</surname><given-names>M</given-names></name></person-group><article-title>Quality assessment of dimensionality reduction: Rank-based criteria</article-title><source>Neurocomputing</source><year>2009</year><volume>72</volume><fpage>1431</fpage><lpage>1443</lpage><pub-id pub-id-type="doi">10.1016/j.neucom.2008.12.017</pub-id></element-citation></ref><ref id="CR23"><label>23.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Wolf</surname><given-names>FA</given-names></name><name><surname>Angerer</surname><given-names>P</given-names></name><name><surname>Theis</surname><given-names>FJ</given-names></name></person-group><article-title>SCANPY: large-scale single-cell gene expression data analysis</article-title><source>Genome Biol.</source><year>2018</year><volume>19</volume><fpage>15</fpage><pub-id pub-id-type="doi">10.1186/s13059-017-1382-0</pub-id><pub-id pub-id-type="pmid">29409532</pub-id></element-citation></ref><ref id="CR24"><label>24.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Macosko</surname><given-names>EZ</given-names></name><etal/></person-group><article-title>Highly parallel genome-wide expression profiling of individual cells using nanoliter droplets</article-title><source>Cell</source><year>2015</year><volume>161</volume><fpage>1202</fpage><lpage>1214</lpage><pub-id pub-id-type="doi">10.1016/j.cell.2015.05.002</pub-id><pub-id pub-id-type="pmid">26000488</pub-id></element-citation></ref><ref id="CR25"><label>25.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Shekhar</surname><given-names>K</given-names></name><etal/></person-group><article-title>Comprehensive classification of retinal bipolar neurons by single-cell transcriptomics</article-title><source>Cell</source><year>2016</year><volume>166</volume><fpage>1308</fpage><lpage>1323</lpage><pub-id pub-id-type="doi">10.1016/j.cell.2016.07.054</pub-id><pub-id pub-id-type="pmid">27565351</pub-id></element-citation></ref><ref id="CR26"><label>26.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Harris</surname><given-names>KD</given-names></name><etal/></person-group><article-title>Classes and continua of hippocampal CA1 inhibitory neurons revealed by single-cell transcriptomics</article-title><source>PLoS Biol.</source><year>2018</year><volume>16</volume><fpage>e2006387</fpage><pub-id pub-id-type="doi">10.1371/journal.pbio.2006387</pub-id><pub-id pub-id-type="pmid">29912866</pub-id></element-citation></ref><ref id="CR27"><label>27.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Cadwell</surname><given-names>CR</given-names></name><etal/></person-group><article-title>Electrophysiological, transcriptomic and morphologic profiling of single neurons using Patch-seq</article-title><source>Nat. Biotechnol.</source><year>2016</year><volume>34</volume><fpage>199</fpage><pub-id pub-id-type="doi">10.1038/nbt.3445</pub-id><pub-id pub-id-type="pmid">26689543</pub-id></element-citation></ref><ref id="CR28"><label>28.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Kiselev</surname><given-names>VY</given-names></name><name><surname>Yiu</surname><given-names>A</given-names></name><name><surname>Hemberg</surname><given-names>M</given-names></name></person-group><article-title>scmap: projection of single-cell RNA-seq data across data sets</article-title><source>Nat. Methods</source><year>2018</year><volume>15</volume><fpage>359</fpage><pub-id pub-id-type="doi">10.1038/nmeth.4644</pub-id><pub-id pub-id-type="pmid">29608555</pub-id></element-citation></ref><ref id="CR29"><label>29.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Berman</surname><given-names>GJ</given-names></name><name><surname>Choi</surname><given-names>DM</given-names></name><name><surname>Bialek</surname><given-names>W</given-names></name><name><surname>Shaevitz</surname><given-names>JW</given-names></name></person-group><article-title>Mapping the stereotyped behaviour of freely moving fruit flies</article-title><source>J. Roy. Soc. Interface</source><year>2014</year><volume>11</volume><fpage>20140672</fpage><pub-id pub-id-type="doi">10.1098/rsif.2014.0672</pub-id><pub-id pub-id-type="pmid">25142523</pub-id></element-citation></ref><ref id="CR30"><label>30.</label><mixed-citation publication-type="other">Poli&#x0010d;ar, P. G., Stra&#x0017e;ar, M. &#x00026; Zupan, B. Embedding to reference t-SNE space addresses batch effects in single-cell classification. <ext-link ext-link-type="uri" xlink:href="https://www.biorxiv.org/content/10.1101/671404v1">https://www.biorxiv.org/content/10.1101/671404v1</ext-link> (2019).</mixed-citation></ref><ref id="CR31"><label>31.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Tasic</surname><given-names>B</given-names></name><etal/></person-group><article-title>Adult mouse cortical cell taxonomy revealed by single cell transcriptomics</article-title><source>Nat. Neurosci.</source><year>2016</year><volume>19</volume><fpage>335</fpage><pub-id pub-id-type="doi">10.1038/nn.4216</pub-id><pub-id pub-id-type="pmid">26727548</pub-id></element-citation></ref><ref id="CR32"><label>32.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>van der Maaten</surname><given-names>L</given-names></name></person-group><article-title>Accelerating t-SNE using tree-based algorithms</article-title><source>J. Mach. Learning Res.</source><year>2014</year><volume>15</volume><fpage>3221</fpage><lpage>3245</lpage></element-citation></ref><ref id="CR33"><label>33.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Linderman</surname><given-names>GC</given-names></name><name><surname>Steinerberger</surname><given-names>S</given-names></name></person-group><article-title>Clustering with t-SNE, provably</article-title><source>SIAM J. Math. Data Sci.</source><year>2019</year><volume>1</volume><fpage>313</fpage><lpage>332</lpage><pub-id pub-id-type="doi">10.1137/18M1216134</pub-id></element-citation></ref><ref id="CR34"><label>34.</label><mixed-citation publication-type="other">Linderman, G. C., Rachh, M., Hoskins, J. G., Steinerberger, S. &#x00026; Kluger, Y. Efficient algorithms for t-distributed stochastic neighborhood embedding. <ext-link ext-link-type="uri" xlink:href="https://arxiv.org/abs/1712.09005">https://arxiv.org/abs/1712.09005</ext-link> (2017).</mixed-citation></ref><ref id="CR35"><label>35.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Englund</surname><given-names>C</given-names></name><etal/></person-group><article-title>Pax6, Tbr2, and Tbr1 are expressed sequentially by radial glia, intermediate progenitor cells, and postmitotic neurons in developing neocortex</article-title><source>J. Neurosci.</source><year>2005</year><volume>25</volume><fpage>247</fpage><lpage>251</lpage><pub-id pub-id-type="doi">10.1523/JNEUROSCI.2899-04.2005</pub-id><pub-id pub-id-type="pmid">15634788</pub-id></element-citation></ref><ref id="CR36"><label>36.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Yuzwa</surname><given-names>SA</given-names></name><etal/></person-group><article-title>Developmental emergence of adult neural stem cells as revealed by single-cell transcriptional profiling</article-title><source>Cell Rep.</source><year>2017</year><volume>21</volume><fpage>3970</fpage><lpage>3986</lpage><pub-id pub-id-type="doi">10.1016/j.celrep.2017.12.017</pub-id><pub-id pub-id-type="pmid">29281841</pub-id></element-citation></ref><ref id="CR37"><label>37.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Iacono</surname><given-names>Giovanni</given-names></name><name><surname>Mereu</surname><given-names>Elisabetta</given-names></name><name><surname>Guillaumet-Adkins</surname><given-names>Amy</given-names></name><name><surname>Corominas</surname><given-names>Roser</given-names></name><name><surname>Cusc&#x000f3;</surname><given-names>Ivon</given-names></name><name><surname>Rodr&#x000ed;guez-Esteban</surname><given-names>Gustavo</given-names></name><name><surname>Gut</surname><given-names>Marta</given-names></name><name><surname>P&#x000e9;rez-Jurado</surname><given-names>Luis Alberto</given-names></name><name><surname>Gut</surname><given-names>Ivo</given-names></name><name><surname>Heyn</surname><given-names>Holger</given-names></name></person-group><article-title>bigSCale: an analytical framework for big-scale single-cell data</article-title><source>Genome Research</source><year>2018</year><volume>28</volume><issue>6</issue><fpage>878</fpage><lpage>890</lpage><pub-id pub-id-type="doi">10.1101/gr.230771.117</pub-id><pub-id pub-id-type="pmid">29724792</pub-id></element-citation></ref><ref id="CR38"><label>38.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Bhaduri</surname><given-names>A</given-names></name><name><surname>Nowakowski</surname><given-names>TJ</given-names></name><name><surname>Pollen</surname><given-names>AA</given-names></name><name><surname>Kriegstein</surname><given-names>AR</given-names></name></person-group><article-title>Identification of cell types in a mouse brain single-cell atlas using low sampling coverage</article-title><source>BMC Biol.</source><year>2018</year><volume>16</volume><fpage>113</fpage><pub-id pub-id-type="doi">10.1186/s12915-018-0580-x</pub-id><pub-id pub-id-type="pmid">30309354</pub-id></element-citation></ref><ref id="CR39"><label>39.</label><mixed-citation publication-type="other">Tang, J. Liu, J., Zhang, M. &#x00026; Mei, Q. Visualizing large-scale and high-dimensional data. In <italic>Proc. 25th International Conference on World Wide Web</italic> 287&#x02013;297 (2016).</mixed-citation></ref><ref id="CR40"><label>40.</label><mixed-citation publication-type="other">Chan, D. M. Rao, R., Huang, F. &#x00026; Canny, J. F. GPU accelerated t-distributed stochastic neighbor embedding. <italic>J. Parallel Distributed Comput.</italic><bold>131</bold>, 1&#x02013;13 (2019).</mixed-citation></ref><ref id="CR41"><label>41.</label><mixed-citation publication-type="other">Kobak, D., Linderman, G., Steinerberger, S., Kluger, Y. &#x00026; Berens, P. Heavy-tailed kernels reveal a finer cluster structure in t-SNE visualisations. In <italic>Proceedings of the&#x000a0;European Conference on Machine Learning and Principles and Practice of Knowledge Discovery in Databases</italic>, in print. <ext-link ext-link-type="uri" xlink:href="https://arxiv.org/abs/1902.05804">https://arxiv.org/abs/1902.05804</ext-link> (2019).</mixed-citation></ref><ref id="CR42"><label>42.</label><mixed-citation publication-type="other">van der Maaten, L. Learning a parametric embedding by preserving local structure. In <italic>Proceedings of the Twelth International Conference on Artificial Intelligence and Statistics</italic> 384&#x02013;391 (2009).</mixed-citation></ref><ref id="CR43"><label>43.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Cho</surname><given-names>H</given-names></name><name><surname>Berger</surname><given-names>B</given-names></name><name><surname>Peng</surname><given-names>J</given-names></name></person-group><article-title>Generalizable and scalable visualization of single-cell data using neural networks</article-title><source>Cell Syst.</source><year>2018</year><volume>7</volume><fpage>185</fpage><lpage>191</lpage><pub-id pub-id-type="doi">10.1016/j.cels.2018.05.017</pub-id><pub-id pub-id-type="pmid">29936184</pub-id></element-citation></ref><ref id="CR44"><label>44.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Ding</surname><given-names>J</given-names></name><name><surname>Condon</surname><given-names>A</given-names></name><name><surname>Shah</surname><given-names>SP</given-names></name></person-group><article-title>Interpretable dimensionality reduction of single cell transcriptome data with deep generative models</article-title><source>Nat. Commun.</source><year>2018</year><volume>9</volume><fpage>2002</fpage><pub-id pub-id-type="doi">10.1038/s41467-018-04368-5</pub-id><pub-id pub-id-type="pmid">29784946</pub-id></element-citation></ref><ref id="CR45"><label>45.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Pezzotti</surname><given-names>N</given-names></name><name><surname>H&#x000f6;llt</surname><given-names>T</given-names></name><name><surname>Lelieveldt</surname><given-names>B</given-names></name><name><surname>Eisemann</surname><given-names>E</given-names></name><name><surname>Vilanova</surname><given-names>A</given-names></name></person-group><article-title>Hierarchical stochastic neighbor embedding</article-title><source>Comput. Graphics Forum</source><year>2016</year><volume>35</volume><fpage>21</fpage><lpage>30</lpage><pub-id pub-id-type="doi">10.1111/cgf.12878</pub-id></element-citation></ref><ref id="CR46"><label>46.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Wolf</surname><given-names>FA</given-names></name><etal/></person-group><article-title>PAGA: graph abstraction reconciles clustering with trajectory inference through a topology preserving map of single cells</article-title><source>Genome Biol.</source><year>2019</year><volume>20</volume><fpage>59</fpage><pub-id pub-id-type="doi">10.1186/s13059-019-1663-x</pub-id><pub-id pub-id-type="pmid">30890159</pub-id></element-citation></ref><ref id="CR47"><label>47.</label><mixed-citation publication-type="other">Hinton, G. E. &#x00026; Roweis, S.T. Stochastic neighbor embedding. In <italic>Advances in Neural Information Processing Systems</italic> 857&#x02013;864 (2003).</mixed-citation></ref><ref id="CR48"><label>48.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Pezzotti</surname><given-names>N</given-names></name><etal/></person-group><article-title>Approximated and user steerable tSNE for progressive visual analytics</article-title><source>IEEE Trans. Visualization Comput. Graphics</source><year>2017</year><volume>23</volume><fpage>1739</fpage><lpage>1752</lpage><pub-id pub-id-type="doi">10.1109/TVCG.2016.2570755</pub-id></element-citation></ref><ref id="CR49"><label>49.</label><mixed-citation publication-type="other">Andrews, T. S. &#x00026; Hemberg, M. M3Drop: Dropout-based feature selection for scRNASeq. <italic>Bioinformatics</italic> (2018).</mixed-citation></ref><ref id="CR50"><label>50.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Zheng</surname><given-names>GXY</given-names></name><etal/></person-group><article-title>Massively parallel digital transcriptional profiling of single cells</article-title><source>Nat. Commun.</source><year>2017</year><volume>8</volume><fpage>14049</fpage><pub-id pub-id-type="doi">10.1038/ncomms14049</pub-id><pub-id pub-id-type="pmid">28091601</pub-id></element-citation></ref><ref id="CR51"><label>51.</label><mixed-citation publication-type="other">Townes, F. W., Hicks, S. C., Aryee, M. J. &#x00026; Irizarry, R. A. Feature selection and dimension reduction for single cell RNA-seq based on a multinomial model. <ext-link ext-link-type="uri" xlink:href="https://www.biorxiv.org/content/10.1101/574574v1">https://www.biorxiv.org/content/10.1101/574574v1</ext-link> (2019).</mixed-citation></ref><ref id="CR52"><label>52.</label><mixed-citation publication-type="other">Poli&#x0010d;ar, P. G., Stra&#x0017e;ar, M. &#x00026; Zupanopen, B. TSNE: a modular python library for t-SNE dimensionality reduction and embedding. <ext-link ext-link-type="uri" xlink:href="https://www.biorxiv.org/content/10.1101/731877v3">https://www.biorxiv.org/content/10.1101/731877v3</ext-link> (2019).</mixed-citation></ref></ref-list></back></article>