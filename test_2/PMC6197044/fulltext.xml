<!DOCTYPE article PUBLIC "-//NLM//DTD JATS (Z39.96) Journal Archiving and Interchange DTD v1.1 20151215//EN" "JATS-archivearticle1.dtd"> 
<article xmlns:xlink="http://www.w3.org/1999/xlink" xmlns:mml="http://www.w3.org/1998/Math/MathML" article-type="research-article"><?properties open_access?><?DTDIdentifier.IdentifierValue -//NLM//DTD JATS (Z39.96) Journal Publishing DTD v1.1 20151215//EN?><?DTDIdentifier.IdentifierType public?><?SourceDTD.DTDName JATS-journalpublishing1.dtd?><?SourceDTD.Version 1.1?><?ConverterInfo.XSLTName jp2nlmx2.xsl?><?ConverterInfo.Version 1?><front><journal-meta><journal-id journal-id-type="nlm-ta">PeerJ</journal-id><journal-id journal-id-type="iso-abbrev">PeerJ</journal-id><journal-id journal-id-type="publisher-id">peerj</journal-id><journal-id journal-id-type="pmc">peerj</journal-id><journal-title-group><journal-title>PeerJ</journal-title></journal-title-group><issn pub-type="epub">2167-8359</issn><publisher><publisher-name>PeerJ Inc.</publisher-name><publisher-loc>San Francisco, USA</publisher-loc></publisher></journal-meta><article-meta><article-id pub-id-type="pmcid">6197044</article-id><article-id pub-id-type="publisher-id">5692</article-id><article-id pub-id-type="doi">10.7717/peerj.5692</article-id><article-categories><subj-group subj-group-type="heading"><subject>Bioinformatics</subject></subj-group><subj-group subj-group-type="heading"><subject>Computational Biology</subject></subj-group></article-categories><title-group><article-title>Distributed Bayesian networks reconstruction on the whole genome scale</article-title></title-group><contrib-group><contrib id="author-1" contrib-type="author" corresp="yes"><name><surname>Frolova</surname><given-names>Alina</given-names></name><email>fshodan@gmail.com</email><email>a.o.frolova@imbg.org.ua</email><xref ref-type="aff" rid="aff-1">1</xref></contrib><contrib id="author-2" contrib-type="author"><name><surname>Wilczy&#x00144;ski</surname><given-names>Bartek</given-names></name><xref ref-type="aff" rid="aff-2">2</xref></contrib><aff id="aff-1"><label>1</label><institution>Institute of Molecular Biology and Genetics</institution>, <city>Kyiv</city>, <country>Ukraine</country></aff><aff id="aff-2"><label>2</label><institution>Institute of Informatics, University of Warsaw</institution>, <city>Warsaw</city>, <country>Poland</country></aff></contrib-group><contrib-group><contrib contrib-type="editor"><name><surname>B&#x000e4;hler</surname><given-names>J&#x000fc;rg</given-names></name></contrib></contrib-group><pub-date pub-type="epub" date-type="pub" iso-8601-date="2018-10-19"><day>19</day><month>10</month><year iso-8601-date="2018">2018</year></pub-date><pub-date pub-type="collection"><year>2018</year></pub-date><volume>6</volume><elocation-id>e5692</elocation-id><history><date date-type="received" iso-8601-date="2018-04-06"><day>6</day><month>4</month><year iso-8601-date="2018">2018</year></date><date date-type="accepted" iso-8601-date="2018-09-05"><day>5</day><month>9</month><year iso-8601-date="2018">2018</year></date></history><permissions><copyright-statement>&#x000a9;2018 Frolova and Wilczy&#x00144;ski</copyright-statement><copyright-year>2018</copyright-year><copyright-holder>Frolova and Wilczy&#x00144;ski</copyright-holder><license xlink:href="http://creativecommons.org/licenses/by/4.0/"><license-p>This is an open access article distributed under the terms of the <ext-link ext-link-type="uri" xlink:href="http://creativecommons.org/licenses/by/4.0/">Creative Commons Attribution License</ext-link>, which permits unrestricted use, distribution, reproduction and adaptation in any medium and for any purpose provided that it is properly attributed. For attribution, the original author(s), title, publication source (PeerJ) and either DOI or URL of the article must be cited.</license-p></license></permissions><self-uri xlink:href="https://peerj.com/articles/5692"/><abstract><sec><title>Background</title><p>Bayesian networks are directed acyclic graphical models widely used to represent the probabilistic relationships between random variables. They have been applied in various biological contexts, including gene regulatory networks and protein&#x02013;protein interactions inference. Generally, learning Bayesian networks from experimental data is NP-hard, leading to widespread use of heuristic search methods giving suboptimal results. However, in cases when the acyclicity of the graph can be externally ensured, it is possible to find the optimal network in polynomial time. While our previously developed tool BNFinder implements polynomial time algorithm, reconstructing networks with the large amount of experimental data still leads to computations on single CPU growing exceedingly.</p></sec><sec><title>Results</title><p>In the present paper we propose parallelized algorithm designed for multi-core and distributed systems and its implementation in the improved version of BNFinder&#x02014;tool for learning optimal Bayesian networks. The new algorithm has been tested on different simulated and experimental datasets showing that it has much better efficiency of parallelization than the previous version. BNFinder gives comparable results in terms of accuracy with respect to current state-of-the-art inference methods, giving significant advantage in cases when external information such as regulators list or prior edge probability can be introduced, particularly for datasets with static gene expression observations.</p></sec><sec><title>Conclusions</title><p>We show that the new method can be used to reconstruct networks in the size range of thousands of genes making it practically applicable to whole genome datasets of prokaryotic systems and large components of eukaryotic genomes. Our benchmarking results on realistic datasets indicate that the tool should be useful to a wide audience of researchers interested in discovering dependencies in their large-scale transcriptomic datasets.</p></sec></abstract><kwd-group kwd-group-type="author"><kwd>Bayesian networks learning</kwd><kwd>Gene regulatory networks inference</kwd><kwd>Parallel and distributed computing</kwd></kwd-group><funding-group><award-group id="fund-1"><funding-source>National Center for Science grant</funding-source><award-id>DEC-2012/05/B/N22/0567</award-id></award-group><award-group id="fund-2"><funding-source>SKILLS programme</funding-source></award-group><award-group id="fund-3"><funding-source>National program of Grid technologies implementation and usage in Ukraine</funding-source><award-id>69-53/13</award-id><award-id> 0117U002812</award-id></award-group><funding-statement>This work was partially supported by the National Center for Science grant (decision number DEC-2012/05/B/N22/0567) and Foundation for Polish Science within the SKILLS programme. This work was also supported by National program of Grid technologies implementation and usage in Ukraine (project number 69-53/13 and 0117U002812). There was no additional external funding received for this study. The funders had no role in study design, data collection and analysis, decision to publish, or preparation of the manuscript.</funding-statement></funding-group></article-meta></front><body><sec sec-type="intro"><title>Introduction</title><p>Bayesian networks (BNs) are graphical representations of multivariate joint probability distributions factorized consistently with the dependency structure among variables. In practice, this often gives concise structures that are easy to interpret even for non-specialists. A BN is a directed acyclic graph with nodes representing random variables and edges representing conditional dependencies between the nodes. Nodes that are not connected represent variables that are independent conditionally on their parent variables&#x000a0;(<xref rid="ref-13" ref-type="bibr">Friedman &#x00026; Koller, 2003</xref>). In general, inferring BN structure is NP-hard&#x000a0;(<xref rid="ref-6" ref-type="bibr">Chickering, Heckerman &#x00026; Meek, 2004</xref>), however it was shown by <xref rid="ref-8" ref-type="bibr">Dojer (2006)</xref> that it is possible to find the optimal network structure in polynomial time when datasets are fixed in size and the acyclicity of the graph is pre-determined by external constraints. The acyclicity can be ensured in two cases: when inferring dynamic BNs from time-series data (the &#x0201c;unrolled&#x0201d; graph, i.e.,&#x000a0;graph with a copy of each variable in each discretized time point, is always acyclic), or when user defines the regulation hierarchy restricting the set of possible edges in case of static BNs (for example, by introducing the list of potential regulators). Therefore the minimal information required to infer dynamic BN is expression values matrix, and in case of static BN&#x02014;expression values matrix and the list of potential parent variables.</p><p>This algorithm was implemented in BNFinder&#x02014;a tool for BNs reconstruction from experimental data&#x000a0;(<xref rid="ref-31" ref-type="bibr">Wilczy&#x00144;ski &#x00026; Dojer, 2009</xref>).</p><p>One of the common use of BNs in bioinformatics is inference of interactions between genes&#x000a0;(<xref rid="ref-35" ref-type="bibr">Zou &#x00026; Conzen, 2005</xref>) and proteins (<xref rid="ref-16" ref-type="bibr">Jansen et al., 2003</xref>). Even though it was originally developed for this purpose, BNFinder is a generic tool for reconstructing regulatory interactions. Since its original publication, it was successfully applied to linking expression data with sequence motif information&#x000a0;(<xref rid="ref-7" ref-type="bibr">Dabrowski et al., 2010</xref>), identifying histone modifications connected to enhancer activity (<xref rid="ref-4" ref-type="bibr">Bonn et al., 2012</xref>) and to predicting gene expression profiles of tissue-specific genes&#x000a0;(<xref rid="ref-32" ref-type="bibr">Wilczynski et al., 2012</xref>).</p><p>BNFinder is implemented in Python programming language and is therefore available for most modern operating systems. It is a command line tool, but the usage is quite easy even for the scientists without a strong Computer Science background. The learning data must be passed to BNFinder in a text file split into 3 parts: preamble, experiment specification and experiment data. The preamble allows users to specify some features of the data and/or network, while the next two parts contain the learning data, essentially formatted as a table with space- or tab-separated values. For example, if the user wants to infer the network with four genes {G1, G2, G3, G4}, where G1 and G2 are known transcription factors, the input file would look like <xref rid="table-1" ref-type="table">Table 1</xref>.</p><p>In cases when more information is available about the experiment, the preamble section of the input file can be used to incorporate perturbational data, prior probabilities of the genes interaction or the expected structure of the signaling pathway (especially in cases when one expects cascade activation of the regulatory factors). These parameters are not required but they can substantially increase the accuracy of inferred network. Readers interested in applying BNFinder to their own data might find it useful to look through the BNFinder tutorial (<ext-link ext-link-type="uri" xlink:href="https://github.com/sysbio-vo/bnfinder/raw/master/doc/bnfinder_tutorial.pdf">https://github.com/sysbio-vo/bnfinder/raw/master/doc/bnfinder_tutorial.pdf</ext-link>), which includes several working examples of simple and more complex usage scenarios.</p><table-wrap id="table-1" orientation="portrait" position="float"><object-id pub-id-type="doi">10.7717/peerj.5692/table-1</object-id><label>Table 1</label><caption><title> An example of BNFinder input learning data for inferring static BN with four genes, where genes G1 and G2 are regulators (transcription factors).</title><p>The first line denotes preamble (in this case - regulators list), the second line&#x02014;experiment specifications (the list of experiments names), and the rest of lines denote experiment data (gene expression values).</p></caption><alternatives><graphic xlink:href="peerj-06-5692-g012"/><table frame="hsides" rules="groups"><colgroup span="1"><col span="1"/><col span="1"/><col span="1"/><col span="1"/><col span="1"/><col span="1"/><col span="1"/></colgroup><thead><tr><th colspan="7" rowspan="1">#regulators G1 G2</th></tr><tr><th rowspan="1" colspan="1">conditions</th><th rowspan="1" colspan="1">EXP0</th><th rowspan="1" colspan="1">EXP1</th><th rowspan="1" colspan="1">EXP2</th><th rowspan="1" colspan="1">EXP3</th><th rowspan="1" colspan="1">EXP4</th><th rowspan="1" colspan="1">EXP5</th></tr></thead><tbody><tr><td rowspan="1" colspan="1">G1</td><td rowspan="1" colspan="1">0.2</td><td rowspan="1" colspan="1">3.4</td><td rowspan="1" colspan="1">1.3</td><td rowspan="1" colspan="1">7.4</td><td rowspan="1" colspan="1">2.2</td><td rowspan="1" colspan="1">0.4</td></tr><tr><td rowspan="1" colspan="1">G2</td><td rowspan="1" colspan="1">4.5</td><td rowspan="1" colspan="1">7.8</td><td rowspan="1" colspan="1">0.3</td><td rowspan="1" colspan="1">5.6</td><td rowspan="1" colspan="1">3.3</td><td rowspan="1" colspan="1">1.1</td></tr><tr><td rowspan="1" colspan="1">G3</td><td rowspan="1" colspan="1">1.0</td><td rowspan="1" colspan="1">2.9</td><td rowspan="1" colspan="1">0.8</td><td rowspan="1" colspan="1">5.5</td><td rowspan="1" colspan="1">1.6</td><td rowspan="1" colspan="1">2.8</td></tr><tr><td rowspan="1" colspan="1">G4</td><td rowspan="1" colspan="1">3.2</td><td rowspan="1" colspan="1">6.5</td><td rowspan="1" colspan="1">0.5</td><td rowspan="1" colspan="1">3.1</td><td rowspan="1" colspan="1">8.2</td><td rowspan="1" colspan="1">5.0</td></tr></tbody></table></alternatives></table-wrap><p>BNFinder supports several output formats, the simplest of which is SIF (Simple Interaction File), where each line represents the fact of a single interaction between two variables. The SIF output for the network in <xref rid="table-1" ref-type="table">Table 1</xref> shows positive correlation between G1 and G3, G2 and G4 genes:</p><preformat> 
 
G1&#x000a0;+&#x000a0;G3 
G2&#x000a0;+&#x000a0;G4    </preformat><p>The detailed explanation on all input parameters and their influence on output data is described in the user manual, freely available from the dedicated github repository&#x02014;<ext-link ext-link-type="uri" xlink:href="https://github.com/sysbio-vo/bnfinder/raw/master/doc/bnfinder_doc_all.pdf">https://github.com/sysbio-vo/bnfinder/raw/master/doc/bnfinder_doc_all.pdf</ext-link>.</p><p>Even though BNFinder can be applied to many different datasets, the practical usage of the algorithm is limited by its running times that can be relatively long. Since the algorithm published by <xref rid="ref-8" ref-type="bibr">Dojer (2006)</xref> has the capacity to be parallelized by design and the current version of BNFinder (<xref rid="ref-9" ref-type="bibr">Dojer et al., 2013</xref>) has only a simple parallelization implemented, we have developed a new version that takes advantage of multiple cores via the python multiprocessing module and gives better performance.</p></sec><sec><title>Implementation</title><p>The general scheme of the learning algorithm is the following: for each of the random variables find the best possible set of parent variables by considering them in a carefully chosen order of increasing scoring function. This function consists of two components: one is penalizing the complexity of a network and the other one is evaluating the possibility of explaining data by a network. The acyclicity of the graph allows to compute the parents set of each variable independently, therefore algorithm first starts with computing scores for all possible singleton parents sets for a given random variable. Then it checks if penalty on increasing parents set size is too high or if it reached user defined parents set size limit, and if no&#x02014;proceeds with two-element parents sets and so on. The detailed description of the algorithm and scoring functions is given in Dojer manuscript (<xref rid="ref-8" ref-type="bibr">Dojer, 2006</xref>).</p><p>Current parallelization in BNFinder version 2 (<xref rid="ref-9" ref-type="bibr">Dojer et al., 2013</xref>) can be considered <bold>variable-wise</bold> as it distributes the work done on each variable between the different threads. However, such approach has natural limitations. Firstly, the number of parallelized tasks cannot exceed the number of random variables in the problem, meaning that in the cases where only a few variables are considered (e.g., in classification by BNs) we get a very limited performance boost. Secondly, <bold>variable-wise</bold> parallelization might be vulnerable (in terms of performance) to the datasets with highly heterogeneous variables, i.e., variables whose true dependency graph has a wide range of connections. As the time spent on computing parent sets for different variables varies - it leads to uneven load of threads. In biology we usually observe networks with scale-free topology consisting of a few hub nodes with many parents and a large number of nodes that have one or small number of connections (<xref rid="ref-2" ref-type="bibr">Barabasi &#x00026; Oltvai, 2004</xref>). If one applies <bold>variable-wise</bold> algorithm to such networks the potential gain in the algorithm performance is not greater than in the case where all the nodes have as many parents as the hub node with the largest parent set.</p><p>While <bold>variable-wise</bold> algorithm is the most straightforward one, it is also possible to consider different possible parents sets in parallel, as is the case for the <bold>set-wise</bold> algorithm. It means that in the first step we compute singleton parents sets using all available threads, in the second step we compute two-element parents sets in parallel and so on, until we reach parents sets size limit or scoring function limit. However, the <bold>set-wise</bold> algorithm requires more synchronizations between the threads (<xref rid="ref-18" ref-type="bibr">McCool, Reinders &#x00026; Robison, 2012</xref>) in comparison with the <bold>variable-wise</bold>. On top of that allocating large number of cores to the variable whose parents set is very quick to compute may result in lower performance due to the context switching. The latter is the process of storing the state of a thread, so it can be restored and execution resumed from the same point later. Context switch is governed by operating system and has a cost in performance, therefore if we allocate 100 cores to the variable which true singleton parent is found in the first step (which is quick to compute as we only need to score single parent-variable interactions), it would probably take more time than when allocating 10 cores. As it is difficult to tell, which problem might be more important in practice, we have implemented and tested two approaches: <bold>set-wise</bold> only and <bold>hybrid</bold> one - a natural combination of <bold>variable-wise</bold> and <bold>set-wise</bold>. It should be noted that, while the variable-wise parallelization was already implemented in the BNFinder, the set-wise and hybrid methods are novel in this particular application.</p><p><xref ref-type="fig" rid="fig-1">Figure 1</xref> shows parallelization algorithms schema in a simplified way for better understanding. As stated above, <bold>set-wise</bold> algorithm uses each given core to compute parents sets for one gene and after finding parents it proceeds with the next gene. On the contrary, <bold>hybrid</bold> algorithm uniformly distributes cores between genes, for example, if a user has three genes in the network and six cores available, each gene will have two cores for computing its parents set. If there are seven cores available, one gene will have three cores, while other two genes will have two cores. Thus, once the gene is processed, the freed cores cannot be allocated to other genes, which may be a potential disadvantage.</p><fig id="fig-1" orientation="portrait" position="float"><object-id pub-id-type="doi">10.7717/peerj.5692/fig-1</object-id><label>Figure 1</label><caption><title>Parallelization algorithms schema.</title><p>For simplicity the plot depicts the case with two random variables (genes, proteins or other biological entities), three parents (regulators), and four CPUs. However, this example can be easily extended to more variables, and in the end the user gets output as shown on <bold>Result</bold> subplot. After considering parents sets of a same size BNFinder checks if either parents set size limit is reached or scoring function penalty is too high to decide if proceed next. (A) <bold>Variable-wise</bold> algorithm can only parallelize between variables, therefore out of four CPU it uses only two. (B) <bold>Hybrid</bold> algorithm uses two levels of parallelization&#x02014;between variables and between parents sets of each variable, thus, it uses two CPUs per variable in a given example. In general it uniformly distributes cores among variables. (C) <bold>Set-wise</bold> algorithm implements parallelization between parents sets only, thus, considering variables sequentially and using four CPUs per variable.</p></caption><graphic xlink:href="peerj-06-5692-g001"/></fig><p>So, the pure theoretical complexity of <bold>set-wise</bold> (left side of inequality) and <bold>hybrid</bold> (right side of inequality) algorithms can be described in the following way: <disp-formula id="NONUM-d2e305"><alternatives><graphic xlink:href="peerj-06-5692-e001.jpg" mimetype="image" mime-subtype="png" position="float" orientation="portrait"/><tex-math id="M1">\documentclass[12pt]{minimal}
\usepackage{amsmath}
\usepackage{wasysym} 
\usepackage{amsfonts} 
\usepackage{amssymb} 
\usepackage{amsbsy}
\usepackage{upgreek}
\usepackage{mathrsfs}
\setlength{\oddsidemargin}{-69pt}
\begin{document}
}{}\begin{eqnarray*} \frac{\sum _{i=1}^{n}{t}_{i}}{k} = \frac{({\mathop{{avg}\nolimits }\nolimits }_{i=1}^{n}{t}_{i})n}{k} \leq \frac{({\mathop{\max \nolimits }\nolimits }_{i=1}^{n}{t}_{i})n}{k} \end{eqnarray*}\end{document}</tex-math><mml:math id="mml-NONUM-d2e305"><mml:mstyle displaystyle="true"><mml:mfrac><mml:mrow><mml:munderover><mml:mrow><mml:mo mathsize="big" movablelimits="false">&#x02211;</mml:mo></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mi>n</mml:mi></mml:mrow></mml:munderover><mml:msub><mml:mrow><mml:mi>t</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mrow><mml:mi>k</mml:mi></mml:mrow></mml:mfrac><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:mrow><mml:mfenced separators="" open="(" close=")"><mml:msubsup><mml:mrow><mml:mo>avg</mml:mo></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mi>n</mml:mi></mml:mrow></mml:msubsup><mml:msub><mml:mrow><mml:mi>t</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub></mml:mfenced></mml:mrow><mml:mi>n</mml:mi></mml:mrow><mml:mrow><mml:mi>k</mml:mi></mml:mrow></mml:mfrac><mml:mo>&#x02264;</mml:mo><mml:mfrac><mml:mrow><mml:mrow><mml:mfenced separators="" open="(" close=")"><mml:msubsup><mml:mrow><mml:mo class="qopname">max</mml:mo></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mi>n</mml:mi></mml:mrow></mml:msubsup><mml:msub><mml:mrow><mml:mi>t</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub></mml:mfenced></mml:mrow><mml:mi>n</mml:mi></mml:mrow><mml:mrow><mml:mi>k</mml:mi></mml:mrow></mml:mfrac></mml:mstyle></mml:math></alternatives></disp-formula>where <italic>k</italic> is the cores number, <italic>n</italic> is the number of random variables, and <italic>t</italic><sub><italic>i</italic></sub> is the time one needs to compute optimal parents set for the <italic>i</italic>th variable using one core.</p><p>Thus, the time to reconstruct the whole network in case of a <bold>set-wise</bold> approach is the sum of time needed for each random variable, which is in fact average time one spends on finding the parents set for one variable, while inferring BN with a <bold>hybrid</bold> approach is bounded by the maximum time one spends on one variable. This estimate does not take into account the time, which operating system spends on multi-threading or accessing the disk storage.</p></sec><sec sec-type="results"><title>Results</title><sec><title>Performance testing</title><sec><title>Algorithms comparison</title><p>We compared implementations of three different algorithms: <bold>variable-wise</bold>, <bold>set-wise</bold> and <bold>hybrid</bold>. The original implementation (<bold>variable-wise</bold>) serves as a baseline for computing the speed-up and efficiency of the parallelization. For testing we used synthetic benchmark data as well as real datasets concerning protein phosphorylation network published by <xref rid="ref-25" ref-type="bibr">Sachs et al. (2005)</xref>. The efficiency is defined as speed-up divided by the number of cores used.</p><p><bold>Set-wise</bold> and <bold>hybrid</bold> algorithms performance on a 20-gene synthetic network was very similar, while the speed-up and efficiency comparison revealed more differences between the algorithms (see <xref ref-type="fig" rid="fig-2">Fig. 2</xref>). There is no regulators list for this network, so BNFinder reconstructed a dynamic BN. <bold>Hybrid</bold> algorithm showed more unstable behavior, performing better when the number of cores correlates with the number of genes. It outperformed <bold>set-wise</bold> when the number of cores exceeded the number of genes two times at least, however it didn&#x02019;t show any speed-up when increasing the number of cores from 42 to 50. The latter is easily explained by the algorithm design, since running time is bound by the most computationally complex variable, using 41&#x02013;59 cores cannot give performance boost as long as this variable provided with one core only.</p><fig id="fig-2" orientation="portrait" position="float"><object-id pub-id-type="doi">10.7717/peerj.5692/fig-2</object-id><label>Figure 2</label><caption><title>Synthetic data testing.</title><p>Comparing performance (A), speed-up (B) and efficiency (C) of algorithms on synthetic benchmark data: 20 variables &#x000d7;2,000 observations. Speed-up is a ratio of the performance with increase of the cores number. Efficiency is a speed-up normalized by the number of cores.</p></caption><graphic xlink:href="peerj-06-5692-g002"/></fig><p>The Sachs et al. network we tried next has 11 proteins. The regulators are selected from those proteins and introduced in the cascade manner, which denotes expected layer structure of the signaling pathway. The derivation of the structure relied on the simultaneous measurement of multiple phosphorylated protein and phospholipid components in thousands of individual primary human immune system cells. Perturbing these cells with molecular interventions drove the ordering of connections between pathway components. We took the data from the article, and transformed it into the format suitable for BNFinder. In particular, first layer can regulate all the following, while each next one cannot regulate previous layers. On the first layer only singleton parents set is possible consisting of <italic>plcg</italic> protein, on the second layer we have two regulators, <italic>PIP3</italic> and previously defined <italic>plcg</italic>, making it possible to search for singleton and two-element parents sets for the rest of proteins, and so on.</p><p>Sachs et al. data showed significant difference between two algorithms. Clearly, the <bold>set-wise</bold> algorithm outperforms the <bold>hybrid</bold> one: using 11 cores it showed 8&#x000d7;&#x000a0;speed-up, while the <bold>hybrid</bold> algorithm showed only 1.5&#x000d7;&#x000a0;speed-up (see <xref ref-type="fig" rid="fig-3">Fig. 3</xref>). <bold>Hybrid</bold> algorithm performance was hindered by highly heterogeneous variables in the input data, because out of the 11 proteins in the network <italic>pakts473</italic> has 6 parents, <italic>p44/42</italic> has 3 parents, while others have 1&#x02013;2 parents. Importantly, the better performing algorithm is also the one showing more consistent behavior.</p><fig id="fig-3" orientation="portrait" position="float"><object-id pub-id-type="doi">10.7717/peerj.5692/fig-3</object-id><label>Figure 3</label><caption><title>Sachs et al. data testing.</title><p>Comparing performance (A), speed-up (B) and efficiency (C) of algorithms on protein phosphorylation data: 11 variables&#x000a0;&#x000d7;&#x000a0;1,023 observations (<xref rid="ref-25" ref-type="bibr">Sachs et al., 2005</xref>). Speed-up is a ratio of the performance with increase of the cores number. Efficiency is a speed-up normalized by the number of cores.</p></caption><graphic xlink:href="peerj-06-5692-g003"/></fig><p>However, the way the regulators are introduced in the input file produces uneven load by itself, as each next variable has bigger set of potential parents. Therefore, we generated more benchmark data with different number of regulator and target genes, where we could define regulators in one layer manner or similar to Sachs data. Moreover, the underlying structure of generated networks was designed to be heterogeneous. Namely, it contains genes with gradually increasing number of parents: first gene has zero regulators, second gene&#x02014;one regulator, third&#x02014;two regulators and so on. The datasets were generated with <italic>BayesGen.py</italic> script that is included in the supplementary material. It takes the desired connectivity between variables and simulates the observations as emissions from a BN with bimodal Gaussian distributions of variables.</p><p>The results of multiple tests showed that introducing complex layer structure of regulators always resulted in the <bold>hybrid</bold> algorithm poor performance. It either showed much worse results regardless of the number of cores as in <xref ref-type="fig" rid="fig-3">Fig. 3</xref> or it showed comparable speed-up when the number of cores was three times bigger than the number of genes. In cases when regulators were supplied as one single list both algorithms showed results similar to those in <xref ref-type="fig" rid="fig-2">Fig. 2</xref>, namely the <bold>set-wise</bold> algorithm was better when the number of cores was lower than the number of genes, while the <bold>hybrid</bold> algorithm was better in the opposite case (although there was no such dramatic difference as in the case of the layered regulators structure). The more observations per regulator-target interaction we had, the better BNFinder predicted the network structure. However, as we studied running times per gene we observed that variables with the biggest number of parents did not always result in the longest computations. The latter is explained by how the scoring function works. BNFinder stops when the penalty for increasing the set of parents is so big that it cannot improve beyond what it has already found. In general, if the optimal parent set is very good in predicting the child variable value BNFinder will finish searching earlier. It means that the whole family of three-element parents sets can have worse scores than the two-element parents set, but the algorithm will proceed further because it has not yet reached the penalty on increasing the set size.</p><p>In particular, running times also depend on the number of observations and the number of nodes in the networks. For example, <xref ref-type="fig" rid="fig-4">Fig. 4</xref> shows that increasing the number of observations by 10&#x000d7;&#x000a0;leads to 12&#x000d7;&#x000a0;longer running time for the network of the same size, while 8-gene networks take 3 times longer to compute in comparison to 7-gene networks having the same number of observations.</p><fig id="fig-4" orientation="portrait" position="float"><object-id pub-id-type="doi">10.7717/peerj.5692/fig-4</object-id><label>Figure 4</label><caption><title>Hybrid algorithm performance on the datasets of different size.</title><p>The tendency is preserved for larger numbers of cores as well.</p></caption><graphic xlink:href="peerj-06-5692-g004"/></fig><p>Since there is no obvious winner between <bold>set-wise</bold> and <bold>hybrid</bold> algorithms, we decided to provide users with both options with <bold>set-wise</bold> being the default algorithm.</p><p>Tests on benchmark and Sachs data were performed on the same server with AMD Opteron (TM) Processor 6,272 (4 CPUs with total of 64 cores) and 512GB RAM. During the tests the server was loaded only by regular system processes, but to ensure statistical significance we performed each test five times, plotting average values with standard deviations.</p></sec><sec><title>Distributed computations testing</title><p>For the new version of BNFinder we also implemented an option for distributed usage of the tool. The idea is quite simple and did not require specific python libraries or tools. The user has to submit the file with subset of genes as input argument, so BNFinder can calculate partial result. When all the genes are processed user must place all the results into one folder and run BNFinder again, so it will aggregate the results.</p><p>For the tests we chose Challenge 5 (Genome-Scale Network Inference) data from DREAM2 competition (Dialogue for Reverse Engineering Assessments and Methods) (<xref rid="ref-28" ref-type="bibr">Stolovitzky, Prill &#x00026; Califano, 2009</xref>; <xref rid="ref-10" ref-type="bibr">DREAM Initiative, 2009</xref>). Challenge data is a log-normalized compendium of Escherichia coli expression profiles, which was provided by Tim Gardner to DREAM initiative (<xref rid="ref-12" ref-type="bibr">Faith et al., 2007</xref>). The participants were not informed about the data origin and were provided only with 3,456 genes&#x000a0;&#x000d7;&#x000a0;300 experiments dataset and the list of transcription factors.</p><p>BNFinder was tested with different parents set limit parameter value (i.e., maximum number of potential parents), which increases the computation time dramatically in non-linear way, especially in case of dataset with many variables. We compared <bold>set-wise</bold> algorithm performance with context likelihood of relatedness (CLR) algorithm - an extension of the relevance networks approach, that utilizes the concept of mutual information (<xref rid="ref-12" ref-type="bibr">Faith et al., 2007</xref>). We chose CLR, because it is very fast and easy to use tool, which provides good results. In addition, CLR-based algorithm - synergy augmented CLR (SA-CLR) was best performed algorithm on Challenge 5 (<xref rid="ref-30" ref-type="bibr">Watkinson et al., 2009</xref>).</p><p>The CLR tests were performed on the GP-DREAM platform, designed for the application and development of network inference and consensus methods (<xref rid="ref-23" ref-type="bibr">Reich et al., 2006</xref>). BNFinder tests were done within Ukrainian Grid Infrastructure (<xref rid="ref-29" ref-type="bibr">VO &#x0201c;Infrastructure&#x0201d;, 2011</xref>), which was accessed through nordugrid-arc middleware (arc client version 4.1.0 (<xref rid="ref-11" ref-type="bibr">Ellert et al., 2007</xref>)), so the tasks submitting process was automated and unified. The results presented in <xref rid="table-2" ref-type="table">Table 2</xref> are not precisely comparable due to differences in used hardware, especially when using such heterogeneous environment as Grid. In addition, we could not obtain stable number of cores over time with the Grid, as the clusters were loaded with other tasks. However, running times can give a rough estimate for those who plan to use BNFinder on large datasets.</p><table-wrap id="table-2" orientation="portrait" position="float"><object-id pub-id-type="doi">10.7717/peerj.5692/table-2</object-id><label>Table 2</label><caption><title>DREAM2 Challenge 5 data testing.</title><p>BNFinder <bold>set-wise</bold> algorithm is used with 4 cores and 4 genes per task. The tasks were then distributed among computational nodes. <italic>l</italic> stands for BNFinder parents sets limit. CLR with cutoff means limiting output results to 100,000 genes interactions.</p></caption><alternatives><graphic xlink:href="peerj-06-5692-g013"/><table frame="hsides" rules="groups"><colgroup span="1"><col span="1"/><col span="1"/><col span="1"/><col span="1"/><col span="1"/><col span="1"/><col span="1"/></colgroup><thead><tr><th rowspan="1" colspan="1"/><th rowspan="1" colspan="1">CLR</th><th rowspan="1" colspan="1">CLR with cutoff</th><th rowspan="1" colspan="1">BNF, <italic>l</italic>&#x000a0;=&#x000a0;1</th><th rowspan="1" colspan="1">BNF, <italic>l</italic>&#x000a0;=&#x000a0;2</th><th rowspan="1" colspan="1">BNF, <italic>l</italic>&#x000a0;=&#x000a0;3</th><th rowspan="1" colspan="1">BNF, <italic>l</italic>&#x000a0;=&#x000a0;3</th></tr><tr><th rowspan="1" colspan="1"/><th rowspan="1" colspan="1"/><th rowspan="1" colspan="1"/><th rowspan="1" colspan="1"/><th rowspan="1" colspan="1"/><th rowspan="1" colspan="1">Intel Xeon E5345</th><th rowspan="1" colspan="1">Intel Xeon E5-2690</th></tr></thead><tbody><tr><td rowspan="1" colspan="1">CPU time, hours</td><td rowspan="1" colspan="1">0.7879</td><td rowspan="1" colspan="1">0.1999</td><td rowspan="1" colspan="1">2.0021</td><td rowspan="1" colspan="1">383.7149</td><td rowspan="1" colspan="1">109,200</td><td rowspan="1" colspan="1">54,800</td></tr><tr><td rowspan="1" colspan="1">Actual time, hours</td><td rowspan="1" colspan="1">0.2626</td><td rowspan="1" colspan="1">0.0666</td><td rowspan="1" colspan="1">0.0667</td><td rowspan="1" colspan="1">12.7904</td><td rowspan="1" colspan="1">336</td><td rowspan="1" colspan="1">169</td></tr><tr><td rowspan="1" colspan="1">Total CPU number</td><td rowspan="1" colspan="1">3</td><td rowspan="1" colspan="1">3</td><td rowspan="1" colspan="1">30</td><td rowspan="1" colspan="1">30</td><td rowspan="1" colspan="1">&#x0223c;325</td><td rowspan="1" colspan="1">&#x0223c;325</td></tr></tbody></table></alternatives></table-wrap><p>Even though computing with parents sets limit of 3 takes significant amount of time and resources, it is clear that BNFinder is able to reconstruct genome-scale datasets, significantly broadening its application range after it was adapted to parallel and distributed computing.</p></sec></sec><sec><title>Accuracy testing</title><p>Previously we compared accuracy of BNFinder algorithm with Banjo (<xref rid="ref-31" ref-type="bibr">Wilczy&#x00144;ski &#x00026; Dojer, 2009</xref>) on data provided with the tool and separately on Sachs data (<xref rid="ref-9" ref-type="bibr">Dojer et al., 2013</xref>), which we used in this work to test the performance. Here we performed accuracy testing on 14 different datasets, both synthetic and taken from microarray experiments. No other additional data or information was used for the networks inference except those mentioned in the datasets description below.</p><p><bold>DREAM2 Genome Scale Network Inference</bold> 3,456 genes &#x000d7;300 experiments dataset, log-normalized compendium of Escherichia coli expression profiles described above (<xref rid="ref-28" ref-type="bibr">Stolovitzky, Prill &#x00026; Califano, 2009</xref>). Transcription factors list is provided with the data.</p><p><bold>DREAM4 In Silico Network Challenge:</bold> time course datasets showing how the simulated network responds to a perturbation and how it relaxes upon its removal. There are 5 different datasets with 10 and 100 genes each. For networks of size 10, datasets consist of 5 different time series replicates, while networks of size 100 has 10 time series replicates. Each time series has 21 time points (<xref rid="ref-27" ref-type="bibr">Stolovitzky, Monroe &#x00026; Califano, 2007</xref>).</p><p><bold>Yeast time series:</bold> 102 genes &#x000d7;582 experiments datasets with time series after drug perturbation from the yeast rapamycin experiment described in <xref rid="ref-33" ref-type="bibr">Yeung et al. (2011)</xref>. There are 582&#x02215;6&#x000a0;=&#x000a0;97 replicates (the 95 segregants plus two parental strains of the segregants), each with measurements at 6 time points. Prior probabilities of gene regulations are provided.</p><p><bold>Yeast static:</bold> 85 genes&#x000a0;&#x000d7;&#x000a0;111 experiments subset of the data used for network inference in yeast by <xref rid="ref-5" ref-type="bibr">Brem &#x00026; Kruglyak (2005)</xref>. Prior probabilities of genes regulations are provided. TF-gene regulations were extracted from YEASTRACT repository (<ext-link ext-link-type="uri" xlink:href="http://www.yeastract.com">http://www.yeastract.com</ext-link>, version 2013927).</p><p><bold>Yeast static synthetic:</bold> 2,000 genes &#x000d7;2,000 experiments dataset generated using GNW simulator (<xref rid="ref-26" ref-type="bibr">Schaffter, Marbach &#x00026; Floreano, 2011</xref>) by extracting parts of known real network structures capturing several of their important structural properties. To produce gene expression data, the simulator relies on a system of non-linear ordinary differential equations. TF-gene regulations were extracted from YEASTRACT repository (version 2013927). The adjacency matrix of true underlying network structure of this dataset has symmetrical form, therefore it is not possible to evaluate the direction of interaction in this case.</p><p>DREAM2 data was downloaded from the challenge website, DREAM4, YeastTS (time series), and Brem data was imported from NetworkBMA (<xref rid="ref-34" ref-type="bibr">Young, Raftery &#x00026; Yeung, 2014</xref>) R package, while synthetic Yeast static data (GNW2000) was imported from NetBenchmark (<xref rid="ref-3" ref-type="bibr">Bellot et al., 2015</xref>) R package.</p><p><xref rid="table-3" ref-type="table">Table 3</xref> summarizes gene regulatory network inference methods we used for benchmarking. Specifically, we used FastBMA method implemented in NetworkBMA R package, while the rest of the methods were accessed through NetBenchmark, a bioconductor package for reproducible benchmarks of gene regulatory network inference. The methods were used with default parameters, while for FastBMA, Genie3 and BNFinder prior edge probabilities and TF-gene regulations were supplied where applicable.</p><table-wrap id="table-3" orientation="portrait" position="float"><object-id pub-id-type="doi">10.7717/peerj.5692/table-3</object-id><label>Table 3</label><caption><title>Gene regulatory network inference methods used for benchmarking.</title></caption><alternatives><graphic xlink:href="peerj-06-5692-g014"/><table frame="hsides" rules="groups"><colgroup span="1"><col span="1"/><col span="1"/></colgroup><thead><tr><th rowspan="1" colspan="1"><bold>Inference Approach</bold></th><th rowspan="1" colspan="1"><bold>Method</bold></th></tr></thead><tbody><tr><td rowspan="1" colspan="1">Co-expression algorithms</td><td rowspan="1" colspan="1">MutRank (<xref rid="ref-22" ref-type="bibr">Obayashi &#x00026; Kinoshita 2009</xref>)</td></tr><tr><td rowspan="1" colspan="1">Information-theoretic approaches</td><td rowspan="1" colspan="1">CLR (<xref rid="ref-12" ref-type="bibr">Faith et al. 2007</xref>), ARACNE (<xref rid="ref-17" ref-type="bibr">Margolin et al. 2006</xref>), PCIT (<xref rid="ref-24" ref-type="bibr">Reverter &#x00026; Chan 2008</xref>), C3NET (<xref rid="ref-1" ref-type="bibr">Altay &#x00026; Emmert-Streib 2010</xref>)</td></tr><tr><td rowspan="1" colspan="1">Feature selection approaches</td><td rowspan="1" colspan="1">MRNET (<xref rid="ref-20" ref-type="bibr">Meyer et al. 2007</xref>), MRNETB (<xref rid="ref-19" ref-type="bibr">Meyer et al. 2010</xref>), Genie3 (<xref rid="ref-15" ref-type="bibr">Huynh-Thu et al. 2010</xref>)</td></tr><tr><td rowspan="1" colspan="1">Bayesian model averaging</td><td rowspan="1" colspan="1">FastBMA (<xref rid="ref-14" ref-type="bibr">Hung et al. 2017</xref>)</td></tr></tbody></table></alternatives></table-wrap><p>We used two metrics to assess methods performance: Area Under the Precision Recall curve (AUPR) or Area Under Receiver Operating Characteristic curve (AUROC), implemented in MINET R package (<xref rid="ref-21" ref-type="bibr">Meyer, Lafitte &#x00026; Bontempi, 2008</xref>). However, this approach gives an estimation of the global behavior of the method, therefore in NetBenchmark package <xref rid="ref-3" ref-type="bibr">Bellot et al. (2015)</xref> evaluated the inferred networks using only the top best 20% of the total number of possible connections. The latter allows us to correctly compare methods with sparse and concise outputs. We used both MINET and NetBenchmark evaluation functions in order to assess the impact on methods rankings.</p><p>FastBMA, Genie3 and BNFinder methods allow us to infer directed interactions, therefore they were additionally evaluated on directed gold networks (where applicable), while for the undirected evaluation gold network adjacency matrices were converted to symmetrical ones (higher edge probabilities are preserved) as well as outputs of directed methods.</p><p>In case of static gene expression data FastBMA can infer the regulators of a particular gene by regressing it on the expression levels of the other genes. Therefore we used the method with time series data only.</p><p>We mostly used DREAM2 data for running times tests and evaluated accuracy of CLR method only. The results of BNFinder and CLR tests are shown in <xref rid="table-4" ref-type="table">Table 4</xref>.</p><table-wrap id="table-4" orientation="portrait" position="float"><object-id pub-id-type="doi">10.7717/peerj.5692/table-4</object-id><label>Table 4</label><caption><title>DREAM2 Genome Scale Network Inference.</title><p>BNFinder and CLR are compared with the best scored method using 100% of output interactions. BNFinder is used with parents sets limit 1 and suboptimal parents sets 100, CLR is used with default parameters. Evaluation of BNF on TF-TF free gold standard is provided as well. All the output interactions are considered for calculating areas under curves.</p></caption><alternatives><graphic xlink:href="peerj-06-5692-g015"/><table frame="hsides" rules="groups"><colgroup span="1"><col align="center" span="1"/><col align="center" span="1"/><col align="center" span="1"/><col align="center" span="1"/><col align="center" span="1"/></colgroup><thead><tr><th align="center" rowspan="1" colspan="1"/><th align="center" rowspan="1" colspan="1">CLR</th><th align="center" rowspan="1" colspan="1">BNF</th><th align="center" rowspan="1" colspan="1">BNF, gold standard</th><th align="center" rowspan="1" colspan="1">Winner: Team 48</th></tr><tr><th align="center" rowspan="1" colspan="1"/><th align="center" rowspan="1" colspan="1"/><th align="center" rowspan="1" colspan="1"/><th align="center" rowspan="1" colspan="1">without TF-TF</th><th align="center" rowspan="1" colspan="1"/></tr></thead><tbody><tr><td align="center" rowspan="1" colspan="1">AUPR</td><td align="center" rowspan="1" colspan="1">0.051398</td><td align="center" rowspan="1" colspan="1">0.028769</td><td align="center" rowspan="1" colspan="1">0.030584</td><td align="center" rowspan="1" colspan="1">0.059499</td></tr><tr><td align="center" rowspan="1" colspan="1">AUROC</td><td align="center" rowspan="1" colspan="1">0.617187</td><td align="center" rowspan="1" colspan="1">0.606326</td><td align="center" rowspan="1" colspan="1">0.629420</td><td align="center" rowspan="1" colspan="1">0.610643</td></tr></tbody></table></alternatives></table-wrap><p>We ranked AUROC and AUPR values across all the methods for each of five 10 and 100 genes network from DREAM4 challenge. Different evaluation strategies for 10-gene networks showed quite a different results (<xref ref-type="fig" rid="fig-5">Figs. 5</xref> and <xref ref-type="fig" rid="fig-6">6</xref>), while 100-gene networks results were more consistent among MINET and NetBechmark (<xref ref-type="fig" rid="fig-7">Figs. 7</xref> and <xref ref-type="fig" rid="fig-8">8</xref>). We believe that networks of a small size might not be a good benchmark data as even a slightest change in the obtained scores might disrupt rankings dramatically. This is especially valid for the methods, which output might differ each run due to the nature of underlying algorithms (e.g., regression, greedy hill climbing). There is no single best method for DREAM4 data, while Genie3, MRNET, MRNETB, FastBMA, and BNFinder scored first at least once.</p><fig id="fig-5" orientation="portrait" position="float"><object-id pub-id-type="doi">10.7717/peerj.5692/fig-5</object-id><label>Figure 5</label><caption><title>DREAM4 10 genes network, evaluation by MINET package.</title><p>Area under ROC (A) and PR (B) curves are ranked across different methods: the highest value is ranked first, and the lowest&#x02014;ranked last. BNFinder is used with parents sets limit 2 and suboptimal parents sets 30.</p></caption><graphic xlink:href="peerj-06-5692-g005"/></fig><fig id="fig-6" orientation="portrait" position="float"><object-id pub-id-type="doi">10.7717/peerj.5692/fig-6</object-id><label>Figure 6</label><caption><title>DREAM4 10 genes network, evaluation by NetBenchmark package.</title><p>Area under ROC (A) and PR (B) curves are ranked across different methods: the highest value is ranked first, and the lowest&#x02014;ranked last. BNFinder is used with parents sets limit 2 and suboptimal parents sets 30.</p></caption><graphic xlink:href="peerj-06-5692-g006"/></fig><fig id="fig-7" orientation="portrait" position="float"><object-id pub-id-type="doi">10.7717/peerj.5692/fig-7</object-id><label>Figure 7</label><caption><title>DREAM4 100 genes network, evaluation by MINET package.</title><p>Area under ROC (A) and PR (B) curves are ranked across different methods: the highest value is ranked first, and the lowest&#x02014;ranked last. BNFinder is used with parents sets limit 2 and suboptimal parents sets 30.</p></caption><graphic xlink:href="peerj-06-5692-g007"/></fig><fig id="fig-8" orientation="portrait" position="float"><object-id pub-id-type="doi">10.7717/peerj.5692/fig-8</object-id><label>Figure 8</label><caption><title>DREAM4 100 genes network, evaluation by NetBenchmark package.</title><p>Area under ROC (A) and PR (B) curves are ranked across different methods: the highest value is ranked first, and the lowest&#x02014;ranked last. BNFinder is used with parents sets limit 2 and suboptimal parents sets 30.</p></caption><graphic xlink:href="peerj-06-5692-g008"/></fig><p>Yeast time series network inference showed extremely bad results for all the methods with MutRank having slightly better AUROC = 0.58 and AUPR = 0.07 values according to MINET package. In contrast to synthetic DREAM4 data which has 21 time points, YeastTS has only 6, which could explain worse results.</p><p>Surprisingly, BNFinder significantly outperformed other methods when reconstructing network from Brem at al. static gene expression data (<xref ref-type="fig" rid="fig-9">Fig. 9</xref>). Importantly, Genie3 method was also supplied with the same regulators list as BNFinder, but it has led to worse results contrary to using Genie3 without regulators. The other methods were used without any additional prior information as implemented in NetBenchmark package.</p><fig id="fig-9" orientation="portrait" position="float"><object-id pub-id-type="doi">10.7717/peerj.5692/fig-9</object-id><label>Figure 9</label><caption><title>Brem et al. Yeast dataset, evaluation by NetBenchmark package.</title><p>Directed and non-directed (with symmetrical adjacency matrix) gold standard network evaluation is shown in different colours. Area under ROC (A) and PR (B) curves values are considered. Genie3.noregs is the result of Genie3 execution without the regulators list. BNFinder is used with parents sets limit 2 and suboptimal parents sets 30.</p></caption><graphic xlink:href="peerj-06-5692-g009"/></fig><p>We also studied the effect of the number of experiments on the accuracy of inferred network. For GNW2000 synthetic Yeast data we performed two separate tests: one with full dataset&#x02014;2,000 experiments, and second with only 150 randomly selected observational points. <xref ref-type="fig" rid="fig-10">Figure 10</xref> clearly shows that all the methods improved their results on the full dataset, with BNFinder being among the top methods and having best AUPR on the reduced dataset. Interestingly, we did not see such a major difference between BNFinder and other methods in contrast to Brem at al. data, given the same input parameters and both datasets being of Yeast origin. It shows the importance of developing new gold standards based on experimental data from model organisms as synthetic data only cannot reflect all the complexity of biological interactions.</p><fig id="fig-10" orientation="portrait" position="float"><object-id pub-id-type="doi">10.7717/peerj.5692/fig-10</object-id><label>Figure 10</label><caption><title>GNW 2000 genes Yeast synthetic dataset, evaluation by NetBenchmark package.</title><p>Area under ROC (A) and PR (B) curves values are considered. GNW 2,000 short dataset contains only 150 observations, while GNW 2,000 has all the 2,000 observations. The effect of observations number increase is clearly seen for all the methods. Genie3.noregs is the result of Genie3 execution without the regulators list. BNFinder is used with parents sets limit 2 and suboptimal parents sets 30.</p></caption><graphic xlink:href="peerj-06-5692-g010"/></fig><sec><title> Exploring BNFinder parameter space.</title><p>The main advantage of BNFinder in comparison with heuristic search Bayesian tools such as Banjo is that BNFinder reconstructs optimal networks, which also means that the same parameters lead to the same result. However, with BNFinder one can use a number of input arguments such as scoring functions (Bayesian-Dirichlet equivalence, Minimal Description Length or Mutual information test), static or dynamic (also with self-regulatory loops) BNs, perturbation data, or even prior information on the network structure. All of these may alter results significantly, so, naturally we are interested in choosing best parameters for a particular dataset. Here we studied the impact of two very important parameters: parents sets limit and number of suboptimal parents sets (gives alternative sets of regulators with lower scores).</p><p>In <xref rid="table-5" ref-type="table">Table 5</xref> we have summarized the total number of interactions returned by BNFinder with different maximal parents per gene and different number of suboptimal parent sets. The results indicate that increasing the size of the allowed parent set leads to the decrease in the total returned edges in the network. This may seem surprising at first, but it is consistent with highly overlapping suboptimal parents sets. Theoretically, increasing parents set limit should lead to better precision, while increasing the number of suboptimal parents set should increase the number of false positives by adding lower scored parents. However, it may depend on the particular dataset, especially on the number of observations available. On top of that, in cases where using higher number of parents per variable is computationally challenging, suboptimal parents may compensate for this limitation.</p><table-wrap id="table-5" orientation="portrait" position="float"><object-id pub-id-type="doi">10.7717/peerj.5692/table-5</object-id><label>Table 5</label><caption><title>The number of the interactions in the output network based on different BNFinder parameters.</title><p>DREAM2 Genome Scale Network Inference data is used.</p></caption><alternatives><graphic xlink:href="peerj-06-5692-g016"/><table frame="hsides" rules="groups"><colgroup span="1"><col span="1"/><col span="1"/><col span="1"/><col span="1"/></colgroup><thead><tr><th rowspan="1" colspan="1"/><th rowspan="1" colspan="1">Subparents = 25</th><th rowspan="1" colspan="1">Subparents =50</th><th rowspan="1" colspan="1">Subparents = 100</th></tr></thead><tbody><tr><td rowspan="1" colspan="1">Parent limit = 1</td><td rowspan="1" colspan="1">78,366</td><td rowspan="1" colspan="1">156,685</td><td rowspan="1" colspan="1">313,061</td></tr><tr><td rowspan="1" colspan="1">Parent limit = 2</td><td rowspan="1" colspan="1">65,108</td><td rowspan="1" colspan="1">116,424</td><td rowspan="1" colspan="1">213,389</td></tr></tbody></table></alternatives></table-wrap><p>We studied the effect of different parameters by plotting AUPR against AUROC values. <xref ref-type="fig" rid="fig-11">Figure 11</xref> shows that on 2,000 genes&#x000a0;&#x000d7;&#x000a0;2,000 experiments synthetic dataset using two parents per gene is always better than one, and increasing the number of suboptimal parents leads to an increase in AUROC and a slight decrease in AUPR values. Inferring a network from the same dataset with only 150 experiments sometimes resulted in a lower AUPR for two parents per gene cases in comparison with singleton parents sets. While BNFinder scoring function penalizes for parents set size increase it might still produce false positives when the number of observational points is low and the number of variables is more than ten folds bigger. Importantly, zero (or very low) number of sub-optimal parent sets leads to extremely sparse output network (the number of edges is much less than 20% of all possible interaction) and therefore poor AUPR and AUROC values.</p><fig id="fig-11" orientation="portrait" position="float"><object-id pub-id-type="doi">10.7717/peerj.5692/fig-11</object-id><label>Figure 11</label><caption><title>BNFinder parameter space examination on GNW 2000 genes Yeast synthetic dataset, evaluation by NetBenchmark package.</title><p>GNW 2,000 short dataset contains only 150 observations, while GNW 2000 has all the 2,000 observations. <italic>Limit</italic> stands for parents set size limit, while <italic>subopt</italic> denotes the number of suboptimal parents set in the output network.</p></caption><graphic xlink:href="peerj-06-5692-g011"/></fig><p>In general, we can conclude that if the user is interested in the very top of the strongest interactions in the network, one should use small numbers of sub-optimal parent (up to 5) sets and small limit on the parent-set size (up to 3). However, if one is interested in discovering the more global picture of the true regulatory network, one should focus on the higher number of sub-optimal parent sets with limit on the set size as high as it is computationally feasible.</p><p>The results of all performance and accuracy tests with the scripts to generate all the plots are available from a dedicated github repository&#x02014;<ext-link ext-link-type="uri" xlink:href="https://github.com/sysbio-vo/article-bnf-suppl">https://github.com/sysbio-vo/article-bnf-suppl</ext-link>.</p></sec></sec></sec><sec sec-type="discussion"><title>Discussion</title><sec><title>Performance</title><p>Despite seemingly complex behavior of the <bold>hybrid</bold> algorithm and many cases where the <bold>hybrid</bold> and the <bold>set-wise</bold> algorithms can be applied, we can give users the best practice guidance for BNFinder application. In case of small networks where number of variables is 2 or more times less than the number of cores it is advised to use the <bold>hybrid</bold> algorithm, because the <bold>set-wise</bold> would generate more context switching events per variable. The same applies when a user imposes parent set limit equal or less than 3, which makes the computational load per variable more even. In case when the complex layered structure of regulators is introduced it is always better to use the <bold>set-wise</bold>. In case of big networks, when the number of variables is greater than the number of cores in a single computational unit, one can also use the new BNFinder feature, which allows to define subset of genes as it was described in <bold>Distributed computations testing</bold> section of this paper. Defined subsets can be computed separately and simultaneously on different computational units, and user should apply the same logic when choosing parallelization algorithm as for the smaller networks.</p><p>And finally, the user may just use the default parameters as <bold>set-wise</bold> algorithm did not show major drop in performance in comparison to the <bold>hybrid</bold> one.</p></sec><sec><title>Accuracy of reconstruction</title><p>While we understand that there are many more tools for gene regulatory networks reconstruction in the literature we believe that NetBenchmark package is representative for the field since it incorporates state-of-the-art methods, which are based on a variety of different algorithms. On top of that using benchmarking tool makes it easier for other researchers to compare their methods to our results.</p><p>Measuring AUROC and AUPR values on 14 different datasets revealed that studied methods behave differently on different datasets, and none of the methods scored best in all cases. In general, time series data proved to be more challenging for the methods than inferring network from static gene expression datasets. Our results on 10 genes networks evaluation with top 20% and 100% interactions showed that such small networks can hardly be used as the only source of comparison.</p><p>Testing BNFinder on the mentioned datasets we concluded that it performed best on the static gene expression datasets with additional prior knowledge (transcription factors list, prior edge probability between genes), while for other methods such as Genie3 the same information did not yield significant improvement.</p><p>It should be noted, that in most of these scenarios, our knowledge of the true network connections is also limited and different tools use different definitions of a meaningful &#x0201c;connection&#x0201d;, therefore it is expected that, for example, a tool using mutual information will capture a different subset of connections than a tool using Bayesian-Dirichled equivalence. While our opinion is that such automated methods will be gaining importance as their accuracy increases, there is still a lot of work ahead of us on careful validation of the problems various tools have and on refinement of the definitions of regulatory interactions.</p></sec></sec><sec sec-type="conclusions"><title>Conclusions</title><p>The improvement over previous version of BNFinder made it feasible to analyze datasets that were impossible to analyze before by utilizing the power of distributed and parallel computing. It allowed us to significantly extend the application range of the tool, and, for the first time, to compare it with the best-performing non-Bayesian methods. BNFinder showed overall comparable performance on synthetic and real biological data, providing significant advantage in cases when prior knowledge on genes interactions can be introduced. This can lead to further research on the optimization of the BNFinder method for the purpose of finding larger networks with better accuracy. We provide the new BNFinder implementation freely for all interested researchers under a GNU GPL 2.0 license.</p></sec><sec sec-type="supplementary-material" id="supplemental-information"><title> Supplemental Information</title><supplementary-material content-type="local-data" id="supp-1"><object-id pub-id-type="doi">10.7717/peerj.5692/supp-1</object-id><label>Supplemental Information 1</label><caption><title>BNFinder v2.2. source code</title></caption><media xlink:href="peerj-06-5692-s001.zip"><caption><p>Click here for additional data file.</p></caption></media></supplementary-material></sec></body><back><ack><p>For distributed calculations authors used computational clusters of Taras Shevchenko National University of Kyiv, Institute of Molecular Biology and Genetics of NASU, Institute of Food Biotechnology and Genomics of NASU, joint cluster of SSI &#x0201c;Institute for Single Crystals&#x0201d; and Institute for Scintillation Materials of NASU. We would like to express out gratitude to Prof. Maria Obolenska from Institute of Molecular Biology and Genetics, Kyiv, Ukraine for the proofreading and critique. We also thank Dr. Veronika Gurianova from Bogomoletz Institute of Physiology, Kyiv, Ukraine for her valuable comments on the article visuals, which helped us to make the plots more clear and understandable. We are extremely grateful to Dr. Pau Bellot from Centre for Research in Agricultural Genomics (CRAG), Barcelona, Spain, one of the NetBenchmark R package authors and maintainers, for the assistance with package related problems. Together we were able to fix two bugs, which under specific circumstances might have hindered evaluation results. The virtue of Open Source has yet again proven to positively influence the scientific advance.</p></ack><sec sec-type="additional-information"><title>Additional Information and Declarations</title><fn-group content-type="competing-interests"><title>Competing Interests</title><fn id="conflict-1" fn-type="COI-statement"><p>The authors declare there are no competing interests.</p></fn></fn-group><fn-group content-type="author-contributions"><title>Author Contributions</title><fn id="contribution-1" fn-type="con"><p><xref ref-type="contrib" rid="author-1">Alina Frolova</xref> conceived and designed the experiments, performed the experiments, analyzed the data, prepared figures and/or tables, authored or reviewed drafts of the paper, approved the final draft.</p></fn><fn id="contribution-2" fn-type="con"><p><xref ref-type="contrib" rid="author-2">Bartek Wilczy&#x00144;ski</xref> conceived and designed the experiments, authored or reviewed drafts of the paper, approved the final draft.</p></fn></fn-group><fn-group content-type="other"><title>Data Availability</title><fn id="addinfo-1"><p>The following information was supplied regarding data availability:</p><p>BNFinder tool source code:</p><p>
<ext-link ext-link-type="uri" xlink:href="https://github.com/sysbio-vo/bnfinder">https://github.com/sysbio-vo/bnfinder</ext-link>.</p><p>Scripts to generate figures, run methods etc:</p><p>
<ext-link ext-link-type="uri" xlink:href="https://github.com/sysbio-vo/article-bnf-suppl">https://github.com/sysbio-vo/article-bnf-suppl</ext-link>.</p></fn></fn-group></sec><ref-list content-type="authoryear"><title>References</title><ref id="ref-1"><label>Altay &#x00026; Emmert-Streib (2010)</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Altay</surname><given-names>G</given-names></name><name><surname>Emmert-Streib</surname><given-names>F</given-names></name></person-group><year>2010</year><article-title>Inferring the conservative causal core of gene regulatory networks</article-title><source>BMC Systems Biology</source><volume>4</volume><issue>1</issue><fpage>132</fpage><pub-id pub-id-type="doi">10.1186/1752-0509-4-132</pub-id><pub-id pub-id-type="pmid">20920161</pub-id></element-citation></ref><ref id="ref-2"><label>Barabasi &#x00026; Oltvai (2004)</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Barabasi</surname><given-names>A-L</given-names></name><name><surname>Oltvai</surname><given-names>ZN</given-names></name></person-group><year>2004</year><article-title>Network biology: understanding the cell&#x02019;s functional organization</article-title><source>Nature Reviews Genetics</source><volume>5</volume><issue>2</issue><fpage>101</fpage><lpage>113</lpage><pub-id pub-id-type="doi">10.1038/nrg1272</pub-id></element-citation></ref><ref id="ref-3"><label>Bellot et&#x000a0;al. (2015)</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Bellot</surname><given-names>P</given-names></name><name><surname>Olsen</surname><given-names>C</given-names></name><name><surname>Salembier</surname><given-names>P</given-names></name><name><surname>Oliveras-Verg&#x000e9;s</surname><given-names>A</given-names></name><name><surname>Meyer</surname><given-names>PE</given-names></name></person-group><year>2015</year><article-title>NetBenchmark: a bioconductor package for reproducible benchmarks of gene regulatory network inference</article-title><source>BMC Bioinformatics</source><volume>16</volume><issue>1</issue><fpage>312</fpage><pub-id pub-id-type="doi">10.1186/s12859-015-0728-4</pub-id><pub-id pub-id-type="pmid">26415849</pub-id></element-citation></ref><ref id="ref-4"><label>Bonn et&#x000a0;al. (2012)</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Bonn</surname><given-names>S</given-names></name><name><surname>Zinzen</surname><given-names>RP</given-names></name><name><surname>Girardot</surname><given-names>C</given-names></name><name><surname>Gustafson</surname><given-names>EH</given-names></name><name><surname>Perez-Gonzalez</surname><given-names>A</given-names></name><name><surname>Delhomme</surname><given-names>N</given-names></name><name><surname>Ghavi-Helm</surname><given-names>Y</given-names></name><name><surname>Wilczy&#x00144;ski</surname><given-names>B</given-names></name><name><surname>Riddell</surname><given-names>A</given-names></name><name><surname>Furlong</surname><given-names>EE</given-names></name></person-group><year>2012</year><article-title>Tissue-specific analysis of chromatin state identifies temporal signatures of enhancer activity during embryonic development</article-title><source>Nature Genetics</source><volume>44</volume><issue>2</issue><fpage>148</fpage><lpage>156</lpage><pub-id pub-id-type="doi">10.1038/ng.1064</pub-id><pub-id pub-id-type="pmid">22231485</pub-id></element-citation></ref><ref id="ref-5"><label>Brem &#x00026; Kruglyak (2005)</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Brem</surname><given-names>RB</given-names></name><name><surname>Kruglyak</surname><given-names>L</given-names></name></person-group><year>2005</year><article-title>The landscape of genetic complexity across 5,700 gene expression traits in yeast</article-title><source>Proceedings of the National Academy of Sciences of the United States of America</source><volume>102</volume><issue>5</issue><fpage>1572</fpage><lpage>1577</lpage><pub-id pub-id-type="doi">10.1073/pnas.0408709102</pub-id><pub-id pub-id-type="pmid">15659551</pub-id></element-citation></ref><ref id="ref-6"><label>Chickering, Heckerman &#x00026; Meek (2004)</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Chickering</surname><given-names>DM</given-names></name><name><surname>Heckerman</surname><given-names>D</given-names></name><name><surname>Meek</surname><given-names>C</given-names></name></person-group><year>2004</year><article-title>Large-sample learning of Bayesian networks is NP-hard</article-title><source>The Journal of Machine Learning Research</source><volume>5</volume><fpage>1287</fpage><lpage>1330</lpage></element-citation></ref><ref id="ref-7"><label>Dabrowski et&#x000a0;al. (2010)</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Dabrowski</surname><given-names>M</given-names></name><name><surname>Dojer</surname><given-names>N</given-names></name><name><surname>Zawadzka</surname><given-names>M</given-names></name><name><surname>Mieczkowski</surname><given-names>J</given-names></name><name><surname>Kaminska</surname><given-names>B</given-names></name></person-group><year>2010</year><article-title>Comparative analysis of cis-regulation following stroke and seizures in subspaces of conserved eigensystems</article-title><source>BMC Systems Biology</source><volume>4</volume><issue>1</issue><fpage>86</fpage><pub-id pub-id-type="doi">10.1186/1752-0509-4-86</pub-id><pub-id pub-id-type="pmid">20565733</pub-id></element-citation></ref><ref id="ref-8"><label>Dojer (2006)</label><element-citation publication-type="book"><person-group person-group-type="author"><name><surname>Dojer</surname><given-names>N</given-names></name></person-group><year>2006</year><article-title>Learning Bayesian networks does not have to be NP-hard</article-title><source>Mathematical foundations of computer science 2006: 31st international symposium, MFCS 2006, Star&#x000e1; Lesn&#x000e1;, Slovakia, August 28&#x02013;September 1, 2006, Proceedings</source><series>LNCS sublibrary: theoretical computer science and general issues</series><person-group person-group-type="editor"><name><surname>Kr&#x000e1;lovic</surname><given-names>R</given-names></name><name><surname>Urzyczyn</surname><given-names>P</given-names></name></person-group><publisher-name>Springer</publisher-name><publisher-loc>Berlin/Heidelberg</publisher-loc><fpage>305</fpage><lpage>314</lpage></element-citation></ref><ref id="ref-9"><label>Dojer et&#x000a0;al. (2013)</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Dojer</surname><given-names>N</given-names></name><name><surname>Bednarz</surname><given-names>P</given-names></name><name><surname>Podsiad&#x00142;o</surname><given-names>A</given-names></name><name><surname>Wilczy&#x00144;ski</surname><given-names>B</given-names></name></person-group><year>2013</year><article-title>BNFinder2: faster Bayesian network learning and Bayesian classification</article-title><source>Bioinformatics</source><volume>29</volume><issue>16</issue><fpage>2068</fpage><lpage>2070</lpage><pub-id pub-id-type="pmid">23818512</pub-id></element-citation></ref><ref id="ref-10"><label>DREAM Initiative (2009)</label><element-citation publication-type="other"><person-group person-group-type="author"><collab>DREAM Initiative</collab></person-group><year>2009</year><article-title>DREAM2, Challenge 5 synopsis</article-title><date-in-citation content-type="access-date" iso-8601-date="2018-04-02">02 April 2018</date-in-citation><uri xlink:href="https://www.synapse.org/#!Synapse:syn3034894/wiki/74418">https://www.synapse.org/#!Synapse:syn3034894/wiki/74418</uri></element-citation></ref><ref id="ref-11"><label>Ellert et&#x000a0;al. (2007)</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Ellert</surname><given-names>M</given-names></name><name><surname>Gr&#x000f8;nager</surname><given-names>M</given-names></name><name><surname>Konstantinov</surname><given-names>A</given-names></name><name><surname>K&#x000f3;nya</surname><given-names>B</given-names></name><name><surname>Lindemann</surname><given-names>J</given-names></name><name><surname>Livenson</surname><given-names>I</given-names></name><name><surname>Nielsen</surname><given-names>JL</given-names></name><name><surname>Niinim&#x000e4;ki</surname><given-names>M</given-names></name><name><surname>Smirnova</surname><given-names>O</given-names></name><name><surname>W&#x000e4;&#x000e4;n&#x000e4;nen</surname><given-names>A</given-names></name></person-group><year>2007</year><article-title>Advanced resource connector middleware for lightweight computational grids</article-title><source>Future Generation Computer Systems</source><volume>23</volume><issue>2</issue><fpage>219</fpage><lpage>240</lpage><pub-id pub-id-type="doi">10.1016/j.future.2006.05.008</pub-id></element-citation></ref><ref id="ref-12"><label>Faith et&#x000a0;al. (2007)</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Faith</surname><given-names>JJ</given-names></name><name><surname>Hayete</surname><given-names>B</given-names></name><name><surname>Thaden</surname><given-names>JT</given-names></name><name><surname>Mogno</surname><given-names>I</given-names></name><name><surname>Wierzbowski</surname><given-names>J</given-names></name><name><surname>Cottarel</surname><given-names>G</given-names></name><name><surname>Kasif</surname><given-names>S</given-names></name><name><surname>Collins</surname><given-names>JJ</given-names></name><name><surname>Gardner</surname><given-names>TS</given-names></name></person-group><year>2007</year><article-title>Large-scale mapping and validation of Escherichia coli transcriptional regulation from a compendium of expression profiles</article-title><source>PLOS Biology</source><volume>5</volume><issue>1</issue><elocation-id>e8</elocation-id><pub-id pub-id-type="doi">10.1371/journal.pbio.0050008</pub-id><pub-id pub-id-type="pmid">17214507</pub-id></element-citation></ref><ref id="ref-13"><label>Friedman &#x00026; Koller (2003)</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Friedman</surname><given-names>N</given-names></name><name><surname>Koller</surname><given-names>D</given-names></name></person-group><year>2003</year><article-title>Being Bayesian about network structure. A Bayesian approach to structure discovery in Bayesian networks</article-title><source>Machine Learning</source><volume>50</volume><issue>1&#x02013;2</issue><fpage>95</fpage><lpage>125</lpage><pub-id pub-id-type="doi">10.1023/A:1020249912095</pub-id></element-citation></ref><ref id="ref-14"><label>Hung et&#x000a0;al. (2017)</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Hung</surname><given-names>L-H</given-names></name><name><surname>Shi</surname><given-names>K</given-names></name><name><surname>Wu</surname><given-names>M</given-names></name><name><surname>Young</surname><given-names>WC</given-names></name><name><surname>Raftery</surname><given-names>AE</given-names></name><name><surname>Yeung</surname><given-names>KY</given-names></name></person-group><year>2017</year><article-title>fastBMA: scalable network inference and transitive reduction</article-title><source>GigaScience</source><volume>6</volume><issue>10</issue><fpage>gix078</fpage></element-citation></ref><ref id="ref-15"><label>Huynh-Thu et&#x000a0;al. (2010)</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Huynh-Thu</surname><given-names>VA</given-names></name><name><surname>Irrthum</surname><given-names>A</given-names></name><name><surname>Wehenkel</surname><given-names>L</given-names></name><name><surname>Geurts</surname><given-names>P</given-names></name></person-group><year>2010</year><article-title>Inferring regulatory networks from expression data using tree-based methods</article-title><source>PLOS ONE</source><volume>5</volume><issue>9</issue><fpage>1</fpage><lpage>10</lpage><pub-id pub-id-type="doi">10.1371/journal.pone.0012776</pub-id></element-citation></ref><ref id="ref-16"><label>Jansen et&#x000a0;al. (2003)</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Jansen</surname><given-names>R</given-names></name><name><surname>Yu</surname><given-names>H</given-names></name><name><surname>Greenbaum</surname><given-names>D</given-names></name><name><surname>Kluger</surname><given-names>Y</given-names></name><name><surname>Krogan</surname><given-names>NJ</given-names></name><name><surname>Chung</surname><given-names>S</given-names></name><name><surname>Emili</surname><given-names>A</given-names></name><name><surname>Snyder</surname><given-names>M</given-names></name><name><surname>Greenblatt</surname><given-names>JF</given-names></name><name><surname>Gerstein</surname><given-names>M</given-names></name></person-group><year>2003</year><article-title>A Bayesian networks approach for predicting protein&#x02013;protein interactions from genomic data</article-title><source>Science</source><volume>302</volume><issue>5644</issue><fpage>449</fpage><lpage>453</lpage><pub-id pub-id-type="doi">10.1126/science.1087361</pub-id><pub-id pub-id-type="pmid">14564010</pub-id></element-citation></ref><ref id="ref-17"><label>Margolin et&#x000a0;al. (2006)</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Margolin</surname><given-names>AA</given-names></name><name><surname>Nemenman</surname><given-names>I</given-names></name><name><surname>Basso</surname><given-names>K</given-names></name><name><surname>Wiggins</surname><given-names>C</given-names></name><name><surname>Stolovitzky</surname><given-names>G</given-names></name><name><surname>Dalla&#x000a0;Favera</surname><given-names>R</given-names></name><name><surname>Califano</surname><given-names>A</given-names></name></person-group><year>2006</year><article-title>ARACNE: an algorithm for the reconstruction of gene regulatory networks in a mammalian cellular context</article-title><volume>7</volume><issue>1</issue><source>BMC Bioinformatics</source><fpage>S7</fpage><pub-id pub-id-type="doi">10.1186/1471-2105-7-S1-S7</pub-id></element-citation></ref><ref id="ref-18"><label>McCool, Reinders &#x00026; Robison (2012)</label><element-citation publication-type="book"><person-group person-group-type="author"><name><surname>McCool</surname><given-names>M</given-names></name><name><surname>Reinders</surname><given-names>J</given-names></name><name><surname>Robison</surname><given-names>A</given-names></name></person-group><year>2012</year><source>Structured parallel programming: patterns for efficient computation</source><publisher-name>Elsevier</publisher-name><publisher-loc>Waltham</publisher-loc></element-citation></ref><ref id="ref-19"><label>Meyer et&#x000a0;al. (2010)</label><element-citation publication-type="book"><person-group person-group-type="author"><name><surname>Meyer</surname><given-names>P</given-names></name><name><surname>Marbach</surname><given-names>D</given-names></name><name><surname>Roy</surname><given-names>S</given-names></name><name><surname>Kellis</surname><given-names>M</given-names></name></person-group><year>2010</year><article-title>Information-theoretic inference of gene networks using backward elimination</article-title><source>BioComp</source><fpage>700</fpage><lpage>705</lpage></element-citation></ref><ref id="ref-20"><label>Meyer et&#x000a0;al. (2007)</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Meyer</surname><given-names>PE</given-names></name><name><surname>Kontos</surname><given-names>K</given-names></name><name><surname>Lafitte</surname><given-names>F</given-names></name><name><surname>Bontempi</surname><given-names>G</given-names></name></person-group><year>2007</year><article-title>Information-theoretic inference of large transcriptional regulatory networks</article-title><source>EURASIP Journal on Bioinformatics and Systems Biology</source><volume>2007</volume><comment>Article 79879</comment><pub-id pub-id-type="doi">10.1155/2007/79879</pub-id></element-citation></ref><ref id="ref-21"><label>Meyer, Lafitte &#x00026; Bontempi (2008)</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Meyer</surname><given-names>PE</given-names></name><name><surname>Lafitte</surname><given-names>F</given-names></name><name><surname>Bontempi</surname><given-names>G</given-names></name></person-group><year>2008</year><article-title>Minet: an open source R/Bioconductor package for mutual information based network inference</article-title><source>BMC Bioinformatics</source><volume>9</volume><comment>Article 461</comment></element-citation></ref><ref id="ref-22"><label>Obayashi &#x00026; Kinoshita (2009)</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Obayashi</surname><given-names>T</given-names></name><name><surname>Kinoshita</surname><given-names>K</given-names></name></person-group><year>2009</year><article-title>Rank of correlation coefficient as a comparable measure for biological significance of gene coexpression</article-title><source>DNA Research</source><volume>16</volume><issue>5</issue><fpage>249</fpage><lpage>260</lpage><pub-id pub-id-type="doi">10.1093/dnares/dsp016</pub-id><pub-id pub-id-type="pmid">19767600</pub-id></element-citation></ref><ref id="ref-23"><label>Reich et&#x000a0;al. (2006)</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Reich</surname><given-names>M</given-names></name><name><surname>Liefeld</surname><given-names>T</given-names></name><name><surname>Gould</surname><given-names>J</given-names></name><name><surname>Lerner</surname><given-names>J</given-names></name><name><surname>Tamayo</surname><given-names>P</given-names></name><name><surname>Mesirov</surname><given-names>JP</given-names></name></person-group><year>2006</year><article-title>GenePattern 2.0</article-title><source>Nature Genetics</source><volume>38</volume><issue>5</issue><fpage>500</fpage><lpage>501</lpage><pub-id pub-id-type="doi">10.1038/ng0506-500</pub-id><pub-id pub-id-type="pmid">16642009</pub-id></element-citation></ref><ref id="ref-24"><label>Reverter &#x00026; Chan (2008)</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Reverter</surname><given-names>A</given-names></name><name><surname>Chan</surname><given-names>EK</given-names></name></person-group><year>2008</year><article-title>Combining partial correlation and an information theory approach to the reversed engineering of gene co-expression networks</article-title><source>Bioinformatics</source><volume>24</volume><issue>21</issue><fpage>2491</fpage><lpage>2497</lpage><pub-id pub-id-type="doi">10.1093/bioinformatics/btn482</pub-id><pub-id pub-id-type="pmid">18784117</pub-id></element-citation></ref><ref id="ref-25"><label>Sachs et&#x000a0;al. (2005)</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Sachs</surname><given-names>K</given-names></name><name><surname>Perez</surname><given-names>O</given-names></name><name><surname>Pe&#x02019;er</surname><given-names>D</given-names></name><name><surname>Lauffenburger</surname><given-names>DA</given-names></name><name><surname>Nolan</surname><given-names>GP</given-names></name></person-group><year>2005</year><article-title>Causal protein-signaling networks derived from multiparameter single-cell data</article-title><source>Science</source><volume>308</volume><issue>5721</issue><fpage>523</fpage><lpage>529</lpage><pub-id pub-id-type="doi">10.1126/science.1105809</pub-id><pub-id pub-id-type="pmid">15845847</pub-id></element-citation></ref><ref id="ref-26"><label>Schaffter, Marbach &#x00026; Floreano (2011)</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Schaffter</surname><given-names>T</given-names></name><name><surname>Marbach</surname><given-names>D</given-names></name><name><surname>Floreano</surname><given-names>D</given-names></name></person-group><year>2011</year><article-title>GeneNetWeaver: in silico benchmark generation and performance profiling of network inference methods</article-title><source>Bioinformatics</source><volume>27</volume><issue>16</issue><fpage>2263</fpage><lpage>2270</lpage><pub-id pub-id-type="doi">10.1093/bioinformatics/btr373</pub-id><pub-id pub-id-type="pmid">21697125</pub-id></element-citation></ref><ref id="ref-27"><label>Stolovitzky, Monroe &#x00026; Califano (2007)</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Stolovitzky</surname><given-names>G</given-names></name><name><surname>Monroe</surname><given-names>D</given-names></name><name><surname>Califano</surname><given-names>A</given-names></name></person-group><year>2007</year><article-title>Dialogue on reverse-engineering assessment and methods</article-title><source>Annals of the New York Academy of Sciences</source><volume>1115</volume><issue>1</issue><fpage>1</fpage><lpage>22</lpage><pub-id pub-id-type="doi">10.1196/annals.1407.021</pub-id><pub-id pub-id-type="pmid">17925349</pub-id></element-citation></ref><ref id="ref-28"><label>Stolovitzky, Prill &#x00026; Califano (2009)</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Stolovitzky</surname><given-names>G</given-names></name><name><surname>Prill</surname><given-names>RJ</given-names></name><name><surname>Califano</surname><given-names>A</given-names></name></person-group><year>2009</year><article-title>Lessons from the DREAM2 challenges</article-title><source>Annals of the New York Academy of Sciences</source><volume>1158</volume><issue>1</issue><fpage>159</fpage><lpage>195</lpage><pub-id pub-id-type="doi">10.1111/j.1749-6632.2009.04497.x</pub-id><pub-id pub-id-type="pmid">19348640</pub-id></element-citation></ref><ref id="ref-29"><label>VO &#x0201c;Infrastructure&#x0201d; (2011)</label><element-citation publication-type="other"><person-group person-group-type="author"><collab>VO &#x0201c;Infrastructure&#x0201d;</collab></person-group><year>2011</year><article-title>Ukrainian National Grid Infrastructure</article-title><date-in-citation content-type="access-date" iso-8601-date="2018-04-02">02 April 2018</date-in-citation><uri xlink:href="http://infrastructure.kiev.ua/en/">http://infrastructure.kiev.ua/en/</uri></element-citation></ref><ref id="ref-30"><label>Watkinson et&#x000a0;al. (2009)</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Watkinson</surname><given-names>J</given-names></name><name><surname>Liang</surname><given-names>K-C</given-names></name><name><surname>Wang</surname><given-names>X</given-names></name><name><surname>Zheng</surname><given-names>T</given-names></name><name><surname>Anastassiou</surname><given-names>D</given-names></name></person-group><year>2009</year><article-title>Inference of regulatory gene interactions from expression data using three-way mutual information</article-title><source>Annals of the New York Academy of Sciences</source><volume>1158</volume><issue>1</issue><fpage>302</fpage><lpage>313</lpage><pub-id pub-id-type="doi">10.1111/j.1749-6632.2008.03757.x</pub-id><pub-id pub-id-type="pmid">19348651</pub-id></element-citation></ref><ref id="ref-31"><label>Wilczy&#x00144;ski &#x00026; Dojer (2009)</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Wilczy&#x00144;ski</surname><given-names>B</given-names></name><name><surname>Dojer</surname><given-names>N</given-names></name></person-group><year>2009</year><article-title>BNFinder: exact and efficient method for learning Bayesian networks</article-title><source>Bioinformatics</source><volume>25</volume><issue>2</issue><fpage>286</fpage><lpage>287</lpage><pub-id pub-id-type="doi">10.1093/bioinformatics/btn505</pub-id><pub-id pub-id-type="pmid">18826957</pub-id></element-citation></ref><ref id="ref-32"><label>Wilczynski et&#x000a0;al. (2012)</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Wilczynski</surname><given-names>B</given-names></name><name><surname>Liu</surname><given-names>Y-H</given-names></name><name><surname>Yeo</surname><given-names>ZX</given-names></name><name><surname>Furlong</surname><given-names>EE</given-names></name></person-group><year>2012</year><article-title>Predicting spatial and temporal gene expression using an integrative model of transcription factor occupancy and chromatin state</article-title><source>PLOS Computational Biology</source><volume>8</volume><issue>12</issue><elocation-id>e1002798</elocation-id><pub-id pub-id-type="doi">10.1371/journal.pcbi.1002798</pub-id><pub-id pub-id-type="pmid">23236268</pub-id></element-citation></ref><ref id="ref-33"><label>Yeung et&#x000a0;al. (2011)</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Yeung</surname><given-names>KY</given-names></name><name><surname>Dombek</surname><given-names>KM</given-names></name><name><surname>Lo</surname><given-names>K</given-names></name><name><surname>Mittler</surname><given-names>JE</given-names></name><name><surname>Zhu</surname><given-names>J</given-names></name><name><surname>Schadt</surname><given-names>EE</given-names></name><name><surname>Bumgarner</surname><given-names>RE</given-names></name><name><surname>Raftery</surname><given-names>AE</given-names></name></person-group><year>2011</year><article-title>Construction of regulatory networks using expression time-series data of a genotyped population</article-title><source>Proceedings of the National Academy of Sciences</source><volume>108</volume><issue>48</issue><fpage>19436</fpage><lpage>19441</lpage><pub-id pub-id-type="doi">10.1073/pnas.1116442108</pub-id></element-citation></ref><ref id="ref-34"><label>Young, Raftery &#x00026; Yeung (2014)</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Young</surname><given-names>WC</given-names></name><name><surname>Raftery</surname><given-names>AE</given-names></name><name><surname>Yeung</surname><given-names>KY</given-names></name></person-group><year>2014</year><article-title>Fast Bayesian inference for gene regulatory networks using ScanBMA</article-title><source>BMC Systems Biology</source><volume>8</volume><issue>1</issue><fpage>47</fpage><pub-id pub-id-type="doi">10.1186/1752-0509-8-47</pub-id><pub-id pub-id-type="pmid">24742092</pub-id></element-citation></ref><ref id="ref-35"><label>Zou &#x00026; Conzen (2005)</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Zou</surname><given-names>M</given-names></name><name><surname>Conzen</surname><given-names>SD</given-names></name></person-group><year>2005</year><article-title>A new dynamic Bayesian network (DBN) approach for identifying gene regulatory networks from time course microarray data</article-title><source>Bioinformatics</source><volume>21</volume><issue>1</issue><fpage>71</fpage><lpage>79</lpage><pub-id pub-id-type="doi">10.1093/bioinformatics/bth463</pub-id><pub-id pub-id-type="pmid">15308537</pub-id></element-citation></ref></ref-list></back></article>