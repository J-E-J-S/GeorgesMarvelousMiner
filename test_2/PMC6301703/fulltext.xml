<!DOCTYPE article PUBLIC "-//NLM//DTD JATS (Z39.96) Journal Archiving and Interchange DTD v1.1 20151215//EN" "JATS-archivearticle1.dtd"> 
<article xmlns:xlink="http://www.w3.org/1999/xlink" xmlns:mml="http://www.w3.org/1998/Math/MathML" article-type="other"><?properties open_access?><?DTDIdentifier.IdentifierValue -//NLM//DTD JATS (Z39.96) Journal Publishing DTD v1.1d3 20150301//EN?><?DTDIdentifier.IdentifierType public?><?SourceDTD.DTDName JATS-journalpublishing1.dtd?><?SourceDTD.Version 39.96?><?ConverterInfo.XSLTName jp2nlmx2.xsl?><?ConverterInfo.Version 1?><front><journal-meta><journal-id journal-id-type="nlm-ta">PLoS Biol</journal-id><journal-id journal-id-type="iso-abbrev">PLoS Biol</journal-id><journal-id journal-id-type="publisher-id">plos</journal-id><journal-id journal-id-type="pmc">plosbiol</journal-id><journal-title-group><journal-title>PLoS Biology</journal-title></journal-title-group><issn pub-type="ppub">1544-9173</issn><issn pub-type="epub">1545-7885</issn><publisher><publisher-name>Public Library of Science</publisher-name><publisher-loc>San Francisco, CA USA</publisher-loc></publisher></journal-meta><article-meta><article-id pub-id-type="pmcid">6301703</article-id><article-id pub-id-type="pmid">30532167</article-id><article-id pub-id-type="doi">10.1371/journal.pbio.3000070</article-id><article-id pub-id-type="publisher-id">PBIOLOGY-D-18-00466</article-id><article-categories><subj-group subj-group-type="heading"><subject>Essay</subject></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Research and Analysis Methods</subject><subj-group><subject>Simulation and Modeling</subject></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Physical Sciences</subject><subj-group><subject>Mathematics</subject><subj-group><subject>Statistics</subject><subj-group><subject>Statistical Data</subject></subj-group></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Physical Sciences</subject><subj-group><subject>Mathematics</subject><subj-group><subject>Statistics</subject><subj-group><subject>Statistical Models</subject></subj-group></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Research and Analysis Methods</subject><subj-group><subject>Research Assessment</subject><subj-group><subject>Reproducibility</subject></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Computer and Information Sciences</subject><subj-group><subject>Data Visualization</subject></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Computer and Information Sciences</subject><subj-group><subject>Artificial Intelligence</subject><subj-group><subject>Machine Learning</subject></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Biology and Life Sciences</subject><subj-group><subject>Genetics</subject><subj-group><subject>Genomics</subject></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Biology and Life Sciences</subject><subj-group><subject>Computational Biology</subject><subj-group><subject>Genome Analysis</subject></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Biology and Life Sciences</subject><subj-group><subject>Genetics</subject><subj-group><subject>Genomics</subject><subj-group><subject>Genome Analysis</subject></subj-group></subj-group></subj-group></subj-group></article-categories><title-group><article-title>Analysis validation has been neglected in the Age of Reproducibility</article-title></title-group><contrib-group><contrib contrib-type="author"><contrib-id authenticated="true" contrib-id-type="orcid">http://orcid.org/0000-0001-7529-2771</contrib-id><name><surname>Lotterhos</surname><given-names>Kathleen E.</given-names></name><role content-type="http://credit.casrai.org/">Writing &#x02013; original draft</role><role content-type="http://credit.casrai.org/">Writing &#x02013; review &#x00026; editing</role><xref ref-type="aff" rid="aff001"><sup>1</sup></xref></contrib><contrib contrib-type="author"><contrib-id authenticated="true" contrib-id-type="orcid">http://orcid.org/0000-0002-5015-1099</contrib-id><name><surname>Moore</surname><given-names>Jason H.</given-names></name><role content-type="http://credit.casrai.org/">Writing &#x02013; original draft</role><role content-type="http://credit.casrai.org/">Writing &#x02013; review &#x00026; editing</role><xref ref-type="aff" rid="aff002"><sup>2</sup></xref></contrib><contrib contrib-type="author"><contrib-id authenticated="true" contrib-id-type="orcid">http://orcid.org/0000-0001-7242-2673</contrib-id><name><surname>Stapleton</surname><given-names>Ann E.</given-names></name><role content-type="http://credit.casrai.org/">Conceptualization</role><role content-type="http://credit.casrai.org/">Visualization</role><role content-type="http://credit.casrai.org/">Writing &#x02013; original draft</role><role content-type="http://credit.casrai.org/">Writing &#x02013; review &#x00026; editing</role><xref ref-type="aff" rid="aff003"><sup>3</sup></xref><xref ref-type="corresp" rid="cor001">*</xref></contrib></contrib-group><aff id="aff001"><label>1</label>
<addr-line>Northeastern University Marine Science Center, Northeastern University, Boston, Massachusetts, United States of America</addr-line></aff><aff id="aff002"><label>2</label>
<addr-line>Institute for Biomedical Informatics, Division of Informatics, Department of Biostatistics, Epidemiology, &#x00026; Informatics, University of Pennsylvania, Philadelphia, Pennsylvania, United States of America</addr-line></aff><aff id="aff003"><label>3</label>
<addr-line>Department of Biology and Marine Biology, University of North Carolina Wilmington, Wilmington, North Carolina, United States of America</addr-line></aff><author-notes><fn fn-type="COI-statement" id="coi001"><p>The authors have declared that no competing interests exist.</p></fn><corresp id="cor001">* E-mail: <email>stapletona@uncw.edu</email></corresp></author-notes><pub-date pub-type="epub"><day>10</day><month>12</month><year>2018</year></pub-date><pub-date pub-type="collection"><month>12</month><year>2018</year></pub-date><pub-date pub-type="pmc-release"><day>10</day><month>12</month><year>2018</year></pub-date><!-- PMC Release delay is 0 months and 0 days and was based on the <pub-date pub-type="epub"/>. --><volume>16</volume><issue>12</issue><elocation-id>e3000070</elocation-id><permissions><copyright-statement>&#x000a9; 2018 Lotterhos et al</copyright-statement><copyright-year>2018</copyright-year><copyright-holder>Lotterhos et al</copyright-holder><license xlink:href="http://creativecommons.org/licenses/by/4.0/"><license-p>This is an open access article distributed under the terms of the <ext-link ext-link-type="uri" xlink:href="http://creativecommons.org/licenses/by/4.0/">Creative Commons Attribution License</ext-link>, which permits unrestricted use, distribution, and reproduction in any medium, provided the original author and source are credited.</license-p></license></permissions><self-uri content-type="pdf" xlink:href="pbio.3000070.pdf"/><abstract><p>Increasingly complex statistical models are being used for the analysis of biological data. Recent commentary has focused on the ability to compute the same outcome for a given dataset (reproducibility). We argue that a reproducible statistical analysis is not necessarily valid because of unique patterns of nonindependence in every biological dataset. We advocate that analyses should be evaluated with known-truth simulations that capture biological reality, a process we call &#x0201c;analysis validation.&#x0201d; We review the process of validation and suggest criteria that a validation project should meet. We find that different fields of science have historically failed to meet all criteria, and we suggest ways to implement meaningful validation in training and practice.</p></abstract><abstract abstract-type="toc"><p>Just as we do controls for experiments we should all do controls for data analysis &#x02013; this is easy to say but requires dedication to implement. This Essay explains the need for analysis validation and provides specific suggestions for how to get started.</p></abstract><funding-group><funding-statement>This material is based upon work supported by the National Science Foundation under Grant No. NSF grant 1655701 to KEL. This work was supported by National Institutes of Health grants LM012601, LM010098, and AI116794 to JHM. This work was supported by Competitive Grant no. 2017-67013-26188 from the USDA National Institute of Food and Agriculture to AES. The funders had no role in study design, data collection and analysis, decision to publish, or preparation of the manuscript.</funding-statement></funding-group><counts><fig-count count="1"/><table-count count="0"/><page-count count="15"/></counts><custom-meta-group><custom-meta><meta-name>PLOS Publication Stage</meta-name><meta-value>vor-update-to-uncorrected-proof</meta-value></custom-meta><custom-meta><meta-name>Publication Update</meta-name><meta-value>2018-12-20</meta-value></custom-meta></custom-meta-group></article-meta></front><body><sec id="sec001"><title>Background</title><p>The literature is awash with &#x0201c;re&#x0201d;-words: reproducibility, repeatability, replicability&#x02014;even &#x0201c;preproducibility&#x0201d; [<xref rid="pbio.3000070.ref001" ref-type="bibr">1</xref>] [<xref rid="pbio.3000070.ref002" ref-type="bibr">2</xref>] [<xref rid="pbio.3000070.ref003" ref-type="bibr">3</xref>] has found its way into this web of &#x0201c;re&#x0201d; (for definitions, please see <xref ref-type="boxed-text" rid="pbio.3000070.box001">Box 1</xref>). In this essay, we argue that just because a statistical analysis is reproducible or repeatable or re-whatever does not mean that it is valid. A valid statistical outcome means that the analysis has ended in a true positive or true negative result. To answer the new questions that can now be asked because the data are available, many investigators have developed new, customized data analyses and applied them to their data. However, applying a novel data analysis to an existing empirical dataset is unsatisfying because we do not know how many true positives are detected or how many false positives are generated when using empirical data. Thus, investigators need known-truth simulations to evaluate the novel statistical model they have developed. Many investigators do attempt this, but they evaluate their method under data simulated under the exact distributions and processes assumed by the method, which results in the evaluation generally favoring their method. Novel statistical methodologies need to be challenged with a variety of creative simulations that capture the spectrum of biological processes that could have created the patterns in the data. The best way to determine validity is to simulate data that capture similar patterns in the data, analyze the simulated data with various statistical approaches, and evaluate which approach yields the most accurate results. We call this process of simulation and evaluation &#x0201c;analysis validation,&#x0201d; and we assert that this is a fundamental skill for everyone, including biologists.</p><boxed-text id="pbio.3000070.box001" position="float" orientation="portrait"><sec id="sec002"><title>Box 1. Definitions</title><p>benchmark: something serving as a standard by which related items may be judged.</p><p>confusion matrix: table of true positives, false positives, true negatives, and false negatives that result from analysis of known-truth data. Many other metrics are available to visualize or summarize these basic tabular results, for example, the precision and recall, the sensitivity and specificity, the positive predictive value (PPV), the area under the curve (AUC), and newer measures such as the h-measure (<ext-link ext-link-type="uri" xlink:href="https://www.hmeasure.net/">https://www.hmeasure.net/</ext-link>) and plots such as the precision-recall curve (PRC).</p><p>equifinality: the idea that many processes can produce similar patterns and the same processes can produce different patterns [<xref rid="pbio.3000070.ref008" ref-type="bibr">8</xref>].</p><p>gold standard dataset: collected, measured dataset that has the best possible information about signal and noise, i.e., best possible accuracy.</p><p>ground truth data: dataset with signal evaluated using an independent method and thus with maximum possible accuracy for a measured dataset; this term is often used in remote sensing.</p><p>known truth: term we prefer when measuring true and false positives from created datasets, whether the dataset was created using pure simulation, simulation of y given existing x values and/or distributions, or from data with signal identified from independent validation testing.</p><p>null simulation: data simulated under the null hypothesis but simulated with similar patterns of nonindependence as that observed in the real data.</p><p>overfitting: to use a <ext-link ext-link-type="uri" xlink:href="https://en.wiktionary.org/wiki/statistical">statistical</ext-link>
<ext-link ext-link-type="uri" xlink:href="https://en.wiktionary.org/wiki/model">model</ext-link> that has too many <ext-link ext-link-type="uri" xlink:href="https://en.wiktionary.org/wiki/parameter">parameters</ext-link> relative to the size of the sample, leading to a good fit with the sample data but a poor fit with new data (<ext-link ext-link-type="uri" xlink:href="https://en.wiktionary.org/wiki/overfit">https://en.wiktionary.org/wiki/overfit</ext-link>).</p><p>repeatability: ability to make the same signals again.</p><p>replicate: to make or do or perform again, and there is a more detailed explanation at <ext-link ext-link-type="uri" xlink:href="http://www.replicability.tau.ac.il/index.php/replicability-in-science/replicability-vs-reproducibility.html">http://www.replicability.tau.ac.il/index.php/replicability-in-science/replicability-vs-reproducibility.html</ext-link>.</p><p>reproducibility: ability to cause to exist again, to produce again, by generation or the like, and in more detail:</p><disp-quote><p>&#x0201c;in many fields of study there are examples of scientific investigations that cannot be fully replicated because of a lack of time or resources. In such a situation, there is a need for a minimum standard that can fill the void between full replication and nothing. One candidate for this minimum standard is &#x0201c;reproducible research&#x0201d;, which requires that data sets and computer code be made available to others for verifying published results and conducting alternative analyses.&#x0201d; [<xref rid="pbio.3000070.ref009" ref-type="bibr">9</xref>]</p></disp-quote><p>Statistical definitions and illustrations are available in Patil and colleagues [<xref rid="pbio.3000070.ref010" ref-type="bibr">10</xref>].</p><p>simulation: the act of imitating the behavior of some situation or some process by means of something suitably analogous (especially for the purpose of study or personnel training); (computer science) the technique of representing the real world by a computer program; &#x0201c;a simulation should imitate the internal processes and not merely the results of the thing being simulated.&#x0201d;</p><p>sensitivity analysis: systematic testing of the importance of factors and factor values in generating outputs (<ext-link ext-link-type="uri" xlink:href="https://www.nist.gov/sites/default/files/documents/itl/antd/philadelphiainterface052607.pdf">https://www.nist.gov/sites/default/files/documents/itl/antd/philadelphiainterface052607.pdf</ext-link>). This concept is related to feature selection in machine learning, to effect size estimation in classical linear models, and to understanding the effects of uncertainty in parameters on the results from mathematical models.</p><p>synthetic dataset: dataset generated from a function (equation) with reproducible values for signal and noise; this is often referred to as a simulation in statistics.</p><p>true positive/false positive/true negative/false negative: the count of detected signal (true positives) and noise (true negative), with the misclassified cases as false positive and negative. The full four-way table is termed the confusion matrix (see above).</p><p>validation: finding or testing the truth of something.</p><p>The source of all definitions without references is the free dictionary, <ext-link ext-link-type="uri" xlink:href="http://www.dict.org/bin/Dict">http://www.dict.org/bin/Dict</ext-link>.</p></sec></boxed-text></sec><sec id="sec003"><title>Why analysis validation?</title><p>Analysis validation is necessary because every biological dataset is unique in the pattern of correlation or dependency among samples. In introductory biostatistics, we teach students that individuals sampled from a population should be chosen at random (each individual chosen with equal probability) and that individuals should be independent of each other (individuals are not related to each other or interacting in some way). Unfortunately, for many biological datasets, these two properties of a good sample are violated because of logistical constraints in random sampling, because of shared ecological and evolutionary histories, and because of spatial and temporal autocorrelation. These properties of a good sample are also difficult to attain in the age of Big Data because highly dimensional datasets have unique challenges, including noise accumulation, spurious correlation, correlation between predictors and residual noise, and measurement errors [<xref rid="pbio.3000070.ref004" ref-type="bibr">4</xref>]. Equifinality (<xref ref-type="boxed-text" rid="pbio.3000070.box001">Box 1</xref>) is ubiquitous in biological datasets. For example, statistical models that analyze patterns in DNA sequences of the human genome might make it look like those sequences have been selected for [<xref rid="pbio.3000070.ref005" ref-type="bibr">5</xref>] [<xref rid="pbio.3000070.ref006" ref-type="bibr">6</xref>], but models of human history that include both population growth and spatial structure can generate the observed patterns without selection [<xref rid="pbio.3000070.ref007" ref-type="bibr">7</xref>]. Many processes can lead to the same pattern. Biologists have often used &#x0201c;off-the-shelf&#x0201d; analyses, but these rarely capture the variety of processes and sampling designs that may have generated a pattern and often have important assumptions such as multivariate normality. In some cases, even analytic approaches that are specifically designed for a type of dataset can be problematic because they make assumptions that are not met by the data. Therefore, to determine if a statistical outcome is valid, we need to better understand how accurately a statistical analysis is able to model the data.</p><p>In an attempt to confront some of these statistical issues presented by biological realism, a preponderance of new and more complex statistical methodologies are being proposed. In many cases, these methods are applied to data in which the true positives and true negatives are unknown or these methods are evaluated with data simulated following the assumptions of the method. However, it&#x02019;s not always clear if the real data meet those assumptions. For this reason, the three of us, along with many of our colleagues, have started to take a more inquiry-based approach to data analysis. We mentor and teach analysis validation, which can also be stated as &#x0201c;test the tests.&#x0201d; We postulate that every experimental biology question and dataset deserves its own validation because every biological dataset and question is unique. In this essay, we provide some examples below from our personal experiences in statistical genomics, but the concepts we discuss apply to all areas of biology.</p><disp-quote><p>How do people get here? Scientists do a data analysis and then read about a new analysis approach, which they try&#x02026;then they wonder which one is right. That leads them to designing simulations and consideration of parameter importance.&#x02014;Matthew Stephens, University of Chicago</p></disp-quote><p>Just like we do controls for experiments, we should all do controls for data analysis. Of course, this is not easy. The nonindependence in biological systems due to shared evolutionary history, experimental design, and other limits can make thickets of constraints that have no obvious best path.</p><p>Doing an analysis validation from the beginning of a research project gives you the opportunity to justify your choices for the data you will collect and makes the statistical review process more efficient in many ways. First, documentation helps reviewers understand why you may have chosen particular settings for a statistical model that you ran on the data rather than using the default settings. Second, it helps the researcher understand what range of conclusions could be drawn from a significant result in the data. Third, it helps reviewers without statistical expertise to evaluate the results. Since there are not enough biostatisticians to review all biology grants and manuscripts, analysis validation can help streamline the review process and prevent misapplication of models in the future.</p><p>Analysis validation can be performed on many types of statistical models. These include probabilistic models, in which insights into nature can be made through parameter estimation or null hypothesis testing, as well as machine learning or algorithmic models, which aim to optimize the predictive accuracy of an algorithm rather than estimate a parameter. We advocate that the following criteria should be met for analysis validation: (i) known-truth simulations are used for evaluation of methods, (ii) the processes used to simulate data should be creative in capturing biological reality, (iii) the processes used to simulate data should not match the assumptions of one particular method, and (iv) the code for the simulations and validation should be reproducible and curated to enable future methods comparisons. Validation projects that meet these criteria will result in a better understanding of the benefits and shortcomings of different models that may be used to analyze data, and result in more robust application of models to data.</p></sec><sec id="sec004"><title>How to validate a data analysis</title><sec id="sec005"><title>Research question and planning (<xref ref-type="fig" rid="pbio.3000070.g001">Fig 1</xref>, flowchart steps 1, 2, and 3)</title><p>Before beginning a research project, explicitly formulate your research question or hypothesis and note what data are needed to answer that question. Once you identify the data necessary to answer the research question, plan for what kind of data will be collected, identify the types of statistical methods that may be appropriate, learn about their assumptions, and then assess in what ways the data may fail to meet the assumptions of those methods. All too often, investigators explicitly plan for collecting data without a detailed strategy for analyzing that data and relating the results back to the research question or hypothesis. Planning is an important part of meeting the first three of the criteria outlined in &#x0201c;Why analysis validation?&#x0201d;</p><fig id="pbio.3000070.g001" orientation="portrait" position="float"><object-id pub-id-type="doi">10.1371/journal.pbio.3000070.g001</object-id><label>Fig 1</label><caption><title>Flow chart showing some of the key steps in constructing simulations and validating data analysis methods.</title><p>PRC, precision-recall curve.</p></caption><graphic xlink:href="pbio.3000070.g001"/></fig></sec><sec id="sec006"><title>Get organized to simulate (<xref ref-type="fig" rid="pbio.3000070.g001">Fig 1</xref>, flowchart steps 4, 5, and 6)</title><p>A key part of conducting a successful analysis validation study is to have a well-organized system for keeping track of simulations and results. When considering the steps in analysis validation (simulation, analysis of simulations, results from the analysis on the simulation, evaluation of the results and the calculation of performance metrics, and figures and/or visualization), a good rule of thumb is to have a folder for each of these steps in the pipeline in addition to folders for simulation and analysis scripts. Be aware that there is a random component to simulation and to some statistical approaches (for example, those based on Markov chain Monte Carlo or machine learning) and that random seeds should be specified in the pipeline so that results are reproducible. As in any analysis, proper data management and software curation standards are also required (for example, versioning, <xref ref-type="fig" rid="pbio.3000070.g001">Fig 1</xref>). Since new methods are being consistently developed, it is important to structure your organization system and pipelines in such a way that new methods can be easily evaluated against previous ones, even by a person who did not contribute to the original study. In <xref ref-type="boxed-text" rid="pbio.3000070.box002">Box 2</xref>, we highlight some useful tools for performing and organizing an analysis validation study. Being organized is an important part of meeting the final criterion outlined in &#x0201c;Why analysis validation?&#x0201d;</p><boxed-text id="pbio.3000070.box002" position="float" orientation="portrait"><sec id="sec007"><title>Box 2. Validation management tools</title><p>For each example below, we highlight the special feature that was used to focus the design.</p><list list-type="bullet"><list-item><p>DSC, Dynamic Statistical Comparisons: <ext-link ext-link-type="uri" xlink:href="https://stephenslab.github.io/dsc-wiki/">https://stephenslab.github.io/dsc-wiki/</ext-link>, <ext-link ext-link-type="uri" xlink:href="https://github.com/stephens999/dscr/blob/master/intro.md">https://github.com/stephens999/dscr/blob/master/intro.md</ext-link>. This tool organizes inputs and outputs for simulation and analysis and leverages powerful Script-of-Scripts pipelines, with a focus on enabling the user to add new functionality easily. This program priority is to be &#x0201c;extensible&#x0201d;: to easily allow additional methods and simulations.</p></list-item><list-item><p>The simulator R package (<ext-link ext-link-type="uri" xlink:href="https://arxiv.org/abs/1607.00021">https://arxiv.org/abs/1607.00021</ext-link>, <ext-link ext-link-type="uri" xlink:href="http://faculty.bscb.cornell.edu/~bien/simulator.html">http://faculty.bscb.cornell.edu/~bien/simulator.html</ext-link>) can be used to track simulation processes and handle mechanics such as random numbers and plotting, with a modular specification of what the user would need to consider for simulations, analyses, and metrics. This program priority is to be &#x0201c;manageable&#x0201d;: to allow users to easily keep track of the different processes and stages in their simulations.</p></list-item><list-item><p>CyVerse Validate (<ext-link ext-link-type="uri" xlink:href="http://validate-10.readthedocs.io/en/latest/">http://validate-10.readthedocs.io/en/latest/</ext-link>) uses public computational resources (for democratic access to resources) and a generalizable computation management tool (Agave, <ext-link ext-link-type="uri" xlink:href="https://tacc-cloud.readthedocs.io/projects/agave/en/latest/">https://tacc-cloud.readthedocs.io/projects/agave/en/latest/</ext-link> for genome-wide association studies (GWAS) tool comparisons. This project priority is to be &#x0201c;scalable&#x0201d;: to allow researchers to compare analyses and manage running of simulations using public compute resources that accommodate increased computational demand.</p></list-item></list><p>From the Machine Learning community, we highlight repository examples that illustrate how simulations can be shared:</p><list list-type="bullet"><list-item><p>The Penn Machine Learning Benchmark (PMLB) at <ext-link ext-link-type="uri" xlink:href="https://github.com/EpistasisLab/penn-ml-benchmarks">https://github.com/EpistasisLab/penn-ml-benchmarks</ext-link>. This effort leverages github functionality to track use and curate the code and data.</p></list-item><list-item><p>Image analysis (for example, ImageNet, image-net.org) repositories are used for storage of gold standard datasets and use links and publications to track usage and results.</p></list-item></list><p>There are many other tools and repositories available. We encourage readers to post additional suggestions in the comments section associated with this essay, noting use cases and target user and contributor communities.</p></sec></boxed-text></sec><sec id="sec008"><title>Plan simulations, find necessary expertise and resources (<xref ref-type="fig" rid="pbio.3000070.g001">Fig 1</xref>, flowchart steps 5, 7, and 8)</title><p>Once you have planned how to organize your validation project, ask yourself the following:</p><list list-type="bullet"><list-item><p>If I simulate data under the null (or some other) hypothesis and analyze it the same way as the real data, what results do I get?</p></list-item><list-item><p>If I make changes to the simulations, how does the output change? What increases false positives and false negatives?</p></list-item></list><p>With complex situations, the null simulation could be hard to decide on, so your experience with the system and your specific question will assist in prioritizing the number and range of simulations you plan to do (<xref ref-type="fig" rid="pbio.3000070.g001">Fig 1</xref>). Don&#x02019;t plan to simulate data that follow the exact model of the statistical method being evaluated; instead, consider the types of nonindependence in the real data and consider different process that could produce the same pattern. Designing simulations will be important for meeting the second and third criteria outlined in &#x0201c;Why analysis validation?&#x0201d; This range helps you determine what the key factors/parameters are in your system and may prompt you to answer new questions in your next set of experiments. Simulations let you explore your system and help you optimize resources for biological verification. A simulation project should normally include both the equations and theory, the code and functions you used to create the data, and the output files that result from running the code (though in some cases, it is not optimal to store large output files, and options for reproducible rerunning can be provided instead).</p><p>Nuances in data analysis can affect the outcomes of studies; important details include data filtering, imputation of missing data values, and model selection approaches. These should be included in simulations in ways that reflect the experimental design and data collection. Since it is time consuming and often impossible to reproduce the results without the analysis scripts, curation of simulations and analysis methods in reproducible pipelines is an important component of a validation project (<xref ref-type="boxed-text" rid="pbio.3000070.box002">Box 2</xref>, and necessary to meet the fourth criterion outlined in &#x0201c;Why analysis validation?&#x0201d;). Doing the simulations also ensures you thoroughly understand how to do the data analysis, which will save you time later when you have your experimental results.</p></sec><sec id="sec009"><title>Compare the results and calculate performance metrics for different statistical models (<xref ref-type="fig" rid="pbio.3000070.g001">Fig 1</xref>, flowchart step 9)</title><p>After the simulations have been analyzed with different statistical models, the known truth of the simulations can be used to compare the performance of the different models. Performance metrics come in two flavors: those based on a confusion matrix for a single cutoff (for example, a cutoff that gives 1% false positives or a cutoff P-value), and those based on comparison of all thresholds, such as the area under the curve of the precision-recall graph (AUC-PR) [<xref rid="pbio.3000070.ref011" ref-type="bibr">11</xref>]. Performance metrics based on the confusion matrix for a single cutoff can sometimes be misleading because a method that performs better than another at one cutoff may perform worse at a different cutoff. The AUC is generally preferred because it integrates over all possible cutoffs for the data.</p></sec><sec id="sec010"><title>Simulation management and curation (<xref ref-type="fig" rid="pbio.3000070.g001">Fig 1</xref>, flowchart steps 6 and 10)</title><p>Beyond managing your own work, there is real synergy in working with shared, community simulation repositories, as we have seen in the fields of machine learning and image analysis. The evolution community has called for a bank of simulations that can be used to validate or verify methods, <ext-link ext-link-type="uri" xlink:href="https://www.nescent.org/cal/calendar_detail.php-id=1105.html">https://www.nescent.org/cal/calendar_detail.php-id=1105.html</ext-link>, as has the National Institutes of Health (NIH) workshop on genetic simulation [<xref rid="pbio.3000070.ref012" ref-type="bibr">12</xref>]. Consider how your simulations will be curated and shared (criterion four in &#x0201c;Why analysis validation?&#x0201d;)&#x02014;your work does have value for others!</p></sec></sec><sec id="sec011"><title>Evolution of analysis validation across fields</title><p>Across different fields, the criteria for analysis validation varies. Here, we review whether current practices typically meet the four criteria outlined in &#x0201c;Why analysis validation?&#x0201d; While we recognize that analysis validation is a process in which models and simulations necessarily start simply and become more and more complex as knowledge accumulates, below, we show that despite knowledge increasing rapidly, there is still a lag in the rate this knowledge is incorporated into testing methods.</p><p>Computer scientists a have a long-standing culture of using public datasets for the development and evaluation of machine learning methods. The computer science goal is to answer questions about algorithm performance relative to prior algorithms, so computer scientists are naturally more interested in algorithms and easy access to benchmark data. A widely used source of public data is the UCI Machine Learning Repository from the University of California Irvine that has been available since 1987 (<ext-link ext-link-type="uri" xlink:href="http://archive.ics.uci.edu/ml">http://archive.ics.uci.edu/ml</ext-link>). This repository currently has more than 400 datasets from a wide range of different disciplines, including nearly 100 from the biological and biomedical sciences. Other sets of benchmark data have been assembled, such as the Penn Machine Learning Benchmark (PMLB) resource from the University of Pennsylvania that includes both public and simulated data [<xref rid="pbio.3000070.ref013" ref-type="bibr">13</xref>]. While these resources are generally very useful for methods comparisons, they aren&#x02019;t without problems. For example, it is difficult to benchmark and compare algorithms with real data since the truth is not known. Further, it is often not known or understood how the data were generated and what the quality control issues are. It is also common to evaluate algorithms on a subset of the datasets, which raises questions about whether the data used were selected to maximize performance of the method being developed. These issues and others were raised in a recent community survey of best practices for those working on a type of machine learning called genetic programming [<xref rid="pbio.3000070.ref014" ref-type="bibr">14</xref>]. This paper went as far as to recommend blacklisting some benchmarks because they were too easy, out of date, or not appropriate for the methods being developed. As the number of statistical models increase, the number of benchmarks does not, especially for experimentally validated datasets, which are difficult and expensive to generate&#x02014;which increases the risk of overfitting because more and more models are developed, but only the ones that show a significant improvement are published. In other words, testing an increasing number of methods on a small group of datasets until you discover a better model is analogous to running a large number of statistical models on one dataset until you find one that is significant. Thus, common current practice in computer science fails to meet our first three criteria for analysis validation because the truth is unknown for the benchmark datasets.</p><p>In contrast, statisticians normally create and use simulations, as well as using public datasets, for new method development. However, statisticians do not have sharing tradition, a widely used common repository for simulations, or common metadata standards for simulations. There are some efforts to develop repositories, such as the workshop and repository for genome-wide analysis simulations described by Peng and colleagues [<xref rid="pbio.3000070.ref015" ref-type="bibr">15</xref>] [<xref rid="pbio.3000070.ref012" ref-type="bibr">12</xref>], but this is not widespread. Typically, statistics instructors create simulations to use in class, but they are not often shared or scalable, and learning simulation construction is not typically part of the undergraduate statistics curriculum. In 2015&#x02013;2016, the need for simulation management was addressed by statisticians, and since then, there have been some development efforts for management systems (<xref ref-type="boxed-text" rid="pbio.3000070.box002">Box 2</xref>). The field of statistics thus provides a great example of using simulations to evaluate methods (our first criterion) but does not meet our other criteria because simulations often follow assumptions of the methods, and publications do not always include the code to rerun the simulations. Only biostatisticians would be focused on our second criteria (creative simulations); we advocate for more biostatistician&#x02013;biologist partnerships in development of simulation systems that are statistically sound and biologically relevant.</p><p>Ecology and evolutionary biology both have a long tradition of simulations for analysis method development, but like statisticians, these scientists have not historically shared simulations and code. For example, method comparisons in landscape ecology produced a paper with over 4,000 citations since 2006 [<xref rid="pbio.3000070.ref016" ref-type="bibr">16</xref>] and the establishment of a preferred method with over 5,500 citations [<xref rid="pbio.3000070.ref017" ref-type="bibr">17</xref>]. Typically, however, these fields of biology have grown through the cyclical process of proposing a statistical model, recognizing that the model is insufficient, proposing a new model and validating the model with simulated data, recognizing that the simulated data were overly simplistic, proposing more realistic simulations and models, and so on. A good example of how this cyclical process has played out in evolutionary biology is for a statistical test called an F<sub>ST</sub> outlier test, which seeks to identify which loci in a genome are under selection and which are neutral. In 1973, Lewontin and Krakeur [<xref rid="pbio.3000070.ref018" ref-type="bibr">18</xref>] were the first to propose that unusually large or &#x0201c;outlier&#x0201d; values of F<sub>ST</sub> indicate that the locus may be affected by selection. Difficulties with the method were immediately recognized, however, because the variation in F<sub>ST</sub> depends on sample sizes and the degree of independence of the evolutionary histories of sampled populations [<xref rid="pbio.3000070.ref019" ref-type="bibr">19</xref>] [<xref rid="pbio.3000070.ref020" ref-type="bibr">20</xref>] [<xref rid="pbio.3000070.ref021" ref-type="bibr">21</xref>]. The next major improvement on the F<sub>ST</sub> outlier test was to account for differences in sample size [<xref rid="pbio.3000070.ref022" ref-type="bibr">22</xref>], which became a widely used method (cited &#x0003e;1,500 times) despite the fact that the model was evaluated on relatively simple simulations and the model still did not account for varying degrees of nonindependence among sampled populations. Analysis validation on this method with more realistic simulated data was able to clearly illustrate how shared evolutionary history (a source of nonindependence among samples) caused the method to have many false positives [<xref rid="pbio.3000070.ref023" ref-type="bibr">23</xref>]. Recently, many flavors of F<sub>ST</sub> outlier tests have been evaluated with more realistic simulations, and they have much lower false positive rates because they control for nonindependence among populations in the calculation of significance of test statistics [<xref rid="pbio.3000070.ref024" ref-type="bibr">24</xref>] [<xref rid="pbio.3000070.ref025" ref-type="bibr">25</xref>] [<xref rid="pbio.3000070.ref026" ref-type="bibr">26</xref>] [<xref rid="pbio.3000070.ref027" ref-type="bibr">27</xref>]. We note that the standards for our first three criteria have improved over time in the fields of ecology and evolutionary biology, but these fields still fail to use shared repositories or benchmarks for evaluation (the fourth criterion).</p><p>Bioinformaticians and statistical genomicists typically share simulation results and pseudocode rapidly (for example, biostars <ext-link ext-link-type="uri" xlink:href="https://www.biostars.org/">https://www.biostars.org/</ext-link>, SEQanswers <ext-link ext-link-type="uri" xlink:href="http://seqanswers.com/">http://seqanswers.com/</ext-link>) but do not routinely use shared repositories or shared design patterns for simulations. As in ecology and evolutionary biology, comparisons of methods are often done by specialists and published as static results. Bioinformatics and statistical genomics researchers have been slow to evaluate methods against biologically realistic simulations, which is in part due to the computational challenge of simulating genomes and the process of simulating next-generation sequencing because simulation tools have only recently become available [<xref rid="pbio.3000070.ref028" ref-type="bibr">28</xref>, <xref rid="pbio.3000070.ref029" ref-type="bibr">29</xref>, and <xref rid="pbio.3000070.ref030" ref-type="bibr">30</xref>]. Because of the latency in generating known-truth simulations in these fields, there is still much to be learned about the consequences of violating the assumptions of statistical models for genomic data analysis. For example, a common goal of many genomics studies is to identify the genetic markers that increase risk for common human diseases, which are often identified with statistical tests called genome-wide association studies (GWASs). Modern human GWASs were developed in the mid-2000s with the availability of chips for genotyping [<xref rid="pbio.3000070.ref031" ref-type="bibr">31</xref>] [<xref rid="pbio.3000070.ref032" ref-type="bibr">32</xref>] and quickly converged on a standard protocol for data processing and analysis that helped facilitate the reduction of false positives and an increase in the replication of results across multiple studies. While the human GWAS approach has had success identifying numerous genetic risk factors [<xref rid="pbio.3000070.ref033" ref-type="bibr">33</xref>], there are very few discoveries that have led to new prevention and treatment strategies. It is generally recognized that many real genetic risk factors may have been missed because the rigid analytical approach makes many important assumptions that might not be valid. For example, typical human GWASs assume that each single-nucleotide polymorphism (SNP) has an additive effect on risk that is independent of genomic and ecological context (for example, a univariate linear model), an assumption that is increasingly being questioned for complex disease traits [<xref rid="pbio.3000070.ref034" ref-type="bibr">34</xref>]. There is also an extensive list of numerous other statistical assumptions that may not make sense given the enormous complexity of common human diseases. Violation of any of these assumptions could invalidate the data analysis method, at which point an independent experimental biological validation (for example, gene editing) becomes pointless. Our experience with GWASs has thus taught us that careful listing and scrutiny of all the assumptions of the analysis, and how the data may violate them, is an important component of designing simulations for analysis validation. Thus, while bioinformatics and statistical genomics have a history of creating simulations for methods evaluation (the first criterion), these simulations are in many cases overly simplistic and do not often capture biological reality and are not typically shared in common repositories, so they fail to fulfill the remaining criteria.</p><p>Across many fields, contests have historically played and continue to play an important role in analysis method development and in teaching and learning about validation. Open competitions for data analysis have a long history and have been key in the development of protein structure prediction methods (<ext-link ext-link-type="uri" xlink:href="http://predictioncenter.org/index.cgi">http://predictioncenter.org/index.cgi</ext-link>), in early microarray data analysis (<ext-link ext-link-type="uri" xlink:href="http://camda.duke.edu/">http://camda.duke.edu/</ext-link>), and in association and/or quantitative trait locus (QTL) analysis (<ext-link ext-link-type="uri" xlink:href="https://www.gaworkshop.org/">https://www.gaworkshop.org/</ext-link>, <ext-link ext-link-type="uri" xlink:href="http://qtl-mas-2012.kassiopeagroup.com/en/index.php">http://qtl-mas-2012.kassiopeagroup.com/en/index.php</ext-link>). Some examples of competition-based innovations that have moved the whole field forward include the dialogue for reverse engineering assessments and methods (DREAM) challenge for pathway inference and networks in biology and medicine (<ext-link ext-link-type="uri" xlink:href="http://dreamchallenges.org/project/dream-5-network-inference-challenge/">http://dreamchallenges.org/project/dream-5-network-inference-challenge/</ext-link>) and the protein structure effort WeFold [<xref rid="pbio.3000070.ref035" ref-type="bibr">35</xref>] (<ext-link ext-link-type="uri" xlink:href="https://wefold.nersc.gov/wordpress/">https://wefold.nersc.gov/wordpress/</ext-link>). We highlight DREAM and WeFold because they have contributed an emphasis on collaboration&#x02014;with tools developed to support team interaction and with incentives to improve teamwork during challenges. The open release of simulated data in the QTL-marker&#x02013;assisted selection (QTL-MAS) project and for experimentally determined structures in critical assessment of techniques for protein structure prediction (CASP) has also benefited the community of researchers in these areas. Challenges are also used as explicit teaching and learning tools. For example, the software and statistical methods for population genetics (SSMPG) workshop uses a data challenge as a way to learn how to analyze a genome for the regions involved in local adaptation (<ext-link ext-link-type="uri" xlink:href="https://github.com/bcm-uga/SSMPG2017">https://github.com/bcm-uga/SSMPG2017</ext-link>). The students are presented with a simulated dataset (with known true positives and true negatives) and receive several tutorials on statistical methods that may be used to analyze the data. Students are then given free time to analyze the simulated data as they see fit and submit their results to a website that returns a score based on the number of true and false discoveries in their submission. The website posts the scores on a leaderboard, and students can work to improve their score through reanalysis of the data. Through this process, they learn about both the strengths and weaknesses of the different methods, the best practices for analyzing the data, and how analysis validation works. Academic and commercial contests have moved toward increased code and simulation sharing in recent years and could provide effective incentives and training relevant to all four of our criteria if the contest designers prioritize those aspects.</p></sec><sec id="sec012"><title>Shortcomings of other approaches for evaluation</title><p>Often, biologists are reluctant to undertake a simulation project because they don&#x02019;t have the expertise or they think it unfeasible, and so they evaluate and compare methods on real data instead. This can be accomplished through a sensitivity analysis and/or cross-validation. Note that neither of these approaches can give insight into whether a particular outcome gives a true positive or false positive result. Thus, although these approaches have some benefits and caveats discussed below, both of these approaches fail to meet the first and most important criterion for analysis validation (using simulations).</p><p>A sensitivity analysis determines how robust the results are to different decisions made while analyzing the data. In the field of genomics, for example, it may be how sensitive results are to the way missing genotypes are interpolated for analysis, while in the field of landscape ecology, it may be how sensitive results are to the way data are interpolated across spatial locations. Sensitivity analysis has the benefit of identifying particular choices or parameters that may influence outcomes.</p><p>Cross-validation is a procedure that partitions the data into a training set that is used to fit model parameters and a test set that is used to measure the prediction errors. However, cross-validation is just measuring error of predictions&#x02014;therefore, it measures precision and not accuracy. If your data violate the assumptions of the model and you get the wrong result, you can still have a precise cross-validation that is not accurate (i.e., all darts hit the same place on the dartboard, but they are far from the bullseye). Because in biology, many different processes can create the same pattern, a model can perform well in a cross-validation but still model a different process from the one that created the data. Analysis validation can help resolve disputes on how the output of statistical models should be interpreted, even when they perform well in cross-validation (for example, [<xref rid="pbio.3000070.ref036" ref-type="bibr">36</xref>]).</p><p>Cross-validation with real data is also problematic for comparing the performance of statistical and machine learning methods because the true signal in the data is unknown. One method may appear to perform better than another on a real dataset simply because it is doing a better job of modeling systematic noise or error rather than true signal. This can yield misleading claims of method performance, which in turn can negatively influence studies that adopt these methods. We recommend that comparison of methods be first performed using simulated data in which the truth is known. The challenge here is to simulate realistic patterns that appropriately challenge the methods. One clear advantage of simulation for method comparison is that it is relatively easy to simulate data with differing sample sizes, numbers of variables or features, varying amounts of noise, varying effect sizes, varying pattern complexity, etc. The ability to vary simulation parameters makes it much easier to determine the strengths and weaknesses of different methods. We recommend that real data be used with cross-validation or other similar methods only after a comprehensive simulation study has been completed. Any comparisons with real data should be followed by an in-depth interpretation of the results to compare the biological plausibility of the models that are generated in addition to standard estimates of error that are provided by cross-validation.</p></sec><sec id="sec013"><title>A path toward validation for all</title><p>We postulate that simulation and validation is likely to be a key skill to teach early, the same way we teach lab notebooks, protocols, and experimental design in the natural sciences (for example, <ext-link ext-link-type="uri" xlink:href="http://www.lifescied.org/content/13/2/265">http://www.lifescied.org/content/13/2/265</ext-link> and <ext-link ext-link-type="uri" xlink:href="https://www.lifescied.org/doi/abs/10.1187/cbe.13-11-0218">https://www.lifescied.org/doi/abs/10.1187/cbe.13-11-0218</ext-link>). Colon-Berlingeri and Burrowes, for example, describe the use of simulated data in biology curricula [<xref rid="pbio.3000070.ref037" ref-type="bibr">37</xref>]. Many biology faculty have used simulation modules to teach experimental design and data analysis to undergraduates, historically using EcoBeaker and Virtual Flylab (Desharnais and Bell, <ext-link ext-link-type="uri" xlink:href="http://www.imej.wfu.edu/articles/1999/2/01/printver.asp">http://www.imej.wfu.edu/articles/1999/2/01/printver.asp</ext-link>) and now Simbio (<ext-link ext-link-type="uri" xlink:href="http://simbio.com/promos/experimental-design">http://simbio.com/promos/experimental-design</ext-link>). It would be very helpful to have additional materials available for other audiences along with teaching materials that are specific to analysis validation. It is abundantly clear that open source is the sustainable path forward in making analysis and simulation tools available to everyone.</p><p>In addition to supporting use of open source software, graduate programs should already be requiring trackable electronic notebooks for all students and policies for review of these; additional development of these policies would be a great opportunity for collaboration with research compliance offices. A requirement like this is already in place for the graduate program in Genomics and Computational Biology at the University of Pennsylvania, where students have their electronic notebooks reviewed by the graduate committee at each annual meeting. Notebooks are reviewed for completeness with respect to manuscripts and published papers in which the ability to reproduce the work of the student is an important consideration. Incomplete notebooks are reported to the chair of the graduate program and the adviser. There are several benefits to this kind of policy beyond ensuring reproducibility of the results. First, it can lead to an improved mentoring relationship with the student. Second, it encourages the student to more carefully document their work beyond what might be required to reproduce a result. Third, it fosters developmental rather than punitive tracking of the student&#x02019;s progress. Training in data curation (one source for more detail on data about data is <ext-link ext-link-type="uri" xlink:href="http://www.datacarpentry.org/organization-genomics/01-tidiness/">http://www.datacarpentry.org/organization-genomics/01-tidiness/</ext-link>) is also likely to be valuable for all, and we advocate for more dialog with information schools and librarians in theory and practice for development of scalable curation teaching methods and tools as a complement to specific training in simulation for validations. Doing simulations early makes data analysis and peer review more efficient, which benefits students as they progress toward their degrees and has the potential to improve their career trajectories.</p><p>A longer-term advantage of simulation is the potential to characterize repositories of simulations using mathematical similarity, as well as using text-based or manual ontologies; this would allow building on existing efforts such as ontology development (Coehlo and colleagues 2012, <ext-link ext-link-type="uri" xlink:href="https://bibliotecadigital.fgv.br/dspace/bitstream/handle/10438/15033/Towards_an_Ontology_for_Mathematical_Modeling_with_Application_to_Epidemiology.pdf">https://bibliotecadigital.fgv.br/dspace/bitstream/handle/10438/15033/Towards_an_Ontology_for_Mathematical_Modeling_with_Application_to_Epidemiology.pdf</ext-link>), automated analysis such as OntoMathPro (<ext-link ext-link-type="uri" xlink:href="http://ontomathpro.org/ontology/">http://ontomathpro.org/ontology/</ext-link>), and exploiting equation libraries such as the Digital Library of Mathematical Functions (<ext-link ext-link-type="uri" xlink:href="https://dlmf.nist.gov/">https://dlmf.nist.gov/</ext-link>).</p><p>The rise in simulations is expected to drive new computer science research and applications (<ext-link ext-link-type="uri" xlink:href="https://upcommons.upc.edu/handle/2117/96661">https://upcommons.upc.edu/handle/2117/96661</ext-link>). Novel methods for incentivizing collaboration and simulation and new ways to support long-term curation, taxonomic grouping in repositories, and search are needed. Every field calls analysis validation something slightly different (<xref ref-type="boxed-text" rid="pbio.3000070.box001">Box 1</xref>), which impedes search serendipity and thus dissemination. One straightforward early step would be workshops and hackathons for simulation-management tool developers that are coordinated with gateway cyberinfrastructure developers (<ext-link ext-link-type="uri" xlink:href="https://sciencegateways.org/">https://sciencegateways.org/</ext-link>), so as to better connect scientists with scalable open access computational resources, and design and implementation input from curation system experts such as ontologists and librarians.</p><p>We suggest starting with a focus on designing simulation repositories that update gracefully, that leverage shared libraries for simulation features such as missingness, noise, and equation taxonomy, and that can be run with original and novel analysis code on public computational resources. Lessons learned from existing image repositories will be valuable in designing new simulation repositories. We also recommend that both sustainability and adaptability of any curation and repository effort be a notable component of funding. We advocate for a living, widely used repository system that scales well and leverages volunteer contributions in an exemplary way. Ideally, fields would agree on benchmark simulations that would be used to measure performance on all developed methods. In our experience, the fields of ecology and quantitative genetics have excellent individual examples of scientists who combine modeling and experimentation. We encourage deeper integration of these complementary skills for all biologists at all levels.</p></sec></body><back><ack><p>We thank Casey Greene and Daniel Himmelstein, University of Pennsylvania, Yishi Wang, UNCW, S. Stanley Young, CGStat LLC, Matthew Fitzpatrick, Sara Schaal, and Kevin Freeman for their insightful comments on an early draft of this commentary. AES thanks Susan J. Simmons, NCSU, for patiently teaching her statistics and the importance of simulations (<ext-link ext-link-type="uri" xlink:href="https://datacarpentry.org/blog/2017/01/statistics">https://datacarpentry.org/blog/2017/01/statistics</ext-link>).</p></ack><glossary><title>Abbreviations</title><def-list><def-item><term>AUC</term><def><p>area under the curve</p></def></def-item><def-item><term>CASP</term><def><p>critical assessment of techniques for protein structure prediction</p></def></def-item><def-item><term>DREAM</term><def><p>dialogue for reverse engineering assessments and methods</p></def></def-item><def-item><term>DSC</term><def><p>Dynamic Statistical Comparisons</p></def></def-item><def-item><term>GWAS</term><def><p>genome-wide association study</p></def></def-item><def-item><term>NIH</term><def><p>National Institutes of Health</p></def></def-item><def-item><term>PMLB</term><def><p>Penn Machine Learning Benchmark</p></def></def-item><def-item><term>PPV</term><def><p>positive predictive value</p></def></def-item><def-item><term>PR</term><def><p>precision recall</p></def></def-item><def-item><term>PRC</term><def><p>precision-recall curve</p></def></def-item><def-item><term>QTL</term><def><p>quantitative trait locus</p></def></def-item><def-item><term>QTL-MAS</term><def><p>QTL-marker&#x02013;assisted selection</p></def></def-item><def-item><term>SNP</term><def><p>single-nucleotide polymorphism</p></def></def-item><def-item><term>SSMPG</term><def><p>software and statistical methods for population genetics</p></def></def-item><def-item><term>UCI</term><def><p>University of California Irvine</p></def></def-item></def-list></glossary><ref-list><title>References</title><ref id="pbio.3000070.ref001"><label>1</label><mixed-citation publication-type="journal"><name><surname>Leek</surname><given-names>JT</given-names></name>, <name><surname>Jager</surname><given-names>LR</given-names></name>. <article-title>Is Most Published Research Really False? Annual Review of Statistics and Its Application</article-title>. <source>Annual Reviews</source>; <year>2017</year>;<volume>4</volume>: <fpage>109</fpage>&#x02013;<lpage>122</lpage>. <pub-id pub-id-type="doi">10.1146/annurev-statistics-060116-054104</pub-id></mixed-citation></ref><ref id="pbio.3000070.ref002"><label>2</label><mixed-citation publication-type="journal"><name><surname>Baker</surname><given-names>M</given-names></name>. <article-title>1,500 scientists lift the lid on reproducibility</article-title>. <source>Nature</source>. <year>2016</year>;<volume>533</volume>: <fpage>452</fpage>&#x02013;<lpage>4</lpage>. <pub-id pub-id-type="doi">10.1038/533452a</pub-id>
<?supplied-pmid 27225100?><pub-id pub-id-type="pmid">27225100</pub-id></mixed-citation></ref><ref id="pbio.3000070.ref003"><label>3</label><mixed-citation publication-type="journal"><name><surname>Stark</surname><given-names>PB</given-names></name>. <article-title>Before reproducibility must come preproducibility</article-title>. <source>Nature</source>. Springer Nature; <year>2018</year>;<volume>557</volume>: <fpage>613</fpage>&#x02013;<lpage>613</lpage>. <pub-id pub-id-type="doi">10.1038/d41586-018-05256-0</pub-id>
<?supplied-pmid 29795524?><pub-id pub-id-type="pmid">29795524</pub-id></mixed-citation></ref><ref id="pbio.3000070.ref004"><label>4</label><mixed-citation publication-type="journal"><name><surname>Fan</surname><given-names>J</given-names></name>, <name><surname>Han</surname><given-names>F</given-names></name>, <name><surname>Liu</surname><given-names>H</given-names></name>. <article-title>Challenges of Big Data analysis</article-title>. <source>National Science Review</source>. Oxford University Press (OUP); <year>2014</year>;<volume>1</volume>: <fpage>293</fpage>&#x02013;<lpage>314</lpage>. <pub-id pub-id-type="doi">10.1093/nsr/nwt032</pub-id>
<?supplied-pmid 25419469?><pub-id pub-id-type="pmid">25419469</pub-id></mixed-citation></ref><ref id="pbio.3000070.ref005"><label>5</label><mixed-citation publication-type="journal"><name><surname>Mekel-Bobrov</surname><given-names>N</given-names></name>. <article-title>Ongoing Adaptive Evolution of ASPM a Brain Size Determinant in Homo sapiens</article-title>. <source>Science</source>. American Association for the Advancement of Science (AAAS); <year>2005</year>;<volume>309</volume>: <fpage>1720</fpage>&#x02013;<lpage>1722</lpage>. <pub-id pub-id-type="doi">10.1126/science.1116815</pub-id>
<?supplied-pmid 16151010?><pub-id pub-id-type="pmid">16151010</pub-id></mixed-citation></ref><ref id="pbio.3000070.ref006"><label>6</label><mixed-citation publication-type="journal"><name><surname>Evans</surname><given-names>PD</given-names></name>. <article-title>Microcephalin a Gene Regulating Brain Size, Continues to Evolve Adaptively in Humans</article-title>. <source>Science</source>. American Association for the Advancement of Science (AAAS); <year>2005</year>;<volume>309</volume>: <fpage>1717</fpage>&#x02013;<lpage>1720</lpage>. <pub-id pub-id-type="doi">10.1126/science.1113722</pub-id>
<?supplied-pmid 16151009?><pub-id pub-id-type="pmid">16151009</pub-id></mixed-citation></ref><ref id="pbio.3000070.ref007"><label>7</label><mixed-citation publication-type="journal"><name><surname>Currat</surname><given-names>M</given-names></name>. <article-title>Comment on Ongoing Adaptive Evolution of ASPM a Brain Size Determinant in Homo sapiens and Microcephalin a Gene Regulating Brain Size, Continues to Evolve Adaptively in Humans</article-title>. <source>Science</source>. American Association for the Advancement of Science (AAAS); <year>2006</year>;<volume>313</volume>: <fpage>172a</fpage>&#x02013;<lpage>172a</lpage>. <pub-id pub-id-type="doi">10.1126/science.1122712</pub-id>
<?supplied-pmid 16840683?><pub-id pub-id-type="pmid">16840683</pub-id></mixed-citation></ref><ref id="pbio.3000070.ref008"><label>8</label><mixed-citation publication-type="book"><collab>Bertalanffy Lvon</collab>. <source>General System Theory: Foundations, Development, Applications</source>. <year>1969</year>.</mixed-citation></ref><ref id="pbio.3000070.ref009"><label>9</label><mixed-citation publication-type="journal"><name><surname>Peng</surname><given-names>RD</given-names></name>. <article-title>Reproducible research and Biostatistics</article-title>. <source>Biostatistics</source>. Oxford University Press (OUP); <year>2009</year>;<volume>10</volume>: <fpage>405</fpage>&#x02013;<lpage>408</lpage>. <pub-id pub-id-type="doi">10.1093/biostatistics/kxp014</pub-id>
<?supplied-pmid 19535325?><pub-id pub-id-type="pmid">19535325</pub-id></mixed-citation></ref><ref id="pbio.3000070.ref010"><label>10</label><mixed-citation publication-type="other">Patil P, Peng RD, Leek J. A statistical definition for reproducibility and replicability. BioRxiv 066803 [Preprint]. 2016 [cited 2016 July 29]. Available from: <ext-link ext-link-type="uri" xlink:href="https://www.biorxiv.org/content/early/2016/07/29/066803">https://www.biorxiv.org/content/early/2016/07/29/066803</ext-link></mixed-citation></ref><ref id="pbio.3000070.ref011"><label>11</label><mixed-citation publication-type="other">Davis J, Goadrich M. The relationship between Precision-Recall and ROC curves. Proceedings of the 23rd international conference on Machine learning&#x02014;ICML 06; Pittsburgh, PA, USA. New York: ACM Press; 2006. doi:10.1145/1143844.1143874</mixed-citation></ref><ref id="pbio.3000070.ref012"><label>12</label><mixed-citation publication-type="journal"><name><surname>Chen</surname><given-names>H-S</given-names></name>, <name><surname>Hutter</surname><given-names>CM</given-names></name>, <name><surname>Mechanic</surname><given-names>LE</given-names></name>, <name><surname>Amos</surname><given-names>CI</given-names></name>, <name><surname>Bafna</surname><given-names>V</given-names></name>, <name><surname>Hauser</surname><given-names>ER</given-names></name>, <etal>et al</etal>
<article-title>Genetic Simulation Tools for Post-Genome Wide Association Studies of Complex Diseases</article-title>. <source>Genetic Epidemiology</source>. Wiley; <year>2014</year>;<volume>39</volume>: <fpage>11</fpage>&#x02013;<lpage>19</lpage>. <pub-id pub-id-type="doi">10.1002/gepi.21870</pub-id>
<?supplied-pmid 25371374?><pub-id pub-id-type="pmid">25371374</pub-id></mixed-citation></ref><ref id="pbio.3000070.ref013"><label>13</label><mixed-citation publication-type="journal"><name><surname>Olson</surname><given-names>RS</given-names></name>, <name><surname>La</surname><given-names>CW</given-names></name>, <name><surname>Orzechowski</surname><given-names>P</given-names></name>, <name><surname>Urbanowicz</surname><given-names>RJ</given-names></name>, <name><surname>Moore</surname><given-names>JH</given-names></name>. <article-title>PMLB: a large benchmark suite for machine learning evaluation and comparison</article-title>. <source>BioData Min</source>. <year>2017</year>;<volume>10</volume>: <fpage>36</fpage>
<pub-id pub-id-type="doi">10.1186/s13040-017-0154-4</pub-id>
<?supplied-pmid 29238404?><pub-id pub-id-type="pmid">29238404</pub-id></mixed-citation></ref><ref id="pbio.3000070.ref014"><label>14</label><mixed-citation publication-type="journal"><name><surname>White</surname><given-names>DR</given-names></name>, <name><surname>McDermott</surname><given-names>J</given-names></name>, <name><surname>Castelli</surname><given-names>M</given-names></name>, <name><surname>Manzoni</surname><given-names>L</given-names></name>, <name><surname>Goldman</surname><given-names>BW</given-names></name>, <name><surname>Kronberger</surname><given-names>G</given-names></name>, <etal>et al</etal>
<article-title>Better GP benchmarks: community survey results and proposals</article-title>. <source>Genetic Programming and Evolvable Machines</source>. Springer Nature; <year>2012</year>;<volume>14</volume>: <fpage>3</fpage>&#x02013;<lpage>29</lpage>. <pub-id pub-id-type="doi">10.1007/s10710-012-9177-2</pub-id></mixed-citation></ref><ref id="pbio.3000070.ref015"><label>15</label><mixed-citation publication-type="journal"><name><surname>Peng</surname><given-names>B</given-names></name>, <name><surname>Chen</surname><given-names>H-S</given-names></name>, <name><surname>Mechanic</surname><given-names>LE</given-names></name>, <name><surname>Racine</surname><given-names>B</given-names></name>, <name><surname>Clarke</surname><given-names>J</given-names></name>, <name><surname>Gillanders</surname><given-names>E</given-names></name>, <etal>et al</etal>
<article-title>Genetic Data Simulators and their Applications: An Overview</article-title>. <source>Genetic Epidemiology</source>. Wiley; <year>2014</year>;<volume>39</volume>: <fpage>2</fpage>&#x02013;<lpage>10</lpage>. <pub-id pub-id-type="doi">10.1002/gepi.21876</pub-id>
<?supplied-pmid 25504286?><pub-id pub-id-type="pmid">25504286</pub-id></mixed-citation></ref><ref id="pbio.3000070.ref016"><label>16</label><mixed-citation publication-type="journal"><name><surname>Elith</surname><given-names>J</given-names></name>, <name><surname>Graham</surname><given-names>CH</given-names></name>, <name><surname>Anderson</surname><given-names>RP</given-names></name>, <name><surname>Dud&#x000ed;k</surname><given-names>M</given-names></name>, <name><surname>Ferrier</surname><given-names>S</given-names></name>, <name><surname>Guisan</surname><given-names>A</given-names></name>, <etal>et al</etal>
<article-title>Novel methods improve prediction of species&#x02019; distributions from occurrence data</article-title>. <source>Ecography</source>. Wiley; <year>2006</year>;<volume>29</volume>: <fpage>129</fpage>&#x02013;<lpage>151</lpage>. <pub-id pub-id-type="doi">10.1111/j.2006.0906&#x02013;7590.04596.x</pub-id></mixed-citation></ref><ref id="pbio.3000070.ref017"><label>17</label><mixed-citation publication-type="journal"><name><surname>Phillips</surname><given-names>SJ</given-names></name>, <name><surname>Anderson</surname><given-names>RP</given-names></name>, <name><surname>Schapire</surname><given-names>RE</given-names></name>. <article-title>Maximum entropy modeling of species geographic distributions</article-title>. <source>Ecological Modelling</source>. Elsevier BV; <year>2006</year>;<volume>190</volume>: <fpage>231</fpage>&#x02013;<lpage>259</lpage>. <pub-id pub-id-type="doi">10.1016/j.ecolmodel.2005.03.026</pub-id></mixed-citation></ref><ref id="pbio.3000070.ref018"><label>18</label><mixed-citation publication-type="journal"><name><surname>Lewontin</surname><given-names>RC</given-names></name>, <name><surname>Krakauer</surname><given-names>J</given-names></name>. <article-title>Distribution of gene frequency as a test of the theory of the selective neutrality of polymorphisms</article-title>. <source>Genetics</source>. <year>1973</year>;<volume>74</volume>: <fpage>175</fpage>&#x02013;<lpage>95</lpage>. <?supplied-pmid 4711903?><pub-id pub-id-type="pmid">4711903</pub-id></mixed-citation></ref><ref id="pbio.3000070.ref019"><label>19</label><mixed-citation publication-type="journal"><name><surname>Lewontin</surname><given-names>RC</given-names></name>, <name><surname>Krakauer</surname><given-names>J</given-names></name>. <article-title>Letters to the editors: Testing the heterogeneity of F values</article-title>. <source>Genetics</source>. <year>1975</year>;<volume>80</volume>: <fpage>397</fpage>&#x02013;<lpage>8</lpage>. <?supplied-pmid 1132692?><pub-id pub-id-type="pmid">1132692</pub-id></mixed-citation></ref><ref id="pbio.3000070.ref020"><label>20</label><mixed-citation publication-type="journal"><name><surname>Robertson</surname><given-names>A</given-names></name>. <article-title>Letters to the editors: Remarks on the Lewontin-Krakauer test</article-title>. <source>Genetics</source>. <year>1975</year>;<volume>80</volume>: <fpage>396</fpage>
<?supplied-pmid 1132691?><pub-id pub-id-type="pmid">1132691</pub-id></mixed-citation></ref><ref id="pbio.3000070.ref021"><label>21</label><mixed-citation publication-type="journal"><name><surname>Nei</surname><given-names>M</given-names></name>, <name><surname>Maruyama</surname><given-names>T</given-names></name>. <article-title>Letters to the editors: Lewontin-Krakauer test for neutral genes</article-title>. <source>Genetics</source>. <year>1975</year>;<volume>80</volume>: <fpage>395</fpage>
<?supplied-pmid 1132690?><pub-id pub-id-type="pmid">1132690</pub-id></mixed-citation></ref><ref id="pbio.3000070.ref022"><label>22</label><mixed-citation publication-type="journal"><name><surname>Beaumont</surname><given-names>MA</given-names></name>, <name><surname>Nichols</surname><given-names>RA</given-names></name>. <article-title>Evaluating Loci for Use in the Genetic Analysis of Population Structure</article-title>. <source>Proceedings of the Royal Society B: Biological Sciences</source>. The Royal Society; <year>1996</year>;<volume>263</volume>: <fpage>1619</fpage>&#x02013;<lpage>1626</lpage>. <pub-id pub-id-type="doi">10.1098/rspb.1996.0237</pub-id></mixed-citation></ref><ref id="pbio.3000070.ref023"><label>23</label><mixed-citation publication-type="journal"><name><surname>Lotterhos</surname><given-names>KE</given-names></name>, <name><surname>Whitlock</surname><given-names>MC</given-names></name>. <article-title>Evaluation of demographic history and neutral parameterization on the performance of FSToutlier tests</article-title>. <source>Molecular Ecology</source>. Wiley; <year>2014</year>;<volume>23</volume>: <fpage>2178</fpage>&#x02013;<lpage>2192</lpage>. <pub-id pub-id-type="doi">10.1111/mec.12725</pub-id>
<?supplied-pmid 24655127?><pub-id pub-id-type="pmid">24655127</pub-id></mixed-citation></ref><ref id="pbio.3000070.ref024"><label>24</label><mixed-citation publication-type="journal"><name><surname>Whitlock</surname><given-names>MC</given-names></name>, <name><surname>Lotterhos</surname><given-names>KE</given-names></name>. <article-title>Reliable Detection of Loci Responsible for Local Adaptation: Inference of a Null Model through Trimming the Distribution of FST</article-title>. <source>The American Naturalist</source>. University of Chicago Press; <year>2015</year>;<volume>186</volume>: <fpage>S24</fpage>&#x02013;<lpage>S36</lpage>. <pub-id pub-id-type="doi">10.1086/682949</pub-id>
<?supplied-pmid 26656214?><pub-id pub-id-type="pmid">26656214</pub-id></mixed-citation></ref><ref id="pbio.3000070.ref025"><label>25</label><mixed-citation publication-type="journal"><name><surname>Luu</surname><given-names>K</given-names></name>, <name><surname>Bazin</surname><given-names>E</given-names></name>, <name><surname>Blum</surname><given-names>MGB</given-names></name>. <article-title>pcadapt: an R package to perform genome scans for selection based on principal component analysis</article-title>. <source>Mol Ecol Resour</source>. <year>2017</year>;<volume>17</volume>(<issue>1</issue>):<fpage>67</fpage>&#x02013;<lpage>77</lpage>. Epub 2016 Sep 7. <pub-id pub-id-type="doi">10.1111/1755-0998.12592</pub-id>
<?supplied-pmid 27601374?><pub-id pub-id-type="pmid">27601374</pub-id></mixed-citation></ref><ref id="pbio.3000070.ref026"><label>26</label><mixed-citation publication-type="journal"><name><surname>Gautier</surname><given-names>M</given-names></name>. <article-title>Genome-Wide Scan for Adaptive Divergence and Association with Population-Specific Covariates</article-title>. <source>Genetics</source>. <year>2015</year>
<month>12</month>;<volume>201</volume>(<issue>4</issue>):<fpage>1555</fpage>&#x02013;<lpage>79</lpage>. Epub 2015 Oct 19. <pub-id pub-id-type="doi">10.1534/genetics.115.181453</pub-id>
<?supplied-pmid 26482796?><pub-id pub-id-type="pmid">26482796</pub-id></mixed-citation></ref><ref id="pbio.3000070.ref027"><label>27</label><mixed-citation publication-type="journal"><name><surname>Fariello</surname><given-names>MI</given-names></name>, <name><surname>Boitard</surname><given-names>S</given-names></name>, <name><surname>Naya</surname><given-names>H</given-names></name>, <name><surname>SanCristobal</surname><given-names>M</given-names></name>, <name><surname>Servin</surname><given-names>B</given-names></name>. <article-title>Detecting Signatures of Selection Through Haplotype Differentiation Among Hierarchically Structured Populations</article-title>. <source>Genetics</source>. Genetics Society of America; <year>2013</year>;<volume>193</volume>: <fpage>929</fpage>&#x02013;<lpage>941</lpage>. <pub-id pub-id-type="doi">10.1534/genetics.112.147231</pub-id>
<?supplied-pmid 23307896?><pub-id pub-id-type="pmid">23307896</pub-id></mixed-citation></ref><ref id="pbio.3000070.ref028"><label>28</label><mixed-citation publication-type="journal"><name><surname>Messer</surname><given-names>PW</given-names></name>. <article-title>SLiM: Simulating Evolution with Selection and Linkage</article-title>. <source>Genetics</source>. Genetics Society of America; <year>2013</year>;<volume>194</volume>: <fpage>1037</fpage>&#x02013;<lpage>1039</lpage>. <pub-id pub-id-type="doi">10.1534/genetics.113.152181</pub-id>
<?supplied-pmid 23709637?><pub-id pub-id-type="pmid">23709637</pub-id></mixed-citation></ref><ref id="pbio.3000070.ref029"><label>29</label><mixed-citation publication-type="journal"><name><surname>Peng</surname><given-names>B</given-names></name>, <name><surname>Kimmel</surname><given-names>M</given-names></name>. <article-title>simuPOP: a forward-time population genetics simulation environment</article-title>. <source>Bioinformatics</source>. Oxford University Press (OUP); <year>2005</year>;<volume>21</volume>: <fpage>3686</fpage>&#x02013;<lpage>3687</lpage>. <pub-id pub-id-type="doi">10.1093/bioinformatics/bti584</pub-id>
<?supplied-pmid 16020469?><pub-id pub-id-type="pmid">16020469</pub-id></mixed-citation></ref><ref id="pbio.3000070.ref030"><label>30</label><mixed-citation publication-type="journal"><name><surname>Escalona</surname><given-names>M</given-names></name>, <name><surname>Rocha</surname><given-names>S</given-names></name>, <name><surname>Posada</surname><given-names>D</given-names></name>. <article-title>A comparison of tools for the simulation of genomic next-generation sequencing data</article-title>. <source>Nature Reviews Genetics</source>. Springer Nature; <year>2016</year>;<volume>17</volume>: <fpage>459</fpage>&#x02013;<lpage>469</lpage>. <pub-id pub-id-type="doi">10.1038/nrg.2016.57</pub-id>
<?supplied-pmid 27320129?><pub-id pub-id-type="pmid">27320129</pub-id></mixed-citation></ref><ref id="pbio.3000070.ref031"><label>31</label><mixed-citation publication-type="journal"><name><surname>Hirschhorn</surname><given-names>JN</given-names></name>, <name><surname>Daly</surname><given-names>MJ</given-names></name>. <article-title>Genome-wide association studies for common diseases and complex traits</article-title>. <source>Nat Rev Genet</source>. <year>2005</year>;<volume>6</volume>: <fpage>95</fpage>&#x02013;<lpage>108</lpage>. <pub-id pub-id-type="doi">10.1038/nrg1521</pub-id>
<?supplied-pmid 15716906?><pub-id pub-id-type="pmid">15716906</pub-id></mixed-citation></ref><ref id="pbio.3000070.ref032"><label>32</label><mixed-citation publication-type="journal"><name><surname>Wang</surname><given-names>WYS</given-names></name>, <name><surname>Barratt</surname><given-names>BJ</given-names></name>, <name><surname>Clayton</surname><given-names>DG</given-names></name>, <name><surname>Todd</surname><given-names>JA</given-names></name>. <article-title>Genome-wide association studies: theoretical and practical concerns</article-title>. <source>Nature Reviews Genetics</source>. Springer Nature; <year>2005</year>;<volume>6</volume>: <fpage>109</fpage>&#x02013;<lpage>118</lpage>. <pub-id pub-id-type="doi">10.1038/nrg1522</pub-id>
<?supplied-pmid 15716907?><pub-id pub-id-type="pmid">15716907</pub-id></mixed-citation></ref><ref id="pbio.3000070.ref033"><label>33</label><mixed-citation publication-type="journal"><name><surname>Visscher</surname><given-names>PM</given-names></name>, <name><surname>Wray</surname><given-names>NR</given-names></name>, <name><surname>Zhang</surname><given-names>Q</given-names></name>, <name><surname>Sklar</surname><given-names>P</given-names></name>, <name><surname>McCarthy</surname><given-names>MI</given-names></name>, <name><surname>Brown</surname><given-names>MA</given-names></name>, <etal>et al</etal>
<article-title>10 Years of GWAS Discovery: Biology, Function, and Translation</article-title>. <source>Am J Hum Genet</source>. <year>2017</year>;<volume>101</volume>: <fpage>5</fpage>&#x02013;<lpage>22</lpage>. <pub-id pub-id-type="doi">10.1016/j.ajhg.2017.06.005</pub-id>
<?supplied-pmid 28686856?><pub-id pub-id-type="pmid">28686856</pub-id></mixed-citation></ref><ref id="pbio.3000070.ref034"><label>34</label><mixed-citation publication-type="journal"><name><surname>Sanjak</surname><given-names>J</given-names></name>, <name><surname>Long</surname><given-names>AD</given-names></name>, <name><surname>Thornton</surname><given-names>KR</given-names></name>. <article-title>A model of compound heterozygous loss-of-function alleles is broadly consistent with observations from complex-disease GWAS datasets</article-title>. <source>PLoS Genet</source>. <year>2017</year>
<month>1</month>
<day>19</day>;<volume>13</volume>(<issue>1</issue>):<fpage>e1006573</fpage>
<pub-id pub-id-type="doi">10.1371/journal.pgen.1006573</pub-id>
<?supplied-pmid 28103232?><pub-id pub-id-type="pmid">28103232</pub-id></mixed-citation></ref><ref id="pbio.3000070.ref035"><label>35</label><mixed-citation publication-type="journal"><name><surname>Keaser</surname><given-names>C</given-names></name>, <name><surname>McGuffin</surname><given-names>LJ</given-names></name>, <name><surname>Wallner</surname><given-names>B</given-names></name>, <name><surname>Chopra</surname><given-names>G</given-names></name>, <name><surname>Adhikari</surname><given-names>B</given-names></name>, <name><surname>Bhattacharya</surname><given-names>D</given-names></name>, <etal>et al</etal>
<article-title>An analysis and evaluation of the WeFold collaborative for protein structure prediction and its pipelines in CASP11 and CASP12</article-title>. <source>Scientific Reports</source>. <year>2018</year>;<volume>8</volume>:<fpage>9939</fpage>
<pub-id pub-id-type="doi">10.1038/s41598-018-26812-8</pub-id> Available from: <ext-link ext-link-type="uri" xlink:href="https://www.nature.com/articles/s41598-018-26812-8">https://www.nature.com/articles/s41598-018-26812-8</ext-link>. <?supplied-pmid 29967418?><pub-id pub-id-type="pmid">29967418</pub-id></mixed-citation></ref><ref id="pbio.3000070.ref036"><label>36</label><mixed-citation publication-type="journal"><name><surname>Fitzpatrick</surname><given-names>MC</given-names></name>, <name><surname>Keller</surname><given-names>SR</given-names></name>, <name><surname>Lotterhos</surname><given-names>KE</given-names></name>. <article-title>Comment on &#x0201c;Genomic signals of selection predict climate-driven population declines in a migratory bird&#x0201d;</article-title>. <source>Science</source>. <ext-link ext-link-type="uri" xlink:href="http://science.sciencemag.org/content/361/6401/eaat7279/tab-article-info">http://science.sciencemag.org/content/361/6401/eaat7279/tab-article-info</ext-link>; <year>2018</year>;<volume>361</volume> Retrieved: <ext-link ext-link-type="uri" xlink:href="http://science.sciencemag.org/content/361/6401/eaat7279">http://science.sciencemag.org/content/361/6401/eaat7279</ext-link></mixed-citation></ref><ref id="pbio.3000070.ref037"><label>37</label><mixed-citation publication-type="book"><name><surname>Colon-Berlingeri</surname><given-names>M</given-names></name>, <name><surname>Burrowes</surname><given-names>PA</given-names></name>. <chapter-title>Teaching Biology through Statistics: Application of Statistical Methods in Genetics and Zoology Courses</chapter-title>
<name><surname>Jungck</surname><given-names>JR</given-names></name>, editor. <source>CBELife Sciences Education</source>. <publisher-name>American Society for Cell Biology (ASCB)</publisher-name>; <year>2011</year>;<volume>10</volume>: <fpage>259</fpage>&#x02013;<lpage>267</lpage>. <pub-id pub-id-type="doi">10.1187/cbe.10-11-0137</pub-id></mixed-citation></ref></ref-list></back></article>